{
  "type": "pull",
  "pull": {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545",
    "id": 2526397126,
    "node_id": "PR_kwDOABII586WlcLG",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/32545",
    "diff_url": "https://github.com/bitcoin/bitcoin/pull/32545.diff",
    "patch_url": "https://github.com/bitcoin/bitcoin/pull/32545.patch",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545",
    "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545/commits",
    "review_comments_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545/comments",
    "review_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments%7B/number%7D",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545/comments",
    "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/75bdb925f404f41874adf0fcefca0f1641fcb4e6",
    "number": 32545,
    "state": "closed",
    "locked": false,
    "maintainer_can_modify": false,
    "title": "Replace cluster linearization algorithm with SFL",
    "user": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
      "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
      "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false,
      "name": null,
      "patch_url": null
    },
    "body": "Part of cluster mempool: #30289.\r\n\r\nThis replaces the cluster linearization algorithm introduced in #30126 and #30286 (a combination of LIMO with candidate-set search), with a completely different algorithm: [spanning-forest linearization](https://delvingbitcoin.org/t/spanning-forest-cluster-linearization/1419/1), which appears to have much better performance for hard clusters. See [this post](https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303/68) for a comparison between various linearization algorithms, and [this post](https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303/73) for benchmarks comparing them. Replaying historical mempool data on it shows that it can effectively linearize every observed cluster up to 64 transactions optimally within tens of microseconds, though pathological examples can be created which take longer.\r\n\r\nThe algorithm is effectively a very specialized version of the [simplex algorithm](https://en.wikipedia.org/wiki/Simplex_algorithm) to the problem of finding high-feerate topological subsets of clusters, but modified to find all consecutive such subsets concurrently rather than just the first one. See the post above for how it is related.\r\n\r\nIt represents the cluster as partitioned into a set of chunks, each with a spanning tree of its internal dependencies connecting the transactions. Randomized improvements are made by selecting dependencies to add and remove to these spanning trees, merging and splitting chunks, until no more improvements are possible, or a computation budget is reached. Like simplex, it does not necessarily make progress in every step, and thus has no upper bound on its runtime to find optimal, but randomization makes long runtimes very unlikely, and additionally makes it hard to adversarially construct clusters in which the algorithm reliably makes bad choices.\r\n\r\n",
    "labels": [
      {
        "id": 164208572,
        "node_id": "MDU6TGFiZWwxNjQyMDg1NzI=",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/Mempool",
        "name": "Mempool",
        "color": "fef2c0",
        "default": false
      }
    ],
    "milestone": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/milestones/74",
      "html_url": "https://github.com/bitcoin/bitcoin/milestone/74",
      "labels_url": "https://api.github.com/repos/bitcoin/bitcoin/milestones/74/labels",
      "id": 12610874,
      "node_id": "MI_kwDOABII584AwG06",
      "number": 74,
      "state": "open",
      "title": "31.0",
      "creator": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "open_issues": 13,
      "closed_issues": 20,
      "created_at": "2025-03-25T18:44:16Z",
      "updated_at": "2025-12-19T15:14:54Z"
    },
    "created_at": "2025-05-17T23:24:56Z",
    "updated_at": "2025-12-19T15:14:54Z",
    "closed_at": "2025-12-19T15:14:54Z",
    "mergeable_state": "unknown",
    "merged": true,
    "merged_at": "2025-12-19T15:14:54Z",
    "merged_by": {
      "login": "fanquake",
      "id": 863730,
      "node_id": "MDQ6VXNlcjg2MzczMA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fanquake",
      "html_url": "https://github.com/fanquake",
      "followers_url": "https://api.github.com/users/fanquake/followers",
      "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
      "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
      "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
      "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
      "organizations_url": "https://api.github.com/users/fanquake/orgs",
      "repos_url": "https://api.github.com/users/fanquake/repos",
      "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
      "received_events_url": "https://api.github.com/users/fanquake/received_events",
      "type": "User",
      "site_admin": false,
      "name": null,
      "patch_url": null
    },
    "merge_commit_sha": "0c862bc7ea2832f459233046518740613a177993",
    "assignees": [],
    "requested_reviewers": [
      {
        "login": "jonatack",
        "id": 2415484,
        "node_id": "MDQ6VXNlcjI0MTU0ODQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2415484?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jonatack",
        "html_url": "https://github.com/jonatack",
        "followers_url": "https://api.github.com/users/jonatack/followers",
        "following_url": "https://api.github.com/users/jonatack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jonatack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jonatack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jonatack/subscriptions",
        "organizations_url": "https://api.github.com/users/jonatack/orgs",
        "repos_url": "https://api.github.com/users/jonatack/repos",
        "events_url": "https://api.github.com/users/jonatack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jonatack/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    ],
    "requested_teams": [],
    "head": {
      "label": "sipa:202505_sfl",
      "ref": "202505_sfl",
      "sha": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "repo": {
        "id": 1458655,
        "node_id": "MDEwOlJlcG9zaXRvcnkxNDU4NjU1",
        "name": "bitcoin",
        "full_name": "sipa/bitcoin",
        "owner": {
          "login": "sipa",
          "id": 548488,
          "node_id": "MDQ6VXNlcjU0ODQ4OA==",
          "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/sipa",
          "html_url": "https://github.com/sipa",
          "followers_url": "https://api.github.com/users/sipa/followers",
          "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
          "organizations_url": "https://api.github.com/users/sipa/orgs",
          "repos_url": "https://api.github.com/users/sipa/repos",
          "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/sipa/received_events",
          "type": "User",
          "site_admin": false,
          "name": null,
          "patch_url": null
        },
        "private": false,
        "html_url": "https://github.com/sipa/bitcoin",
        "description": "Bitcoin integration/staging tree",
        "fork": true,
        "url": "https://api.github.com/repos/sipa/bitcoin",
        "archive_url": "https://api.github.com/repos/sipa/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/sipa/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/sipa/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/sipa/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/sipa/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/sipa/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/sipa/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/sipa/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/sipa/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/sipa/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/sipa/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/sipa/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/sipa/bitcoin/events",
        "forks_url": "https://api.github.com/repos/sipa/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/sipa/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/sipa/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/sipa/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/sipa/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/sipa/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/sipa/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/sipa/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/sipa/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/sipa/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/sipa/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/sipa/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/sipa/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/sipa/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/sipa/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/sipa/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:sipa/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/sipa/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/sipa/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/sipa/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/sipa/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/sipa/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/sipa/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/sipa/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/sipa/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/sipa/bitcoin/hooks",
        "svn_url": "https://github.com/sipa/bitcoin",
        "homepage": "http://www.bitcoin.org",
        "language": "TypeScript",
        "forks_count": 22,
        "stargazers_count": 90,
        "watchers_count": 90,
        "size": 283558,
        "default_branch": "lows",
        "open_issues_count": 16,
        "is_template": false,
        "topics": [],
        "has_issues": true,
        "has_projects": true,
        "has_wiki": true,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2025-12-19T15:29:36Z",
        "created_at": "2011-03-09T10:46:59Z",
        "updated_at": "2025-10-27T19:08:35Z",
        "allow_forking": true,
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "base": {
      "label": "bitcoin:master",
      "ref": "master",
      "sha": "516ae5ede44a8a6abc59e90f9d89913e254524f4",
      "user": {
        "login": "bitcoin",
        "id": 528860,
        "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/bitcoin",
        "html_url": "https://github.com/bitcoin",
        "followers_url": "https://api.github.com/users/bitcoin/followers",
        "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
        "organizations_url": "https://api.github.com/users/bitcoin/orgs",
        "repos_url": "https://api.github.com/users/bitcoin/repos",
        "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/bitcoin/received_events",
        "type": "Organization",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "repo": {
        "id": 1181927,
        "node_id": "MDEwOlJlcG9zaXRvcnkxMTgxOTI3",
        "name": "bitcoin",
        "full_name": "bitcoin/bitcoin",
        "owner": {
          "login": "bitcoin",
          "id": 528860,
          "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
          "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/bitcoin",
          "html_url": "https://github.com/bitcoin",
          "followers_url": "https://api.github.com/users/bitcoin/followers",
          "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
          "organizations_url": "https://api.github.com/users/bitcoin/orgs",
          "repos_url": "https://api.github.com/users/bitcoin/repos",
          "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/bitcoin/received_events",
          "type": "Organization",
          "site_admin": false,
          "name": null,
          "patch_url": null
        },
        "private": false,
        "html_url": "https://github.com/bitcoin/bitcoin",
        "description": "Bitcoin Core integration/staging tree",
        "fork": false,
        "url": "https://api.github.com/repos/bitcoin/bitcoin",
        "archive_url": "https://api.github.com/repos/bitcoin/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/bitcoin/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/bitcoin/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/bitcoin/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/bitcoin/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/bitcoin/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/bitcoin/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/bitcoin/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/bitcoin/bitcoin/events",
        "forks_url": "https://api.github.com/repos/bitcoin/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/bitcoin/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/bitcoin/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/bitcoin/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/bitcoin/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/bitcoin/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/bitcoin/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/bitcoin/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/bitcoin/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/bitcoin/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/bitcoin/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:bitcoin/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/bitcoin/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/bitcoin/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/bitcoin/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/bitcoin/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/bitcoin/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/bitcoin/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/bitcoin/bitcoin/hooks",
        "svn_url": "https://github.com/bitcoin/bitcoin",
        "homepage": "https://bitcoincore.org/en/download",
        "language": "C++",
        "forks_count": 38374,
        "stargazers_count": 87285,
        "watchers_count": 87285,
        "size": 300582,
        "default_branch": "master",
        "open_issues_count": 721,
        "is_template": false,
        "topics": [
          "bitcoin",
          "c-plus-plus",
          "cryptocurrency",
          "cryptography",
          "p2p"
        ],
        "has_issues": true,
        "has_projects": true,
        "has_wiki": false,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2025-12-19T15:55:30Z",
        "created_at": "2010-12-19T15:16:43Z",
        "updated_at": "2025-12-19T15:55:40Z",
        "allow_forking": true,
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
      }
    },
    "author_association": "MEMBER",
    "draft": false,
    "additions": 1436,
    "deletions": 1416,
    "changed_files": 8,
    "commits": 11,
    "review_comments": 88,
    "comments": 44
  },
  "events": [
    {
      "event": "commented",
      "id": 2888635107,
      "node_id": "IC_kwDOABII586sLRLj",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2888635107",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-17T23:24:59Z",
      "updated_at": "2025-12-19T14:33:18Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/32545.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [instagibbs](https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3675255338), [marcofleon](https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3675295963) |\n| Concept ACK | [jonatack](https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-2861830018) |\n\nIf your review is incorrectly listed, please copy-paste <code>&lt;!--meta-tag:bot-skip--&gt;</code> into the comment that the bot should ignore.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#34085](https://github.com/bitcoin/bitcoin/pull/34085) (cluster mempool: exploit SFL properties in txgraph by sipa)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2888635107",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17700679932,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQfCvD8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17700679932",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "2fb6a0efbebb9f0a5f75f8ad252df21ea2b4871c",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/2fb6a0efbebb9f0a5f75f8ad252df21ea2b4871c",
      "created_at": "2025-05-17T23:38:28Z"
    },
    {
      "event": "labeled",
      "id": 17700682965,
      "node_id": "LE_lADOABII5863DfgAzwAAAAQfCvzV",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17700682965",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-17T23:39:59Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2888640225,
      "node_id": "IC_kwDOABII586sLSbh",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2888640225",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-17T23:40:01Z",
      "updated_at": "2025-05-17T23:40:01Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `ARM, unit tests, no functional tests`: https://github.com/bitcoin/bitcoin/runs/42417371062</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is due to a build error during the compilation of `txgraph.cpp.o`.\n</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2888640225",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17701343343,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQfFRBv",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17701343343",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "3b7477b9577d525cbe4cd7207264162773ab512e",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/3b7477b9577d525cbe4cd7207264162773ab512e",
      "created_at": "2025-05-18T02:12:56Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17701379766,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQfFZ62",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17701379766",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "b920e76496fcdc8d5e6922fb800651987807d1ad",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/b920e76496fcdc8d5e6922fb800651987807d1ad",
      "created_at": "2025-05-18T02:20:54Z"
    },
    {
      "event": "unlabeled",
      "id": 17701576368,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAQfGJ6w",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17701576368",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-18T03:16:08Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17704006957,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQfPbUt",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17704006957",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "1c6bb7280c9fd6b95c8afa2552c9c1bfd38d6c01",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/1c6bb7280c9fd6b95c8afa2552c9c1bfd38d6c01",
      "created_at": "2025-05-18T17:01:59Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17706173337,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQfXsOZ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17706173337",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "df589da0772bfb40b08ae62b6332cebaf1ff695d",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/df589da0772bfb40b08ae62b6332cebaf1ff695d",
      "created_at": "2025-05-19T02:54:44Z"
    },
    {
      "event": "labeled",
      "id": 17706483139,
      "node_id": "LE_lADOABII5863DfgAzwAAAAQfY33D",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17706483139",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-19T03:39:16Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2889517252,
      "node_id": "IC_kwDOABII586sOojE",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2889517252",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-19T03:39:17Z",
      "updated_at": "2025-05-19T03:39:17Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `ARM, unit tests, no functional tests`: https://github.com/bitcoin/bitcoin/runs/42447412610</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is due to a failed CTest test: `cluster_linearize_tests`.\n</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2889517252",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17724049198,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQgb4cu",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17724049198",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "7d5e4dcc35e21b56567c030a493db69a8b42da51",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/7d5e4dcc35e21b56567c030a493db69a8b42da51",
      "created_at": "2025-05-20T01:04:04Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17724726802,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQged4S",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17724726802",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "23072f2b0e3201b00db19bf8fcca474f81593c2f",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/23072f2b0e3201b00db19bf8fcca474f81593c2f",
      "created_at": "2025-05-20T02:30:34Z"
    },
    {
      "event": "unlabeled",
      "id": 17725509234,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAQghc5y",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17725509234",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-20T04:06:05Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "labeled",
      "id": 17732902990,
      "node_id": "LE_lADOABII5863DfgAzwAAAAQg9qBO",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17732902990",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-20T11:59:43Z",
      "label": {
        "name": "Mempool",
        "color": "fef2c0"
      }
    },
    {
      "event": "reviewed",
      "id": 2861830018,
      "node_id": "PRR_kwDOABII586qlA-C",
      "url": null,
      "actor": null,
      "commit_id": "23072f2b0e3201b00db19bf8fcca474f81593c2f",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-05-22T16:09:36Z",
      "author_association": "MEMBER",
      "body": "Concept ACK",
      "user": {
        "login": "jonatack",
        "id": 2415484,
        "node_id": "MDQ6VXNlcjI0MTU0ODQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2415484?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jonatack",
        "html_url": "https://github.com/jonatack",
        "followers_url": "https://api.github.com/users/jonatack/followers",
        "following_url": "https://api.github.com/users/jonatack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jonatack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jonatack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jonatack/subscriptions",
        "organizations_url": "https://api.github.com/users/jonatack/orgs",
        "repos_url": "https://api.github.com/users/jonatack/repos",
        "events_url": "https://api.github.com/users/jonatack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jonatack/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-2861830018",
      "submitted_at": "2025-05-22T16:09:36Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17789642375,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQkWGaH",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17789642375",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "d7ff8026dc5369798d7926f84dec65ca28fb4b19",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/d7ff8026dc5369798d7926f84dec65ca28fb4b19",
      "created_at": "2025-05-23T12:56:39Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17794433014,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQkoX_2",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17794433014",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "d2579527cf6208d81f5037ec55e95cd51ac1b76c",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/d2579527cf6208d81f5037ec55e95cd51ac1b76c",
      "created_at": "2025-05-23T18:06:10Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17801605719,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQlDvJX",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17801605719",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "7fff93160a7d5de2041b87cba9c34dd2304b3d32",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/7fff93160a7d5de2041b87cba9c34dd2304b3d32",
      "created_at": "2025-05-24T21:36:45Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17804834589,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQlQDcd",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17804834589",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "9ee20caf42fe663192e3a6050cca04dcfcd88389",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/9ee20caf42fe663192e3a6050cca04dcfcd88389",
      "created_at": "2025-05-25T16:18:16Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17804895885,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQlQSaN",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17804895885",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "ba7464a8645bf9c9567e50b77a7f2929544b353d",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/ba7464a8645bf9c9567e50b77a7f2929544b353d",
      "created_at": "2025-05-25T16:43:01Z"
    },
    {
      "event": "labeled",
      "id": 17804900083,
      "node_id": "LE_lADOABII5863DfgAzwAAAAQlQTbz",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17804900083",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-25T16:44:43Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2907936831,
      "node_id": "IC_kwDOABII586tU5g_",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2907936831",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-25T16:44:44Z",
      "updated_at": "2025-05-25T16:44:44Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `CentOS, depends, gui`: https://github.com/bitcoin/bitcoin/runs/42858330826</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is due to assertion failures within the `cluster_linearize_tests` and `bench_sanity_check` tests.\n</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2907936831",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "unlabeled",
      "id": 17805031142,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAQlQzbm",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17805031142",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-25T17:37:47Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17805204066,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQlRdpi",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17805204066",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "90b72d5115c35a0ece9600d50ffa50971c012940",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/90b72d5115c35a0ece9600d50ffa50971c012940",
      "created_at": "2025-05-25T18:50:10Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17805253947,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQlRp07",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17805253947",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "55931c3cddee570d1740713760493dce654b6d34",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/55931c3cddee570d1740713760493dce654b6d34",
      "created_at": "2025-05-25T19:10:18Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17852589338,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQoGOUa",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17852589338",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "47bdf8faafc550bf673b4affadc73415160f9ff2",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/47bdf8faafc550bf673b4affadc73415160f9ff2",
      "created_at": "2025-05-28T14:43:19Z"
    },
    {
      "event": "commented",
      "id": 2916658444,
      "node_id": "IC_kwDOABII586t2K0M",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2916658444",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-28T14:57:08Z",
      "updated_at": "2025-05-29T23:37:52Z",
      "author_association": "MEMBER",
      "body": "I'm interested in seeing benchmarks of this on various systems, especially high-end/modern ones (as their performance is likely most predictive of what future hardware will be like).\r\n\r\n```\r\n./build_dev_mode/bin/bench_bitcoin --filter=\"Linearize.*Example.*\" -min-time=10000\r\n```\r\n\r\nHere are some I have gathered:\r\n\r\n<details>\r\n<summary><b>AMD Ryzen 9 5950X 16-Core Processor</b></summary>\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                1.68 |      595,052,476.10 |    0.4% |     11.01 | `LinearizeBoundedExample0`\r\n|                1.92 |      521,264,873.78 |    0.1% |     11.01 | `LinearizeBoundedExample1`\r\n|                1.79 |      557,860,504.16 |    0.3% |     10.58 | `LinearizeBoundedExample2`\r\n|                1.89 |      528,599,597.23 |    0.1% |     10.97 | `LinearizeBoundedExample3`\r\n|                1.81 |      552,507,201.82 |    0.4% |     10.81 | `LinearizeBoundedExample4`\r\n|                1.97 |      508,721,677.18 |    1.0% |     11.05 | `LinearizeBoundedExample5`\r\n|                1.89 |      528,912,231.85 |    0.4% |     11.06 | `LinearizeBoundedExample6`\r\n|                1.79 |      557,221,394.89 |    0.8% |     11.01 | `LinearizeBoundedExample7`\r\n|                1.79 |      557,162,554.42 |    0.3% |     11.05 | `LinearizeBoundedExample8`\r\n|                1.84 |      543,573,897.10 |    0.3% |     10.99 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            1,576.22 |          634,428.95 |    0.4% |     10.95 | `LinearizeOptimallyExample00`\r\n|            3,010.14 |          332,209.92 |    0.3% |     10.99 | `LinearizeOptimallyExample01`\r\n|            5,871.01 |          170,328.44 |    0.4% |     11.09 | `LinearizeOptimallyExample02`\r\n|            6,321.90 |          158,180.35 |    0.6% |     10.55 | `LinearizeOptimallyExample03`\r\n|           15,081.30 |           66,307.30 |    0.4% |     10.99 | `LinearizeOptimallyExample04`\r\n|           12,227.15 |           81,785.18 |    0.2% |     11.01 | `LinearizeOptimallyExample05`\r\n|           12,703.52 |           78,718.34 |    0.4% |     11.02 | `LinearizeOptimallyExample06`\r\n|           11,519.71 |           86,807.71 |    0.3% |     11.01 | `LinearizeOptimallyExample07`\r\n|           14,768.84 |           67,710.11 |    0.5% |     10.93 | `LinearizeOptimallyExample08`\r\n|           19,655.67 |           50,875.90 |    0.3% |     11.03 | `LinearizeOptimallyExample09`\r\n|           11,776.61 |           84,914.06 |    0.1% |     10.97 | `LinearizeOptimallyExample10`\r\n|           17,396.59 |           57,482.51 |    0.5% |     10.97 | `LinearizeOptimallyExample11`\r\n|           25,232.95 |           39,630.72 |    0.3% |     11.04 | `LinearizeOptimallyExample12`\r\n|           28,941.27 |           34,552.73 |    0.2% |     10.98 | `LinearizeOptimallyExample13`\r\n|           36,964.92 |           27,052.68 |    0.7% |     11.00 | `LinearizeOptimallyExample14`\r\n|           37,103.54 |           26,951.61 |    0.3% |     11.02 | `LinearizeOptimallyExample15`\r\n|           43,747.38 |           22,858.51 |    0.3% |     10.98 | `LinearizeOptimallyExample16`\r\n|           59,132.17 |           16,911.27 |    0.8% |     11.04 | `LinearizeOptimallyExample17`\r\n|           61,824.04 |           16,174.94 |    0.2% |     10.54 | `LinearizeOptimallyExample18`\r\n|           73,274.33 |           13,647.34 |    0.6% |     10.65 | `LinearizeOptimallyExample19`\r\n\r\n</details>\r\n\r\n<details>\r\n<summary><b>AMD Ryzen Threadripper PRO 7995WX 96-Cores</b></summary>\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                1.31 |      763,277,399.95 |    0.0% |     10.99 | `LinearizeBoundedExample0`\r\n|                1.53 |      652,463,095.02 |    0.1% |     11.00 | `LinearizeBoundedExample1`\r\n|                1.49 |      672,057,837.39 |    0.0% |     11.00 | `LinearizeBoundedExample2`\r\n|                1.66 |      602,362,799.74 |    0.0% |     10.69 | `LinearizeBoundedExample3`\r\n|                1.52 |      656,146,353.18 |    0.1% |     10.71 | `LinearizeBoundedExample4`\r\n|                1.65 |      607,795,039.45 |    0.0% |     10.76 | `LinearizeBoundedExample5`\r\n|                1.59 |      628,108,657.72 |    0.0% |     10.82 | `LinearizeBoundedExample6`\r\n|                1.50 |      668,384,115.59 |    0.1% |     11.00 | `LinearizeBoundedExample7`\r\n|                1.51 |      663,161,838.88 |    0.0% |     11.01 | `LinearizeBoundedExample8`\r\n|                1.53 |      654,682,223.87 |    0.1% |     10.99 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            1,209.24 |          826,967.78 |    0.3% |     10.98 | `LinearizeOptimallyExample00`\r\n|            2,393.97 |          417,716.84 |    0.0% |     11.01 | `LinearizeOptimallyExample01`\r\n|            4,764.63 |          209,879.68 |    0.0% |     11.01 | `LinearizeOptimallyExample02`\r\n|            5,067.95 |          197,318.41 |    0.1% |     11.01 | `LinearizeOptimallyExample03`\r\n|           12,716.36 |           78,638.87 |    0.0% |     11.01 | `LinearizeOptimallyExample04`\r\n|           10,231.29 |           97,739.43 |    0.0% |     11.01 | `LinearizeOptimallyExample05`\r\n|           10,649.64 |           93,899.84 |    0.0% |     11.01 | `LinearizeOptimallyExample06`\r\n|            9,564.17 |          104,556.95 |    0.1% |     11.01 | `LinearizeOptimallyExample07`\r\n|           11,884.47 |           84,143.41 |    0.3% |     11.00 | `LinearizeOptimallyExample08`\r\n|           16,436.12 |           60,841.62 |    0.1% |     11.00 | `LinearizeOptimallyExample09`\r\n|            9,937.05 |          100,633.51 |    0.1% |     11.00 | `LinearizeOptimallyExample10`\r\n|           14,575.73 |           68,607.20 |    0.2% |     11.02 | `LinearizeOptimallyExample11`\r\n|           21,355.98 |           46,825.28 |    0.1% |     11.01 | `LinearizeOptimallyExample12`\r\n|           24,439.13 |           40,917.99 |    0.0% |     11.00 | `LinearizeOptimallyExample13`\r\n|           31,407.36 |           31,839.67 |    0.1% |     11.00 | `LinearizeOptimallyExample14`\r\n|           31,366.41 |           31,881.24 |    0.1% |     11.01 | `LinearizeOptimallyExample15`\r\n|           37,182.88 |           26,894.10 |    0.1% |     11.00 | `LinearizeOptimallyExample16`\r\n|           50,528.12 |           19,790.96 |    0.3% |     11.02 | `LinearizeOptimallyExample17`\r\n|           52,714.16 |           18,970.24 |    0.1% |     11.00 | `LinearizeOptimallyExample18`\r\n|           62,357.87 |           16,036.47 |    0.1% |     10.57 | `LinearizeOptimallyExample19`\r\n</details>\r\n\r\n<details>\r\n<summary><b>Apple 2023 MacBook Pro - M2 Max</b></summary>\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                1.53 |      655,436,526.57 |    0.7% |      1.10 | `LinearizeBoundedExample0`\r\n|                1.81 |      552,194,379.23 |    0.2% |      1.10 | `LinearizeBoundedExample1`\r\n|                1.52 |      656,148,852.84 |    0.4% |      1.09 | `LinearizeBoundedExample2`\r\n|                1.75 |      572,294,606.97 |    0.7% |      1.06 | `LinearizeBoundedExample3`\r\n|                1.62 |      615,593,105.29 |    0.3% |      1.07 | `LinearizeBoundedExample4`\r\n|                1.78 |      561,989,024.83 |    1.2% |      1.08 | `LinearizeBoundedExample5`\r\n|                1.69 |      592,612,447.36 |    0.2% |      1.10 | `LinearizeBoundedExample6`\r\n|                1.58 |      633,450,827.45 |    0.3% |      1.10 | `LinearizeBoundedExample7`\r\n|                1.56 |      640,690,050.49 |    0.1% |      1.10 | `LinearizeBoundedExample8`\r\n|                1.59 |      628,148,004.87 |    0.2% |      1.09 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            1,499.94 |          666,693.94 |    0.4% |      1.09 | `LinearizeOptimallyExample00`\r\n|            2,884.51 |          346,679.16 |    0.2% |      1.10 | `LinearizeOptimallyExample01`\r\n|            5,815.27 |          171,961.12 |    0.1% |      1.10 | `LinearizeOptimallyExample02`\r\n|            6,097.37 |          164,005.14 |    0.2% |      1.05 | `LinearizeOptimallyExample03`\r\n|           13,502.59 |           74,059.89 |    0.1% |      1.10 | `LinearizeOptimallyExample04`\r\n|           11,447.25 |           87,357.24 |    0.1% |      1.10 | `LinearizeOptimallyExample05`\r\n|           11,639.59 |           85,913.71 |    0.1% |      1.10 | `LinearizeOptimallyExample06`\r\n|            9,557.65 |          104,628.26 |    0.1% |      1.10 | `LinearizeOptimallyExample07`\r\n|           12,139.84 |           82,373.43 |    0.1% |      1.10 | `LinearizeOptimallyExample08`\r\n|           18,237.62 |           54,831.73 |    0.1% |      1.10 | `LinearizeOptimallyExample09`\r\n|           11,806.18 |           84,701.39 |    0.1% |      1.10 | `LinearizeOptimallyExample10`\r\n|           17,519.95 |           57,077.80 |    0.2% |      1.09 | `LinearizeOptimallyExample11`\r\n|           24,397.16 |           40,988.37 |    0.2% |      1.10 | `LinearizeOptimallyExample12`\r\n|           28,264.97 |           35,379.48 |    0.1% |      1.10 | `LinearizeOptimallyExample13`\r\n|           36,230.91 |           27,600.74 |    0.5% |      1.10 | `LinearizeOptimallyExample14`\r\n|           36,251.16 |           27,585.33 |    0.3% |      1.10 | `LinearizeOptimallyExample15`\r\n|           42,480.07 |           23,540.45 |    0.3% |      1.10 | `LinearizeOptimallyExample16`\r\n|           59,497.62 |           16,807.39 |    0.4% |      1.10 | `LinearizeOptimallyExample17`\r\n|           62,192.70 |           16,079.06 |    0.2% |      1.06 | `LinearizeOptimallyExample18`\r\n|           73,604.11 |           13,586.20 |    0.7% |      1.06 | `LinearizeOptimallyExample19`\r\n\r\n</details>\r\n\r\n<details>\r\n<summary><b>Intel Core Processor (Haswell, no TSX) [VPS]</b></summary>\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                4.39 |      227,695,874.58 |    0.4% |     10.99 | `LinearizeBoundedExample0`\r\n|                5.32 |      187,925,655.80 |    2.3% |     11.09 | `LinearizeBoundedExample1`\r\n|                4.96 |      201,470,069.83 |    1.6% |     11.13 | `LinearizeBoundedExample2`\r\n|                5.47 |      182,878,034.13 |    1.9% |     10.75 | `LinearizeBoundedExample3`\r\n|                5.02 |      199,278,377.58 |    2.6% |     10.73 | `LinearizeBoundedExample4`\r\n|                5.69 |      175,678,783.21 |    2.7% |     11.08 | `LinearizeBoundedExample5`\r\n|                5.53 |      180,751,956.64 |    4.1% |     11.00 | `LinearizeBoundedExample6`\r\n|                5.80 |      172,338,240.84 |    2.0% |     10.81 | `LinearizeBoundedExample7`\r\n|                5.24 |      190,865,678.33 |    3.1% |     10.63 | `LinearizeBoundedExample8`\r\n|                5.51 |      181,564,438.26 |    2.9% |     11.38 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            4,399.38 |          227,304.78 |    1.9% |     11.18 | `LinearizeOptimallyExample00`\r\n|            8,789.91 |          113,766.77 |    0.9% |     10.84 | `LinearizeOptimallyExample01`\r\n|           15,890.75 |           62,929.71 |    1.6% |     11.07 | `LinearizeOptimallyExample02`\r\n|           19,082.82 |           52,403.17 |    2.2% |     11.00 | `LinearizeOptimallyExample03`\r\n|           44,627.25 |           22,407.83 |    1.8% |     11.20 | `LinearizeOptimallyExample04`\r\n|           33,718.11 |           29,657.66 |    1.1% |     11.03 | `LinearizeOptimallyExample05`\r\n|           35,473.62 |           28,189.96 |    1.1% |     11.05 | `LinearizeOptimallyExample06`\r\n|           33,162.95 |           30,154.13 |    1.5% |     10.88 | `LinearizeOptimallyExample07`\r\n|           45,473.12 |           21,991.01 |    0.9% |     11.12 | `LinearizeOptimallyExample08`\r\n|           57,919.95 |           17,265.21 |    1.1% |     11.04 | `LinearizeOptimallyExample09`\r\n|           32,640.19 |           30,637.08 |    2.1% |     11.16 | `LinearizeOptimallyExample10`\r\n|           46,559.58 |           21,477.86 |    1.5% |     10.98 | `LinearizeOptimallyExample11`\r\n|           66,614.50 |           15,011.75 |    1.4% |     10.55 | `LinearizeOptimallyExample12`\r\n|           76,783.09 |           13,023.70 |    0.5% |     10.74 | `LinearizeOptimallyExample13`\r\n|           97,635.10 |           10,242.22 |    1.7% |     11.00 | `LinearizeOptimallyExample14`\r\n|           99,854.80 |           10,014.54 |    0.8% |     11.00 | `LinearizeOptimallyExample15`\r\n|          119,444.66 |            8,372.08 |    1.2% |     11.11 | `LinearizeOptimallyExample16`\r\n|          156,160.25 |            6,403.68 |    0.9% |     10.98 | `LinearizeOptimallyExample17`\r\n|          163,364.57 |            6,121.28 |    0.8% |     10.90 | `LinearizeOptimallyExample18`\r\n|          193,524.10 |            5,167.32 |    1.2% |     11.14 | `LinearizeOptimallyExample19`\r\n\r\n</details>\r\n\r\n<details>\r\n<summary><b>12th Gen Intel(R) Core(TM) i5-12500H [laptop]</b></summary>\r\n\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                1.75 |      571,671,353.08 |    0.1% |     10.99 | `LinearizeBoundedExample0`\r\n|                2.05 |      487,547,934.48 |    0.1% |     11.00 | `LinearizeBoundedExample1`\r\n|                1.97 |      506,752,217.57 |    0.1% |     10.64 | `LinearizeBoundedExample2`\r\n|                2.24 |      447,162,026.45 |    0.1% |     11.00 | `LinearizeBoundedExample3`\r\n|                2.08 |      480,557,495.14 |    0.1% |     11.01 | `LinearizeBoundedExample4`\r\n|                2.30 |      434,505,839.40 |    0.1% |     11.12 | `LinearizeBoundedExample5`\r\n|                2.21 |      451,557,580.61 |    0.0% |     11.00 | `LinearizeBoundedExample6`\r\n|                2.25 |      444,374,372.72 |    0.0% |     11.00 | `LinearizeBoundedExample7`\r\n|                2.12 |      471,017,980.18 |    0.1% |     10.93 | `LinearizeBoundedExample8`\r\n|                2.22 |      450,256,469.71 |    1.1% |     11.07 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            1,586.71 |          630,233.45 |    0.1% |     10.98 | `LinearizeOptimallyExample00`\r\n|            3,268.23 |          305,976.43 |    0.0% |     11.00 | `LinearizeOptimallyExample01`\r\n|            6,858.84 |          145,797.34 |    0.2% |     10.54 | `LinearizeOptimallyExample02`\r\n|            7,873.51 |          127,008.11 |    0.1% |     10.73 | `LinearizeOptimallyExample03`\r\n|           17,277.23 |           57,879.64 |    0.1% |     11.00 | `LinearizeOptimallyExample04`\r\n|           14,178.66 |           70,528.55 |    0.1% |     11.00 | `LinearizeOptimallyExample05`\r\n|           16,009.26 |           62,463.84 |    0.0% |     10.99 | `LinearizeOptimallyExample06`\r\n|           12,586.44 |           79,450.57 |    1.6% |     10.87 | `LinearizeOptimallyExample07`\r\n|           15,396.54 |           64,949.64 |    0.0% |     11.00 | `LinearizeOptimallyExample08`\r\n|           24,369.54 |           41,034.82 |    0.0% |     11.00 | `LinearizeOptimallyExample09`\r\n|           13,610.19 |           73,474.38 |    0.1% |     10.99 | `LinearizeOptimallyExample10`\r\n|           20,073.90 |           49,815.92 |    0.1% |     11.01 | `LinearizeOptimallyExample11`\r\n|           30,462.32 |           32,827.44 |    0.3% |     11.12 | `LinearizeOptimallyExample12`\r\n|           34,713.56 |           28,807.18 |    0.3% |     10.93 | `LinearizeOptimallyExample13`\r\n|           44,015.70 |           22,719.17 |    0.1% |     11.00 | `LinearizeOptimallyExample14`\r\n|           43,492.08 |           22,992.69 |    0.1% |     11.00 | `LinearizeOptimallyExample15`\r\n|           51,596.62 |           19,381.12 |    0.1% |     11.01 | `LinearizeOptimallyExample16`\r\n|           71,384.39 |           14,008.67 |    0.2% |     10.69 | `LinearizeOptimallyExample17`\r\n|           73,714.84 |           13,565.79 |    0.1% |     10.69 | `LinearizeOptimallyExample18`\r\n|           87,910.27 |           11,375.24 |    0.0% |     10.82 | `LinearizeOptimallyExample19`\r\n\r\n</details>",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2916658444",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2918119652,
      "node_id": "IC_kwDOABII586t7vjk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2918119652",
      "actor": {
        "login": "davidgumberg",
        "id": 2257631,
        "node_id": "MDQ6VXNlcjIyNTc2MzE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2257631?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/davidgumberg",
        "html_url": "https://github.com/davidgumberg",
        "followers_url": "https://api.github.com/users/davidgumberg/followers",
        "following_url": "https://api.github.com/users/davidgumberg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/davidgumberg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/davidgumberg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/davidgumberg/subscriptions",
        "organizations_url": "https://api.github.com/users/davidgumberg/orgs",
        "repos_url": "https://api.github.com/users/davidgumberg/repos",
        "events_url": "https://api.github.com/users/davidgumberg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/davidgumberg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T03:16:46Z",
      "updated_at": "2025-05-29T05:16:15Z",
      "author_association": "CONTRIBUTOR",
      "body": "_(built with Clang)_\r\n\r\n<details> <summary> \r\n\r\n#### AMD Ryzen 9 9950X 16-Core Processor </summary>\r\n```bash\r\n./build/bin/bench_bitcoin --filter=\"Linearize.*Example.*\" -min-time=10000\r\n```\r\n|             ns/cost |              cost/s |    err% |        ins/cost |        cyc/cost |    IPC |       bra/cost |   miss% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------------:|----------------:|-------:|---------------:|--------:|----------:|:----------\r\n|                1.19 |      836,855,166.72 |    0.4% |           20.42 |            5.13 |  3.984 |           2.29 |    2.4% |     11.05 | `LinearizeBoundedExample0`\r\n|                1.44 |      695,776,928.37 |    0.1% |           24.33 |            6.17 |  3.945 |           2.74 |    2.4% |     10.99 | `LinearizeBoundedExample1`\r\n|                1.17 |      852,566,861.36 |    0.2% |           18.78 |            5.03 |  3.733 |           2.33 |    3.2% |     11.04 | `LinearizeBoundedExample2`\r\n|                1.36 |      735,968,415.25 |    0.1% |           19.54 |            5.83 |  3.349 |           2.36 |    4.6% |     10.57 | `LinearizeBoundedExample3`\r\n|                1.24 |      805,653,703.91 |    0.0% |           18.58 |            5.33 |  3.487 |           2.27 |    4.2% |     10.56 | `LinearizeBoundedExample4`\r\n|                1.34 |      745,442,570.61 |    0.1% |           20.46 |            5.76 |  3.553 |           2.50 |    4.1% |     10.62 | `LinearizeBoundedExample5`\r\n|                1.27 |      784,639,270.59 |    0.0% |           19.10 |            5.47 |  3.490 |           2.35 |    4.3% |     10.65 | `LinearizeBoundedExample6`\r\n|                1.18 |      847,347,367.90 |    0.2% |           18.45 |            5.07 |  3.642 |           2.23 |    3.6% |     10.70 | `LinearizeBoundedExample7`\r\n|                1.19 |      841,752,012.32 |    0.2% |           18.65 |            5.10 |  3.657 |           2.29 |    3.5% |     10.70 | `LinearizeBoundedExample8`\r\n|                1.20 |      833,486,862.05 |    0.1% |           19.07 |            5.15 |  3.703 |           2.31 |    3.2% |     10.79 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |          ins/op |          cyc/op |    IPC |         bra/op |   miss% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------------:|----------------:|-------:|---------------:|--------:|----------:|:----------\r\n|            1,062.27 |          941,380.47 |    0.2% |       23,154.64 |        4,561.62 |  5.076 |       2,732.15 |    1.1% |     10.99 | `LinearizeOptimallyExample00`\r\n|            2,199.32 |          454,686.52 |    0.1% |       44,955.91 |        9,443.49 |  4.761 |       5,125.75 |    1.2% |     11.01 | `LinearizeOptimallyExample01`\r\n|            4,655.43 |          214,803.15 |    0.1% |       76,020.42 |       19,989.80 |  3.803 |       8,376.75 |    2.7% |     11.01 | `LinearizeOptimallyExample02`\r\n|            4,687.57 |          213,330.01 |    0.2% |       79,606.35 |       20,125.95 |  3.955 |       8,838.43 |    2.7% |     10.99 | `LinearizeOptimallyExample03`\r\n|           11,198.28 |           89,299.41 |    0.1% |      180,121.05 |       48,080.45 |  3.746 |      21,333.25 |    2.9% |     11.01 | `LinearizeOptimallyExample04`\r\n|            8,806.12 |          113,557.33 |    0.0% |      148,315.36 |       37,809.30 |  3.923 |      17,597.94 |    2.9% |     10.83 | `LinearizeOptimallyExample05`\r\n|            8,881.81 |          112,589.68 |    0.0% |      129,414.56 |       38,127.56 |  3.394 |      15,799.78 |    4.3% |     10.83 | `LinearizeOptimallyExample06`\r\n|            7,396.23 |          135,204.04 |    0.0% |      139,880.41 |       31,756.73 |  4.405 |      16,345.08 |    2.7% |     10.67 | `LinearizeOptimallyExample07`\r\n|            9,691.58 |          103,182.40 |    0.0% |      201,859.77 |       41,612.38 |  4.851 |      23,957.84 |    1.1% |     11.01 | `LinearizeOptimallyExample08`\r\n|           13,912.45 |           71,878.08 |    0.1% |      205,829.89 |       59,733.52 |  3.446 |      25,060.12 |    4.2% |     11.00 | `LinearizeOptimallyExample09`\r\n|            9,799.39 |          102,047.14 |    0.1% |      131,704.66 |       42,074.45 |  3.130 |      13,959.94 |    5.7% |     11.00 | `LinearizeOptimallyExample10`\r\n|           14,178.88 |           70,527.42 |    0.1% |      181,891.98 |       60,879.32 |  2.988 |      18,797.61 |    5.9% |     11.02 | `LinearizeOptimallyExample11`\r\n|           19,417.52 |           51,499.89 |    0.1% |      231,655.76 |       83,370.63 |  2.779 |      26,582.04 |    6.6% |     11.01 | `LinearizeOptimallyExample12`\r\n|           21,875.47 |           45,713.31 |    0.1% |      262,258.87 |       93,911.73 |  2.793 |      30,218.20 |    6.7% |     11.00 | `LinearizeOptimallyExample13`\r\n|           28,875.31 |           34,631.67 |    0.1% |      336,971.73 |      123,981.98 |  2.718 |      38,520.06 |    6.5% |     11.01 | `LinearizeOptimallyExample14`\r\n|           27,860.30 |           35,893.37 |    0.1% |      334,160.29 |      119,619.93 |  2.794 |      37,727.10 |    6.5% |     11.00 | `LinearizeOptimallyExample15`\r\n|           33,495.46 |           29,854.79 |    0.1% |      395,850.86 |      143,808.78 |  2.753 |      45,419.38 |    6.8% |     11.00 | `LinearizeOptimallyExample16`\r\n|           46,820.27 |           21,358.27 |    0.2% |      527,868.16 |      201,024.15 |  2.626 |      60,683.66 |    7.4% |     11.01 | `LinearizeOptimallyExample17`\r\n|           47,420.53 |           21,087.91 |    0.1% |      549,255.39 |      203,589.67 |  2.698 |      62,108.84 |    7.0% |     11.01 | `LinearizeOptimallyExample18`\r\n|           56,870.07 |           17,583.94 |    0.2% |      665,564.77 |      244,167.60 |  2.726 |      75,210.75 |    6.7% |     10.98 | `LinearizeOptimallyExample19`\r\n</details>\r\n<details>\r\n<summary> \r\n\r\n#### AMD Ryzen 9 7900X 12-Core Processor </summary>\r\n```bash\r\n./build/bin/bench_bitcoin --filter=\"Linearize.*Example.*\" -min-time=10000\r\n```\r\n\r\n|             ns/cost |              cost/s |    err% |        ins/cost |        cyc/cost |    IPC |       bra/cost |   miss% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------------:|----------------:|-------:|---------------:|--------:|----------:|:----------\r\n|                1.36 |      737,410,406.03 |    0.2% |           20.58 |            6.34 |  3.247 |           2.34 |    2.5% |     11.02 | `LinearizeBoundedExample0`\r\n|                1.65 |      606,854,042.04 |    0.1% |           24.57 |            7.70 |  3.190 |           2.76 |    2.5% |     10.99 | `LinearizeBoundedExample1`\r\n|                1.31 |      760,547,140.52 |    0.1% |           18.87 |            6.14 |  3.071 |           2.36 |    3.4% |     11.02 | `LinearizeBoundedExample2`\r\n|                1.52 |      657,532,700.47 |    0.0% |           19.61 |            7.11 |  2.758 |           2.38 |    4.9% |     10.63 | `LinearizeBoundedExample3`\r\n|                1.39 |      718,444,894.17 |    0.1% |           18.63 |            6.51 |  2.864 |           2.30 |    4.3% |     10.63 | `LinearizeBoundedExample4`\r\n|                1.52 |      656,965,976.43 |    0.1% |           20.51 |            7.11 |  2.882 |           2.53 |    4.1% |     10.71 | `LinearizeBoundedExample5`\r\n|                1.44 |      694,175,863.25 |    0.1% |           19.12 |            6.73 |  2.839 |           2.39 |    4.5% |     10.72 | `LinearizeBoundedExample6`\r\n|                1.34 |      745,455,006.56 |    0.0% |           18.49 |            6.27 |  2.948 |           2.27 |    3.8% |     10.81 | `LinearizeBoundedExample7`\r\n|                1.35 |      740,869,763.95 |    0.2% |           18.70 |            6.31 |  2.965 |           2.32 |    3.7% |     10.83 | `LinearizeBoundedExample8`\r\n|                1.36 |      733,610,430.06 |    0.0% |           19.17 |            6.37 |  3.009 |           2.34 |    3.4% |     11.00 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |          ins/op |          cyc/op |    IPC |         bra/op |   miss% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------------:|----------------:|-------:|---------------:|--------:|----------:|:----------\r\n|            1,231.66 |          811,912.24 |    0.0% |       23,357.46 |        5,757.88 |  4.057 |       2,788.34 |    1.0% |     11.01 | `LinearizeOptimallyExample00`\r\n|            2,608.32 |          383,388.20 |    0.1% |       44,890.34 |       12,192.83 |  3.682 |       5,176.76 |    1.2% |     11.02 | `LinearizeOptimallyExample01`\r\n|            5,129.41 |          194,954.12 |    0.1% |       76,112.07 |       23,977.96 |  3.174 |       8,574.18 |    2.6% |     10.99 | `LinearizeOptimallyExample02`\r\n|            5,283.32 |          189,274.88 |    0.1% |       79,355.44 |       24,692.88 |  3.214 |       8,960.39 |    2.7% |     11.01 | `LinearizeOptimallyExample03`\r\n|           12,510.48 |           79,933.00 |    0.1% |      178,410.73 |       58,475.18 |  3.051 |      21,948.73 |    3.0% |     11.00 | `LinearizeOptimallyExample04`\r\n|            9,699.21 |          103,101.15 |    0.1% |      147,263.70 |       45,334.12 |  3.248 |      18,517.16 |    2.7% |     10.99 | `LinearizeOptimallyExample05`\r\n|            9,890.03 |          101,111.94 |    0.1% |      128,779.01 |       46,228.98 |  2.786 |      16,175.51 |    4.5% |     11.00 | `LinearizeOptimallyExample06`\r\n|            8,853.35 |          112,951.56 |    0.1% |      138,404.58 |       41,381.10 |  3.345 |      16,972.04 |    2.6% |     10.83 | `LinearizeOptimallyExample07`\r\n|           11,429.49 |           87,493.00 |    0.0% |      199,933.47 |       53,426.08 |  3.742 |      24,782.93 |    1.0% |     11.00 | `LinearizeOptimallyExample08`\r\n|           15,278.31 |           65,452.27 |    0.1% |      203,844.43 |       71,404.74 |  2.855 |      25,811.52 |    4.2% |     10.98 | `LinearizeOptimallyExample09`\r\n|           10,430.03 |           95,877.04 |    0.1% |      130,835.87 |       48,749.71 |  2.684 |      14,322.22 |    5.7% |     11.01 | `LinearizeOptimallyExample10`\r\n|           14,955.33 |           66,865.78 |    0.1% |      181,388.73 |       69,905.18 |  2.595 |      19,826.07 |    5.7% |     11.01 | `LinearizeOptimallyExample11`\r\n|           20,192.09 |           49,524.34 |    0.1% |      229,811.63 |       94,374.34 |  2.435 |      27,200.27 |    6.6% |     11.01 | `LinearizeOptimallyExample12`\r\n|           23,265.71 |           42,981.71 |    0.3% |      260,056.43 |      108,734.94 |  2.392 |      30,956.74 |    6.7% |     10.99 | `LinearizeOptimallyExample13`\r\n|           29,690.95 |           33,680.30 |    0.1% |      334,363.41 |      138,778.90 |  2.409 |      39,510.12 |    6.4% |     10.99 | `LinearizeOptimallyExample14`\r\n|           29,188.83 |           34,259.68 |    0.1% |      331,541.94 |      136,412.59 |  2.430 |      38,603.88 |    6.3% |     10.99 | `LinearizeOptimallyExample15`\r\n|           35,084.30 |           28,502.78 |    0.0% |      391,658.97 |      163,986.36 |  2.388 |      46,505.21 |    6.6% |     11.00 | `LinearizeOptimallyExample16`\r\n|           47,904.99 |           20,874.65 |    0.1% |      521,828.04 |      223,869.99 |  2.331 |      62,246.01 |    7.0% |     11.01 | `LinearizeOptimallyExample17`\r\n|           49,498.85 |           20,202.49 |    0.1% |      543,459.92 |      231,331.22 |  2.349 |      63,630.07 |    6.7% |     11.01 | `LinearizeOptimallyExample18`\r\n|           59,173.83 |           16,899.36 |    0.1% |      658,965.47 |      276,557.48 |  2.383 |      77,128.66 |    6.3% |     11.00 | `LinearizeOptimallyExample19`\r\n</details>\r\n\r\n\r\n\r\n",
      "user": {
        "login": "davidgumberg",
        "id": 2257631,
        "node_id": "MDQ6VXNlcjIyNTc2MzE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2257631?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/davidgumberg",
        "html_url": "https://github.com/davidgumberg",
        "followers_url": "https://api.github.com/users/davidgumberg/followers",
        "following_url": "https://api.github.com/users/davidgumberg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/davidgumberg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/davidgumberg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/davidgumberg/subscriptions",
        "organizations_url": "https://api.github.com/users/davidgumberg/orgs",
        "repos_url": "https://api.github.com/users/davidgumberg/repos",
        "events_url": "https://api.github.com/users/davidgumberg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/davidgumberg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2918119652",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2919479775,
      "node_id": "IC_kwDOABII586uA7nf",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2919479775",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T13:51:43Z",
      "updated_at": "2025-05-29T14:36:42Z",
      "author_association": "MEMBER",
      "body": "> I'm interested in seeing benchmarks of this on various systems, especially high-end/modern ones (as their performance is likely most predictive of what future hardware will be like).\r\n\r\nBelow are benchmarks on MacBook M2 PRO 2023.\r\nCompiled using clang with only build bench cmake option.\r\n```\r\ncmake -B build -DBUILD_BENCH=ON && cmake --build build\r\n```\r\n<details>\r\n<summary> origin/pr/32545 47bdf8faafc550bf673b4affadc73415160f9ff2</summary>\r\n\r\n```terminal\r\nabubakarismail@Abubakars-MacBook-Pro ~/D/W/b/bitcoin ((47bdf8fa))> ./build/bin/bench_bitcoin --filter=\"Linearize.*Example.*\" -min-ti\r\nme=1000\r\n```\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                1.85 |      539,881,102.87 |    6.1% |     10.64 | :wavy_dash: `LinearizeBoundedExample0` (Unstable with ~171,993.8 iters. Increase `minEpochIterations` to e.g. 1719938)\r\n|                2.16 |      463,765,560.64 |    1.9% |     11.52 | `LinearizeBoundedExample1`\r\n|                1.89 |      529,370,444.85 |    3.4% |     11.88 | `LinearizeBoundedExample2`\r\n|                2.09 |      478,266,850.10 |    2.1% |     10.69 | `LinearizeBoundedExample3`\r\n|                2.00 |      500,459,378.92 |    3.4% |     10.99 | `LinearizeBoundedExample4`\r\n|                2.23 |      448,896,053.69 |    4.1% |     12.62 | `LinearizeBoundedExample5`\r\n|                2.21 |      453,201,053.94 |    6.2% |      9.74 | :wavy_dash: `LinearizeBoundedExample6` (Unstable with ~70,645.3 iters. Increase `minEpochIterations` to e.g. 706453)\r\n|                1.88 |      531,282,530.06 |    1.7% |     11.59 | `LinearizeBoundedExample7`\r\n|                1.82 |      550,292,679.97 |    1.5% |     11.85 | `LinearizeBoundedExample8`\r\n|                1.81 |      553,506,180.26 |    1.1% |     10.68 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            1,927.91 |          518,696.06 |    1.2% |     11.39 | `LinearizeOptimallyExample00`\r\n|            3,227.99 |          309,790.35 |    1.0% |     10.99 | `LinearizeOptimallyExample01`\r\n|            6,619.50 |          151,068.72 |    2.3% |     10.17 | `LinearizeOptimallyExample02`\r\n|            6,648.74 |          150,404.54 |    1.1% |     10.67 | `LinearizeOptimallyExample03`\r\n|           15,989.38 |           62,541.52 |    1.7% |     11.11 | `LinearizeOptimallyExample04`\r\n|           13,491.31 |           74,121.78 |    4.1% |     12.15 | `LinearizeOptimallyExample05`\r\n|           12,958.96 |           77,166.66 |    1.0% |     10.63 | `LinearizeOptimallyExample06`\r\n|           11,525.25 |           86,766.02 |    3.7% |     11.77 | `LinearizeOptimallyExample07`\r\n|           14,095.38 |           70,945.21 |    0.6% |     10.80 | `LinearizeOptimallyExample08`\r\n|           21,410.11 |           46,706.90 |    1.1% |     11.46 | `LinearizeOptimallyExample09`\r\n|           13,372.29 |           74,781.50 |    1.5% |     11.06 | `LinearizeOptimallyExample10`\r\n|           19,803.65 |           50,495.75 |    3.2% |     10.79 | `LinearizeOptimallyExample11`\r\n|           26,699.86 |           37,453.38 |    1.1% |     11.15 | `LinearizeOptimallyExample12`\r\n|           36,106.95 |           27,695.50 |    8.0% |     11.03 | :wavy_dash: `LinearizeOptimallyExample13` (Unstable with ~24,184.5 iters. Increase `minEpochIterations` to e.g. 241845)\r\n|           41,346.30 |           24,185.96 |    3.3% |     10.49 | `LinearizeOptimallyExample14`\r\n|           41,673.85 |           23,995.86 |    1.6% |      9.89 | `LinearizeOptimallyExample15`\r\n|           47,425.14 |           21,085.87 |    1.1% |     11.07 | `LinearizeOptimallyExample16`\r\n|           66,540.78 |           15,028.38 |    2.4% |     11.26 | `LinearizeOptimallyExample17`\r\n|           66,934.73 |           14,939.93 |    1.4% |     10.54 | `LinearizeOptimallyExample18`\r\n|           81,828.99 |           12,220.61 |    1.8% |     11.44 | `LinearizeOptimallyExample19`\r\n</details>\r\n\r\n~Almost 10x speedup~ \r\nedit: bench cases changed, so not comparable with master.\r\n",
      "user": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2919479775",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2919488733,
      "node_id": "IC_kwDOABII586uA9zd",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2919488733",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T13:54:31Z",
      "updated_at": "2025-05-29T13:54:31Z",
      "author_association": "MEMBER",
      "body": "@ismaelsadeeq Not an apples-to-apples comparison I'm afraid, because the benchmark cases are changed in this PR too. Can you run the `LinearizeBoundedExample?` benchmarks too?",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2919488733",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "mentioned",
      "id": 17869002602,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQpE1dq",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17869002602",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T13:54:32Z"
    },
    {
      "event": "subscribed",
      "id": 17869002623,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQpE1d_",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17869002623",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T13:54:32Z"
    },
    {
      "event": "commented",
      "id": 2919605052,
      "node_id": "IC_kwDOABII586uBaM8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2919605052",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T14:35:45Z",
      "updated_at": "2025-05-29T14:35:45Z",
      "author_association": "MEMBER",
      "body": "> @ismaelsadeeq Not an apples-to-apples comparison I'm afraid, because the benchmark cases are changed in this PR too\r\n\r\nOops sorry haven't take a look, I was hoping I can compare locally myself. I saw a link to the bench results comparing them in the description ðŸ‘ðŸ¾ \r\n\r\n> Can you run the LinearizeBoundedExample? benchmarks too?\r\n\r\nYep I did and updated the bench results. previous one was not pointing to your latest push.\r\n\r\n\r\n",
      "user": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2919605052",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "mentioned",
      "id": 17869696782,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQpHe8O",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17869696782",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T14:35:46Z"
    },
    {
      "event": "subscribed",
      "id": 17869696810,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQpHe8q",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17869696810",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T14:35:46Z"
    },
    {
      "event": "commented",
      "id": 2919935290,
      "node_id": "IC_kwDOABII586uCq06",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2919935290",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T16:28:15Z",
      "updated_at": "2025-05-29T16:28:15Z",
      "author_association": "MEMBER",
      "body": "Ran apples to apples out of curiosity. One example ran marginally slower on this PR (but still very fast), many are many multiples faster and some see 500x+ improvements.",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2919935290",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2920277088,
      "node_id": "IC_kwDOABII586uD-Rg",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2920277088",
      "actor": {
        "login": "gmaxwell",
        "id": 858454,
        "node_id": "MDQ6VXNlcjg1ODQ1NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/858454?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gmaxwell",
        "html_url": "https://github.com/gmaxwell",
        "followers_url": "https://api.github.com/users/gmaxwell/followers",
        "following_url": "https://api.github.com/users/gmaxwell/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/gmaxwell/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/gmaxwell/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
        "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
        "repos_url": "https://api.github.com/users/gmaxwell/repos",
        "events_url": "https://api.github.com/users/gmaxwell/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T18:47:51Z",
      "updated_at": "2025-05-29T21:37:07Z",
      "author_association": "CONTRIBUTOR",
      "body": "@instagibbs  I believe the only cases that should be slower with SFL are either very small examples (where their time is irrelevant because its very low per tx compared to bigger clusters)  and ones with huge numbers of dependencies.   Beyond huge dependencies being generally unrepresentative they're also expensive to generate because every dependency needs a vin, they also tend to be so slow with both that I guess neither will run to completion in practice.\r\n\r\nA better way to compare across implementations might be some kind of optimization time vs amount of fee required to create a cluster with that dependency geometry (just assuming a 1s/vb feerate or something, not adding up the actual costs in the cluster because another cluster could exist with the same topology but different fees/size). like fee = 16\\*txn + 41\\*inputs_consumed + 9\\*outputs_consumed_within_cluster -- so I'd hope to find that SFL always beats the current exponential algorithm on this kind of metric (except for very small inputs).\r\n\r\nThe exponential algorithm gets faster with dependency rich clusters because the linearization essentially becomes topologically forced, so the current algorithm doesn't have many options to consider.  If it massive high dependency clusters became common on the network in the future it might make sense to bring back the exponential algorithm for  them.  :P  but I doubt that would happen.\r\n",
      "user": {
        "login": "gmaxwell",
        "id": 858454,
        "node_id": "MDQ6VXNlcjg1ODQ1NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/858454?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gmaxwell",
        "html_url": "https://github.com/gmaxwell",
        "followers_url": "https://api.github.com/users/gmaxwell/followers",
        "following_url": "https://api.github.com/users/gmaxwell/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/gmaxwell/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/gmaxwell/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
        "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
        "repos_url": "https://api.github.com/users/gmaxwell/repos",
        "events_url": "https://api.github.com/users/gmaxwell/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2920277088",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "mentioned",
      "id": 17873542757,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQpWJ5l",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17873542757",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T18:47:52Z"
    },
    {
      "event": "subscribed",
      "id": 17873542769,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQpWJ5x",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17873542769",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-29T18:47:52Z"
    },
    {
      "event": "commented",
      "id": 2923413036,
      "node_id": "IC_kwDOABII586uP74s",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2923413036",
      "actor": {
        "login": "fjahr",
        "id": 1322187,
        "node_id": "MDQ6VXNlcjEzMjIxODc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1322187?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fjahr",
        "html_url": "https://github.com/fjahr",
        "followers_url": "https://api.github.com/users/fjahr/followers",
        "following_url": "https://api.github.com/users/fjahr/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fjahr/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fjahr/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fjahr/subscriptions",
        "organizations_url": "https://api.github.com/users/fjahr/orgs",
        "repos_url": "https://api.github.com/users/fjahr/repos",
        "events_url": "https://api.github.com/users/fjahr/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fjahr/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-30T20:26:27Z",
      "updated_at": "2025-05-30T20:26:27Z",
      "author_association": "CONTRIBUTOR",
      "body": "> I'm interested in seeing benchmarks of this on various systems\r\n\r\n<details>\r\n<summary>Macbook Pro M4</summary>\r\n\r\n$ build/bin/bench_bitcoin --filter=\"Linearize.*Example.*\" -min-time=10000\r\n\r\n|             ns/cost |              cost/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|                1.12 |      893,382,447.85 |    0.5% |     11.06 | `LinearizeBoundedExample0`\r\n|                1.34 |      743,601,759.92 |    0.7% |     11.07 | `LinearizeBoundedExample1`\r\n|                1.14 |      880,692,144.98 |    0.3% |     10.99 | `LinearizeBoundedExample2`\r\n|                1.33 |      749,663,261.00 |    0.3% |     10.98 | `LinearizeBoundedExample3`\r\n|                1.24 |      807,545,779.18 |    0.5% |     10.57 | `LinearizeBoundedExample4`\r\n|                1.37 |      730,046,090.82 |    0.4% |     10.64 | `LinearizeBoundedExample5`\r\n|                1.28 |      779,862,831.19 |    0.4% |     10.66 | `LinearizeBoundedExample6`\r\n|                1.17 |      856,937,081.55 |    0.4% |     10.71 | `LinearizeBoundedExample7`\r\n|                1.19 |      840,624,085.43 |    0.2% |     10.74 | `LinearizeBoundedExample8`\r\n|                1.19 |      840,938,970.51 |    0.4% |     10.74 | `LinearizeBoundedExample9`\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|            1,155.37 |          865,524.35 |    0.2% |     11.00 | `LinearizeOptimallyExample00`\r\n|            2,170.00 |          460,828.59 |    0.2% |     11.04 | `LinearizeOptimallyExample01`\r\n|            4,507.21 |          221,866.90 |    0.2% |     11.01 | `LinearizeOptimallyExample02`\r\n|            4,435.85 |          225,435.87 |    0.3% |     10.96 | `LinearizeOptimallyExample03`\r\n|           10,189.93 |           98,136.12 |    0.2% |     11.02 | `LinearizeOptimallyExample04`\r\n|            8,854.57 |          112,936.09 |    0.4% |     10.79 | `LinearizeOptimallyExample05`\r\n|            8,685.08 |          115,140.05 |    0.1% |     10.82 | `LinearizeOptimallyExample06`\r\n|            7,162.17 |          139,622.57 |    0.0% |     10.64 | `LinearizeOptimallyExample07`\r\n|            9,120.88 |          109,638.49 |    0.0% |     11.00 | `LinearizeOptimallyExample08`\r\n|           12,780.73 |           78,242.79 |    0.1% |     11.00 | `LinearizeOptimallyExample09`\r\n|            9,242.70 |          108,193.53 |    0.1% |     10.98 | `LinearizeOptimallyExample10`\r\n|           13,653.81 |           73,239.62 |    0.3% |     11.04 | `LinearizeOptimallyExample11`\r\n|           19,211.80 |           52,051.34 |    0.2% |     11.00 | `LinearizeOptimallyExample12`\r\n|           22,243.75 |           44,956.45 |    0.1% |     11.00 | `LinearizeOptimallyExample13`\r\n|           28,409.81 |           35,199.11 |    0.2% |     10.99 | `LinearizeOptimallyExample14`\r\n|           28,265.23 |           35,379.16 |    0.1% |     10.99 | `LinearizeOptimallyExample15`\r\n|           33,767.58 |           29,614.20 |    0.3% |     11.02 | `LinearizeOptimallyExample16`\r\n|           46,851.80 |           21,343.90 |    0.4% |     11.03 | `LinearizeOptimallyExample17`\r\n|           48,470.35 |           20,631.17 |    0.1% |     10.98 | `LinearizeOptimallyExample18`\r\n|           57,668.81 |           17,340.40 |    0.4% |     10.98 | `LinearizeOptimallyExample19`\r\n\r\n</details>",
      "user": {
        "login": "fjahr",
        "id": 1322187,
        "node_id": "MDQ6VXNlcjEzMjIxODc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1322187?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fjahr",
        "html_url": "https://github.com/fjahr",
        "followers_url": "https://api.github.com/users/fjahr/followers",
        "following_url": "https://api.github.com/users/fjahr/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fjahr/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fjahr/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fjahr/subscriptions",
        "organizations_url": "https://api.github.com/users/fjahr/orgs",
        "repos_url": "https://api.github.com/users/fjahr/repos",
        "events_url": "https://api.github.com/users/fjahr/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fjahr/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2923413036",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17900829865,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQq-Pyp",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900829865",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "de458666f4e7e297dbf9aa6e0b231a4cdc734fcf",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/de458666f4e7e297dbf9aa6e0b231a4cdc734fcf",
      "created_at": "2025-05-31T13:17:22Z"
    },
    {
      "event": "commented",
      "id": 2925180422,
      "node_id": "IC_kwDOABII586uWrYG",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2925180422",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:00Z",
      "updated_at": "2025-05-31T13:24:00Z",
      "author_association": "MEMBER",
      "body": "@instagibbs @ismaelsadeeq @gmaxwell FWIW, I didn't include apples-to-apples comparison because the large-scale comparison [benchmarks](https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303/73) I did (especially, [this one](https://delvingbitcoin.org/uploads/default/original/2X/2/22ad16f71db37fcb8cadb8a8f73c4acfd3def203.png)) were just overwhelmingly in favor of SFL over the existing one. The benchmarks were mostly done to decide between SFL and another replacement algorithm, GGT, but see the reasons for choosing SFL [here](https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303/68).\r\n\r\nA fair apples-to-apples comparison I think needs to use a dataset large enough to encompass both good and bad cases for each of the algorithms, and not be specifically biased for one of them, which is hard in a benchmark I can include in the PR directly. If people are interested, I can try to clean up the branch I used to create the graphs above, however.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2925180422",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "mentioned",
      "id": 17900881168,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQq-cUQ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900881168",
      "actor": {
        "login": "gmaxwell",
        "id": 858454,
        "node_id": "MDQ6VXNlcjg1ODQ1NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/858454?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gmaxwell",
        "html_url": "https://github.com/gmaxwell",
        "followers_url": "https://api.github.com/users/gmaxwell/followers",
        "following_url": "https://api.github.com/users/gmaxwell/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/gmaxwell/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/gmaxwell/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
        "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
        "repos_url": "https://api.github.com/users/gmaxwell/repos",
        "events_url": "https://api.github.com/users/gmaxwell/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:01Z"
    },
    {
      "event": "subscribed",
      "id": 17900881171,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQq-cUT",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900881171",
      "actor": {
        "login": "gmaxwell",
        "id": 858454,
        "node_id": "MDQ6VXNlcjg1ODQ1NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/858454?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gmaxwell",
        "html_url": "https://github.com/gmaxwell",
        "followers_url": "https://api.github.com/users/gmaxwell/followers",
        "following_url": "https://api.github.com/users/gmaxwell/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/gmaxwell/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/gmaxwell/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
        "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
        "repos_url": "https://api.github.com/users/gmaxwell/repos",
        "events_url": "https://api.github.com/users/gmaxwell/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:01Z"
    },
    {
      "event": "mentioned",
      "id": 17900881172,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQq-cUU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900881172",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:01Z"
    },
    {
      "event": "subscribed",
      "id": 17900881175,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQq-cUX",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900881175",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:01Z"
    },
    {
      "event": "mentioned",
      "id": 17900881179,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQq-cUb",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900881179",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:01Z"
    },
    {
      "event": "subscribed",
      "id": 17900881181,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQq-cUd",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17900881181",
      "actor": {
        "login": "ismaelsadeeq",
        "id": 48946461,
        "node_id": "MDQ6VXNlcjQ4OTQ2NDYx",
        "avatar_url": "https://avatars.githubusercontent.com/u/48946461?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ismaelsadeeq",
        "html_url": "https://github.com/ismaelsadeeq",
        "followers_url": "https://api.github.com/users/ismaelsadeeq/followers",
        "following_url": "https://api.github.com/users/ismaelsadeeq/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/ismaelsadeeq/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/ismaelsadeeq/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/ismaelsadeeq/subscriptions",
        "organizations_url": "https://api.github.com/users/ismaelsadeeq/orgs",
        "repos_url": "https://api.github.com/users/ismaelsadeeq/repos",
        "events_url": "https://api.github.com/users/ismaelsadeeq/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/ismaelsadeeq/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T13:24:01Z"
    },
    {
      "event": "commented",
      "id": 2925757556,
      "node_id": "IC_kwDOABII586uY4R0",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2925757556",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-31T21:25:43Z",
      "updated_at": "2025-06-01T12:32:17Z",
      "author_association": "MEMBER",
      "body": "Thanks for all the benchmarks, here are some graphs created from them to show their relative performance:\r\n\r\n\r\n<img src=\"https://github.com/user-attachments/assets/963a45e2-c44d-4c15-a85b-a42f2dd209a1\" width=49% height=49%><img src=\"https://github.com/user-attachments/assets/84f85f6d-977c-4f2d-b290-0b16426fc21f\" width=49% height=49%>\r\n<img src=\"https://github.com/user-attachments/assets/3615f788-c055-4d18-8acb-6d26a3884815\" width=49% height=49%><img src=\"https://github.com/user-attachments/assets/26f533e5-65e5-4e0d-bf46-2a392c96439e\" width=49% height=49%>\r\n<img src=\"https://github.com/user-attachments/assets/98f55616-4d0d-4eac-8a6c-c4076432f50f\" width=100% height=100%>\r\n\r\n(code & data to generate them is [here](https://gist.github.com/sipa/f002a7e552fedabd5d727eb4a55624f0))",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2925757556",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2928370752,
      "node_id": "IC_kwDOABII586ui2RA",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2928370752",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-02T01:43:15Z",
      "updated_at": "2025-06-04T12:42:51Z",
      "author_association": "MEMBER",
      "body": "If people are interested in a much larger scale comparison between the old and the new algorithm, checkout https://github.com/sipa/bitcoin/commits/bench_sfl_css, build its `bin/bench_bitcoin`, and:\r\n\r\n```\r\nwget https://bitcoin.sipa.be/clusters/clusters.tgz\r\ntar -xzf clusters.tgz\r\nfor F in clusters_sim2023_large clusters_medium clusters_spanning clusters_bipartite; do time ./build/bin/bench_bitcoin --filter=\"LinearizeDataSet\" <$F >$F.out; done\r\nzstd -19 clusters_*.out\r\n```\r\n\r\nAnd then PR the resulting `*.out.zst` files to https://github.com/sipa/lin-benches/tree/main/data.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2928370752",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2939458958,
      "node_id": "IC_kwDOABII586vNJWO",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2939458958",
      "actor": {
        "login": "l0rinc",
        "id": 1841944,
        "node_id": "MDQ6VXNlcjE4NDE5NDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1841944?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/l0rinc",
        "html_url": "https://github.com/l0rinc",
        "followers_url": "https://api.github.com/users/l0rinc/followers",
        "following_url": "https://api.github.com/users/l0rinc/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/l0rinc/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/l0rinc/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/l0rinc/subscriptions",
        "organizations_url": "https://api.github.com/users/l0rinc/orgs",
        "repos_url": "https://api.github.com/users/l0rinc/repos",
        "events_url": "https://api.github.com/users/l0rinc/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/l0rinc/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-04T10:21:34Z",
      "updated_at": "2025-06-04T10:21:34Z",
      "author_association": "CONTRIBUTOR",
      "body": "I've run the command on a `Raspberry Pi 4 Model B - Cortex-A72 4-Core ARM with SanDisk SSD PLUS 1TB (USB 3.0)` with to have data about lower-end hardware as well. \r\n\r\n<details>\r\n<summary>full command</summary>\r\n\r\n```bash\r\ngit remote add sipa https://github.com/sipa/bitcoin.git || true && git fetch sipa bench_sfl_css && git switch -C bench_sfl_css sipa/bench_sfl_css && \\\r\ngit clean -fxd && git reset --hard && \\\r\ncmake -B build -DBUILD_BENCH=ON -DCMAKE_BUILD_TYPE=Release && cmake --build build -j\"$(nproc)\" && \\\r\nwget -q https://bitcoin.sipa.be/clusters/clusters.tgz && tar -xzf clusters.tgz && \\\r\nfor F in clusters_sim2023_large clusters_medium clusters_spanning clusters_bipartite; do \\\r\n    time build/bin/bench_bitcoin --filter=\"LinearizeDataSet\" <\"$F\" >\"$F.out\"; \\\r\ndone && \\\r\ntar -czf clusters.out.tgz clusters_*.out\r\n```\r\n\r\n</details>\r\n\r\nIt took considerably longer than expected (~13h):\r\n* `clusters_sim2023_large`: 11h 39m\r\n* `clusters_medium`: 26m 33s\r\n* `clusters_spanning`: 19m 37s\r\n* `clusters_bipartite`: 37m 17s\r\n\r\nLet's see if I can attach it here: [clusters.out.tgz](https://github.com/user-attachments/files/20589411/clusters.out.tgz)\r\n",
      "user": {
        "login": "l0rinc",
        "id": 1841944,
        "node_id": "MDQ6VXNlcjE4NDE5NDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1841944?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/l0rinc",
        "html_url": "https://github.com/l0rinc",
        "followers_url": "https://api.github.com/users/l0rinc/followers",
        "following_url": "https://api.github.com/users/l0rinc/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/l0rinc/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/l0rinc/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/l0rinc/subscriptions",
        "organizations_url": "https://api.github.com/users/l0rinc/orgs",
        "repos_url": "https://api.github.com/users/l0rinc/repos",
        "events_url": "https://api.github.com/users/l0rinc/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/l0rinc/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2939458958",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 2939904739,
      "node_id": "IC_kwDOABII586vO2Lj",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2939904739",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-04T12:44:36Z",
      "updated_at": "2025-06-04T12:46:07Z",
      "author_association": "MEMBER",
      "body": "I've created a repo for benchmark data, and added my results plus @l0rinc's: https://github.com/sipa/lin-benches/tree/main/data.\r\n\r\nAlso, is this with 32-bit or 64-bit userspace?",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2939904739",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "mentioned",
      "id": 17981057029,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAQvwSgF",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17981057029",
      "actor": {
        "login": "l0rinc",
        "id": 1841944,
        "node_id": "MDQ6VXNlcjE4NDE5NDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1841944?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/l0rinc",
        "html_url": "https://github.com/l0rinc",
        "followers_url": "https://api.github.com/users/l0rinc/followers",
        "following_url": "https://api.github.com/users/l0rinc/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/l0rinc/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/l0rinc/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/l0rinc/subscriptions",
        "organizations_url": "https://api.github.com/users/l0rinc/orgs",
        "repos_url": "https://api.github.com/users/l0rinc/repos",
        "events_url": "https://api.github.com/users/l0rinc/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/l0rinc/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-04T12:44:38Z"
    },
    {
      "event": "subscribed",
      "id": 17981057059,
      "node_id": "SE_lADOABII5863DfgAzwAAAAQvwSgj",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17981057059",
      "actor": {
        "login": "l0rinc",
        "id": 1841944,
        "node_id": "MDQ6VXNlcjE4NDE5NDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1841944?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/l0rinc",
        "html_url": "https://github.com/l0rinc",
        "followers_url": "https://api.github.com/users/l0rinc/followers",
        "following_url": "https://api.github.com/users/l0rinc/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/l0rinc/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/l0rinc/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/l0rinc/subscriptions",
        "organizations_url": "https://api.github.com/users/l0rinc/orgs",
        "repos_url": "https://api.github.com/users/l0rinc/repos",
        "events_url": "https://api.github.com/users/l0rinc/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/l0rinc/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-04T12:44:38Z"
    },
    {
      "event": "commented",
      "id": 2940026257,
      "node_id": "IC_kwDOABII586vPT2R",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2940026257",
      "actor": {
        "login": "l0rinc",
        "id": 1841944,
        "node_id": "MDQ6VXNlcjE4NDE5NDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1841944?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/l0rinc",
        "html_url": "https://github.com/l0rinc",
        "followers_url": "https://api.github.com/users/l0rinc/followers",
        "following_url": "https://api.github.com/users/l0rinc/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/l0rinc/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/l0rinc/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/l0rinc/subscriptions",
        "organizations_url": "https://api.github.com/users/l0rinc/orgs",
        "repos_url": "https://api.github.com/users/l0rinc/repos",
        "events_url": "https://api.github.com/users/l0rinc/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/l0rinc/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-04T13:22:05Z",
      "updated_at": "2025-06-04T13:22:05Z",
      "author_association": "CONTRIBUTOR",
      "body": "> Also, is this with 32-bit or 64-bit userspace?\r\n\r\n64-bit userspace (AArch64)\r\n```bash\r\n$ file bitcoind\r\nbitcoind: ELF 64-bit LSB pie executable, ARM aarch64, version 1 (GNU/Linux), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, BuildID[sha1]=7e059ec01f7460042910ca4ed15270382269c9d5, for GNU/Linux 3.7.0, with debug_info, not stripped\r\n```\r\n\r\n<details>\r\n<summary>additional details</summary>\r\n\r\n```bash\r\n$ getconf LONG_BIT\r\n64\r\n$ dpkg --print-architecture\r\narm64\r\n$ uname -m\r\naarch64\r\n```\r\n\r\n</details>",
      "user": {
        "login": "l0rinc",
        "id": 1841944,
        "node_id": "MDQ6VXNlcjE4NDE5NDQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1841944?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/l0rinc",
        "html_url": "https://github.com/l0rinc",
        "followers_url": "https://api.github.com/users/l0rinc/followers",
        "following_url": "https://api.github.com/users/l0rinc/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/l0rinc/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/l0rinc/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/l0rinc/subscriptions",
        "organizations_url": "https://api.github.com/users/l0rinc/orgs",
        "repos_url": "https://api.github.com/users/l0rinc/repos",
        "events_url": "https://api.github.com/users/l0rinc/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/l0rinc/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2940026257",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18119296956,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQ3_oe8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18119296956",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "58b6fc7b4d86a55b6ef603c5c224c024a1633e1f",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/58b6fc7b4d86a55b6ef603c5c224c024a1633e1f",
      "created_at": "2025-06-12T16:32:53Z"
    },
    {
      "event": "commented",
      "id": 2967662605,
      "node_id": "IC_kwDOABII586w4vAN",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2967662605",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-12T17:28:34Z",
      "updated_at": "2025-06-12T17:28:34Z",
      "author_association": "MEMBER",
      "body": "Rebased on top of #30605.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-2967662605",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18122293050,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQ4LD86",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18122293050",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "8b3968fcf16c0622ed9e5c1f879f7585f1b409f7",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/8b3968fcf16c0622ed9e5c1f879f7585f1b409f7",
      "created_at": "2025-06-12T20:23:31Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18153032810,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAQ6AUxq",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18153032810",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "505bc96f11699cc93116dba688944d8e3e867cbd",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/505bc96f11699cc93116dba688944d8e3e867cbd",
      "created_at": "2025-06-14T22:56:29Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18577466813,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAARTTaW9",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18577466813",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "545c11da465b2e7beda9eedc55d94a7c328a6039",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/545c11da465b2e7beda9eedc55d94a7c328a6039",
      "created_at": "2025-07-11T03:19:17Z"
    },
    {
      "event": "labeled",
      "id": 18879085564,
      "node_id": "LE_lADOABII5863DfgAzwAAAARlR_v8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18879085564",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-07-29T13:38:10Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 19065088361,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAARwXilp",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19065088361",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "6a7377d09981d59963792d01bd0bdfed608628f0",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/6a7377d09981d59963792d01bd0bdfed608628f0",
      "created_at": "2025-08-09T03:53:54Z"
    },
    {
      "event": "labeled",
      "id": 19065522331,
      "node_id": "LE_lADOABII5863DfgAzwAAAARwZMib",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19065522331",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-08-09T04:45:24Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3170201265,
      "node_id": "IC_kwDOABII58689W6x",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3170201265",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-08-09T04:45:26Z",
      "updated_at": "2025-08-09T04:45:26Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `no wallet, libbitcoinkernel`: https://github.com/bitcoin/bitcoin/runs/47723469045</sub>\n<sub>LLM reason (âœ¨ experimental): The build failed due to compilation errors in cluster_linearize.cpp caused by incorrect member access of a tuple, leading to a build error.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3170201265",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "unlabeled",
      "id": 19065563066,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAARwZWe6",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19065563066",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-08-09T04:49:58Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 19067741928,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAARwhqbo",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19067741928",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "8bca6bb6613c61a432100f70ddd529b214f82180",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/8bca6bb6613c61a432100f70ddd529b214f82180",
      "created_at": "2025-08-09T13:43:39Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 19068209278,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAARwjch-",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19068209278",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "3d2b9b410afe711e78cb39cea817e553894d69e3",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/3d2b9b410afe711e78cb39cea817e553894d69e3",
      "created_at": "2025-08-09T15:16:21Z"
    },
    {
      "event": "unlabeled",
      "id": 19068454244,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAARwkYVk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19068454244",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-08-09T16:11:59Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "convert_to_draft",
      "id": 19640770308,
      "node_id": "CTDE_lADOABII5863DfgAzwAAAASSrl8E",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19640770308",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-09-11T15:31:42Z"
    },
    {
      "event": "commented",
      "id": 3281455036,
      "node_id": "IC_kwDOABII587Dlwe8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3281455036",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-09-11T15:32:12Z",
      "updated_at": "2025-09-11T15:32:12Z",
      "author_association": "MEMBER",
      "body": "I'm working on some improvements and reorganization of the commit here, so marking it as draft for now.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3281455036",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 19640795635,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAASSrsHz",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/19640795635",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "d2b1b99217e2e2dc0aa476b331f18ad8509bdd86",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/d2b1b99217e2e2dc0aa476b331f18ad8509bdd86",
      "created_at": "2025-09-11T15:32:46Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20325418677,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAS7fUa1",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20325418677",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "af64d36848124dee85c0d0c70400fd8c30172246",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/af64d36848124dee85c0d0c70400fd8c30172246",
      "created_at": "2025-10-16T18:01:47Z"
    },
    {
      "event": "ready_for_review",
      "id": 20325472340,
      "node_id": "RFRE_lADOABII5863DfgAzwAAAAS7fhhU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20325472340",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-10-16T18:04:26Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20326289139,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAS7io7z",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20326289139",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "68c4b554f5c24ccdee94b6243a52fab009863775",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/68c4b554f5c24ccdee94b6243a52fab009863775",
      "created_at": "2025-10-16T18:51:16Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20326360247,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAS7i6S3",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20326360247",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "52b983bf90e0bc5809a166924abe762f0d2bd975",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/52b983bf90e0bc5809a166924abe762f0d2bd975",
      "created_at": "2025-10-16T18:54:16Z"
    },
    {
      "event": "commented",
      "id": 3412455674,
      "node_id": "IC_kwDOABII587LZfD6",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3412455674",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-10-16T19:01:42Z",
      "updated_at": "2025-10-16T19:01:42Z",
      "author_association": "MEMBER",
      "body": "Rebased, and made a significant change to the SFL algorithm itself:\r\n* Switched to a different technique for making the initial state topological. The big advantage is that this approach also works when one already has a linearization which is not entirely topological already.\r\n\r\nAlso the following changes to the `cluster_linearize.h` code in general:\r\n* Using SFL gaining the ability to fix existing linearizations, replaced `FixLinearization` with just making this feature part of `Linearize`.\r\n* With the LIMO-based `Linearize`, and `MergeLinearizations` (see below), gone, there is no more need for the `LinearizationChunking` class.\r\n\r\nAnd as a result some changes in `TxGraph` are possible too:\r\n* Removed the need for `FixLinearization` by introducing `QualityLevel` states to represent \"may be non-topological\", which makes the next call to `Linearize()` do the fixing instead.\r\n* Removed `MergeLinearizations`, as it was never used.\r\n* As SFL, upon being fed an existing linearization, runs through an initialization procedure that is pretty much equivalent to `PostLinearize`, drop all calls to `PostLinearize()` *prior* to `Linearize()` calls.\r\n* Because the new algorithm randomizes output linearization order (within equal-chunk-feerate parts), undo some of the non-determinism that introduces by always calling `PostLinearize()` *after* `Linearize()` calls (before it would only do this if non-optimal).\r\n",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3412455674",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 3412487618,
      "node_id": "IC_kwDOABII587LZm3C",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3412487618",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-10-16T19:10:54Z",
      "updated_at": "2025-10-16T19:10:54Z",
      "author_association": "MEMBER",
      "body": "This PR has grown quite a bit in scope (despite still being a net negative in LoC!), so I don't think it's unreasonable to split it up into an SFL-specific one, and one with follow-up changes to `txgraph`, or even further. I'll wait for reviewer comments.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3412487618",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "review_requested",
      "id": 20369331382,
      "node_id": "RRE_lADOABII5863DfgAzwAAAAS-G1S2",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20369331382",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-10-20T00:29:45Z",
      "requested_reviewer": {
        "login": "Copilot",
        "id": 175728472,
        "node_id": "BOT_kgDOCnlnWA",
        "avatar_url": "https://avatars.githubusercontent.com/in/946600?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/Copilot",
        "html_url": "https://github.com/apps/copilot-pull-request-reviewer",
        "followers_url": "https://api.github.com/users/Copilot/followers",
        "following_url": "https://api.github.com/users/Copilot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/Copilot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/Copilot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/Copilot/subscriptions",
        "organizations_url": "https://api.github.com/users/Copilot/orgs",
        "repos_url": "https://api.github.com/users/Copilot/repos",
        "events_url": "https://api.github.com/users/Copilot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/Copilot/received_events",
        "type": "Bot",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "review_requester": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    },
    {
      "event": "reviewed",
      "id": 3354761107,
      "node_id": "PRR_kwDOABII587H9ZeT",
      "url": null,
      "actor": null,
      "commit_id": "52b983bf90e0bc5809a166924abe762f0d2bd975",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-10-20T00:30:41Z",
      "author_association": "NONE",
      "body": "## Pull Request Overview\n\nThis PR replaces the existing cluster linearization algorithm (LIMO with candidate-set search) with a new spanning-forest linearization (SFL) algorithm that offers significantly better performance for complex clusters. The new algorithm uses a fundamentally different approach based on maintaining spanning trees within chunks and performing split/merge operations.\n\n**Key Changes:**\n- Replaces search-based linearization with spanning-forest based approach\n- Simplifies quality level management by introducing `NEEDS_FIX` and `NEEDS_SPLIT_FIX` states\n- Updates the `ExtractTransactions` interface to use two separate visitor callbacks\n\n### Reviewed Changes\n\nCopilot reviewed 6 out of 7 changed files in this pull request and generated 2 comments.\n\n<details>\n<summary>Show a summary per file</summary>\n\n| File | Description |\r\n| ---- | ----------- |\r\n| src/txgraph.cpp | Implements quality level changes, updates transaction extraction to use two-pass visitors, modifies merging/splitting logic to work with new algorithm |\r\n| src/test/util/cluster_linearize.h | Adjusts test utilities for changed type parameters and updated iteration bounds |\r\n| src/test/fuzz/txgraph.cpp | Updates fuzz tests to use new chunking API |\r\n| src/test/fuzz/cluster_linearize.cpp | Removes tests for deprecated algorithm components, adds tests for new chunking functions |\r\n| src/cluster_linearize.h | Replaces entire linearization algorithm implementation with spanning-forest approach, adds `ChunkLinearizationInfo` function |\r\n| src/bench/cluster_linearize.cpp | Updates benchmarks to test new algorithm with historical and random cluster examples |\n</details>\n\n\n\n<details>\n<summary>Comments suppressed due to low confidence (1)</summary>\n\n**src/test/fuzz/cluster_linearize.cpp:1**\n* [nitpick] The variable name `done` changed from `TestBitSet` to `SetType`. While this makes the code more generic, verify that this change aligns with the intended test coverage, as the original code may have been explicitly testing with `TestBitSet` for specific reasons.\n```\n// Copyright (c) The Bitcoin Core developers\n```\n</details>\n\n\n\n---\n\n<sub>**Tip:** Customize your code reviews with copilot-instructions.md. <a href=\"/bitcoin/bitcoin/new/master/.github?filename=copilot-instructions.md\" class=\"Link--inTextBlock\" target=\"_blank\" rel=\"noopener noreferrer\">Create the file</a> or <a href=\"https://docs.github.com/en/copilot/customizing-copilot/adding-repository-custom-instructions-for-github-copilot\" class=\"Link--inTextBlock\" target=\"_blank\" rel=\"noopener noreferrer\">learn how to get started</a>.</sub>",
      "user": {
        "login": "Copilot",
        "id": 175728472,
        "node_id": "BOT_kgDOCnlnWA",
        "avatar_url": "https://avatars.githubusercontent.com/in/946600?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/Copilot",
        "html_url": "https://github.com/apps/copilot-pull-request-reviewer",
        "followers_url": "https://api.github.com/users/Copilot/followers",
        "following_url": "https://api.github.com/users/Copilot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/Copilot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/Copilot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/Copilot/subscriptions",
        "organizations_url": "https://api.github.com/users/Copilot/orgs",
        "repos_url": "https://api.github.com/users/Copilot/repos",
        "events_url": "https://api.github.com/users/Copilot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/Copilot/received_events",
        "type": "Bot",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3354761107",
      "submitted_at": "2025-10-20T00:30:41Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20509541606,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATGdsTm",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20509541606",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "5ea671df2a33765452e6591760e629f3f83b29f8",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/5ea671df2a33765452e6591760e629f3f83b29f8",
      "created_at": "2025-10-26T12:56:09Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20518318012,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATG_K-8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20518318012",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "222a43bd390657f38c8399bc6478aa5376cff293",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/222a43bd390657f38c8399bc6478aa5376cff293",
      "created_at": "2025-10-27T08:10:54Z"
    },
    {
      "event": "commented",
      "id": 3450065966,
      "node_id": "IC_kwDOABII587No9Qu",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3450065966",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-10-27T08:35:59Z",
      "updated_at": "2025-10-27T08:35:59Z",
      "author_association": "MEMBER",
      "body": "I have added an additional fuzz test (`clusterlin_sfl`) which verifies properties of the underlying data structure (`SpanningForestState`) plus sanity checks on it (as opposed to `clusterlin_linearize` which only tests the higher-level `Linearize()` function implemented in function of it).\r\n\r\nIt's no longer a net reduction in LoC now :(",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3450065966",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20519308683,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATHC82L",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20519308683",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "159b7d8999017413eca68685a574e82b6a0a429c",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/159b7d8999017413eca68685a574e82b6a0a429c",
      "created_at": "2025-10-27T09:00:21Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20677656594,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATQfAAS",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20677656594",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "b99e56b2168a244e416438706b70e2b0cd8fdefb",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/b99e56b2168a244e416438706b70e2b0cd8fdefb",
      "created_at": "2025-11-03T15:22:31Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 20701467647,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATR51P_",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/20701467647",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "0ed64ff9fc4637074489e462b8fc34a27fbd8c0c",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/0ed64ff9fc4637074489e462b8fc34a27fbd8c0c",
      "created_at": "2025-11-04T12:25:11Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21122758420,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATrA7cU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21122758420",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "052b313ebc52bbf78fe127882fd6811efbaf0240",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/052b313ebc52bbf78fe127882fd6811efbaf0240",
      "created_at": "2025-11-23T15:42:27Z"
    },
    {
      "event": "commented",
      "id": 3568091456,
      "node_id": "IC_kwDOABII587UrMFA",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3568091456",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-11-23T15:42:52Z",
      "updated_at": "2025-11-23T15:42:52Z",
      "author_association": "MEMBER",
      "body": "Rebased on top of #33629.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3568091456",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "labeled",
      "id": 21163652528,
      "node_id": "LE_lADOABII5863DfgAzwAAAATtc7Ww",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21163652528",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-11-25T12:33:58Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21163750740,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAATtdTVU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21163750740",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/060e1856b1749f4172875455e8e65a303608c709",
      "created_at": "2025-11-25T12:38:56Z"
    },
    {
      "event": "commented",
      "id": 3575453927,
      "node_id": "IC_kwDOABII587VHRjn",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3575453927",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-11-25T12:39:31Z",
      "updated_at": "2025-11-25T12:39:31Z",
      "author_association": "MEMBER",
      "body": "Rebased after merge of #33629.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3575453927",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "unlabeled",
      "id": 21166816492,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAATto_zs",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21166816492",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-11-25T14:56:34Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "milestoned",
      "id": 21224283348,
      "node_id": "MIE_lADOABII5863DfgAzwAAAATxENzU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21224283348",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-11-27T16:09:02Z",
      "milestone": {
        "title": "31.0"
      }
    },
    {
      "event": "review_requested",
      "id": 21302255561,
      "node_id": "RRE_lADOABII5863DfgAzwAAAAT1tp_J",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21302255561",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-02T10:33:28Z",
      "requested_reviewer": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "review_requester": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    },
    {
      "event": "review_requested",
      "id": 21302255597,
      "node_id": "RRE_lADOABII5863DfgAzwAAAAT1tp_t",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21302255597",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-02T10:33:28Z",
      "requested_reviewer": {
        "login": "sdaftuar",
        "id": 7463573,
        "node_id": "MDQ6VXNlcjc0NjM1NzM=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sdaftuar",
        "html_url": "https://github.com/sdaftuar",
        "followers_url": "https://api.github.com/users/sdaftuar/followers",
        "following_url": "https://api.github.com/users/sdaftuar/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sdaftuar/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sdaftuar/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
        "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
        "repos_url": "https://api.github.com/users/sdaftuar/repos",
        "events_url": "https://api.github.com/users/sdaftuar/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "review_requester": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    },
    {
      "event": "review_requested",
      "id": 21302255617,
      "node_id": "RRE_lADOABII5863DfgAzwAAAAT1tqAB",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21302255617",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-02T10:33:28Z",
      "requested_reviewer": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "review_requester": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    },
    {
      "event": "reviewed",
      "id": 3536407029,
      "node_id": "PRR_kwDOABII587SyUn1",
      "url": null,
      "actor": null,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-03T19:10:47Z",
      "author_association": "CONTRIBUTOR",
      "body": "Did a first pass of the changes in `cluster_linearize.h`, left a couple small comments. I'm running a few of the fuzz targets, including the new one, and I'll leave those going for a while.\r\n\r\nStill need to look at the tests thoroughly. Let me know if there's anything specific you think reviewers can do that would be useful.",
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3536407029",
      "submitted_at": "2025-12-03T19:10:28Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "commented",
      "id": 3609135872,
      "node_id": "IC_kwDOABII587XHwsA",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3609135872",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-03T22:35:32Z",
      "updated_at": "2025-12-03T22:35:32Z",
      "author_association": "MEMBER",
      "body": "FWIW, I'm writing a Python version of SFL with simpler data structures and less optimizations. It needs some polishing, but I'll post it here. It could be used as a form of documentation, or live in the functional test framework.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3609135872",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "commented",
      "id": 3612546191,
      "node_id": "IC_kwDOABII587XUxSP",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3612546191",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-04T14:32:44Z",
      "updated_at": "2025-12-04T14:32:44Z",
      "author_association": "MEMBER",
      "body": "glancing through the PR now\r\n\r\nhow bad would it be to merge all the way through \"clusterlin: replace cluster linearization with SFL implementation (feature)\", maybe some of the commits that drops unused things (ala \"clusterlin: remove unused MergeLinearizations (cleanup)\") and defer the other optimisations for next PR?",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3612546191",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21403892232,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT7xXoI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21403892232",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "a84d98035fd3ebc79b9ba847478e7bf51a710988",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/a84d98035fd3ebc79b9ba847478e7bf51a710988",
      "created_at": "2025-12-06T20:15:37Z"
    },
    {
      "event": "commented",
      "id": 3621078014,
      "node_id": "IC_kwDOABII587X1UP-",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3621078014",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-06T20:18:51Z",
      "updated_at": "2025-12-06T20:18:51Z",
      "author_association": "MEMBER",
      "body": "I have reorganized this PR, dropping most optimizations in favor of a future follow-up.\r\n\r\nAddressed comments, added more explanations, and made a few code simplifications.\r\n\r\nA python version of the algorithm, lacking most optimizations and using simpler data structures than the C++ version, can be found in https://gist.github.com/sipa/822f60db6608a26bb4aae75fd31bcb12 (in sfl.py).",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3621078014",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21404088225,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT7yHeh",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21404088225",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "8ca4b324f1954894685c6602b6e21e3687ecca4b",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/8ca4b324f1954894685c6602b6e21e3687ecca4b",
      "created_at": "2025-12-06T20:50:31Z"
    },
    {
      "event": "labeled",
      "id": 21404098424,
      "node_id": "LE_lADOABII5863DfgAzwAAAAT7yJ94",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21404098424",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-06T20:51:54Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3621105129,
      "node_id": "IC_kwDOABII587X1a3p",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3621105129",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-06T20:52:03Z",
      "updated_at": "2025-12-06T20:52:03Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `Windows native, fuzz, VS 2022`: https://github.com/bitcoin/bitcoin/actions/runs/19993713242/job/57338160248</sub>\n<sub>LLM reason (âœ¨ experimental): Fuzz txgraph failed due to an assertion failure in cluster_linearize (transactions overlapping in SetInfo|=), causing exit code 1.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3621105129",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21405769571,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT74h9j",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21405769571",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "8fe6a71941ab327772f6018c9da9d7ee8f371bc4",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/8fe6a71941ab327772f6018c9da9d7ee8f371bc4",
      "created_at": "2025-12-06T23:13:30Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21406444321,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT77Gsh",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21406444321",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "d2e7f53c3c3c451d6e193463cf0eb93aa8c9711e",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/d2e7f53c3c3c451d6e193463cf0eb93aa8c9711e",
      "created_at": "2025-12-07T00:51:21Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21406827477,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT78kPV",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21406827477",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "ea86b293ee3a0e91093cc83f244e3204e1240c41",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/ea86b293ee3a0e91093cc83f244e3204e1240c41",
      "created_at": "2025-12-07T02:09:37Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21407370808,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT7-o44",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21407370808",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "created_at": "2025-12-07T03:49:21Z"
    },
    {
      "event": "unlabeled",
      "id": 21407706752,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAT7_66A",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21407706752",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-07T05:06:33Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3623680270,
      "node_id": "IC_kwDOABII587X_PkO",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3623680270",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-07T22:52:00Z",
      "updated_at": "2025-12-07T22:52:10Z",
      "author_association": "MEMBER",
      "body": "Now a proper repository for the Python version: https://github.com/sipa/pyclusterlin",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3623680270",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "reviewed",
      "id": 3541747493,
      "node_id": "PRR_kwDOABII587TGscl",
      "url": null,
      "actor": null,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-08T19:21:52Z",
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3541747493",
      "submitted_at": "2025-12-08T19:21:52Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21454915345,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAT-0AcR",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21454915345",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/d56ddf821d928c9fdac812bb2768a360aeb72913",
      "created_at": "2025-12-09T14:20:18Z"
    },
    {
      "event": "commented",
      "id": 3637245706,
      "node_id": "IC_kwDOABII587Yy_cK",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3637245706",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-10T14:04:51Z",
      "updated_at": "2025-12-10T14:04:51Z",
      "author_association": "MEMBER",
      "body": "I have pushed an additional WIP commit which rewords and expands the big `SpanningForestState` comment. LMK what you think. If reviewers think it's an improvement, I'll squash it into the individual commits.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3637245706",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "reviewed",
      "id": 3562843288,
      "node_id": "PRR_kwDOABII587UXKyY",
      "url": null,
      "actor": null,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-10T15:01:46Z",
      "author_association": "MEMBER",
      "body": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d seems like an improvement, only a couple comments",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3562843288",
      "submitted_at": "2025-12-10T15:01:46Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "reviewed",
      "id": 3562950105,
      "node_id": "PRR_kwDOABII587UXk3Z",
      "url": null,
      "actor": null,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-10T15:06:14Z",
      "author_association": "CONTRIBUTOR",
      "body": "I think this new comment is better.",
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3562950105",
      "submitted_at": "2025-12-10T15:06:14Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21487892756,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUAxzkU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21487892756",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "ab94844ff0c3040d3c11ee1d12297bb0358a70ad",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/ab94844ff0c3040d3c11ee1d12297bb0358a70ad",
      "created_at": "2025-12-10T20:11:19Z"
    },
    {
      "event": "commented",
      "id": 3638795504,
      "node_id": "IC_kwDOABII587Y45zw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3638795504",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-10T20:13:43Z",
      "updated_at": "2025-12-10T20:13:43Z",
      "author_association": "MEMBER",
      "body": "I've squashed in the new explainer comment, plus a number of other changes:\r\n* Split out loading of an existing linearization into a separate commit.\r\n* Split out adding support for reading non-topological inputs to `ReadLinearization` into a separate commit.\r\n* Various small improvements to benchmarks, tests, comments.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3638795504",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21514502781,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUCXUJ9",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21514502781",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "611ca5ef83f6d207a8cdeffb063e6f9ed8857011",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/611ca5ef83f6d207a8cdeffb063e6f9ed8857011",
      "created_at": "2025-12-11T21:49:05Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21514520828,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUCXYj8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21514520828",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "7788709ef4a2454ceeeeabbfe565f5015809f51b",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/7788709ef4a2454ceeeeabbfe565f5015809f51b",
      "created_at": "2025-12-11T21:50:24Z"
    },
    {
      "event": "labeled",
      "id": 21514530867,
      "node_id": "LE_lADOABII5863DfgAzwAAAAUCXbAz",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21514530867",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-11T21:51:07Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "unlabeled",
      "id": 21515631636,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAUCbnwU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21515631636",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-11T23:07:13Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3644700618,
      "node_id": "IC_kwDOABII587ZPbfK",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3644700618",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T03:02:17Z",
      "updated_at": "2025-12-12T03:02:17Z",
      "author_association": "MEMBER",
      "body": "I have added an extensive comment inside the `SpanningForestState::Activate()` function.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3644700618",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21531336042,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUDXh1q",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21531336042",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "abb3e8cb639f6a1729fb5454e16452091954c93e",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/abb3e8cb639f6a1729fb5454e16452091954c93e",
      "created_at": "2025-12-12T16:04:14Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21532143780,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUDanCk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21532143780",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/5259f95b70a77749ced95091454c355803adcf24",
      "created_at": "2025-12-12T16:41:02Z"
    },
    {
      "event": "commented",
      "id": 3647326460,
      "node_id": "IC_kwDOABII587ZZcj8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3647326460",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T16:43:29Z",
      "updated_at": "2025-12-12T16:43:29Z",
      "author_association": "MEMBER",
      "body": "I have rewritten `SpanningForestState::UpdateChunk` to no longer traverse the chunk by walking dependencies, but by looping over all dependencies of the chunk directly, and using the `top_setinfo` to figure out which ones to update. It's a few percent faster, simpler, and additionally allowed dropping the tracking of parent dependencies of a transaction entirely.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3647326460",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "reviewed",
      "id": 3564457615,
      "node_id": "PRR_kwDOABII587UdU6P",
      "url": null,
      "actor": null,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-12T20:58:15Z",
      "author_association": "MEMBER",
      "body": "reviewed through ab1416bb471c9326bb77ee464be6aeebf663e024\r\n\r\ncontinuing on with optimizations next\r\n\r\nonly minor quibbles after the nice reworkings of comments and UpdateChunk",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3564457615",
      "submitted_at": "2025-12-12T20:56:14Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21538016275,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUDxAwT",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21538016275",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "fd9d8664c9776d3c5d2bb5f28a70814ee2f030d7",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/fd9d8664c9776d3c5d2bb5f28a70814ee2f030d7",
      "created_at": "2025-12-12T22:54:24Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21538131581,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUDxc59",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21538131581",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "568d4271b445fdcbd0b371459b806113e36c4dd6",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/568d4271b445fdcbd0b371459b806113e36c4dd6",
      "created_at": "2025-12-12T23:05:47Z"
    },
    {
      "event": "labeled",
      "id": 21538147220,
      "node_id": "LE_lADOABII5863DfgAzwAAAAUDxguU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21538147220",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T23:07:05Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3648454810,
      "node_id": "IC_kwDOABII587ZdwCa",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3648454810",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T23:07:14Z",
      "updated_at": "2025-12-12T23:07:14Z",
      "author_association": "MEMBER",
      "body": "I have addressed most of @instagibbs's comments above, and also rewritten `SpanningForestState::SanityCheck` to no longer rely on walking clusters. It's a bit more verbose now, but maybe easier to follow.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3648454810",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "mentioned",
      "id": 21538150014,
      "node_id": "MEE_lADOABII5863DfgAzwAAAAUDxhZ-",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21538150014",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T23:07:15Z"
    },
    {
      "event": "subscribed",
      "id": 21538150037,
      "node_id": "SE_lADOABII5863DfgAzwAAAAUDxhaV",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21538150037",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T23:07:15Z"
    },
    {
      "event": "commented",
      "id": 3648455055,
      "node_id": "IC_kwDOABII587ZdwGP",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3648455055",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-12T23:07:18Z",
      "updated_at": "2025-12-12T23:07:18Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `Windows-cross to x86_64, ucrt`: https://github.com/bitcoin/bitcoin/actions/runs/20182170466/job/57944882529</sub>\n<sub>LLM reason (âœ¨ experimental): Compilation failed: -Werror treats a range-for loop copying a tuple in cluster_linearize.h as an error.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3648455055",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "unlabeled",
      "id": 21538787610,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAUDz9Ea",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21538787610",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-13T00:24:31Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21543145328,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUEEk9w",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21543145328",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "44b1cdf4cd5dcee201a3f6521990504673b4246d",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/44b1cdf4cd5dcee201a3f6521990504673b4246d",
      "created_at": "2025-12-13T16:07:15Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21549045999,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUEbFjv",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21549045999",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "5e16783d973a93a8691ebf8853748cadee38162c",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/5e16783d973a93a8691ebf8853748cadee38162c",
      "created_at": "2025-12-14T13:50:39Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21552794999,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUEpY13",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21552794999",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "f2d4c8f61e29e773882529faf001655f083ad537",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/f2d4c8f61e29e773882529faf001655f083ad537",
      "created_at": "2025-12-14T22:22:20Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21552911427,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUEp1RD",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21552911427",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "35afd642c79034329a845e82a853e6cc1892f648",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/35afd642c79034329a845e82a853e6cc1892f648",
      "created_at": "2025-12-14T22:46:53Z"
    },
    {
      "event": "labeled",
      "id": 21552917138,
      "node_id": "LE_lADOABII5863DfgAzwAAAAUEp2qS",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21552917138",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-14T22:48:12Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3652335409,
      "node_id": "IC_kwDOABII587Zsjcx",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3652335409",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-14T22:48:24Z",
      "updated_at": "2025-12-14T22:48:24Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `Windows-cross to x86_64, ucrt`: https://github.com/bitcoin/bitcoin/actions/runs/20215030449/job/58026651059</sub>\n<sub>LLM reason (âœ¨ experimental): Compilation failed due to a treated-as-error warning: a boolean expression is being compared to 0 in cluster_linearize.cpp, causing the build to fail.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3652335409",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "unlabeled",
      "id": 21553285210,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAUErQha",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21553285210",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-15T00:03:25Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21555349144,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUEzIaY",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21555349144",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "created_at": "2025-12-15T03:47:55Z"
    },
    {
      "event": "commented",
      "id": 3655633603,
      "node_id": "IC_kwDOABII587Z5IrD",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3655633603",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-15T13:24:38Z",
      "updated_at": "2025-12-15T13:24:38Z",
      "author_association": "MEMBER",
      "body": "I have made a number of changes here since my last comment:\r\n* Made a few more improvements/simplifications to `SpanningForestState::SanityCheck`.\r\n* Simplified the sub-chunk transaction order randomization in `SpanningForestState::GetLinearization`\r\n* Rewrote the `clusterlin_sfl` fuzz test to verify properties of every step of the algorithm, rather than a single final state. It's slower now, but more closely tracks properties like every split+merge improving the diagram, etc. \r\n\r\nI won't make substantial changes like these anymore unless requested by review.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3655633603",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "reviewed",
      "id": 3578357148,
      "node_id": "PRR_kwDOABII587VSWWc",
      "url": null,
      "actor": null,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-15T15:06:31Z",
      "author_association": "CONTRIBUTOR",
      "body": "I ran an incremental mutation test for this PR, specifically for `src/cluster_linearize.h` (which generated 222 mutants), considering unit (`cluster_linearize_tests`), functional (`mempool_packages`), and fuzzing.\r\n\r\nFor fuzzing, existing targets were run with qa-assets inputs. For the `clusterlin_sfl` target, I created a simple corpus from a few hours of executions (not very reliable).\r\n\r\nOverall, the tests are excellent, achieving a mutation rate of over 98% (excluding equivalent mutants and some useless ones). I've commented out some unkilled mutants here; feel free to ignore them or add tests to eliminate them if it makes sense.\r\n\r\nHappy to run it again if any relevant changes are made.",
      "user": {
        "login": "brunoerg",
        "id": 19480819,
        "node_id": "MDQ6VXNlcjE5NDgwODE5",
        "avatar_url": "https://avatars.githubusercontent.com/u/19480819?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/brunoerg",
        "html_url": "https://github.com/brunoerg",
        "followers_url": "https://api.github.com/users/brunoerg/followers",
        "following_url": "https://api.github.com/users/brunoerg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/brunoerg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/brunoerg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/brunoerg/subscriptions",
        "organizations_url": "https://api.github.com/users/brunoerg/orgs",
        "repos_url": "https://api.github.com/users/brunoerg/repos",
        "events_url": "https://api.github.com/users/brunoerg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/brunoerg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3578357148",
      "submitted_at": "2025-12-15T15:06:31Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "reviewed",
      "id": 3579423256,
      "node_id": "PRR_kwDOABII587VWaoY",
      "url": null,
      "actor": null,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-15T21:08:35Z",
      "author_association": "MEMBER",
      "body": "reviewed through 26661a6c655ad148d3ecf200c64b89c439b6d44a\r\n\r\nsorry all I have is ticky-tacky, will go one more pass over before finishing",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3579423256",
      "submitted_at": "2025-12-15T21:08:35Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21577026674,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUGF0xy",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21577026674",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "382cf0ed5f4a4335ada6d4d2d5367db4fa9ca3b4",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/382cf0ed5f4a4335ada6d4d2d5367db4fa9ca3b4",
      "created_at": "2025-12-15T21:20:35Z"
    },
    {
      "event": "reviewed",
      "id": 3580207461,
      "node_id": "PRR_kwDOABII587VZaFl",
      "url": null,
      "actor": null,
      "commit_id": "382cf0ed5f4a4335ada6d4d2d5367db4fa9ca3b4",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-15T21:21:43Z",
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3580207461",
      "submitted_at": "2025-12-15T21:21:43Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21581663599,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUGXg1v",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21581663599",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "edc64813b221598994da52cc5b7124a02ab7e042",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/edc64813b221598994da52cc5b7124a02ab7e042",
      "created_at": "2025-12-16T03:03:40Z"
    },
    {
      "event": "reviewed",
      "id": 3583956871,
      "node_id": "PRR_kwDOABII587VnteH",
      "url": null,
      "actor": null,
      "commit_id": "edc64813b221598994da52cc5b7124a02ab7e042",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-16T16:27:04Z",
      "author_association": "MEMBER",
      "body": "ACK edc64813b221598994da52cc5b7124a02ab7e042\r\n\r\nMuch more straightforward than the in-master linearization approach, even ignoring its clear performance benefits.\r\n",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3583956871",
      "submitted_at": "2025-12-16T16:27:04Z",
      "state": "APPROVED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "review_requested",
      "id": 21597058219,
      "node_id": "RRE_lADOABII5863DfgAzwAAAAUHSPSr",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21597058219",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-16T16:27:09Z",
      "requested_reviewer": {
        "login": "jonatack",
        "id": 2415484,
        "node_id": "MDQ6VXNlcjI0MTU0ODQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2415484?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jonatack",
        "html_url": "https://github.com/jonatack",
        "followers_url": "https://api.github.com/users/jonatack/followers",
        "following_url": "https://api.github.com/users/jonatack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jonatack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jonatack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jonatack/subscriptions",
        "organizations_url": "https://api.github.com/users/jonatack/orgs",
        "repos_url": "https://api.github.com/users/jonatack/repos",
        "events_url": "https://api.github.com/users/jonatack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jonatack/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "review_requester": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    },
    {
      "event": "reviewed",
      "id": 3594428615,
      "node_id": "PRR_kwDOABII587WPqDH",
      "url": null,
      "actor": null,
      "commit_id": "edc64813b221598994da52cc5b7124a02ab7e042",
      "commit_url": null,
      "created_at": null,
      "updated_at": "2025-12-18T19:04:59Z",
      "author_association": "CONTRIBUTOR",
      "body": "ACK edc64813b221598994da52cc5b7124a02ab7e042\n\nThis implementation was easier for me to review/understand than the current one on master, which I spent some time with when reviewing https://github.com/bitcoin/bitcoin/pull/30605. We'll see if I still feel that way after looking at the optimizations.\n\nI ran the `clusterlin_sfl` and `clusterlin_linearize` fuzz targets for a while and no issues came up. Here's the coverage: [sfl](https://marcofleon.github.io/coverage/clusterlin_sfl/) and [linearize](https://marcofleon.github.io/coverage/clusterlin_linearize/).\n\nI also verified that the [test vectors](https://github.com/sipa/pyclusterlin/blob/main/linearization_tests.json) in the python repo are the same ones in the unit test. Both tests pass and arrive at optimal linearizations for the chosen mempool clusters.\n\nLeft a couple non-blocking comments that can be addressed in the follow up, if desired.",
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#pullrequestreview-3594428615",
      "submitted_at": "2025-12-18T19:04:59Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDg2ZGQ1NTBhOWI3MDYxOTVhOWQzZDYxMjRiZTNmN2Q1NjljY2JmZmU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/86dd550a9b706195a9d3d6124be3f7d569ccbffe",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/86dd550a9b706195a9d3d6124be3f7d569ccbffe",
      "tree": {
        "sha": "90b05a7a6223c25617bf5e82ec9c4245561ca86e",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/90b05a7a6223c25617bf5e82ec9c4245561ca86e"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/516ae5ede44a8a6abc59e90f9d89913e254524f4",
          "sha": "516ae5ede44a8a6abc59e90f9d89913e254524f4",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/516ae5ede44a8a6abc59e90f9d89913e254524f4"
        }
      ],
      "message": "clusterlin: add known-correct optimal linearization tests (tests)",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T19:17:28Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-05-17T18:31:38Z"
      },
      "sha": "86dd550a9b706195a9d3d6124be3f7d569ccbffe"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDk1YmZlN2Q1NzRjZmM2OWJiMzVlMzg2Yjg4ZTJjMzAyNmI4YTczMTU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/95bfe7d574cfc69bb35e386b88e2c3026b8a7315",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/95bfe7d574cfc69bb35e386b88e2c3026b8a7315",
      "tree": {
        "sha": "308dcc49d3c75696bb45717b032a012a629d35e9",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/308dcc49d3c75696bb45717b032a012a629d35e9"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/86dd550a9b706195a9d3d6124be3f7d569ccbffe",
          "sha": "86dd550a9b706195a9d3d6124be3f7d569ccbffe",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/86dd550a9b706195a9d3d6124be3f7d569ccbffe"
        }
      ],
      "message": "clusterlin: replace benchmarks with SFL-hard ones (bench)\n\nThis also adds a per-cost variant of each.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T19:17:28Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-05-17T23:08:25Z"
      },
      "sha": "95bfe7d574cfc69bb35e386b88e2c3026b8a7315"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21652410734,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUKlZFu",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21652410734",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "3b37efb18b0994d8513a1ce796ca181f716f1836",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/3b37efb18b0994d8513a1ce796ca181f716f1836",
      "created_at": "2025-12-18T19:27:42Z"
    },
    {
      "event": "commented",
      "id": 3671907357,
      "node_id": "IC_kwDOABII587a3Nwd",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3671907357",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-18T19:29:40Z",
      "updated_at": "2025-12-18T19:29:40Z",
      "author_association": "MEMBER",
      "body": "Addressing review comments:\r\n\r\n```diff\r\ndiff --git a/src/cluster_linearize.h b/src/cluster_linearize.h\r\nindex 817d7d52cd3..7b74d433722 100644\r\n--- a/src/cluster_linearize.h\r\n+++ b/src/cluster_linearize.h\r\n@@ -951,7 +951,12 @@ public:\r\n     {\r\n         // Add transactions one by one, in order of existing linearization.\r\n         for (DepGraphIndex tx : old_linearization) {\r\n-            auto chunk_rep = m_tx_data[tx].chunk_rep;\r\n+            // Since this function must be called after construction, each new transaction added\r\n+            // is in its own singleton chunk still.\r\n+            auto chunk_rep = tx;\r\n+            // Verify that it is indeed in its own chunk.\r\n+            Assume(m_tx_data[tx].chunk_rep == chunk_rep);\r\n+            // Merge the chunk upwards, as long as merging succeeds.\r\n             while (true) {\r\n                 chunk_rep = MergeStep<false>(chunk_rep);\r\n                 if (chunk_rep == TxIdx(-1)) break;\r\ndiff --git a/src/test/fuzz/cluster_linearize.cpp b/src/test/fuzz/cluster_linearize.cpp\r\nindex 5244fb840cd..ccf1be68768 100644\r\n--- a/src/test/fuzz/cluster_linearize.cpp\r\n+++ b/src/test/fuzz/cluster_linearize.cpp\r\n@@ -320,7 +320,7 @@ std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanR\r\n {\r\n     std::vector<DepGraphIndex> linearization;\r\n     TestBitSet todo = depgraph.Positions();\r\n-    // In every iteration one topologically-valid transaction is appended to linearization.\r\n+    // In every iteration one transaction is appended to linearization.\r\n     while (todo.Any()) {\r\n         // Compute the set of transactions to select from.\r\n         TestBitSet potential_next;\r\n```",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3671907357",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "labeled",
      "id": 21653872031,
      "node_id": "LE_lADOABII5863DfgAzwAAAAUKq92f",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21653872031",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-18T20:45:22Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3672152791,
      "node_id": "IC_kwDOABII587a4JrX",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3672152791",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-18T20:45:27Z",
      "updated_at": "2025-12-18T20:45:27Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `fuzzer,address,undefined,integer`: https://github.com/bitcoin/bitcoin/actions/runs/20348793658/job/58467736369</sub>\n<sub>LLM reason (âœ¨ experimental): Fuzz target crashed with a deadly signal during libFuzzer run (exit code 77).</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3672152791",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGM0NjEyNTlmYjYyOTgyZmQwNTRjZGY4ZThmYWM4MDE2ZThkZDlhMDQ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c461259fb62982fd054cdf8e8fac8016e8dd9a04",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/c461259fb62982fd054cdf8e8fac8016e8dd9a04",
      "tree": {
        "sha": "a7dc6a610f1d55cc4cfe51cdf4a1f6a688369daa",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/a7dc6a610f1d55cc4cfe51cdf4a1f6a688369daa"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/95bfe7d574cfc69bb35e386b88e2c3026b8a7315",
          "sha": "95bfe7d574cfc69bb35e386b88e2c3026b8a7315",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/95bfe7d574cfc69bb35e386b88e2c3026b8a7315"
        }
      ],
      "message": "clusterlin: add class implementing SFL state (preparation)\n\nThis adds a data structure representing the optimization state for the spanning-forest\nlinearization algorithm (SFL), plus a fuzz test for its correctness.\n\nThis is preparation for switching over Linearize() to use this algorithm.\n\nSee https://delvingbitcoin.org/t/spanning-forest-cluster-linearization/1419 for\na description of the algorithm.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T20:49:01Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-10T19:22:10Z"
      },
      "sha": "c461259fb62982fd054cdf8e8fac8016e8dd9a04"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGRhNDhlZDlmMzQ4YThhOTM2NzlmZDYyMzgzODA1OWYwNGFjOWU1M2M",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/da48ed9f348a8a93679fd623838059f04ac9e53c",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/da48ed9f348a8a93679fd623838059f04ac9e53c",
      "tree": {
        "sha": "8b44ac2b821538de129fe1388622c7954825a619",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/8b44ac2b821538de129fe1388622c7954825a619"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c461259fb62982fd054cdf8e8fac8016e8dd9a04",
          "sha": "c461259fb62982fd054cdf8e8fac8016e8dd9a04",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/c461259fb62982fd054cdf8e8fac8016e8dd9a04"
        }
      ],
      "message": "clusterlin: ReadLinearization for non-topological (tests)\n\nRather than using an ad-hoc no-dependency copy of the graph when a potentially\nnon-topological linearization is needed in the clusterlin fuzz test, add this\ndirectly as a feature in ReadLinearization().\n\nThis is preparation for a later commit where another use for such a function\nis added.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T20:49:07Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-10T19:22:08Z"
      },
      "sha": "da48ed9f348a8a93679fd623838059f04ac9e53c"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDZhOGZhODIxYjgwY2Y3MWUxOTliMDg1YzYwZDc3ZjZjYTUzM2Y2ZWU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/6a8fa821b80cf71e199b085c60d77f6ca533f6ee",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/6a8fa821b80cf71e199b085c60d77f6ca533f6ee",
      "tree": {
        "sha": "9e6044cca6cbcfdb5d3b3e04ae4ba730aae57ff6",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9e6044cca6cbcfdb5d3b3e04ae4ba730aae57ff6"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/da48ed9f348a8a93679fd623838059f04ac9e53c",
          "sha": "da48ed9f348a8a93679fd623838059f04ac9e53c",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/da48ed9f348a8a93679fd623838059f04ac9e53c"
        }
      ],
      "message": "clusterlin: add support for loading existing linearization (feature)",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:22Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-10T20:03:23Z"
      },
      "sha": "6a8fa821b80cf71e199b085c60d77f6ca533f6ee"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDNlZmM5NGQ2NTY0ZGVjYTRlNWFhZjUyMTlhZGI3MTMwMmY1MjI2NTc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/3efc94d6564deca4e5aaf5219adb71302f522657",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/3efc94d6564deca4e5aaf5219adb71302f522657",
      "tree": {
        "sha": "a9e1715171dad8c832430fa9f01bc22d515de5e2",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/a9e1715171dad8c832430fa9f01bc22d515de5e2"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/6a8fa821b80cf71e199b085c60d77f6ca533f6ee",
          "sha": "6a8fa821b80cf71e199b085c60d77f6ca533f6ee",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/6a8fa821b80cf71e199b085c60d77f6ca533f6ee"
        }
      ],
      "message": "clusterlin: replace cluster linearization with SFL (feature)\n\nThis replaces the existing LIMO linearization algorithm (which internally uses\nancestor set finding and candidate set finding) with the much more performant\nspanning-forest linearization algorithm.\n\nThis removes the old candidate-set search algorithm, and several of its tests,\nbenchmarks, and needed utility code.\n\nThe worst case time per cost is similar to the previous algorithm, so\nACCEPTABLE_ITERS is unchanged.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:31Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-10-23T23:15:21Z"
      },
      "sha": "3efc94d6564deca4e5aaf5219adb71302f522657"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGRkYmZhNGRmYWM3YjMwZDBkYzQ2MmIyOWJkNGM4OWI5MTUyZDAzODE",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/ddbfa4dfac7b30d0dc462b29bd4c89b9152d0381",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/ddbfa4dfac7b30d0dc462b29bd4c89b9152d0381",
      "tree": {
        "sha": "61452cd1df4884f49cd138a793cb9b42685e042a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/61452cd1df4884f49cd138a793cb9b42685e042a"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/3efc94d6564deca4e5aaf5219adb71302f522657",
          "sha": "3efc94d6564deca4e5aaf5219adb71302f522657",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/3efc94d6564deca4e5aaf5219adb71302f522657"
        }
      ],
      "message": "clusterlin: keep FIFO queue of improvable chunks (preparation)\n\nThis introduces a queue of chunks that still need processing, in both\nMakeTopological() and OptimizationStep(). This is simultaneously:\n* A preparation for introducing randomization, by allowing permuting the\n  queue.\n* An improvement to the fairness of suboptimal solutions, by distributing\n  the work more fairly over chunks.\n* An optimization, by avoiding retrying chunks over and over again which\n  are already known to be optimal.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:31Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-10-16T01:46:50Z"
      },
      "sha": "ddbfa4dfac7b30d0dc462b29bd4c89b9152d0381"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDEzYWFkMjZiNzg0ODFmMmFiZDZkNWUzYWU2MjE4ZTQ2ZTRkMDA2MGE",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/13aad26b78481f2abd6d5e3ae6218e46e4d0060a",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/13aad26b78481f2abd6d5e3ae6218e46e4d0060a",
      "tree": {
        "sha": "a3f1712ec4d7956285b12adfabc9536af58aa133",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/a3f1712ec4d7956285b12adfabc9536af58aa133"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/ddbfa4dfac7b30d0dc462b29bd4c89b9152d0381",
          "sha": "ddbfa4dfac7b30d0dc462b29bd4c89b9152d0381",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/ddbfa4dfac7b30d0dc462b29bd4c89b9152d0381"
        }
      ],
      "message": "clusterlin: randomize various decisions in SFL (feature)\n\nThis introduces a local RNG inside the SFL state, which is used to randomize\nvarious decisions inside the algorithm, in order to make it hard to create\npathological clusters which predictably have bad performance.\n\nThe decisions being randomized are:\n* When deciding what chunk to attempt to split, the queue order is\n  randomized.\n* When deciding which dependency to split on, a uniformly random one is\n  chosen among those with higher top feerate than bottom feerate within\n  the chosen chunk.\n* When deciding which chunks to merge, a uniformly random one among those\n  with the higher feerate difference is picked.\n* When merging two chunks, a uniformly random dependency between them is\n  now activated.\n* When making the state topological, the queue of chunks to process is\n  randomized.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:31Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-10T20:06:21Z"
      },
      "sha": "13aad26b78481f2abd6d5e3ae6218e46e4d0060a"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDVjZTI4MDA3NDUxMmY3OWE0YjM4NTFkOGQ0NTNmMzM3ZmE5N2JlNDY",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/5ce280074512f79a4b3851d8d453f337fa97be46",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/5ce280074512f79a4b3851d8d453f337fa97be46",
      "tree": {
        "sha": "628905cd4b3c9df6ffadb591a85a9a81e409bc03",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/628905cd4b3c9df6ffadb591a85a9a81e409bc03"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/13aad26b78481f2abd6d5e3ae6218e46e4d0060a",
          "sha": "13aad26b78481f2abd6d5e3ae6218e46e4d0060a",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/13aad26b78481f2abd6d5e3ae6218e46e4d0060a"
        }
      ],
      "message": "clusterlin: randomize equal-feerate parts of linearization (privacy)\n\nThis places equal-feerate chunks (with no dependencies between them) in random\norder in the linearization output, hiding information about DepGraph insertion\norder from the output. Likewise, it randomizes the order of transactions within\nchunks for the same reason.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:31Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-10-14T19:34:42Z"
      },
      "sha": "5ce280074512f79a4b3851d8d453f337fa97be46"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDkxMzk5YTc5MTIyY2I2YmIyNTZlNjM0MDQ5YWM4M2Y1MzE1NGI2NGI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/91399a79122cb6bb256e634049ac83f53154b64b",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/91399a79122cb6bb256e634049ac83f53154b64b",
      "tree": {
        "sha": "98430e6ae5f62e3dd438400800db4a8147f69145",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/98430e6ae5f62e3dd438400800db4a8147f69145"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/5ce280074512f79a4b3851d8d453f337fa97be46",
          "sha": "5ce280074512f79a4b3851d8d453f337fa97be46",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/5ce280074512f79a4b3851d8d453f337fa97be46"
        }
      ],
      "message": "clusterlin: remove unused MergeLinearizations (cleanup)\n\nThis ended up never being used in txgraph.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:31Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-09-16T17:38:24Z"
      },
      "sha": "91399a79122cb6bb256e634049ac83f53154b64b"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDc1YmRiOTI1ZjQwNGY0MTg3NGFkZjBmY2VmY2EwZjE2NDFmY2I0ZTY",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "tree": {
        "sha": "9c342f0bb377a6edd1d65d8aa1d2c293bb3a9b1e",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9c342f0bb377a6edd1d65d8aa1d2c293bb3a9b1e"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/91399a79122cb6bb256e634049ac83f53154b64b",
          "sha": "91399a79122cb6bb256e634049ac83f53154b64b",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/91399a79122cb6bb256e634049ac83f53154b64b"
        }
      ],
      "message": "clusterlin: drop support for improvable chunking (simplification)\n\nWith MergeLinearizations() gone and the LIMO-based Linearize() replaced by SFL, we do not\nneed a class (LinearizationChunking) that can maintain an incrementally-improving chunk\nset anymore.\n\nReplace it with a function (ChunkLinearizationInfo) that just computes the chunks as\nSetInfos once, and returns them as a vector. This simplifies several call sites too.",
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-12-18T21:01:31Z"
      },
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2025-10-12T13:48:19Z"
      },
      "sha": "75bdb925f404f41874adf0fcefca0f1641fcb4e6"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 21654212341,
      "node_id": "HRFPE_lADOABII5863DfgAzwAAAAUKsQ71",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21654212341",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "commit_url": "https://api.github.com/repos/sipa/bitcoin/commits/75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "created_at": "2025-12-18T21:02:21Z"
    },
    {
      "event": "commented",
      "id": 3672209221,
      "node_id": "IC_kwDOABII587a4XdF",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3672209221",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-18T21:03:42Z",
      "updated_at": "2025-12-18T21:04:31Z",
      "author_association": "MEMBER",
      "body": "Oops, sorry, I had to revert this last change because the property I claimed (each new transaction traversed in `LoadLinearization()` is in its own chunk still) only holds if the input linearization is topological. With that, I don't see an effectively way of asserting that `LoadLinearization()` is called in the right state, without introducing a performance penalty.\r\n\r\n```diff\r\ndiff --git a/src/cluster_linearize.h b/src/cluster_linearize.h\r\nindex 7b74d433722..d65e61d4458 100644\r\n--- a/src/cluster_linearize.h\r\n+++ b/src/cluster_linearize.h\r\n@@ -395,7 +395,7 @@ struct SetInfo\r\n         return *this;\r\n     }\r\n \r\n-    /** Remove the transactions of other from this SetInfo (must be subset). */\r\n+    /** Remove the transactions of other from this SetInfo (which must be a subset). */\r\n     SetInfo& operator-=(const SetInfo& other) noexcept\r\n     {\r\n         Assume(other.transactions.IsSubsetOf(transactions));\r\n@@ -951,11 +951,7 @@ public:\r\n     {\r\n         // Add transactions one by one, in order of existing linearization.\r\n         for (DepGraphIndex tx : old_linearization) {\r\n-            // Since this function must be called after construction, each new transaction added\r\n-            // is in its own singleton chunk still.\r\n-            auto chunk_rep = tx;\r\n-            // Verify that it is indeed in its own chunk.\r\n-            Assume(m_tx_data[tx].chunk_rep == chunk_rep);\r\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\r\n             // Merge the chunk upwards, as long as merging succeeds.\r\n             while (true) {\r\n                 chunk_rep = MergeStep<false>(chunk_rep);\r\n```",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3672209221",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "unlabeled",
      "id": 21655654506,
      "node_id": "UNLE_lADOABII5863DfgAzwAAAAUKxxBq",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21655654506",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-18T22:20:41Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 3675255338,
      "node_id": "IC_kwDOABII587bD_Iq",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3675255338",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-19T14:21:15Z",
      "updated_at": "2025-12-19T14:21:15Z",
      "author_association": "MEMBER",
      "body": "reACK 75bdb925f404f41874adf0fcefca0f1641fcb4e6\r\n\r\nComment cleanups only\r\n\r\n`git range-diff master edc64813b221598994da52cc5b7124a02ab7e042 75bdb925f404f41874adf0fcefca0f1641fcb4e6`",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3675255338",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "review_requested",
      "id": 21671824953,
      "node_id": "RRE_lADOABII5863DfgAzwAAAAULvc45",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21671824953",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-19T14:21:22Z",
      "requested_reviewer": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "review_requester": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      }
    },
    {
      "event": "commented",
      "id": 3675295963,
      "node_id": "IC_kwDOABII587bEJDb",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/3675295963",
      "actor": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-19T14:33:12Z",
      "updated_at": "2025-12-19T14:33:12Z",
      "author_association": "CONTRIBUTOR",
      "body": "reACK 75bdb925f404f41874adf0fcefca0f1641fcb4e6\r\n\r\n> I don't see an effectively way of asserting that LoadLinearization() is called in the right state, without introducing a performance penalty.\r\n\r\nYeah I was thinking `Assume(m_cost == 0)` could potentially work, but that wouldn't work for the optimized sfl branch.",
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#issuecomment-3675295963",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/32545"
    },
    {
      "event": "merged",
      "id": 21672875574,
      "node_id": "ME_lADOABII5863DfgAzwAAAAULzdY2",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21672875574",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": "0c862bc7ea2832f459233046518740613a177993",
      "commit_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/0c862bc7ea2832f459233046518740613a177993",
      "created_at": "2025-12-19T15:14:54Z"
    },
    {
      "event": "closed",
      "id": 21672875609,
      "node_id": "CE_lADOABII5863DfgAzwAAAAULzdZZ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/21672875609",
      "actor": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-12-19T15:14:54Z"
    }
  ],
  "comments": [
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2102935031",
      "pull_request_review_id": 2861830018,
      "id": 2102935031,
      "node_id": "PRRC_kwDOABII5859WD33",
      "diff_hunk": "@@ -539,492 +555,651 @@ class LinearizationChunking\n     }\n };\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n+/** Class to represent the internal state of the spanning-forest linearization algorithm.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 28,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "23072f2b0e3201b00db19bf8fcca474f81593c2f",
      "in_reply_to_id": null,
      "user": {
        "login": "jonatack",
        "id": 2415484,
        "node_id": "MDQ6VXNlcjI0MTU0ODQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2415484?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jonatack",
        "html_url": "https://github.com/jonatack",
        "followers_url": "https://api.github.com/users/jonatack/followers",
        "following_url": "https://api.github.com/users/jonatack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jonatack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jonatack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jonatack/subscriptions",
        "organizations_url": "https://api.github.com/users/jonatack/orgs",
        "repos_url": "https://api.github.com/users/jonatack/repos",
        "events_url": "https://api.github.com/users/jonatack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jonatack/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Appreciate the excellent doxygen documentation here.",
      "created_at": "2025-05-22T16:09:08Z",
      "updated_at": "2025-05-22T16:09:36Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2102935031",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2102935031"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 464,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2443583986",
      "pull_request_review_id": 3354761107,
      "id": 2443583986,
      "node_id": "PRRC_kwDOABII586RpiHy",
      "diff_hunk": "@@ -423,710 +459,933 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their\n+ *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n+ *     remain.\n+ * - Loop until optimal or time runs out:\n+ *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n+ *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of starting with an empty graph and making it topological directly, it is possible to\n+ * bootstrap from an existing linearization:\n+ * - Start with an empty graph.\n+ * - For each transaction t in the existing linearization:\n+ *   - Add the transaction as a singleton chunk to the graph.\n+ *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n+ *     merged result.\n+ *\n+ * This guarantees an initial, topological, state whose output linearization is at least as good\n+ * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ *\n+ * What remains to be specified are two heuristics:\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Define the gain of an active dependency as\n+ *     (feerate(top) - feerate(chunk)) * size(top) * size(chunk), also equal to:\n+ *     fee(top) * size(chunk) - fee(chunk) * size(top).\n+ *   - After every split, it is possible that the top and the bottom chunk merge with each other\n+ *     again in the merge sequence (through a top->bottom dependency, not through the deactivated\n+ *     one, which was bottom->top). Call this a self-merge. If a self-merge does not occur after\n+ *     a split, the resulting linearization is strictly improved (the area under the fee-size\n+ *     diagram increases by at least gain/2), while self-merges do not change it.\n+ *   - Keep track of how many consecutive self-merges a chunk undergoes: incremented upon\n+ *     self-merge, and reset to 0 in both top and bottom otherwise.\n+ *   - If the number of consecutive self-merges is 2 mod 3 (i.e., it is 2, 5, 8, 11, ...), a\n+ *     uniformly random dependency in the chunk among those with strictly positive gain is\n+ *     deactivated.\n+ *   - Otherwise (self-merges so far is not 2 mod 3), a uniformly random dependency within a chunk\n+ *     among those with maximal gain is deactivated, if any with strictly positive gain exist.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - A uniformly random dependency between the two maximum-feerate-difference chunks is activated.\n+ *\n+ * If an optimal state is found by the above procedure, it is still possible that it contains\n+ * chunks that can be split further into equal-feerate chunks. To find these, a second stage is\n+ * added, which acts as if the feerates of transactions are perturbed slightly, to make\n+ * equal-feerate parts of chunks break apart. The idea is:\n+ * - If a transaction t is given slightly higher feerate than it really has, and an equal-feerate\n+ *   topological subset of the chunk exists with t in it, it will be found using the normal\n+ *   algorithm.\n+ * - If a transaction t is given slightly *lower* feerate than it really has, and an equal-feerate\n+ *   topological subset of the chunk exists with t *not* in it, it will be found using the normal\n+ *   algorithm.\n+ * Thus, by picking one transaction in a chunk, and trying both of the approaches above, then if a\n+ * split exists, it must be found, because the subset must either contain t or not contain it.\n+ *\n+ * Specifically, within each chunk:\n+ * - Pick an arbitrary pivot transaction t in the chunk.\n+ * - Loop:\n+ *   - Find a gain=0 dependency d in the chunk where t appears in its top. If not found, stop.\n+ *   - Deactivate d.\n+ *   - Find a dependency e from d's top to d's bottom. If not found, recurse into the created top\n+ *     and bottom chunks.\n+ *   - Activate e.\n+ * - Loop:\n+ *   - Find a gain=0 dependency d in the chunk where t appears in its bottom. If not found, stop.\n+ *   - Deactivate d.\n+ *   - Find a dependency e from d's top to d's bottom. If not found, recurse into the created top\n+ *     and bottom chunks.\n+ *   - Activate e.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = std::conditional_t<(SetType::Size() <= 32), uint8_t, std::conditional_t<(SetType::Size() <= 512), uint16_t, uint32_t>>;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. All active ones (see\n+         *  child_deps_active) appear first. */\n+        std::array<DepIdx, SetType::Size() - 1> child_deps;\n+        /** The number of children of this transaction. Immutable after construction. */\n+        TxIdx child_deps_total{0};\n+        /** The number of active children of this transaction. */\n+        TxIdx child_deps_active{0};\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** The set of parent transactions of this transaction reachable through active\n+         *  dependencies. */\n+        SetType active_parents;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+        /** In what ways this transaction exists in suboptimality lists:\n+         *  - 0: not in m_suboptimal_chunks\n+         *  - >0: in m_suboptimal_chunks, and:\n+         *    - (during optimization) 1: needs processing\n+         *    - (during MakeTopological) 1: needs to be merged upwards\n+         *    - (during MakeTopological) 2: needs to be merged downwards\n+         *    - (during MakeTopological) 3: needs to be merged upwards and downwards */\n+        unsigned suboptimal{0};\n+        /** Number of consecutive self-merges this chunk has experienced. */\n+        uint32_t self_merges;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** Index into the parent's TxData::child_deps where this dependency appears. */\n+        DepIdx child_pos;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+    /** A FIFO of chunk representatives, a pivot tx in it, and the stage it is in (false = first\n+     *  stage, move pivot up, true = second stage, move pivot down). */\n+    VecDeque<std::tuple<TxIdx, TxIdx, bool>> m_nonminimal_chunks;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** A metric for predicting the runtime of the algorithm. Corresponds to ~2ns on Ryzen 7995WX. */\n+    uint64_t m_cost{0};\n+\n+    /** Walk a chunk, starting from transaction start. visit_tx(idx) is called for each encountered\n+     *  transaction. visit_dep_down(dep) is called for each encountered dependency that is traversed\n+     *  in the parent-to-child (downward) direction. */\n+    void Walk(TxIdx start, std::invocable<TxData&> auto visit_tx, std::invocable<DepData&> auto visit_dep_down) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo) {\n+                // Mark the transaction as processed, and invoke the visitor for it.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                visit_tx(tx_data);\n+                // Mark all active parents as to be processed.\n+                todo |= tx_data.active_parents;\n+                todo -= done;\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps}.first(tx_data.child_deps_active);\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    // If this is the first time reaching the child, mark it as todo, and invoke\n+                    // the downward dependency visitor for it. We do not need to check if it isn't\n+                    // already in todo here, because there cannot be multiple dependencies that\n+                    // reach the same transaction; the !done check is purely to prevent travelling\n+                    // an already-travelled dependency back in reverse direction.\n+                    if (!done[dep_entry.child]) {\n+                        Assume(!todo[dep_entry.child]);\n+                        todo.Set(dep_entry.child);\n+                        visit_dep_down(dep_entry);\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n-        }\n+        } while (todo.Any());\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Swap two dependencies in a given transaction's implied list of child deps. */\n+    void SwapChildDeps(TxData& tx_data, DepIdx pos1, DepIdx pos2) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        if (pos1 == pos2) return;\n+        std::swap(tx_data.child_deps[pos1], tx_data.child_deps[pos2]);\n+        m_dep_data[tx_data.child_deps[pos1]].child_pos = pos1;\n+        m_dep_data[tx_data.child_deps[pos2]].child_pos = pos2;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make dep_idx the first inactive dependency in the parent's list of child deps.\n+        SwapChildDeps(parent_tx_data, dep_data.child_pos, parent_tx_data.child_deps_active);\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        int ntx = par_chunk_data.chunk_setinfo.transactions.Count();\n+        m_cost += ntx * 4 - 3;\n+        // Add bottom component to top transactions.\n+        Walk(dep_data.parent,\n+             [](TxData&) noexcept {},\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= bottom_part; });\n+        // Add top component to bottom transactions.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= top_part; });\n+        // Make active.\n+        dep_data.top_setinfo = top_part;\n+        child_tx_data.active_parents.Set(dep_data.parent);\n+        parent_tx_data.child_deps_active += 1;\n+        Assume(parent_tx_data.child_deps_active <= parent_tx_data.child_deps_total);\n+        return top_rep;\n+    }\n \n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make dep_idx the last active dependency in the parent's list of child deps.\n+        SwapChildDeps(parent_tx_data, dep_data.child_pos, parent_tx_data.child_deps_active - 1);\n+        // Make inactive.\n+        child_tx_data.active_parents.Reset(dep_data.parent);\n+        parent_tx_data.child_deps_active -= 1;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        int ntx = chunk_data.chunk_setinfo.transactions.Count();\n+        m_cost += ntx * 4 + 2;\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        chunk_data.chunk_setinfo = top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        Walk(dep_data.parent,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= bottom_part; });\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = bottom_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= top_part; });\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep. Return the representative of the merged chunk, or TxIdx(-1) if no merge took\n+     *  place. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n+            m_cost += 1;\n         }\n+        if (num_deps == 0) return TxIdx(-1);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            m_cost += 1;\n+            if (pick < count) {\n+                for (auto dep : std::span{tx_data.child_deps}.first(tx_data.child_deps_total)\n+                                                             .subspan(tx_data.child_deps_active)) {\n+                    m_cost += 1;\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a uniformly\n+        // random one among them (using random tiebreaker).\n+        SetType explored = chunk_txn;\n+        FeeFrac best_other_chunk_feerate;\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto unreached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            while (unreached.Any()) {\n+                m_cost += 3;\n+                auto chunk_rep = m_tx_data[unreached.First()].chunk_rep;\n+                auto& reached = m_tx_data[m_tx_data[unreached.First()].chunk_rep].chunk_setinfo;\n+                explored |= reached.transactions;\n+                unreached -= explored;\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached.feerate)\n+                                    : FeeRateCompare(reached.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if ((cmp < 0) || (tiebreak >= best_other_chunk_tiebreak)) {\n+                    best_other_chunk_feerate = reached.feerate;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                    best_other_chunk_rep = chunk_rep;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if all of the depended-on chunks have a lower/higher feerate than the chunk\n+        // that tx_idx is in.\n+        if (best_other_chunk_feerate.IsEmpty()) return TxIdx(-1);\n+        if (DownWard && best_other_chunk_feerate << chunk_data.chunk_setinfo.feerate) return TxIdx(-1);\n+        if (!DownWard && best_other_chunk_feerate >> chunk_data.chunk_setinfo.feerate) return TxIdx(-1);\n+        Assume(best_other_chunk_rep != TxIdx(-1));\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. Returns the\n+     *  representative of the merged chunk. */\n+    template<bool DownWard>\n+    TxIdx MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks, if it wasn't already there.\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        if (!chunk_data.suboptimal) {\n+            chunk_data.suboptimal = 1;\n+            m_suboptimal_chunks.push_back(chunk_rep);\n+        }\n+        return chunk_rep;\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n-            }\n+        auto& dep_data = m_dep_data[dep_idx];\n+        // Remember the number of self-merges this chunk underwent so far.\n+        auto self_merges = m_tx_data[m_tx_data[dep_data.parent].chunk_rep].self_merges;\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        auto new_par_chunk_rep = MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        auto new_chl_chunk_rep = MergeSequence<true>(dep_data.child);\n+        // If the parent and child end up in the same chunk, a self-merge happened.\n+        if (new_par_chunk_rep == new_chl_chunk_rep) {\n+            // If so, increment the self_merges counter for this chunk.\n+            m_tx_data[new_par_chunk_rep].self_merges = self_merges + 1;\n+        } else {\n+            // Otherwise, set the counters for both chunks (incl. whatever they merged with) to\n+            // zero.\n+            m_tx_data[new_par_chunk_rep].self_merges = 0;\n+            m_tx_data[new_chl_chunk_rep].self_merges = 0;\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        return m_todo.None();\n+        m_transactions = depgraph.Positions();\n+        m_cost = 10;\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            tx_data.self_merges = 0;\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                dep.child_pos = par_tx_data.child_deps_total;\n+                par_tx_data.child_deps[par_tx_data.child_deps_total++] = dep_idx;\n+                par_tx_data.children.Set(tx);\n+                m_cost += 2;\n+            }\n+        }\n+        // Account for the cost of producing linearization.\n+        m_cost += 2 * m_dep_data.size() + 30 * num_transactions;\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.Count();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Find the best (highest-feerate, smallest among those in case of a tie) ancestor set\n-     *  among the remaining transactions. Requires !AllDone().\n-     *\n-     * Complexity: O(N) where N=depgraph.TxCount();\n-     */\n-    SetInfo<SetType> FindCandidateSet() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        Assume(!AllDone());\n-        std::optional<DepGraphIndex> best;\n-        for (auto i : m_todo) {\n-            if (best.has_value()) {\n-                Assume(!m_ancestor_set_feerates[i].IsEmpty());\n-                if (!(m_ancestor_set_feerates[i] > m_ancestor_set_feerates[*best])) continue;\n+        /** What direction to initially mark all chunks for merging in. It suffices to pick one of\n+         *  the two directions. Note that when a chunk is merged, it is always marked as needing\n+         *  both directions; only the initial set get just one of the two. */\n+        bool init_dir = m_rng.randbool();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                tx_data.suboptimal = 1 + init_dir;\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+                m_cost += 3;\n+            }\n+        }\n+        while (true) {\n+            // If the queue of potentially-suboptimal chunks is empty, we are done.\n+            if (m_suboptimal_chunks.empty()) break;\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            Assume(chunk_data.suboptimal);\n+            auto old_suboptimal = chunk_data.suboptimal;\n+            chunk_data.suboptimal = 0;\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            m_cost += 1;\n+            for (int i = 0; i < 2; ++i) {\n+                if (i ^ flip) {\n+                    if (!(old_suboptimal & 1)) continue;\n+                    // Attempt to merge the chunk upwards.\n+                    auto result_up = MergeStep<false>(chunk);\n+                    if (result_up != TxIdx(-1)) {\n+                        if (!m_tx_data[result_up].suboptimal) {\n+                            m_suboptimal_chunks.push_back(result_up);\n+                        }\n+                        m_tx_data[result_up].suboptimal = 3;\n+                        break;\n+                    }\n+                } else {\n+                    if (!(old_suboptimal & 2)) continue;\n+                    // Attempt to merge the chunk downwards.\n+                    auto result_down = MergeStep<true>(chunk);\n+                    if (result_down != TxIdx(-1)) {\n+                        if (!m_tx_data[result_down].suboptimal) {\n+                            m_suboptimal_chunks.push_back(result_down);\n+                        }\n+                        m_tx_data[result_down].suboptimal = 3;\n+                        break;\n+                    }\n+                }\n             }\n-            best = i;\n         }\n-        Assume(best.has_value());\n-        return {m_depgraph.Ancestors(*best) & m_todo, m_ancestor_set_feerates[*best]};\n     }\n-};\n \n-/** Class encapsulating the state needed to perform search for good candidate sets.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone().\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called to perform a search\n- * over the set of topologically-valid subsets of that remainder, with a limit on how many\n- * combinations are tried.\n- */\n-template<typename SetType>\n-class SearchCandidateFinder\n-{\n-    /** Internal RNG. */\n-    InsecureRandomContext m_rng;\n-    /** m_sorted_to_original[i] is the original position that sorted transaction position i had. */\n-    std::vector<DepGraphIndex> m_sorted_to_original;\n-    /** m_original_to_sorted[i] is the sorted position original transaction position i has. */\n-    std::vector<DepGraphIndex> m_original_to_sorted;\n-    /** Internal dependency graph for the cluster (with transactions in decreasing individual\n-     *  feerate order). */\n-    DepGraph<SetType> m_sorted_depgraph;\n-    /** Which transactions are left to do (indices in m_sorted_depgraph's order). */\n-    SetType m_todo;\n-\n-    /** Given a set of transactions with sorted indices, get their original indices. */\n-    SetType SortedToOriginal(const SetType& arg) const noexcept\n+    /** Initialize the data structure for optimization. It must be topological already. */\n+    void StartOptimizing() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_sorted_to_original[pos]);\n-        return ret;\n+        // Mark chunks suboptimal.\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            Assume(!tx_data.suboptimal);\n+            if (tx_data.chunk_rep == tx) {\n+                tx_data.suboptimal = true;\n+                m_suboptimal_chunks.push_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+                m_cost += 3;\n+            }\n+        }\n     }\n \n-    /** Given a set of transactions with original indices, get their sorted indices. */\n-    SetType OriginalToSorted(const SetType& arg) const noexcept\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_original_to_sorted[pos]);\n-        return ret;\n+        while (true) {\n+            // If the queue of potentially-suboptimal chunks is empty, we are done.\n+            if (m_suboptimal_chunks.empty()) return false;\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            Assume(chunk_data.suboptimal);\n+            chunk_data.suboptimal = false;\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when a split chunk merges in Improve() with one or more existing chunks that\n+            // are themselves on the suboptimal queue.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Determine whether to use max-gain strategy or random strategy. Generally max-gain is\n+            // used, but out of an abundance of caution that max-gain might in\n+            // adversarially-contructed clusters reliably make bad choices, every 3rd attempt to\n+            // split the same cluster uses the random strategy.\n+            const bool use_max_gain = (chunk_data.self_merges % 3) != 2;\n+            // Remember the best dependency seen so far, together with its top feerate.\n+            DepIdx candidate_dep = DepIdx(-1);\n+            FeeFrac candidate_top_feerate; //!< Feerate of the candidate, or {} if random strategy.\n+            uint64_t candidate_tiebreak = std::numeric_limits<uint64_t>::max();\n+            // Iterate over all transactions.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto active_children = std::span{tx_data.child_deps}.first(tx_data.child_deps_active);\n+                for (DepIdx dep_idx : active_children) {\n+                    m_cost += 3;\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    // Define gain(top) = fee(top)*size(chunk) - fee(chunk)*size(top).\n+                    //                  = (feerate(top) - feerate(chunk)) * size(top) * size(chunk).\n+                    // Thus:\n+                    //\n+                    //     gain(top1) > gain(top2)\n+                    // <=>   fee(top1)*size(chunk) - fee(chunk)*size(top1)\n+                    //     > fee(top2)*size(chunk) - fee(chunk)*size(top2)\n+                    // <=> (fee(top1)-fee(top2))*size(chunk) > fee(chunk)*(size(top1)-size(top2))\n+                    //\n+                    // If size(top1)>size(top2), this corresponds to feerate(top1-top2) > feerate(chunk),\n+                    // so we can use FeeRateCompare to discover if dep_data.top_setinfo has better\n+                    // gain than best_top_feerate. As FeeRateCompare() is actually implemented by\n+                    // checking the sign of the cross-product, it even works when\n+                    // size(top1) <= size(top2). When no candidate exists so far (or the random\n+                    // strategy is in use), this is equal to comparing the feerate with the chunk\n+                    // directly (= the sign of gain(top)).\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate - candidate_top_feerate,\n+                                              chunk_data.chunk_setinfo.feerate);\n+                    if (cmp < 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its gain is\n+                    // equal to the candidate so far, but has worse tiebreak. This means that among\n+                    // equal-gain dependencies, a uniformly random one (the one with the highest\n+                    // tiebreak) will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64() >> 1;\n+                    if (cmp == 0 && tiebreak <= candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    if (use_max_gain) candidate_top_feerate = dep_data.top_setinfo.feerate;\n+                    candidate_tiebreak = tiebreak;\n+                }\n+            }\n+            // If a candidate with positive gain was found, activate it.\n+            if (candidate_tiebreak != std::numeric_limits<uint64_t>::max()) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;\n+        }\n     }\n \n-public:\n-    /** Construct a candidate finder for a graph.\n-     *\n-     * @param[in] depgraph   Dependency graph for the to-be-linearized cluster.\n-     * @param[in] rng_seed   A random seed to control the search order.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.Count().\n-     */\n-    SearchCandidateFinder(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept :\n-        m_rng(rng_seed),\n-        m_sorted_to_original(depgraph.TxCount()),\n-        m_original_to_sorted(depgraph.PositionRange())\n+    /** Initialize data structure for minimizing the chunks. Step() cannot be called anymore\n+     *  afterwards. */\n+    void StartMinimizing() noexcept\n     {\n-        // Determine reordering mapping, by sorting by decreasing feerate. Unused positions are\n-        // not included, as they will never be looked up anyway.\n-        DepGraphIndex sorted_pos{0};\n-        for (auto i : depgraph.Positions()) {\n-            m_sorted_to_original[sorted_pos++] = i;\n+        m_nonminimal_chunks.clear();\n+        m_nonminimal_chunks.reserve(m_transactions.Count());\n+        // Gather all chunks, and add the representative of each to m_nonminimal_chunks, with the\n+        // representative itself as pivot.\n+        for (auto i : m_transactions) {\n+            auto& tx_data = m_tx_data[i];\n+            if (tx_data.chunk_rep == i) {\n+                m_nonminimal_chunks.emplace_back(i, i, false);\n+            }\n         }\n-        std::sort(m_sorted_to_original.begin(), m_sorted_to_original.end(), [&](auto a, auto b) {\n-            auto feerate_cmp = depgraph.FeeRate(a) <=> depgraph.FeeRate(b);\n-            if (feerate_cmp == 0) return a < b;\n-            return feerate_cmp > 0;\n-        });\n-        // Compute reverse mapping.\n-        for (DepGraphIndex i = 0; i < m_sorted_to_original.size(); ++i) {\n-            m_original_to_sorted[m_sorted_to_original[i]] = i;\n+        // Randomize the initial order of nonminimal chunks in the queue.\n+        for (TxIdx i = 0; i < m_nonminimal_chunks.size(); ++i) {\n+            TxIdx j = i + m_rng.randrange<TxIdx>(m_nonminimal_chunks.size() - i);\n+            if (i != j) std::swap(m_nonminimal_chunks[i], m_nonminimal_chunks[j]);\n         }\n-        // Compute reordered dependency graph.\n-        m_sorted_depgraph = DepGraph(depgraph, m_original_to_sorted, m_sorted_to_original.size());\n-        m_todo = m_sorted_depgraph.Positions();\n+        m_cost += 2 + 3 * m_nonminimal_chunks.size();\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Try to reduce a chunk's size. Returns false if all chunks are minimal, true otherwise. */\n+    bool MinimizeStep() noexcept\n     {\n-        return m_todo.None();\n+        // If the queue of potentially-non-minimal chunks is empty, we are done.\n+        if (m_nonminimal_chunks.empty()) return false;\n+        // Pop an entry from the potentially-non-minimal chunk queue.\n+        auto [chunk, pivot, move_pivot_down] = m_nonminimal_chunks.front();\n+        m_nonminimal_chunks.pop_front();\n+        auto& chunk_data = m_tx_data[chunk];\n+        Assume(chunk_data.chunk_rep == chunk);\n+        Assume(chunk_data.chunk_setinfo.transactions[pivot]);\n+\n+        // Find a random dependency whose gain is non-negative, and which has pivot as bottom\n+        // (if move_pivot_down) or as top (if !move_pivot_down).\n+        DepIdx candidate_dep = DepIdx(-1);\n+        uint64_t candidate_tiebreak{0};\n+        bool have_any = false;\n+        // Iterate over all transactions.\n+        for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+            const auto& tx_data = m_tx_data[tx];\n+            // Iterate over all active child dependencies of the transaction.\n+            const auto active_children = std::span{tx_data.child_deps}.first(tx_data.child_deps_active);\n+            for (DepIdx dep_idx : active_children) {\n+                m_cost += 3;\n+                const auto& dep_data = m_dep_data[dep_idx];\n+                // Skip if this dependency has negative gain.\n+                if (dep_data.top_setinfo.feerate << chunk_data.chunk_setinfo.feerate) continue;\n+                have_any = true;\n+                // Skip if this dependency does not have pivot in the right place.\n+                if (move_pivot_down == dep_data.top_setinfo.transactions[pivot]) continue;\n+                // Remember this as our chosen dependency if it has a better tiebreak.\n+                uint64_t tiebreak = m_rng.rand64() | 1;\n+                if (tiebreak > candidate_tiebreak) {\n+                    candidate_tiebreak = tiebreak;\n+                    candidate_dep = dep_idx;\n+                }\n+            }\n+        }\n+        // If all dependencies have negative gain, this chunk is optimal.\n+        if (!have_any) return true;\n+        // If all found dependencies have the pivot in the wrong place, try moving the pivot down\n+        // instead of up. If we were already attempting to move it down, no splitting is possible.\n+        if (candidate_tiebreak == 0) {\n+            if (!move_pivot_down) m_nonminimal_chunks.emplace_back(chunk, pivot, true);\n+            return true;\n+        }\n+\n+        // Otherwise, deactivate the dependency that was found.\n+        Deactivate(candidate_dep);\n+        // If the new top has a dependency on the new bottom (opposite from chosen_dep),\n+        // activate it.\n+        auto& candidate_dep_data = m_dep_data[candidate_dep];\n+        auto new_top_rep = m_tx_data[candidate_dep_data.parent].chunk_rep;\n+        auto new_bottom_rep = m_tx_data[candidate_dep_data.child].chunk_rep;\n+        auto new_rep = MergeChunks(new_bottom_rep, new_top_rep);\n+        m_cost += 2;\n+        if (new_rep == TxIdx(-1)) {\n+            // No new dependency was activated, and thus we have found a way to split the\n+            // chunk. Add the created smaller chunks to the queue in random order.\n+            bool top_first = m_rng.randbool();\n+            if (top_first) m_nonminimal_chunks.emplace_back(new_top_rep, new_top_rep, false);\n+            m_nonminimal_chunks.emplace_back(new_bottom_rep, new_bottom_rep, false);\n+            if (!top_first) m_nonminimal_chunks.emplace_back(new_top_rep, new_top_rep, false);\n+        } else {\n+            // A new dependency was activated, so this chunk failed to be split. Keep trying\n+            // with the same pivot (but note that the representative may have changed).\n+            m_nonminimal_chunks.emplace_back(new_rep, pivot, move_pivot_down);\n+        }\n+        return true;\n     }\n \n-    /** Find a high-feerate topologically-valid subset of what remains of the cluster.\n-     *  Requires !AllDone().\n-     *\n-     * @param[in] max_iterations  The maximum number of optimization steps that will be performed.\n-     * @param[in] best            A set/feerate pair with an already-known good candidate. This may\n-     *                            be empty.\n-     * @return                    A pair of:\n-     *                            - The best (highest feerate, smallest size as tiebreaker)\n-     *                              topologically valid subset (and its feerate) that was\n-     *                              encountered during search. It will be at least as good as the\n-     *                              best passed in (if not empty).\n-     *                            - The number of optimization steps that were performed. This will\n-     *                              be <= max_iterations. If strictly < max_iterations, the\n-     *                              returned subset is optimal.\n-     *\n-     * Complexity: possibly O(N * min(max_iterations, sqrt(2^N))) where N=depgraph.TxCount().\n-     */\n-    std::pair<SetInfo<SetType>, uint64_t> FindCandidateSet(uint64_t max_iterations, SetInfo<SetType> best) noexcept\n+    /** Construct a topologically-valid linearization from the current forest state. Must be\n+     *  topological. */\n+    std::vector<DepGraphIndex> GetLinearization() noexcept\n     {\n-        Assume(!AllDone());\n-\n-        // Convert the provided best to internal sorted indices.\n-        best.transactions = OriginalToSorted(best.transactions);\n-\n-        /** Type for work queue items. */\n-        struct WorkItem\n-        {\n-            /** Set of transactions definitely included (and its feerate). This must be a subset\n-             *  of m_todo, and be topologically valid (includes all in-m_todo ancestors of\n-             *  itself). */\n-            SetInfo<SetType> inc;\n-            /** Set of undecided transactions. This must be a subset of m_todo, and have no overlap\n-             *  with inc. The set (inc | und) must be topologically valid. */\n-            SetType und;\n-            /** (Only when inc is not empty) The best feerate of any superset of inc that is also a\n-             *  subset of (inc | und), without requiring it to be topologically valid. It forms a\n-             *  conservative upper bound on how good a set this work item can give rise to.\n-             *  Transactions whose feerate is below best's are ignored when determining this value,\n-             *  which means it may technically be an underestimate, but if so, this work item\n-             *  cannot result in something that beats best anyway. */\n-            FeeFrac pot_feerate;\n-\n-            /** Construct a new work item. */\n-            WorkItem(SetInfo<SetType>&& i, SetType&& u, FeeFrac&& p_f) noexcept :\n-                inc(std::move(i)), und(std::move(u)), pot_feerate(std::move(p_f))\n-            {\n-                Assume(pot_feerate.IsEmpty() == inc.feerate.IsEmpty());\n+        /** The output linearization. */\n+        std::vector<DepGraphIndex> ret;\n+        ret.reserve(m_transactions.Count());\n+        /** A heap with all chunks (by representative) that can currently be included, sorted by\n+         *  chunk feerate and a random tie-breaker. */\n+        std::vector<std::pair<TxIdx, uint64_t>> ready_chunks;\n+        /** Information about chunks:\n+         *  - The first value is only used for chunk representatives, and counts the number of\n+         *    unmet dependencies this chunk has on other chunks (not including dependencies within\n+         *    the chunk itself).\n+         *  - The second value is the number of unmet dependencies overall.\n+         */\n+        std::vector<std::pair<TxIdx, TxIdx>> chunk_deps(m_tx_data.size(), {0, 0});\n+        /** The set of all chunk representatives. */\n+        SetType chunk_reps;\n+        /** A heap with all transactions within the current chunk that can be included, sorted by\n+         *  random value. */\n+        std::vector<std::pair<uint64_t, TxIdx>> ready_tx;\n+        // Populate chunk_deps[c] with the number of {out-of-chunk dependencies, dependencies} the\n+        // child has.\n+        for (TxIdx chl_idx : m_transactions) {\n+            const auto& chl_data = m_tx_data[chl_idx];\n+            chunk_deps[chl_idx].second = chl_data.parents.Count();\n+            auto chl_chunk_rep = chl_data.chunk_rep;\n+            chunk_reps.Set(chl_chunk_rep);\n+            for (auto par_idx : chl_data.parents) {\n+                auto par_chunk_rep = m_tx_data[par_idx].chunk_rep;\n+                chunk_deps[chl_chunk_rep].first += (par_chunk_rep != chl_chunk_rep);\n             }\n-\n-            /** Swap two WorkItems. */\n-            void Swap(WorkItem& other) noexcept\n-            {\n-                swap(inc, other.inc);\n-                swap(und, other.und);\n-                swap(pot_feerate, other.pot_feerate);\n+        }\n+        // Construct a heap with all chunks that have no out-of-chunk dependencies.\n+        /** Comparison function for the heap. */\n+        auto chunk_cmp_fn = [&](const std::pair<TxIdx, uint64_t>& a, const std::pair<TxIdx, uint64_t>& b) noexcept {\n+            auto& chunk_a = m_tx_data[a.first];\n+            auto& chunk_b = m_tx_data[b.first];\n+            Assume(chunk_a.chunk_rep == a.first);\n+            Assume(chunk_b.chunk_rep == b.first);\n+            // First sort by chunk feerate.\n+            if (chunk_a.chunk_setinfo.feerate != chunk_b.chunk_setinfo.feerate) {\n+                return chunk_a.chunk_setinfo.feerate < chunk_b.chunk_setinfo.feerate;\n             }\n+            // Tie-break randomly.\n+            if (a.second != b.second) return a.second < b.second;\n+            // Lastly, tie-break by chunk representative.\n+            return a.first < b.first;\n         };\n-\n-        /** The queue of work items. */\n-        VecDeque<WorkItem> queue;\n-        queue.reserve(std::max<size_t>(256, 2 * m_todo.Count()));\n-\n-        // Create initial entries per connected component of m_todo. While clusters themselves are\n-        // generally connected, this is not necessarily true after some parts have already been\n-        // removed from m_todo. Without this, effort can be wasted on searching \"inc\" sets that\n-        // span multiple components.\n-        auto to_cover = m_todo;\n-        do {\n-            auto component = m_sorted_depgraph.FindConnectedComponent(to_cover);\n-            to_cover -= component;\n-            // If best is not provided, set it to the first component, so that during the work\n-            // processing loop below, and during the add_fn/split_fn calls, we do not need to deal\n-            // with the best=empty case.\n-            if (best.feerate.IsEmpty()) best = SetInfo(m_sorted_depgraph, component);\n-            queue.emplace_back(/*inc=*/SetInfo<SetType>{},\n-                               /*und=*/std::move(component),\n-                               /*pot_feerate=*/FeeFrac{});\n-        } while (to_cover.Any());\n-\n-        /** Local copy of the iteration limit. */\n-        uint64_t iterations_left = max_iterations;\n-\n-        /** The set of transactions in m_todo which have feerate > best's. */\n-        SetType imp = m_todo;\n-        while (imp.Any()) {\n-            DepGraphIndex check = imp.Last();\n-            if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-            imp.Reset(check);\n+        for (TxIdx chunk_rep : chunk_reps) {\n+            if (chunk_deps[chunk_rep].first == 0) ready_chunks.emplace_back(chunk_rep, m_rng.rand64());\n         }\n-\n-        /** Internal function to add an item to the queue of elements to explore if there are any\n-         *  transactions left to split on, possibly improving it before doing so, and to update\n-         *  best/imp.\n-         *\n-         * - inc: the \"inc\" value for the new work item (must be topological).\n-         * - und: the \"und\" value for the new work item ((inc | und) must be topological).\n-         */\n-        auto add_fn = [&](SetInfo<SetType> inc, SetType und) noexcept {\n-            /** SetInfo object with the set whose feerate will become the new work item's\n-             *  pot_feerate. It starts off equal to inc. */\n-            auto pot = inc;\n-            if (!inc.feerate.IsEmpty()) {\n-                // Add entries to pot. We iterate over all undecided transactions whose feerate is\n-                // higher than best. While undecided transactions of lower feerate may improve pot,\n-                // the resulting pot feerate cannot possibly exceed best's (and this item will be\n-                // skipped in split_fn anyway).\n-                for (auto pos : imp & und) {\n-                    // Determine if adding transaction pos to pot (ignoring topology) would improve\n-                    // it. If not, we're done updating pot. This relies on the fact that\n-                    // m_sorted_depgraph, and thus the transactions iterated over, are in decreasing\n-                    // individual feerate order.\n-                    if (!(m_sorted_depgraph.FeeRate(pos) >> pot.feerate)) break;\n-                    pot.Set(m_sorted_depgraph, pos);\n-                }\n-\n-                // The \"jump ahead\" optimization: whenever pot has a topologically-valid subset,\n-                // that subset can be added to inc. Any subset of (pot - inc) has the property that\n-                // its feerate exceeds that of any set compatible with this work item (superset of\n-                // inc, subset of (inc | und)). Thus, if T is a topological subset of pot, and B is\n-                // the best topologically-valid set compatible with this work item, and (T - B) is\n-                // non-empty, then (T | B) is better than B and also topological. This is in\n-                // contradiction with the assumption that B is best. Thus, (T - B) must be empty,\n-                // or T must be a subset of B.\n-                //\n-                // See https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303 section 2.4.\n-                const auto init_inc = inc.transactions;\n-                for (auto pos : pot.transactions - inc.transactions) {\n-                    // If the transaction's ancestors are a subset of pot, we can add it together\n-                    // with its ancestors to inc. Just update the transactions here; the feerate\n-                    // update happens below.\n-                    auto anc_todo = m_sorted_depgraph.Ancestors(pos) & m_todo;\n-                    if (anc_todo.IsSubsetOf(pot.transactions)) inc.transactions |= anc_todo;\n-                }\n-                // Finally update und and inc's feerate to account for the added transactions.\n-                und -= inc.transactions;\n-                inc.feerate += m_sorted_depgraph.FeeRate(inc.transactions - init_inc);\n-\n-                // If inc's feerate is better than best's, remember it as our new best.\n-                if (inc.feerate > best.feerate) {\n-                    best = inc;\n-                    // See if we can remove any entries from imp now.\n-                    while (imp.Any()) {\n-                        DepGraphIndex check = imp.Last();\n-                        if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-                        imp.Reset(check);\n-                    }\n+        std::make_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+        // Pop chunks off the heap, highest-feerate ones first.\n+        while (!ready_chunks.empty()) {\n+            auto [chunk_rep, _rnd] = ready_chunks.front();\n+            std::pop_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+            ready_chunks.pop_back();\n+            Assume(m_tx_data[chunk_rep].chunk_rep == chunk_rep);\n+            Assume(chunk_deps[chunk_rep].first == 0);\n+            const auto& chunk_txn = m_tx_data[chunk_rep].chunk_setinfo.transactions;\n+            // Build heap of all includable transactions in chunk.\n+            for (TxIdx tx_idx : chunk_txn) {\n+                if (chunk_deps[tx_idx].second == 0) {\n+                    ready_tx.emplace_back(m_rng.rand64(), tx_idx);\n                 }\n-\n-                // If no potential transactions exist beyond the already included ones, no\n-                // improvement is possible anymore.\n-                if (pot.feerate.size == inc.feerate.size) return;\n-                // At this point und must be non-empty. If it were empty then pot would equal inc.\n-                Assume(und.Any());\n-            } else {\n-                Assume(inc.transactions.None());\n-                // If inc is empty, we just make sure there are undecided transactions left to\n-                // split on.\n-                if (und.None()) return;\n-            }\n-\n-            // Actually construct a new work item on the queue. Due to the switch to DFS when queue\n-            // space runs out (see below), we know that no reallocation of the queue should ever\n-            // occur.\n-            Assume(queue.size() < queue.capacity());\n-            queue.emplace_back(/*inc=*/std::move(inc),\n-                               /*und=*/std::move(und),\n-                               /*pot_feerate=*/std::move(pot.feerate));\n-        };\n-\n-        /** Internal process function. It takes an existing work item, and splits it in two: one\n-         *  with a particular transaction (and its ancestors) included, and one with that\n-         *  transaction (and its descendants) excluded. */\n-        auto split_fn = [&](WorkItem&& elem) noexcept {\n-            // Any queue element must have undecided transactions left, otherwise there is nothing\n-            // to explore anymore.\n-            Assume(elem.und.Any());\n-            // The included and undecided set are all subsets of m_todo.\n-            Assume(elem.inc.transactions.IsSubsetOf(m_todo) && elem.und.IsSubsetOf(m_todo));\n-            // Included transactions cannot be undecided.\n-            Assume(!elem.inc.transactions.Overlaps(elem.und));\n-            // If pot is empty, then so is inc.\n-            Assume(elem.inc.feerate.IsEmpty() == elem.pot_feerate.IsEmpty());\n-\n-            const DepGraphIndex first = elem.und.First();\n-            if (!elem.inc.feerate.IsEmpty()) {\n-                // If no undecided transactions remain with feerate higher than best, this entry\n-                // cannot be improved beyond best.\n-                if (!elem.und.Overlaps(imp)) return;\n-                // We can ignore any queue item whose potential feerate isn't better than the best\n-                // seen so far.\n-                if (elem.pot_feerate <= best.feerate) return;\n-            } else {\n-                // In case inc is empty use a simpler alternative check.\n-                if (m_sorted_depgraph.FeeRate(first) <= best.feerate) return;\n             }\n-\n-            // Decide which transaction to split on. Splitting is how new work items are added, and\n-            // how progress is made. One split transaction is chosen among the queue item's\n-            // undecided ones, and:\n-            // - A work item is (potentially) added with that transaction plus its remaining\n-            //   descendants excluded (removed from the und set).\n-            // - A work item is (potentially) added with that transaction plus its remaining\n-            //   ancestors included (added to the inc set).\n-            //\n-            // To decide what to split on, consider the undecided ancestors of the highest\n-            // individual feerate undecided transaction. Pick the one which reduces the search space\n-            // most. Let I(t) be the size of the undecided set after including t, and E(t) the size\n-            // of the undecided set after excluding t. Then choose the split transaction t such\n-            // that 2^I(t) + 2^E(t) is minimal, tie-breaking by highest individual feerate for t.\n-            DepGraphIndex split = 0;\n-            const auto select = elem.und & m_sorted_depgraph.Ancestors(first);\n-            Assume(select.Any());\n-            std::optional<std::pair<DepGraphIndex, DepGraphIndex>> split_counts;\n-            for (auto t : select) {\n-                // Call max = max(I(t), E(t)) and min = min(I(t), E(t)). Let counts = {max,min}.\n-                // Sorting by the tuple counts is equivalent to sorting by 2^I(t) + 2^E(t). This\n-                // expression is equal to 2^max + 2^min = 2^max * (1 + 1/2^(max - min)). The second\n-                // factor (1 + 1/2^(max - min)) there is in (1,2]. Thus increasing max will always\n-                // increase it, even when min decreases. Because of this, we can first sort by max.\n-                std::pair<DepGraphIndex, DepGraphIndex> counts{\n-                    (elem.und - m_sorted_depgraph.Ancestors(t)).Count(),\n-                    (elem.und - m_sorted_depgraph.Descendants(t)).Count()};\n-                if (counts.first < counts.second) std::swap(counts.first, counts.second);\n-                // Remember the t with the lowest counts.\n-                if (!split_counts.has_value() || counts < *split_counts) {\n-                    split = t;\n-                    split_counts = counts;\n+            Assume(!ready_tx.empty());\n+            std::make_heap(ready_tx.begin(), ready_tx.end());\n+            // Pop transactions from the heap, append them to linearization, and decrement\n+            // dependency counts.\n+            while (!ready_tx.empty()) {\n+                // Pop from heap.\n+                auto [_rnd2, tx_idx] = ready_tx.front();\n+                Assume(chunk_txn[tx_idx]);\n+                std::pop_heap(ready_tx.begin(), ready_tx.end());\n+                ready_tx.pop_back();\n+                // Append to linearization.\n+                ret.push_back(tx_idx);\n+                // Decrement dependency counts.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                for (TxIdx chl_idx : tx_data.children) {\n+                    auto& chl_data = m_tx_data[chl_idx];\n+                    // Decrement tx dependency count.\n+                    Assume(chunk_deps[chl_idx].second > 0);\n+                    if (--chunk_deps[chl_idx].second == 0 && chunk_txn[chl_idx]) {\n+                        // Child tx has no dependencies left, and is in this chunk. Add it to the tx heap.\n+                        ready_tx.emplace_back(m_rng.rand64(), chl_idx);\n+                        std::push_heap(ready_tx.begin(), ready_tx.end());\n+                    }\n+                    // Decrement chunk dependency count if this is out-of-chunk dependency.\n+                    if (chl_data.chunk_rep != chunk_rep) {\n+                        Assume(chunk_deps[chl_data.chunk_rep].first > 0);\n+                        if (--chunk_deps[chl_data.chunk_rep].first == 0) {\n+                            // Child chunk has no dependencies left. Add it to the chunk heap.\n+                            ready_chunks.emplace_back(chl_data.chunk_rep, m_rng.rand64());\n+                            std::push_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+                        }\n+                    }\n                 }\n             }\n-            // Since there was at least one transaction in select, we must always find one.\n-            Assume(split_counts.has_value());\n-\n-            // Add a work item corresponding to exclusion of the split transaction.\n-            const auto& desc = m_sorted_depgraph.Descendants(split);\n-            add_fn(/*inc=*/elem.inc,\n-                   /*und=*/elem.und - desc);\n-\n-            // Add a work item corresponding to inclusion of the split transaction.\n-            const auto anc = m_sorted_depgraph.Ancestors(split) & m_todo;\n-            add_fn(/*inc=*/elem.inc.Add(m_sorted_depgraph, anc),\n-                   /*und=*/elem.und - anc);\n-\n-            // Account for the performed split.\n-            --iterations_left;\n-        };\n-\n-        // Work processing loop.\n-        //\n-        // New work items are always added at the back of the queue, but items to process use a\n-        // hybrid approach where they can be taken from the front or the back.\n-        //\n-        // Depth-first search (DFS) corresponds to always taking from the back of the queue. This\n-        // is very memory-efficient (linear in the number of transactions). Breadth-first search\n-        // (BFS) corresponds to always taking from the front, which potentially uses more memory\n-        // (up to exponential in the transaction count), but seems to work better in practice.\n-        //\n-        // The approach here combines the two: use BFS (plus random swapping) until the queue grows\n-        // too large, at which point we temporarily switch to DFS until the size shrinks again.\n-        while (!queue.empty()) {\n-            // Randomly swap the first two items to randomize the search order.\n-            if (queue.size() > 1 && m_rng.randbool()) {\n-                queue[0].Swap(queue[1]);\n-            }\n-\n-            // Processing the first queue item, and then using DFS for everything it gives rise to,\n-            // may increase the queue size by the number of undecided elements in there, minus 1\n-            // for the first queue item being removed. Thus, only when that pushes the queue over\n-            // its capacity can we not process from the front (BFS), and should we use DFS.\n-            while (queue.size() - 1 + queue.front().und.Count() > queue.capacity()) {\n-                if (!iterations_left) break;\n-                auto elem = queue.back();\n-                queue.pop_back();\n-                split_fn(std::move(elem));\n-            }\n-\n-            // Process one entry from the front of the queue (BFS exploration)\n-            if (!iterations_left) break;\n-            auto elem = queue.front();\n-            queue.pop_front();\n-            split_fn(std::move(elem));\n         }\n-\n-        // Return the found best set (converted to the original transaction indices), and the\n-        // number of iterations performed.\n-        best.transactions = SortedToOriginal(best.transactions);\n-        return {std::move(best), max_iterations - iterations_left};\n+        Assume(ret.size() == m_transactions.Count());\n+        return ret;\n     }\n \n-    /** Remove a subset of transactions from the cluster being linearized.\n-     *\n-     * Complexity: O(N) where N=done.Count().\n-     */\n-    void MarkDone(const SetType& done) noexcept\n-    {\n-        const auto done_sorted = OriginalToSorted(done);\n-        Assume(done_sorted.Any());\n-        Assume(done_sorted.IsSubsetOf(m_todo));\n-        m_todo -= done_sorted;\n-    }\n+    /** Determine how much work was performed so far. */\n+    uint64_t GetCost() const noexcept { return m_cost; }\n };\n \n /** Find or improve a linearization for a cluster.\n  *\n  * @param[in] depgraph            Dependency graph of the cluster to be linearized.\n- * @param[in] max_iterations      Upper bound on the number of optimization steps that will be done.\n+ * @param[in] max_iterations      Upper bound on the amount of work that will be done.\n  * @param[in] rng_seed            A random number seed to control search order. This prevents peers\n  *                                from predicting exactly which clusters would be hard for us to\n  *                                linearize.\n- * @param[in] old_linearization   An existing linearization for the cluster (which must be\n- *                                topologically valid), or empty.\n+ * @param[in] old_linearization   An existing linearization for the cluster, or empty.\n+ * @param[in] is_topological      (Only relevant if old_linearization is not empty) Whether\n+ *                                old_linearization is topologically valid.\n  * @return                        A tuple of:\n  *                                - The resulting linearization. It is guaranteed to be at least as\n  *                                  good (in the feerate diagram sense) as old_linearization.\n  *                                - A boolean indicating whether the result is guaranteed to be\n  *                                  optimal.\n  *                                - How many optimization steps were actually performed.\n- *\n- * Complexity: possibly O(N * min(max_iterations + N, sqrt(2^N))) where N=depgraph.TxCount().\n  */\n template<typename SetType>\n-std::tuple<std::vector<DepGraphIndex>, bool, uint64_t> Linearize(const DepGraph<SetType>& depgraph, uint64_t max_iterations, uint64_t rng_seed, std::span<const DepGraphIndex> old_linearization = {}) noexcept\n+std::tuple<std::vector<DepGraphIndex>, bool, uint64_t> Linearize(const DepGraph<SetType>& depgraph, uint64_t max_iterations, uint64_t rng_seed, std::span<const DepGraphIndex> old_linearization = {}, bool is_topological = true) noexcept",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 1495,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "52b983bf90e0bc5809a166924abe762f0d2bd975",
      "in_reply_to_id": null,
      "user": {
        "login": "Copilot",
        "id": 175728472,
        "node_id": "BOT_kgDOCnlnWA",
        "avatar_url": "https://avatars.githubusercontent.com/in/946600?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/Copilot",
        "html_url": "https://github.com/apps/copilot-pull-request-reviewer",
        "followers_url": "https://api.github.com/users/Copilot/followers",
        "following_url": "https://api.github.com/users/Copilot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/Copilot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/Copilot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/Copilot/subscriptions",
        "organizations_url": "https://api.github.com/users/Copilot/orgs",
        "repos_url": "https://api.github.com/users/Copilot/repos",
        "events_url": "https://api.github.com/users/Copilot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/Copilot/received_events",
        "type": "Bot",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "The new `is_topological` parameter defaults to `true`, but when `old_linearization` is empty, this parameter is ignored. This could be confusing for API consumers. Consider documenting this behavior more explicitly in the function comment, or validate that when `old_linearization` is empty, `is_topological` is not set to `false`.",
      "created_at": "2025-10-20T00:30:40Z",
      "updated_at": "2025-10-20T00:30:41Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2443583986",
      "author_association": "NONE",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2443583986"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1496,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2443583989",
      "pull_request_review_id": 3354761107,
      "id": 2443583989,
      "node_id": "PRRC_kwDOABII586RpiH1",
      "diff_hunk": "@@ -189,29 +44,7 @@ void BenchPostLinearizeWorstCase(DepGraphIndex ntx, benchmark::Bench& bench)\n     });\n }\n \n-template<typename SetType>\n-void BenchMergeLinearizationsWorstCase(DepGraphIndex ntx, benchmark::Bench& bench)\n-{\n-    DepGraph<SetType> depgraph;\n-    for (DepGraphIndex i = 0; i < ntx; ++i) {\n-        depgraph.AddTransaction({i, 1});\n-        if (i) depgraph.AddDependencies(SetType::Singleton(0), i);\n-    }\n-    std::vector<DepGraphIndex> lin1;\n-    std::vector<DepGraphIndex> lin2;\n-    lin1.push_back(0);\n-    lin2.push_back(0);\n-    for (DepGraphIndex i = 1; i < ntx; ++i) {\n-        lin1.push_back(i);\n-        lin2.push_back(ntx - i);\n-    }\n-    bench.run([&] {\n-        MergeLinearizations(depgraph, lin1, lin2);\n-    });\n-}\n-\n-template<size_t N>\n-void BenchLinearizeOptimally(benchmark::Bench& bench, const std::array<uint8_t, N>& serialized)\n+void BenchLinearizeOptimally(benchmark::Bench& bench, const std::vector<uint8_t>& serialized)",
      "path": "src/bench/cluster_linearize.cpp",
      "position": 1,
      "original_position": 186,
      "commit_id": "8fe6a71941ab327772f6018c9da9d7ee8f371bc4",
      "original_commit_id": "52b983bf90e0bc5809a166924abe762f0d2bd975",
      "in_reply_to_id": null,
      "user": {
        "login": "Copilot",
        "id": 175728472,
        "node_id": "BOT_kgDOCnlnWA",
        "avatar_url": "https://avatars.githubusercontent.com/in/946600?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/Copilot",
        "html_url": "https://github.com/apps/copilot-pull-request-reviewer",
        "followers_url": "https://api.github.com/users/Copilot/followers",
        "following_url": "https://api.github.com/users/Copilot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/Copilot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/Copilot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/Copilot/subscriptions",
        "organizations_url": "https://api.github.com/users/Copilot/orgs",
        "repos_url": "https://api.github.com/users/Copilot/repos",
        "events_url": "https://api.github.com/users/Copilot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/Copilot/received_events",
        "type": "Bot",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "[nitpick] The function signature changed from accepting `const std::array<uint8_t, N>&` to `const std::vector<uint8_t>&`. This removes compile-time size checking. While this makes the function more flexible, it also removes a safety guarantee. Consider if the added flexibility is worth the loss of compile-time size verification.\n```suggestion\ntemplate <size_t N>\nvoid BenchLinearizeOptimally(benchmark::Bench& bench, const std::array<uint8_t, N>& serialized)\n```",
      "created_at": "2025-10-20T00:30:41Z",
      "updated_at": "2025-10-20T00:30:41Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2443583989",
      "author_association": "NONE",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2443583989"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 47,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2586214542",
      "pull_request_review_id": 3536407029,
      "id": 2586214542,
      "node_id": "PRRC_kwDOABII586aJoCO",
      "diff_hunk": "@@ -386,6 +386,22 @@ struct SetInfo\n         return *this;\n     }\n \n+    /** Remove the transactions of other from this SetInfo (must be subset). */\n+    SetInfo& operator-=(const SetInfo& other) noexcept\n+    {\n+        Assume(other.transactions.IsSubsetOf(transactions));\n+        transactions -= other.transactions;\n+        feerate -= other.feerate;\n+        return *this;\n+    }\n+\n+    /** Compute the difference between this and other SetInfo (which must be a subset). */\n+    SetInfo operator-(const SetInfo& other) noexcept",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 14,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "in_reply_to_id": null,
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "```suggestion\n    SetInfo operator-(const SetInfo& other) const noexcept\n```",
      "created_at": "2025-12-03T18:36:42Z",
      "updated_at": "2025-12-03T19:10:28Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2586214542",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2586214542"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 399,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2586249205",
      "pull_request_review_id": 3536407029,
      "id": 2586249205,
      "node_id": "PRRC_kwDOABII586aJwf1",
      "diff_hunk": "@@ -423,710 +459,1071 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their\n+ *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n+ *     remain.\n+ * - Loop until optimal or time runs out:\n+ *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n+ *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of starting with an empty graph and making it topological directly, it is possible to\n+ * bootstrap from an existing linearization:\n+ * - Start with an empty graph.\n+ * - For each transaction t in the existing linearization:\n+ *   - Add the transaction as a singleton chunk to the graph.\n+ *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n+ *     merged result.\n+ *\n+ * This guarantees an initial, topological, state whose output linearization is at least as good\n+ * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ *\n+ * What remains to be specified are two heuristics:\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Define the gain of an active dependency as\n+ *     (feerate(top) - feerate(chunk)) * size(top) * size(chunk), also equal to:\n+ *     fee(top) * size(chunk) - fee(chunk) * size(top).\n+ *   - After every split, it is possible that the top and the bottom chunk merge with each other\n+ *     again in the merge sequence (through a top->bottom dependency, not through the deactivated\n+ *     one, which was bottom->top). Call this a self-merge. If a self-merge does not occur after\n+ *     a split, the resulting linearization is strictly improved (the area under the fee-size\n+ *     diagram increases by at least gain/2), while self-merges do not change it.\n+ *   - Keep track of how many consecutive self-merges a chunk undergoes: incremented upon\n+ *     self-merge, and reset to 0 in both top and bottom otherwise.\n+ *   - If the number of consecutive self-merges is 2 mod 3 (i.e., it is 2, 5, 8, 11, ...), a\n+ *     uniformly random dependency in the chunk among those with strictly positive gain is\n+ *     deactivated.\n+ *   - Otherwise (self-merges so far is not 2 mod 3), a uniformly random dependency within a chunk\n+ *     among those with maximal gain is deactivated, if any with strictly positive gain exist.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - A uniformly random dependency between the two maximum-feerate-difference chunks is activated.\n+ *\n+ * If an optimal state is found by the above procedure, it is still possible that it contains\n+ * chunks that can be split further into equal-feerate chunks. To find these, a second stage is\n+ * added, which acts as if the feerates of transactions are perturbed slightly, to make\n+ * equal-feerate parts of chunks break apart. The idea is:\n+ * - If a transaction t is given slightly higher feerate than it really has, and an equal-feerate\n+ *   topological subset of the chunk exists with t in it, it will be found using the normal\n+ *   algorithm.\n+ * - If a transaction t is given slightly *lower* feerate than it really has, and an equal-feerate\n+ *   topological subset of the chunk exists with t *not* in it, it will be found using the normal\n+ *   algorithm.\n+ * Thus, by picking one transaction in a chunk, and trying both of the approaches above, then if a\n+ * split exists, it must be found, because the subset must either contain t or not contain it.\n+ *\n+ * Specifically, within each chunk:\n+ * - Pick an arbitrary pivot transaction t in the chunk.\n+ * - Loop:\n+ *   - Find a gain=0 dependency d in the chunk where t appears in its top. If not found, stop.\n+ *   - Deactivate d.\n+ *   - Find a dependency e from d's top to d's bottom. If not found, recurse into the created top\n+ *     and bottom chunks.\n+ *   - Activate e.\n+ * - Loop:\n+ *   - Find a gain=0 dependency d in the chunk where t appears in its bottom. If not found, stop.\n+ *   - Deactivate d.\n+ *   - Find a dependency e from d's top to d's bottom. If not found, recurse into the created top\n+ *     and bottom chunks.\n+ *   - Activate e.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = std::conditional_t<(SetType::Size() <= 32), uint8_t, std::conditional_t<(SetType::Size() <= 512), uint16_t, uint32_t>>;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. All active ones (see\n+         *  child_deps_active) appear first. */\n+        std::array<DepIdx, SetType::Size() - 1> child_deps;\n+        /** The number of children of this transaction. Immutable after construction. */\n+        TxIdx child_deps_total{0};\n+        /** The number of active children of this transaction. */\n+        TxIdx child_deps_active{0};\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** The set of parent transactions of this transaction reachable through active\n+         *  dependencies. */\n+        SetType active_parents;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+        /** In what ways this transaction exists in suboptimality lists:\n+         *  - 0: not in m_suboptimal_chunks\n+         *  - >0: in m_suboptimal_chunks, and:\n+         *    - (during optimization) 1: needs processing\n+         *    - (during MakeTopological) 1: needs to be merged upwards\n+         *    - (during MakeTopological) 2: needs to be merged downwards\n+         *    - (during MakeTopological) 3: needs to be merged upwards and downwards */\n+        unsigned suboptimal{0};\n+        /** Number of consecutive self-merges this chunk has experienced. */\n+        uint32_t self_merges;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** Index into the parent's TxData::child_deps where this dependency appears. */\n+        DepIdx child_pos;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+    /** A FIFO of chunk representatives, a pivot tx in it, and the stage it is in (false = first\n+     *  stage, move pivot up, true = second stage, move pivot down). */\n+    VecDeque<std::tuple<TxIdx, TxIdx, bool>> m_nonminimal_chunks;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** A metric for predicting the runtime of the algorithm. Corresponds to ~2ns on Ryzen 7995WX. */\n+    uint64_t m_cost{0};\n+\n+    /** Walk a chunk, starting from transaction start. visit_tx(idx) is called for each encountered\n+     *  transaction. visit_dep_down(dep) is called for each encountered dependency that is traversed\n+     *  in the parent-to-child (downward) direction. */\n+    void Walk(TxIdx start, std::invocable<TxData&> auto visit_tx, std::invocable<DepData&> auto visit_dep_down) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo) {\n+                // Mark the transaction as processed, and invoke the visitor for it.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                visit_tx(tx_data);\n+                // Mark all active parents as to be processed.\n+                todo |= tx_data.active_parents;\n+                todo -= done;\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps}.first(tx_data.child_deps_active);\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    // If this is the first time reaching the child, mark it as todo, and invoke\n+                    // the downward dependency visitor for it. We do not need to check if it isn't\n+                    // already in todo here, because there cannot be multiple dependencies that\n+                    // reach the same transaction; the !done check is purely to prevent travelling\n+                    // an already-travelled dependency back in reverse direction.\n+                    if (!done[dep_entry.child]) {\n+                        Assume(!todo[dep_entry.child]);\n+                        todo.Set(dep_entry.child);\n+                        visit_dep_down(dep_entry);\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n-        }\n+        } while (todo.Any());\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Swap two dependencies in a given transaction's implied list of child deps. */\n+    void SwapChildDeps(TxData& tx_data, DepIdx pos1, DepIdx pos2) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        if (pos1 == pos2) return;\n+        std::swap(tx_data.child_deps[pos1], tx_data.child_deps[pos2]);\n+        m_dep_data[tx_data.child_deps[pos1]].child_pos = pos1;\n+        m_dep_data[tx_data.child_deps[pos2]].child_pos = pos2;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make dep_idx the first inactive dependency in the parent's list of child deps.\n+        SwapChildDeps(parent_tx_data, dep_data.child_pos, parent_tx_data.child_deps_active);\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        int ntx = par_chunk_data.chunk_setinfo.transactions.Count();\n+        m_cost += ntx * 4 - 3;\n+        // Add bottom component to top transactions.\n+        Walk(dep_data.parent,\n+             [](TxData&) noexcept {},\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= bottom_part; });\n+        // Add top component to bottom transactions.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= top_part; });\n+        // Make active.\n+        dep_data.top_setinfo = top_part;\n+        child_tx_data.active_parents.Set(dep_data.parent);\n+        parent_tx_data.child_deps_active += 1;\n+        Assume(parent_tx_data.child_deps_active <= parent_tx_data.child_deps_total);\n+        return top_rep;\n+    }\n \n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make dep_idx the last active dependency in the parent's list of child deps.\n+        SwapChildDeps(parent_tx_data, dep_data.child_pos, parent_tx_data.child_deps_active - 1);\n+        // Make inactive.\n+        child_tx_data.active_parents.Reset(dep_data.parent);\n+        parent_tx_data.child_deps_active -= 1;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        int ntx = chunk_data.chunk_setinfo.transactions.Count();\n+        m_cost += ntx * 4 + 2;\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        chunk_data.chunk_setinfo = top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        Walk(dep_data.parent,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= bottom_part; });\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = bottom_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= top_part; });\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep. Return the representative of the merged chunk, or TxIdx(-1) if no merge took\n+     *  place. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n+            m_cost += 1;\n+        }\n+        if (num_deps == 0) return TxIdx(-1);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            m_cost += 1;\n+            if (pick < count) {\n+                for (auto dep : std::span{tx_data.child_deps}.first(tx_data.child_deps_total)\n+                                                             .subspan(tx_data.child_deps_active)) {\n+                    m_cost += 1;\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n         }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a uniformly\n+        // random one among them (using random tiebreaker).\n+        SetType explored = chunk_txn;\n+        FeeFrac best_other_chunk_feerate;\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto unreached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            while (unreached.Any()) {\n+                m_cost += 3;\n+                auto chunk_rep = m_tx_data[unreached.First()].chunk_rep;\n+                auto& reached = m_tx_data[m_tx_data[unreached.First()].chunk_rep].chunk_setinfo;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 545,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "in_reply_to_id": null,
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "nit: Is there a reason we recalculate here vs just using `chunk_rep` from the line above? \n\nAlso additional nit: The local `chunk_rep` is named the same as the function parameter and both are `TxIdx` I believe. Could be worth having different names? ",
      "created_at": "2025-12-03T18:50:12Z",
      "updated_at": "2025-12-03T19:10:28Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2586249205",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2586249205"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 850,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590318854",
      "pull_request_review_id": 3541747493,
      "id": 2590318854,
      "node_id": "PRRC_kwDOABII586aZSEG",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 37,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "```Suggestion\r\n * The collection of all spanning trees for the entire cluster form a spanning forest. In the extreme each\r\n```",
      "created_at": "2025-12-04T19:31:56Z",
      "updated_at": "2025-12-08T19:21:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2590318854",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590318854"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 474,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590327658",
      "pull_request_review_id": 3541747493,
      "id": 2590327658,
      "node_id": "PRRC_kwDOABII586aZUNq",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 43,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "> or equal\r\n\r\nNeed to understand why, delving seems to suggest the more \"natural\" choice https://delvingbitcoin.org/t/spanning-forest-cluster-linearization/1419 \"If there is an inactive dependency, where the parent and child are in distinct chunks, and the child chunk has higher feerate than the parent chunk, make the dependency active, merging the two chunks.\"",
      "created_at": "2025-12-04T19:35:12Z",
      "updated_at": "2025-12-08T19:21:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2590327658",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590327658"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 481,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590419145",
      "pull_request_review_id": 3541747493,
      "id": 2590419145,
      "node_id": "PRRC_kwDOABII586aZqjJ",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 87,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "do you mean pick a chunk randomly, then observer the dependency/dependee list, and pick the corresponding lowers/highest feerate one for activation?",
      "created_at": "2025-12-04T20:07:34Z",
      "updated_at": "2025-12-08T19:21:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2590419145",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590419145"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 525,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590509887",
      "pull_request_review_id": 3541747493,
      "id": 2590509887,
      "node_id": "PRRC_kwDOABII586aaAs_",
      "diff_hunk": "@@ -1130,6 +1134,103 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the behavior of SpanningForestState.\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    try {\n+        reader >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    /** Whether to make the depgraph connected. */\n+    const bool make_connected = flags & 1;\n+    /** Whether to load an input linearization into SFL state. */\n+    const bool load_linearization = flags & 2;\n+    /** Whether to load a topological input linearization into SFL state. */\n+    const bool load_topological = load_linearization && (flags & 4);\n+    /** Whether to make the SFL state topological. */\n+    const bool make_topological = flags & 8;\n+    /** Whether to do any optimization steps to the SFL state (only if state is topological\n+     *  then). */\n+    const bool try_optimize = flags & 16;\n+\n+    //\n+    // Construct the depgraph and SFL state for it.\n+    //\n+    bool is_topological = false;\n+    if (make_connected) MakeConnected(depgraph);\n+    SpanningForestState sfl(depgraph);\n+\n+    //\n+    // Read and load input linearization, if selected.\n+    //\n+    std::vector<DepGraphIndex> input_lin;\n+    if (load_linearization) {\n+        input_lin = ReadLinearization(depgraph, reader, load_topological);\n+        sfl.LoadLinearization(input_lin);\n+        if (load_topological) is_topological = true;\n+    }\n+\n+    //\n+    // Make topological, if selected.\n+    //\n+    if (make_topological) {\n+        sfl.MakeTopological();\n+        is_topological = true;\n+    }\n+\n+    //\n+    // Perform optimization steps, if selected.\n+    //\n+    bool is_optimal = false;\n+    if (is_topological && try_optimize) {\n+        uint32_t optimize_steps{1};\n+        try {\n+            reader >> VARINT(optimize_steps);\n+        } catch (const std::ios_base::failure&) {}\n+        while (optimize_steps > 0) {\n+            --optimize_steps;\n+            if (!sfl.OptimizeStep()) {\n+                is_optimal = true;\n+                break;\n+            }\n+        }\n+    }\n+\n+    //\n+    // Sanity check the result.\n+    //\n+    sfl.SanityCheck(depgraph);\n+\n+    //\n+    // If the SFL state is (known to be) topological now, we can get a linearization out.\n+    //\n+    if (is_topological) {\n+        auto lin = sfl.GetLinearization();\n+        // Which must be valid.\n+        SanityCheck(depgraph, lin);\n+        // If we started from a topological input, the resulting feerate diagram cannot be worse.",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 143,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "```Suggestion\r\n        // If we started from a topological input, the resulting feerate diagram cannot be worse or incomparable.\r\n```",
      "created_at": "2025-12-04T20:40:31Z",
      "updated_at": "2025-12-08T19:21:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2590509887",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590509887"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 930,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590522916",
      "pull_request_review_id": 3541747493,
      "id": 2590522916,
      "node_id": "PRRC_kwDOABII586aaD4k",
      "diff_hunk": "@@ -799,14 +739,11 @@ FUZZ_TARGET(clusterlin_simple_finder)\n     // AncestorCandidateFinder it is being tested against.",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 152,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "original_commit_id": "85cff48b782538ed5a1c980015dd01cb32986b66",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "85cff48b782538ed5a1c980015dd01cb32986b66\r\n\r\nstraggling AncestorCandidateFinder reference",
      "created_at": "2025-12-04T20:44:57Z",
      "updated_at": "2025-12-08T19:21:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2590522916",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2590522916"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 745,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2593658728",
      "pull_request_review_id": 3541747493,
      "id": 2593658728,
      "node_id": "PRRC_kwDOABII586amBdo",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their\n+ *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n+ *     remain.\n+ * - Loop until optimal or time runs out:\n+ *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n+ *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of starting with an empty graph and making it topological directly, it is possible to\n+ * bootstrap from an existing linearization:\n+ * - Start with an empty graph.\n+ * - For each transaction t in the existing linearization:\n+ *   - Add the transaction as a singleton chunk to the graph.\n+ *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n+ *     merged result.\n+ *\n+ * This guarantees an initial, topological, state whose output linearization is at least as good\n+ * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ *\n+ * What remains to be specified are two heuristics:\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Currently, the first encountered dependency whose would-be top chunk has higher feerate than\n+ *     its would-be bottom chunk is deactivated. This will be changed in a future commit.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - Currently, the first encountered dependency between the two maximum-feerate-difference chunks\n+ *     is activated. This will be changed in a future commit.\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of activations/deactivations performed. */\n+    uint64_t m_operations{0};\n+\n+    /** Walk a chunk, starting from transaction start. visit_tx(idx) is called for each encountered\n+     *  transaction. visit_dep_down(dep) is called for each encountered dependency that is traversed\n+     *  in the parent-to-child (downward) direction. */\n+    void Walk(TxIdx start, std::invocable<TxData&> auto visit_tx, std::invocable<DepData&> auto visit_dep_down) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo) {\n+                // Mark the transaction as processed, and invoke the visitor for it.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                todo.Reset(tx_idx);\n+                visit_tx(tx_data);\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo if not done already.\n+                    if (!done[dep_entry.parent]) {\n+                        todo.Set(dep_entry.parent);\n+                    }\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and invoke\n+                    // the downward dependency visitor for it. We do not need to check if it isn't\n+                    // already in todo here, because there cannot be multiple dependencies that\n+                    // reach the same transaction; the !done check is purely to prevent travelling\n+                    // an already-travelled dependency back in reverse direction.\n+                    if (!done[dep_entry.child]) {\n+                        Assume(!todo[dep_entry.child]);\n+                        todo.Set(dep_entry.child);\n+                        visit_dep_down(dep_entry);\n+                    }\n+                }\n+            }\n+        } while (todo.Any());\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        // Add bottom component to top transactions.\n+        Walk(dep_data.parent,\n+             [](TxData&) noexcept {},\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= bottom_part; });\n+        // Add top component to bottom transactions.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= top_part; });\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        ++m_operations;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        chunk_data.chunk_setinfo = top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        Walk(dep_data.parent,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= bottom_part; });\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = bottom_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= top_part; });\n+        ++m_operations;\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist.. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the first one\n+        // one among them.\n+        SetType explored = chunk_txn;\n+        FeeFrac best_other_chunk_feerate;\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto unreached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            while (unreached.Any()) {\n+                auto chunk_rep = m_tx_data[unreached.First()].chunk_rep;\n+                auto& reached = m_tx_data[m_tx_data[unreached.First()].chunk_rep].chunk_setinfo;\n+                explored |= reached.transactions;\n+                unreached -= explored;\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached.feerate)\n+                                    : FeeRateCompare(reached.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                if ((cmp < 0) || (best_other_chunk_rep == TxIdx(-1))) {\n+                    best_other_chunk_feerate = reached.feerate;\n+                    best_other_chunk_rep = chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if all of the depended-on chunks have a lower/higher feerate than the chunk\n+        // that tx_idx is in.\n+        if (best_other_chunk_feerate.IsEmpty()) return TxIdx(-1);\n+        if (DownWard && best_other_chunk_feerate << chunk_data.chunk_setinfo.feerate) return TxIdx(-1);\n+        if (!DownWard && best_other_chunk_feerate >> chunk_data.chunk_setinfo.feerate) return TxIdx(-1);\n+        Assume(best_other_chunk_rep != TxIdx(-1));\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parent_deps.push_back(dep_idx);\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n+            }\n+        }\n+    }\n+\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n+    {\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n+    }\n+\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n+    {\n+        while (true) {\n+            bool done = true;\n+            // Iterate over all transactions (only processing those which are chunk representatives).\n+            for (auto chunk : m_transactions) {\n+                auto& chunk_data = m_tx_data[chunk];\n+                // If this is not a chunk representative, skip.\n+                if (chunk_data.chunk_rep != chunk) continue;\n+                // Attempt to merge the chunk upwards.\n+                auto result_up = MergeStep<false>(chunk);\n+                if (result_up != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+                // Attempt to merge the chunk downwards.\n+                auto result_down = MergeStep<true>(chunk);\n+                if (result_down != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+            }\n+            // Stop if no changes were made anymore.\n+            if (done) break;\n+        }\n+    }\n+\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n+    {\n+        // Iterate over all transactions (only processing those which are chunk representatives).\n+        for (auto chunk : m_transactions) {\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If this is not a chunk representative, skip.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Iterate over all transactions of the chunk.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    if (!(dep_data.top_setinfo.feerate >> chunk_data.chunk_setinfo.feerate)) continue;\n+                    // Activate it otherwise.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 479,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "```Suggestion\r\n                    // De-activate it otherwise.\r\n```",
      "created_at": "2025-12-05T18:55:11Z",
      "updated_at": "2025-12-08T19:21:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2593658728",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2593658728"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1124,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2595408520",
      "pull_request_review_id": 3548229799,
      "id": 2595408520,
      "node_id": "PRRC_kwDOABII586assqI",
      "diff_hunk": "@@ -386,6 +386,22 @@ struct SetInfo\n         return *this;\n     }\n \n+    /** Remove the transactions of other from this SetInfo (must be subset). */\n+    SetInfo& operator-=(const SetInfo& other) noexcept\n+    {\n+        Assume(other.transactions.IsSubsetOf(transactions));\n+        transactions -= other.transactions;\n+        feerate -= other.feerate;\n+        return *this;\n+    }\n+\n+    /** Compute the difference between this and other SetInfo (which must be a subset). */\n+    SetInfo operator-(const SetInfo& other) noexcept",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 14,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "in_reply_to_id": 2586214542,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-06T20:16:04Z",
      "updated_at": "2025-12-06T20:16:04Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2595408520",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2595408520"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 399,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2595409347",
      "pull_request_review_id": 3548230815,
      "id": 2595409347,
      "node_id": "PRRC_kwDOABII586ass3D",
      "diff_hunk": "@@ -423,710 +459,1071 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their\n+ *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n+ *     remain.\n+ * - Loop until optimal or time runs out:\n+ *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n+ *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of starting with an empty graph and making it topological directly, it is possible to\n+ * bootstrap from an existing linearization:\n+ * - Start with an empty graph.\n+ * - For each transaction t in the existing linearization:\n+ *   - Add the transaction as a singleton chunk to the graph.\n+ *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n+ *     merged result.\n+ *\n+ * This guarantees an initial, topological, state whose output linearization is at least as good\n+ * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ *\n+ * What remains to be specified are two heuristics:\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Define the gain of an active dependency as\n+ *     (feerate(top) - feerate(chunk)) * size(top) * size(chunk), also equal to:\n+ *     fee(top) * size(chunk) - fee(chunk) * size(top).\n+ *   - After every split, it is possible that the top and the bottom chunk merge with each other\n+ *     again in the merge sequence (through a top->bottom dependency, not through the deactivated\n+ *     one, which was bottom->top). Call this a self-merge. If a self-merge does not occur after\n+ *     a split, the resulting linearization is strictly improved (the area under the fee-size\n+ *     diagram increases by at least gain/2), while self-merges do not change it.\n+ *   - Keep track of how many consecutive self-merges a chunk undergoes: incremented upon\n+ *     self-merge, and reset to 0 in both top and bottom otherwise.\n+ *   - If the number of consecutive self-merges is 2 mod 3 (i.e., it is 2, 5, 8, 11, ...), a\n+ *     uniformly random dependency in the chunk among those with strictly positive gain is\n+ *     deactivated.\n+ *   - Otherwise (self-merges so far is not 2 mod 3), a uniformly random dependency within a chunk\n+ *     among those with maximal gain is deactivated, if any with strictly positive gain exist.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - A uniformly random dependency between the two maximum-feerate-difference chunks is activated.\n+ *\n+ * If an optimal state is found by the above procedure, it is still possible that it contains\n+ * chunks that can be split further into equal-feerate chunks. To find these, a second stage is\n+ * added, which acts as if the feerates of transactions are perturbed slightly, to make\n+ * equal-feerate parts of chunks break apart. The idea is:\n+ * - If a transaction t is given slightly higher feerate than it really has, and an equal-feerate\n+ *   topological subset of the chunk exists with t in it, it will be found using the normal\n+ *   algorithm.\n+ * - If a transaction t is given slightly *lower* feerate than it really has, and an equal-feerate\n+ *   topological subset of the chunk exists with t *not* in it, it will be found using the normal\n+ *   algorithm.\n+ * Thus, by picking one transaction in a chunk, and trying both of the approaches above, then if a\n+ * split exists, it must be found, because the subset must either contain t or not contain it.\n+ *\n+ * Specifically, within each chunk:\n+ * - Pick an arbitrary pivot transaction t in the chunk.\n+ * - Loop:\n+ *   - Find a gain=0 dependency d in the chunk where t appears in its top. If not found, stop.\n+ *   - Deactivate d.\n+ *   - Find a dependency e from d's top to d's bottom. If not found, recurse into the created top\n+ *     and bottom chunks.\n+ *   - Activate e.\n+ * - Loop:\n+ *   - Find a gain=0 dependency d in the chunk where t appears in its bottom. If not found, stop.\n+ *   - Deactivate d.\n+ *   - Find a dependency e from d's top to d's bottom. If not found, recurse into the created top\n+ *     and bottom chunks.\n+ *   - Activate e.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = std::conditional_t<(SetType::Size() <= 32), uint8_t, std::conditional_t<(SetType::Size() <= 512), uint16_t, uint32_t>>;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. All active ones (see\n+         *  child_deps_active) appear first. */\n+        std::array<DepIdx, SetType::Size() - 1> child_deps;\n+        /** The number of children of this transaction. Immutable after construction. */\n+        TxIdx child_deps_total{0};\n+        /** The number of active children of this transaction. */\n+        TxIdx child_deps_active{0};\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** The set of parent transactions of this transaction reachable through active\n+         *  dependencies. */\n+        SetType active_parents;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+        /** In what ways this transaction exists in suboptimality lists:\n+         *  - 0: not in m_suboptimal_chunks\n+         *  - >0: in m_suboptimal_chunks, and:\n+         *    - (during optimization) 1: needs processing\n+         *    - (during MakeTopological) 1: needs to be merged upwards\n+         *    - (during MakeTopological) 2: needs to be merged downwards\n+         *    - (during MakeTopological) 3: needs to be merged upwards and downwards */\n+        unsigned suboptimal{0};\n+        /** Number of consecutive self-merges this chunk has experienced. */\n+        uint32_t self_merges;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** Index into the parent's TxData::child_deps where this dependency appears. */\n+        DepIdx child_pos;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+    /** A FIFO of chunk representatives, a pivot tx in it, and the stage it is in (false = first\n+     *  stage, move pivot up, true = second stage, move pivot down). */\n+    VecDeque<std::tuple<TxIdx, TxIdx, bool>> m_nonminimal_chunks;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** A metric for predicting the runtime of the algorithm. Corresponds to ~2ns on Ryzen 7995WX. */\n+    uint64_t m_cost{0};\n+\n+    /** Walk a chunk, starting from transaction start. visit_tx(idx) is called for each encountered\n+     *  transaction. visit_dep_down(dep) is called for each encountered dependency that is traversed\n+     *  in the parent-to-child (downward) direction. */\n+    void Walk(TxIdx start, std::invocable<TxData&> auto visit_tx, std::invocable<DepData&> auto visit_dep_down) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo) {\n+                // Mark the transaction as processed, and invoke the visitor for it.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                visit_tx(tx_data);\n+                // Mark all active parents as to be processed.\n+                todo |= tx_data.active_parents;\n+                todo -= done;\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps}.first(tx_data.child_deps_active);\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    // If this is the first time reaching the child, mark it as todo, and invoke\n+                    // the downward dependency visitor for it. We do not need to check if it isn't\n+                    // already in todo here, because there cannot be multiple dependencies that\n+                    // reach the same transaction; the !done check is purely to prevent travelling\n+                    // an already-travelled dependency back in reverse direction.\n+                    if (!done[dep_entry.child]) {\n+                        Assume(!todo[dep_entry.child]);\n+                        todo.Set(dep_entry.child);\n+                        visit_dep_down(dep_entry);\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n-        }\n+        } while (todo.Any());\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Swap two dependencies in a given transaction's implied list of child deps. */\n+    void SwapChildDeps(TxData& tx_data, DepIdx pos1, DepIdx pos2) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        if (pos1 == pos2) return;\n+        std::swap(tx_data.child_deps[pos1], tx_data.child_deps[pos2]);\n+        m_dep_data[tx_data.child_deps[pos1]].child_pos = pos1;\n+        m_dep_data[tx_data.child_deps[pos2]].child_pos = pos2;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make dep_idx the first inactive dependency in the parent's list of child deps.\n+        SwapChildDeps(parent_tx_data, dep_data.child_pos, parent_tx_data.child_deps_active);\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        int ntx = par_chunk_data.chunk_setinfo.transactions.Count();\n+        m_cost += ntx * 4 - 3;\n+        // Add bottom component to top transactions.\n+        Walk(dep_data.parent,\n+             [](TxData&) noexcept {},\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= bottom_part; });\n+        // Add top component to bottom transactions.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= top_part; });\n+        // Make active.\n+        dep_data.top_setinfo = top_part;\n+        child_tx_data.active_parents.Set(dep_data.parent);\n+        parent_tx_data.child_deps_active += 1;\n+        Assume(parent_tx_data.child_deps_active <= parent_tx_data.child_deps_total);\n+        return top_rep;\n+    }\n \n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make dep_idx the last active dependency in the parent's list of child deps.\n+        SwapChildDeps(parent_tx_data, dep_data.child_pos, parent_tx_data.child_deps_active - 1);\n+        // Make inactive.\n+        child_tx_data.active_parents.Reset(dep_data.parent);\n+        parent_tx_data.child_deps_active -= 1;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        int ntx = chunk_data.chunk_setinfo.transactions.Count();\n+        m_cost += ntx * 4 + 2;\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        chunk_data.chunk_setinfo = top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        Walk(dep_data.parent,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= bottom_part; });\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = bottom_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= top_part; });\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep. Return the representative of the merged chunk, or TxIdx(-1) if no merge took\n+     *  place. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n+            m_cost += 1;\n+        }\n+        if (num_deps == 0) return TxIdx(-1);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            m_cost += 1;\n+            if (pick < count) {\n+                for (auto dep : std::span{tx_data.child_deps}.first(tx_data.child_deps_total)\n+                                                             .subspan(tx_data.child_deps_active)) {\n+                    m_cost += 1;\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n         }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a uniformly\n+        // random one among them (using random tiebreaker).\n+        SetType explored = chunk_txn;\n+        FeeFrac best_other_chunk_feerate;\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto unreached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            while (unreached.Any()) {\n+                m_cost += 3;\n+                auto chunk_rep = m_tx_data[unreached.First()].chunk_rep;\n+                auto& reached = m_tx_data[m_tx_data[unreached.First()].chunk_rep].chunk_setinfo;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 545,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "in_reply_to_id": 2586249205,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Nice catch, done both.",
      "created_at": "2025-12-06T20:16:22Z",
      "updated_at": "2025-12-06T20:16:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2595409347",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2595409347"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 850,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2599895617",
      "pull_request_review_id": 3553764549,
      "id": 2599895617,
      "node_id": "PRRC_kwDOABII586a90JB",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 43,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590327658,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "If you don't merge along equal-feerate dependencies, you can end up in a situation with two equal-feerate \"chunks\" that depend on each other.\r\n\r\nE.g. the AC and BD \"chunks\" in:\r\n\r\n```mermaid\r\ngraph BT;\r\nA[\"A: 1/1\"];\r\nB[\"B: 1/1\"];\r\nC[\"C: 2/1\"];\r\nD[\"D: 2/1\"];\r\nC --> A;\r\nC -.-> B;\r\nD -.-> A;\r\nD --> B;\r\n```\r\n\r\nThe solution is an initial phase where you don't care about splitting equal-feerate parts from one another (this PR), and then a secondary phase where you split up chunks in their minimal components (added in #34023).",
      "created_at": "2025-12-08T19:38:36Z",
      "updated_at": "2025-12-08T19:38:51Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2599895617",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2599895617"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 481,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2599927986",
      "pull_request_review_id": 3553801894,
      "id": 2599927986,
      "node_id": "PRRC_kwDOABII586a98Cy",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 87,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590419145,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Yeah, exactly.\r\n\r\n* Pick a random chunk (from the list you maintain of chunks that need to be considered still)\r\n* See if it can be merged upwards or downwards, and:\r\n  * If so, merge with its max-feerate-difference dependency/depender, and add the resulting chunk to list.\r\n  * If not, remove the chunk from the list.",
      "created_at": "2025-12-08T19:50:41Z",
      "updated_at": "2025-12-08T19:50:41Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2599927986",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2599927986"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 525,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602881920",
      "pull_request_review_id": 3557716068,
      "id": 2602881920,
      "node_id": "PRRC_kwDOABII586bJNOA",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n+ * can be stopped whenever the state is topological. In this case, the output linearization\n+ * consists of each of the chunks, from high to low feerate, each internally ordered in an\n+ * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n+ * linearization is also topological.\n+ *\n+ * At a high level, the algorithm works by performing a sequence of the following operations:\n+ * - Merging:\n+ *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n+ *     equal feerate, that dependency can be made active, merging the two chunks.\n+ *   - Merging is only possible in non-topological forests, and generally helps making it\n+ *     topological.\n+ * - Splitting:\n+ *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n+ *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n+ *     the case because no other active dependency between the top and bottom can exist; if it did,\n+ *     it would form a cycle together with d.\n+ *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Splitting generally helps making a forest's output linearization better, but can result in\n+ *     it becoming non-topological, necessitating merging steps.\n+ *\n+ * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n+ * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n+ * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n+ * optimal state will always be reached.\n+ *\n+ * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n+ * will always be prioritized over splitting:\n+ *\n+ * - Construct an initial topological spanning forest for the graph.\n+ * - Loop until optimal or time runs out:\n+ *   - Perform a splitting step.\n+ *   - Loop until the forest is topological:\n+ *     - Perform a merging step.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n+ * single split followed by merges until topological never makes the output linearization worse.\n+ * In addition, this allows refining the algorithm flow into:\n+ *\n+ * - Construct an initial topological spanning forest for the graph:\n+ *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n+ *     chunk).\n+ *   - Make the graph topological by randomly picking chunks, and merging them (with their\n+ *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n+ *     remain.\n+ * - Loop until optimal or time runs out:\n+ *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n+ *     feerate than its would-be bottom chunk.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n+ *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of starting with an empty graph and making it topological directly, it is possible to\n+ * bootstrap from an existing linearization:\n+ * - Start with an empty graph.\n+ * - For each transaction t in the existing linearization:\n+ *   - Add the transaction as a singleton chunk to the graph.\n+ *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n+ *     merged result.\n+ *\n+ * This guarantees an initial, topological, state whose output linearization is at least as good\n+ * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ *\n+ * What remains to be specified are two heuristics:\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Currently, the first encountered dependency whose would-be top chunk has higher feerate than\n+ *     its would-be bottom chunk is deactivated. This will be changed in a future commit.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - Currently, the first encountered dependency between the two maximum-feerate-difference chunks\n+ *     is activated. This will be changed in a future commit.\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of activations/deactivations performed. */\n+    uint64_t m_operations{0};\n+\n+    /** Walk a chunk, starting from transaction start. visit_tx(idx) is called for each encountered\n+     *  transaction. visit_dep_down(dep) is called for each encountered dependency that is traversed\n+     *  in the parent-to-child (downward) direction. */\n+    void Walk(TxIdx start, std::invocable<TxData&> auto visit_tx, std::invocable<DepData&> auto visit_dep_down) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo) {\n+                // Mark the transaction as processed, and invoke the visitor for it.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                todo.Reset(tx_idx);\n+                visit_tx(tx_data);\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo if not done already.\n+                    if (!done[dep_entry.parent]) {\n+                        todo.Set(dep_entry.parent);\n+                    }\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and invoke\n+                    // the downward dependency visitor for it. We do not need to check if it isn't\n+                    // already in todo here, because there cannot be multiple dependencies that\n+                    // reach the same transaction; the !done check is purely to prevent travelling\n+                    // an already-travelled dependency back in reverse direction.\n+                    if (!done[dep_entry.child]) {\n+                        Assume(!todo[dep_entry.child]);\n+                        todo.Set(dep_entry.child);\n+                        visit_dep_down(dep_entry);\n+                    }\n+                }\n+            }\n+        } while (todo.Any());\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        // Add bottom component to top transactions.\n+        Walk(dep_data.parent,\n+             [](TxData&) noexcept {},\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= bottom_part; });\n+        // Add top component to bottom transactions.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo |= top_part; });\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        ++m_operations;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        chunk_data.chunk_setinfo = top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        Walk(dep_data.parent,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = top_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= bottom_part; });\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        Walk(dep_data.child,\n+             [&](TxData& txdata) noexcept { txdata.chunk_rep = bottom_rep; },\n+             [&](DepData& depdata) noexcept { depdata.top_setinfo -= top_part; });\n+        ++m_operations;\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist.. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the first one\n+        // one among them.\n+        SetType explored = chunk_txn;\n+        FeeFrac best_other_chunk_feerate;\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto unreached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            while (unreached.Any()) {\n+                auto chunk_rep = m_tx_data[unreached.First()].chunk_rep;\n+                auto& reached = m_tx_data[m_tx_data[unreached.First()].chunk_rep].chunk_setinfo;\n+                explored |= reached.transactions;\n+                unreached -= explored;\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached.feerate)\n+                                    : FeeRateCompare(reached.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                if ((cmp < 0) || (best_other_chunk_rep == TxIdx(-1))) {\n+                    best_other_chunk_feerate = reached.feerate;\n+                    best_other_chunk_rep = chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if all of the depended-on chunks have a lower/higher feerate than the chunk\n+        // that tx_idx is in.\n+        if (best_other_chunk_feerate.IsEmpty()) return TxIdx(-1);\n+        if (DownWard && best_other_chunk_feerate << chunk_data.chunk_setinfo.feerate) return TxIdx(-1);\n+        if (!DownWard && best_other_chunk_feerate >> chunk_data.chunk_setinfo.feerate) return TxIdx(-1);\n+        Assume(best_other_chunk_rep != TxIdx(-1));\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parent_deps.push_back(dep_idx);\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n+            }\n+        }\n+    }\n+\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n+    {\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n+    }\n+\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n+    {\n+        while (true) {\n+            bool done = true;\n+            // Iterate over all transactions (only processing those which are chunk representatives).\n+            for (auto chunk : m_transactions) {\n+                auto& chunk_data = m_tx_data[chunk];\n+                // If this is not a chunk representative, skip.\n+                if (chunk_data.chunk_rep != chunk) continue;\n+                // Attempt to merge the chunk upwards.\n+                auto result_up = MergeStep<false>(chunk);\n+                if (result_up != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+                // Attempt to merge the chunk downwards.\n+                auto result_down = MergeStep<true>(chunk);\n+                if (result_down != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+            }\n+            // Stop if no changes were made anymore.\n+            if (done) break;\n+        }\n+    }\n+\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n+    {\n+        // Iterate over all transactions (only processing those which are chunk representatives).\n+        for (auto chunk : m_transactions) {\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If this is not a chunk representative, skip.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Iterate over all transactions of the chunk.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    if (!(dep_data.top_setinfo.feerate >> chunk_data.chunk_setinfo.feerate)) continue;\n+                    // Activate it otherwise.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 479,
      "commit_id": "060e1856b1749f4172875455e8e65a303608c709",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2593658728,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-09T14:22:06Z",
      "updated_at": "2025-12-09T14:22:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2602881920",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602881920"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1124,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602882370",
      "pull_request_review_id": 3557716613,
      "id": 2602882370,
      "node_id": "PRRC_kwDOABII586bJNVC",
      "diff_hunk": "@@ -799,14 +739,11 @@ FUZZ_TARGET(clusterlin_simple_finder)\n     // AncestorCandidateFinder it is being tested against.",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 152,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "original_commit_id": "85cff48b782538ed5a1c980015dd01cb32986b66",
      "in_reply_to_id": 2590522916,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Fixed.",
      "created_at": "2025-12-09T14:22:13Z",
      "updated_at": "2025-12-09T14:22:13Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2602882370",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602882370"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 745,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602882885",
      "pull_request_review_id": 3557717158,
      "id": 2602882885,
      "node_id": "PRRC_kwDOABII586bJNdF",
      "diff_hunk": "@@ -1130,6 +1134,103 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the behavior of SpanningForestState.\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    try {\n+        reader >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    /** Whether to make the depgraph connected. */\n+    const bool make_connected = flags & 1;\n+    /** Whether to load an input linearization into SFL state. */\n+    const bool load_linearization = flags & 2;\n+    /** Whether to load a topological input linearization into SFL state. */\n+    const bool load_topological = load_linearization && (flags & 4);\n+    /** Whether to make the SFL state topological. */\n+    const bool make_topological = flags & 8;\n+    /** Whether to do any optimization steps to the SFL state (only if state is topological\n+     *  then). */\n+    const bool try_optimize = flags & 16;\n+\n+    //\n+    // Construct the depgraph and SFL state for it.\n+    //\n+    bool is_topological = false;\n+    if (make_connected) MakeConnected(depgraph);\n+    SpanningForestState sfl(depgraph);\n+\n+    //\n+    // Read and load input linearization, if selected.\n+    //\n+    std::vector<DepGraphIndex> input_lin;\n+    if (load_linearization) {\n+        input_lin = ReadLinearization(depgraph, reader, load_topological);\n+        sfl.LoadLinearization(input_lin);\n+        if (load_topological) is_topological = true;\n+    }\n+\n+    //\n+    // Make topological, if selected.\n+    //\n+    if (make_topological) {\n+        sfl.MakeTopological();\n+        is_topological = true;\n+    }\n+\n+    //\n+    // Perform optimization steps, if selected.\n+    //\n+    bool is_optimal = false;\n+    if (is_topological && try_optimize) {\n+        uint32_t optimize_steps{1};\n+        try {\n+            reader >> VARINT(optimize_steps);\n+        } catch (const std::ios_base::failure&) {}\n+        while (optimize_steps > 0) {\n+            --optimize_steps;\n+            if (!sfl.OptimizeStep()) {\n+                is_optimal = true;\n+                break;\n+            }\n+        }\n+    }\n+\n+    //\n+    // Sanity check the result.\n+    //\n+    sfl.SanityCheck(depgraph);\n+\n+    //\n+    // If the SFL state is (known to be) topological now, we can get a linearization out.\n+    //\n+    if (is_topological) {\n+        auto lin = sfl.GetLinearization();\n+        // Which must be valid.\n+        SanityCheck(depgraph, lin);\n+        // If we started from a topological input, the resulting feerate diagram cannot be worse.",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 143,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590509887,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-09T14:22:21Z",
      "updated_at": "2025-12-09T14:22:21Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2602882885",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602882885"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 930,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602883512",
      "pull_request_review_id": 3557717955,
      "id": 2602883512,
      "node_id": "PRRC_kwDOABII586bJNm4",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 37,
      "commit_id": "2899f8ce8001fde67bbd98912533bf986a8e52a4",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590318854,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-09T14:22:32Z",
      "updated_at": "2025-12-09T14:22:32Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2602883512",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602883512"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 474,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602974679",
      "pull_request_review_id": 3557835427,
      "id": 2602974679,
      "node_id": "PRRC_kwDOABII586bJj3X",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 43,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590327658,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "makes sense, I am just noting it's not clear at all from the writeup ",
      "created_at": "2025-12-09T14:43:55Z",
      "updated_at": "2025-12-09T14:43:55Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2602974679",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602974679"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 481,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602992209",
      "pull_request_review_id": 3557858496,
      "id": 2602992209,
      "node_id": "PRRC_kwDOABII586bJoJR",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 43,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590327658,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Do you mean the write-up in the code comment added here, on the one on Delving?\n\nDo you think it's worth elaborating on here?",
      "created_at": "2025-12-09T14:48:17Z",
      "updated_at": "2025-12-09T14:48:17Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2602992209",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2602992209"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 481,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2603029050",
      "pull_request_review_id": 3557904759,
      "id": 2603029050,
      "node_id": "PRRC_kwDOABII586bJxI6",
      "diff_hunk": "@@ -653,6 +669,686 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+ *\n+ * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n+ * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n+ * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n+ * dependencies cannot all simultaneously be active.\n+ *\n+ * The sets of transactions that are internally connected by active dependencies are called chunks.\n+ * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n+ * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n+ * The collection of all spanning trees for the entire cluster form a spanning forest. Each\n+ * transaction may be in its own chunk (and thus 0 dependencies are active), or all transactions\n+ * may form a single chunk (and thus N-1 dependencies are active).\n+ *\n+ * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n+ * all transactions in it. We say the spanning forest is topological whenever no inactive\n+ * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 43,
      "commit_id": "d56ddf821d928c9fdac812bb2768a360aeb72913",
      "original_commit_id": "f81f72a11e7c1b0380ac183102474a6dc1df957b",
      "in_reply_to_id": 2590327658,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "sorry, I meant the one on delving. I think it's worth mentioning in the code itself actually.",
      "created_at": "2025-12-09T14:57:49Z",
      "updated_at": "2025-12-09T14:57:49Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2603029050",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2603029050"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 481,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2606896286",
      "pull_request_review_id": 3562843288,
      "id": 2606896286,
      "node_id": "PRRC_kwDOABII586bYhSe",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output",
      "path": "src/cluster_linearize.h",
      "position": 113,
      "original_position": 76,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d\r\n\r\nmight be worth noting this is an if and only if situation. ",
      "created_at": "2025-12-10T14:30:41Z",
      "updated_at": "2025-12-10T15:01:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2606896286",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2606896286"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 502,
      "original_line": 502,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2606981122",
      "pull_request_review_id": 3562950105,
      "id": 2606981122,
      "node_id": "PRRC_kwDOABII586bY2AC",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 38,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": null,
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": " topological = no child before parent yes? Or could be `(= parents before children)`, put another way",
      "created_at": "2025-12-10T14:51:21Z",
      "updated_at": "2025-12-10T15:06:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2606981122",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2606981122"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 479,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2606989114",
      "pull_request_review_id": 3562950105,
      "id": 2606989114,
      "node_id": "PRRC_kwDOABII586bY386",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 62,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": null,
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "typo: acyclic",
      "created_at": "2025-12-10T14:52:54Z",
      "updated_at": "2025-12-10T15:06:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2606989114",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2606989114"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 488,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607004069",
      "pull_request_review_id": 3562843288,
      "id": 2607004069,
      "node_id": "PRRC_kwDOABII586bY7ml",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: We say the state is optimal whenever it is topological and also no active dependency\n+ *            exists for which, if it were to be deactivated, the produced top chunk (the one with\n+ *            the dependency's parent in) has strictly higher feerate than the produced bottom\n+ *            chunk (the one with the dependency's child in).\n  *\n- * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n- * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n- * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n- * optimal state will always be reached.\n+ *            The relevance is that it can be proven that whenever the state is optimal, the\n+ *            produced linearization will also be optimal (in the convexified feerate diagram\n+ *            sense). It can also be proven that for every graph at least one optimal state exists.\n  *\n- * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n- * will always be prioritized over splitting:\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n  *\n- * - Construct an initial topological spanning forest for the graph.\n- * - Loop until optimal or time runs out:\n- *   - Perform a splitting step.\n- *   - Loop until the forest is topological:\n- *     - Perform a merging step.\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n  * - Output the chunks from high to low feerate, each internally sorted topologically.\n  *\n- * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n- * single split followed by merges until topological never makes the output linearization worse.\n- * In addition, this allows refining the algorithm flow into:\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with strictly lower feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with strictly higher feerate than itself.\n  *\n- * - Construct an initial topological spanning forest for the graph:\n- *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n- *     chunk).\n- *   - Make the graph topological by randomly picking chunks, and merging them (with their\n- *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n- *     remain.\n- * - Loop until optimal or time runs out:\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n  *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n  *     feerate than its would-be bottom chunk.\n  *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n- *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n- *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n  * - Output the chunks from high to low feerate, each internally sorted topologically.\n  *\n- * Instead of starting with an empty graph and making it topological directly, it is possible to\n- * bootstrap from an existing linearization:\n- * - Start with an empty graph.\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n  * - For each transaction t in the existing linearization:\n- *   - Add the transaction as a singleton chunk to the graph.\n- *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n- *     merged result.\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n  *\n- * This guarantees an initial topological state whose output linearization is at least as good\n- * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ * What remains to be specified are three heuristics:\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - A uniformly random dependency between the two maximum-feerate-difference chunks is activated.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 179,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d\r\n\r\nto make sure I'm understanding, the two chunks being chosen to be merged are described here, correct? https://github.com/bitcoin/bitcoin/pull/32545/commits/8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d#diff-1433c1fc4926a466291656ba67cf6b029523e4bd5da177ade812f25edf07343cR543\r\n\r\ntop or bottom chunk along with highest/lowest feerate difference which is maximally different\r\n\r\nin effect the new info here is just \"uniformly random\"",
      "created_at": "2025-12-10T14:56:20Z",
      "updated_at": "2025-12-10T15:01:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607004069",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607004069"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 574,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607125395",
      "pull_request_review_id": 3563136873,
      "id": 2607125395,
      "node_id": "PRRC_kwDOABII586bZZOT",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output",
      "path": "src/cluster_linearize.h",
      "position": 113,
      "original_position": 76,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2606896286,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "It's not, but it's pretty subtle.\r\n\r\nYou could have two equal-feerate chunks that depend on each other in one way but not the other one. If so, it doesn't matter whether they're merged or not.\r\n\r\nWorth elaborating on?",
      "created_at": "2025-12-10T15:28:34Z",
      "updated_at": "2025-12-10T15:28:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607125395",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607125395"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 502,
      "original_line": 502,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607141755",
      "pull_request_review_id": 3563158595,
      "id": 2607141755,
      "node_id": "PRRC_kwDOABII586bZdN7",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: We say the state is optimal whenever it is topological and also no active dependency\n+ *            exists for which, if it were to be deactivated, the produced top chunk (the one with\n+ *            the dependency's parent in) has strictly higher feerate than the produced bottom\n+ *            chunk (the one with the dependency's child in).\n  *\n- * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n- * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n- * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n- * optimal state will always be reached.\n+ *            The relevance is that it can be proven that whenever the state is optimal, the\n+ *            produced linearization will also be optimal (in the convexified feerate diagram\n+ *            sense). It can also be proven that for every graph at least one optimal state exists.\n  *\n- * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n- * will always be prioritized over splitting:\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n  *\n- * - Construct an initial topological spanning forest for the graph.\n- * - Loop until optimal or time runs out:\n- *   - Perform a splitting step.\n- *   - Loop until the forest is topological:\n- *     - Perform a merging step.\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n  * - Output the chunks from high to low feerate, each internally sorted topologically.\n  *\n- * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n- * single split followed by merges until topological never makes the output linearization worse.\n- * In addition, this allows refining the algorithm flow into:\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with strictly lower feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with strictly higher feerate than itself.\n  *\n- * - Construct an initial topological spanning forest for the graph:\n- *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n- *     chunk).\n- *   - Make the graph topological by randomly picking chunks, and merging them (with their\n- *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n- *     remain.\n- * - Loop until optimal or time runs out:\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n  *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n  *     feerate than its would-be bottom chunk.\n  *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n- *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n- *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n  * - Output the chunks from high to low feerate, each internally sorted topologically.\n  *\n- * Instead of starting with an empty graph and making it topological directly, it is possible to\n- * bootstrap from an existing linearization:\n- * - Start with an empty graph.\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n  * - For each transaction t in the existing linearization:\n- *   - Add the transaction as a singleton chunk to the graph.\n- *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n- *     merged result.\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n  *\n- * This guarantees an initial topological state whose output linearization is at least as good\n- * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ * What remains to be specified are three heuristics:\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - A uniformly random dependency between the two maximum-feerate-difference chunks is activated.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 179,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2607004069,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I have pushed another updated which drops the \"maximum feerate difference\" explanation entirely. I think encapsulating all of that within \"merge upwards\" and \"merge downwards\" rules is more concrete.\r\n\r\nTo be clear, the \"uniformly random\" aspect is something that doesn't exist in the initial \"[add class implementing SFL state](https://github.com/bitcoin/bitcoin/pull/32545/commits/a21a2451c60918944ebe33eb71725872b7655821)\" PR, it's added in a slightly later commit. The reword commit is at the end, so it's just the final state of the explainer comment.",
      "created_at": "2025-12-10T15:32:34Z",
      "updated_at": "2025-12-10T15:32:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607141755",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607141755"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 574,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607142420",
      "pull_request_review_id": 3563159441,
      "id": 2607142420,
      "node_id": "PRRC_kwDOABII586bZdYU",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 38,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2606981122,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Thanks, fixed!",
      "created_at": "2025-12-10T15:32:44Z",
      "updated_at": "2025-12-10T15:32:45Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607142420",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607142420"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 479,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607142876",
      "pull_request_review_id": 3563160004,
      "id": 2607142876,
      "node_id": "PRRC_kwDOABII586bZdfc",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 62,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2606989114,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Fixed.",
      "created_at": "2025-12-10T15:32:50Z",
      "updated_at": "2025-12-10T15:32:50Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607142876",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607142876"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 488,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607162176",
      "pull_request_review_id": 3563185836,
      "id": 2607162176,
      "node_id": "PRRC_kwDOABII586bZiNA",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: We say the state is optimal whenever it is topological and also no active dependency\n+ *            exists for which, if it were to be deactivated, the produced top chunk (the one with\n+ *            the dependency's parent in) has strictly higher feerate than the produced bottom\n+ *            chunk (the one with the dependency's child in).\n  *\n- * A forest is said to be optimal when neither of these operations are applicable anymore. It can\n- * be shown that the output linearization for an optimal spanning forest is optimal, and that at\n- * least one optimal spanning forest exists for every cluster. Note that no proof exists that an\n- * optimal state will always be reached.\n+ *            The relevance is that it can be proven that whenever the state is optimal, the\n+ *            produced linearization will also be optimal (in the convexified feerate diagram\n+ *            sense). It can also be proven that for every graph at least one optimal state exists.\n  *\n- * To make sure the algorithm can be interrupted quickly and get a valid linearization out, merging\n- * will always be prioritized over splitting:\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n  *\n- * - Construct an initial topological spanning forest for the graph.\n- * - Loop until optimal or time runs out:\n- *   - Perform a splitting step.\n- *   - Loop until the forest is topological:\n- *     - Perform a merging step.\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n  * - Output the chunks from high to low feerate, each internally sorted topologically.\n  *\n- * Merging is always done by maximal feerate difference. This guarantees that the sequence of a\n- * single split followed by merges until topological never makes the output linearization worse.\n- * In addition, this allows refining the algorithm flow into:\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with strictly lower feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with strictly higher feerate than itself.\n  *\n- * - Construct an initial topological spanning forest for the graph:\n- *   - Start with graph with all dependencies inactive (i.e., each transaction is a singleton\n- *     chunk).\n- *   - Make the graph topological by randomly picking chunks, and merging them (with their\n- *     lowest-feerate dependency, or highest-feerate dependee) when possible, until no such chunks\n- *     remain.\n- * - Loop until optimal or time runs out:\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n  *   - Pick a dependency D to deactivate among those whose would-be top chunk has strictly higher\n  *     feerate than its would-be bottom chunk.\n  *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n- *   - Merge T with its lowest-feerate dependency, if any. Repeat the same with the merged result.\n- *   - Merge B with its highest-feerate dependee, if any. Repeat the same with the merged result.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n  * - Output the chunks from high to low feerate, each internally sorted topologically.\n  *\n- * Instead of starting with an empty graph and making it topological directly, it is possible to\n- * bootstrap from an existing linearization:\n- * - Start with an empty graph.\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n  * - For each transaction t in the existing linearization:\n- *   - Add the transaction as a singleton chunk to the graph.\n- *   - Merge the newly created chunk with its lowest-feerate dependency, if any. Repeat with the\n- *     merged result.\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n  *\n- * This guarantees an initial topological state whose output linearization is at least as good\n- * (in the convexified feerate diagram sense) as the input existing linearization bootstrapped from.\n+ * What remains to be specified are three heuristics:\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - A uniformly random dependency between the two maximum-feerate-difference chunks is activated.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 179,
      "commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2607004069,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "ok then I'm reading it correctly and agree to drop the language (I couldn't tell if it was new info or a restatement of prior)",
      "created_at": "2025-12-10T15:38:06Z",
      "updated_at": "2025-12-10T15:38:07Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607162176",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607162176"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 574,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607167947",
      "pull_request_review_id": 3563193706,
      "id": 2607167947,
      "node_id": "PRRC_kwDOABII586bZjnL",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output",
      "path": "src/cluster_linearize.h",
      "position": 113,
      "original_position": 76,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2606896286,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "actually not sure what I meant here on second read, ignore",
      "created_at": "2025-12-10T15:39:44Z",
      "updated_at": "2025-12-10T15:39:44Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607167947",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607167947"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 502,
      "original_line": 502,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607229744",
      "pull_request_review_id": 3563269336,
      "id": 2607229744,
      "node_id": "PRRC_kwDOABII586bZysw",
      "diff_hunk": "@@ -461,96 +461,123 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Class to represent the internal state of the spanning-forest linearization algorithm.\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n  *\n- * At all times, each dependency is marked as \"active\" or \"inactive\", with the constraint that\n- * no cycle of active dependencies may exist when ignoring the direction of those dependencies.\n- * So for example, the diamond (C->X->P, C->Y->P) would be considered a cycle, and those 4\n- * dependencies cannot all simultaneously be active.\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n  *\n- * The sets of transactions that are internally connected by active dependencies are called chunks.\n- * Each chunk of N transactions contains exactly N-1 active dependencies (an additional one would\n- * necessarily form a cycle), and thus those active dependencies form a spanning tree for the chunk.\n- * The collection of all spanning trees for the entire cluster form a spanning forest. In the\n- * extreme, each transaction may be in its own chunk (and thus 0 dependencies are active), or in\n- * the other extreme, all transactions may form a single chunk (and thus N-1 dependencies are\n- * active).\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n  *\n- * Each chunk has a feerate: the total fee of all transactions in it divided by the total size of\n- * all transactions in it. We say the spanning forest is topological whenever no inactive\n- * dependencies exist from one chunk to another chunk with lower or equal feerate. The algorithm\n- * can be stopped whenever the state is topological. In this case, the output linearization\n- * consists of each of the chunks, from high to low feerate, each internally ordered in an\n- * arbitrary but topologically-valid way. If the spanning forest is topological, then the output\n- * linearization is also topological.\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no parent before child)\n+ * way.\n  *\n- * At a high level, the algorithm works by performing a sequence of the following operations:\n- * - Merging:\n- *   - Whenever an inactive dependency exists from a chunk to another chunk which has lower or\n- *     equal feerate, that dependency can be made active, merging the two chunks.\n- *   - Merging is only possible in non-topological forests, and generally helps making it\n- *     topological.\n- * - Splitting:\n- *   - Whenever an active dependency d exists, making it inactive will result in the chunk it is in\n- *     splitting in two: a bottom chunk (which d is from) and a top chunk (which d is to). This is\n- *     the case because no other active dependency between the top and bottom can exist; if it did,\n- *     it would form a cycle together with d.\n- *   - An active dependency can be deactivated whenever its would-be top chunk has strictly higher\n- *     feerate than its would-be bottom chunk.\n- *   - Splitting generally helps making a forest's output linearization better, but can result in\n- *     it becoming non-topological, necessitating merging steps.\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acylic is also equivalent to every chunk of N transactions having exactly\n+ *            N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever no inactive dependency exists between\n+ *                two distinct chunks such that the child chunk has higher or equal feerate than\n+ *                the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output",
      "path": "src/cluster_linearize.h",
      "position": 113,
      "original_position": 76,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "8c990cc2f5a7e93a5debb7eaf20e7f2c887df70d",
      "in_reply_to_id": 2606896286,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "ok, so I just \"forgot\" again that \"or equal\" means you can clearly have same feerate chunks that can be merged, hence not topological in the SFL state sense",
      "created_at": "2025-12-10T15:54:26Z",
      "updated_at": "2025-12-10T15:54:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2607229744",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2607229744"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 502,
      "original_line": 502,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2608193810",
      "pull_request_review_id": 3564457615,
      "id": 2608193810,
      "node_id": "PRRC_kwDOABII586bdeES",
      "diff_hunk": "@@ -53,7 +53,7 @@ static const uint32_t MEMPOOL_HEIGHT = 0x7FFFFFFF;\n /** How many linearization iterations required for TxGraph clusters to have\n  * \"acceptable\" quality, if they cannot be optimally linearized with fewer\n  * iterations. */\n-static constexpr uint64_t ACCEPTABLE_ITERS = 1'700;\n+static constexpr uint64_t ACCEPTABLE_ITERS = 1'000;",
      "path": "src/txmempool.h",
      "position": 1,
      "original_position": 5,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "9a22b41a7988ae297b2c240ff41bb60954c0a73b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "8f0828ea5144f261ff5e0cc39ee5eed17d0eec57\r\n\r\nwhy this reduction? commit message commenting on it could be helpful",
      "created_at": "2025-12-10T20:59:43Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2608193810",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2608193810"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 56,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611075318",
      "pull_request_review_id": 3564457615,
      "id": 2611075318,
      "node_id": "PRRC_kwDOABII586bodj2",
      "diff_hunk": "@@ -52,6 +54,63 @@ void TestDepGraphSerialization(const std::vector<std::pair<FeeFrac, SetType>>& c\n     BOOST_CHECK(depgraph == depgraph_read);\n }\n \n+void TestOptimalLinearization(const std::vector<uint8_t>& enc, const std::vector<FeeFrac>& diagram)",
      "path": "src/test/cluster_linearize_tests.cpp",
      "position": 1,
      "original_position": 20,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "1c008c063df383aff64c564b116802b427a228ce",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "1c008c063df383aff64c564b116802b427a228ce\r\n\r\n```Suggestion\r\nvoid TestOptimalLinearization(const std::vector<uint8_t>& enc, const std::vector<FeeFrac>& optimal_diagram)\r\n```",
      "created_at": "2025-12-11T15:38:42Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2611075318",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611075318"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 57,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611100880",
      "pull_request_review_id": 3564457615,
      "id": 2611100880,
      "node_id": "PRRC_kwDOABII586bojzQ",
      "diff_hunk": "@@ -52,6 +54,63 @@ void TestDepGraphSerialization(const std::vector<std::pair<FeeFrac, SetType>>& c\n     BOOST_CHECK(depgraph == depgraph_read);\n }\n \n+void TestOptimalLinearization(const std::vector<uint8_t>& enc, const std::vector<FeeFrac>& diagram)\n+{\n+    DepGraphIndex tx_count = 0;\n+    FastRandomContext rng;\n+\n+    auto test_fn = [&]<typename SetType>() {\n+        DepGraph<SetType> depgraph;\n+        SpanReader reader(enc);\n+        reader >> Using<DepGraphFormatter>(depgraph);\n+        SanityCheck(depgraph);\n+        std::vector<DepGraphIndex> lin;\n+        for (int iter = 0; iter < 200; ++iter) {\n+            bool opt;\n+            uint64_t cost{0};\n+            switch (rng.randrange(3)) {\n+            case 0:\n+                // Use empty input linearization.\n+                lin.clear();\n+                break;\n+            case 1:\n+                // Reuse previous optimal linearization as input.\n+                break;\n+            case 2:\n+                // Construct random input linearization.\n+                std::shuffle(lin.begin(), lin.end(), rng);\n+                FixLinearization(depgraph, lin);\n+                break;\n+            }\n+            std::tie(lin, opt, cost) = Linearize(depgraph, 1000000, rng.rand64(), lin);",
      "path": "src/test/cluster_linearize_tests.cpp",
      "position": 1,
      "original_position": 48,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "1c008c063df383aff64c564b116802b427a228ce",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "1c008c063df383aff64c564b116802b427a228ce\r\n\r\nPlease leave a note that 1M iterations is enough for all given dependency graphs but often a lot less than MaxOptimalLinearizationIters",
      "created_at": "2025-12-11T15:45:22Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2611100880",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611100880"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 85,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611171333",
      "pull_request_review_id": 3564457615,
      "id": 2611171333,
      "node_id": "PRRC_kwDOABII586bo1AF",
      "diff_hunk": "@@ -210,40 +210,48 @@ void BenchMergeLinearizationsWorstCase(DepGraphIndex ntx, benchmark::Bench& benc\n     });\n }\n \n-template<size_t N>\n-void BenchLinearizeOptimally(benchmark::Bench& bench, const std::array<uint8_t, N>& serialized)\n+void BenchLinearizeOptimallyTotal(benchmark::Bench& bench, const std::string& name, const std::vector<std::vector<uint8_t>>& serializeds)\n {\n-    // Determine how many transactions the serialized cluster has.\n-    DepGraphIndex num_tx{0};\n-    {\n+    for (const auto& serialized : serializeds) {\n         SpanReader reader{serialized};\n-        DepGraph<BitSet<128>> depgraph;\n+        DepGraph<BitSet<64>> depgraph;\n         reader >> Using<DepGraphFormatter>(depgraph);\n-        num_tx = depgraph.TxCount();\n-        assert(num_tx < 128);\n-    }\n+        auto bench_name = strprintf(\"%s_%utx_%udep\", name, depgraph.TxCount(), depgraph.CountDependencies());\n \n-    SpanReader reader{serialized};\n-    auto runner_fn = [&]<typename SetType>() noexcept {\n-        DepGraph<SetType> depgraph;\n-        reader >> Using<DepGraphFormatter>(depgraph);\n+        // Benchmark the total time to optimal.\n         uint64_t rng_seed = 0;\n-        bench.run([&] {\n+        bench.name(bench_name).run([&] {\n             auto [_lin, optimal, _cost] = Linearize(depgraph, /*max_iterations=*/10000000, rng_seed++);\n             assert(optimal);\n         });\n-    };\n-\n-    if (num_tx <= 32) {\n-        runner_fn.template operator()<BitSet<32>>();\n-    } else if (num_tx <= 64) {\n-        runner_fn.template operator()<BitSet<64>>();\n-    } else if (num_tx <= 96) {\n-        runner_fn.template operator()<BitSet<96>>();\n-    } else if (num_tx <= 128) {\n-        runner_fn.template operator()<BitSet<128>>();\n-    } else {\n-        assert(false);\n+    }\n+}\n+\n+void BenchLinearizeOptimallyPerCost(benchmark::Bench& bench, const std::string& name, const std::vector<std::vector<uint8_t>>& serializeds)\n+{\n+    for (const auto& serialized : serializeds) {\n+        SpanReader reader{serialized};\n+        DepGraph<BitSet<64>> depgraph;\n+        reader >> Using<DepGraphFormatter>(depgraph);\n+        auto bench_name = strprintf(\"%s_%utx_%udep\", name, depgraph.TxCount(), depgraph.CountDependencies());\n+\n+        // Determine the cost of 100 rng_seeds.\n+        uint64_t total_cost = 0;\n+        for (uint64_t iter = 0; iter < 100; ++iter) {\n+            auto [_lin, optimal, cost] = Linearize(depgraph, /*max_iterations=*/10000000, /*rng_seed=*/iter);\n+            total_cost += cost;\n+        }\n+\n+        // Benchmark the time per cost.",
      "path": "src/bench/cluster_linearize.cpp",
      "position": 261,
      "original_position": 62,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "094e845f7309c8cf4e172c8fe07e200e054ca2db",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "094e845f7309c8cf4e172c8fe07e200e054ca2db\r\n\r\nTIL, nice",
      "created_at": "2025-12-11T16:04:09Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2611171333",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611171333"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 79,
      "original_line": 79,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611697771",
      "pull_request_review_id": 3564457615,
      "id": 2611697771,
      "node_id": "PRRC_kwDOABII586bq1hr",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 187,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "c2eaf22503f7af057599f02ecb5f24a267ea33e2\r\n\r\nsuggestion:\r\n```\r\n-    /** The set of all transactions in the cluster. */\r\n-    SetType m_transactions;\r\n-    /** Information about each transaction (and chunks). Indexed by TxIdx. */\r\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\r\n+    SetType m_transaction_idxs;\r\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph\r\n+        during construction. Indexed by TxIdx. */\r\n     std::vector<TxData> m_tx_data;\r\n```",
      "created_at": "2025-12-11T18:49:36Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2611697771",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611697771"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 639,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611720199",
      "pull_request_review_id": 3564457615,
      "id": 2611720199,
      "node_id": "PRRC_kwDOABII586bq7AH",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 416,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "c2eaf22503f7af057599f02ecb5f24a267ea33e2\r\n\r\nExposing my ignorance here, but why reserve this value? Deserves a comment.",
      "created_at": "2025-12-11T18:56:07Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2611720199",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611720199"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 916,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611854913",
      "pull_request_review_id": 3564457615,
      "id": 2611854913,
      "node_id": "PRRC_kwDOABII586brb5B",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 311,
      "commit_id": "ab94844ff0c3040d3c11ee1d12297bb0358a70ad",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "c2eaf22503f7af057599f02ecb5f24a267ea33e2\r\n\r\njust making sure this is a quick check to avoid looping over deps, not a correctness requirement",
      "created_at": "2025-12-11T19:43:21Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2611854913",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2611854913"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 965,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2614950800",
      "pull_request_review_id": 3564457615,
      "id": 2614950800,
      "node_id": "PRRC_kwDOABII586b3PuQ",
      "diff_hunk": "@@ -662,6 +678,707 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_effect` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_effect.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_effect;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_effect;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(top_part.transactions, dep_data.parent, top_rep, bottom_part);",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 266,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "a0cb73b4257f771353f6732e7afdaf2d03b51efe\r\n\r\nnow that UpdateChunk has two TxIdx args let's annotate themhere and other three spots",
      "created_at": "2025-12-12T16:58:24Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2614950800",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2614950800"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 920,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615051275",
      "pull_request_review_id": 3564457615,
      "id": 2615051275,
      "node_id": "PRRC_kwDOABII586b3oQL",
      "diff_hunk": "@@ -1230,6 +1054,13 @@ FUZZ_TARGET(clusterlin_sfl)\n             }\n         }\n     }\n+\n+    //\n+    // Verify that optimality is reached within an expected amount of work.\n+    //\n+    if (sfl.GetCost() > MaxOptimalLinearizationIters(depgraph.TxCount())) {\n+        assert(is_optimal);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 312,
      "commit_id": "5e16783d973a93a8691ebf8853748cadee38162c",
      "original_commit_id": "ab1416bb471c9326bb77ee464be6aeebf663e024",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "ab1416bb471c9326bb77ee464be6aeebf663e024\r\n\r\nFeels like dead code to me here considering it's double of whatever you've seen in a large randomized trial.",
      "created_at": "2025-12-12T17:33:57Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615051275",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615051275"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 999,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615112761",
      "pull_request_review_id": 3564457615,
      "id": 2615112761,
      "node_id": "PRRC_kwDOABII586b33Q5",
      "diff_hunk": "@@ -1130,6 +1130,85 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the behavior of SpanningForestState.\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    try {\n+        reader >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    /** Whether to make the depgraph connected. */\n+    const bool make_connected = flags & 1;\n+    /** Whether to make the SFL state topological. */\n+    const bool make_topological = flags & 2;\n+    /** Whether to do any optimization steps to the SFL state (only if state is topological\n+     *  then). */\n+    const bool try_optimize = flags & 4;\n+\n+    //\n+    // Construct the depgraph and SFL state for it.\n+    //\n+    bool is_topological = false;\n+    if (make_connected) MakeConnected(depgraph);\n+    SpanningForestState sfl(depgraph);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 62,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "suggestion:\r\n\r\nfor each of the operations, we could check that the `GetCost()` doesn't return an unexpectedly high jump. Cost should be bounded by series of merges, or a single split and series of merges.",
      "created_at": "2025-12-12T17:57:39Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615112761",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615112761"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1155,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615138367",
      "pull_request_review_id": 3564457615,
      "id": 2615138367,
      "node_id": "PRRC_kwDOABII586b39g_",
      "diff_hunk": "@@ -662,6 +678,707 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_effect` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_effect.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_effect;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_effect;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the represenative for the merged chunk.\n+        UpdateChunk<false>(bottom_part.transactions, dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(bottom_part.transactions, dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n+            }\n+        }\n+    }\n+\n+    /** Make state topological. Can be called after constructing. */\n+    void MakeTopological() noexcept\n+    {\n+        while (true) {\n+            bool done = true;\n+            // Iterate over all transactions (only processing those which are chunk representatives).\n+            for (auto chunk : m_transactions) {\n+                auto& chunk_data = m_tx_data[chunk];\n+                // If this is not a chunk representative, skip.\n+                if (chunk_data.chunk_rep != chunk) continue;\n+                // Attempt to merge the chunk upwards.\n+                auto result_up = MergeStep<false>(chunk);\n+                if (result_up != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+                // Attempt to merge the chunk downwards.\n+                auto result_down = MergeStep<true>(chunk);\n+                if (result_down != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+            }\n+            // Stop if no changes were made anymore.\n+            if (done) break;\n+        }\n+    }\n+\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n+    {\n+        // Iterate over all transactions (only processing those which are chunk representatives).\n+        for (auto chunk : m_transactions) {\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If this is not a chunk representative, skip.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Iterate over all transactions of the chunk.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    if (!(dep_data.top_setinfo.feerate >> chunk_data.chunk_setinfo.feerate)) continue;\n+                    // Deactivate it otherwise.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 500,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "```Suggestion\r\n                    // Deactivate it otherwise and then make it topological with a series of merges.\r\n```",
      "created_at": "2025-12-12T18:08:40Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615138367",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615138367"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1154,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615158883",
      "pull_request_review_id": 3564457615,
      "id": 2615158883,
      "node_id": "PRRC_kwDOABII586b4Chj",
      "diff_hunk": "@@ -662,6 +678,707 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_effect` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_effect.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_effect;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_effect;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the represenative for the merged chunk.\n+        UpdateChunk<false>(bottom_part.transactions, dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(bottom_part.transactions, dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);",
      "path": "src/cluster_linearize.h",
      "position": 666,
      "original_position": 414,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "a0cb73b4257f771353f6732e7afdaf2d03b51efe\r\n\r\nIIUC these two invocations are optimizations we can use since we know where things are potentially mergable next instead of `MakeTopological`?",
      "created_at": "2025-12-12T18:17:11Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615158883",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615158883"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 901,
      "original_line": 901,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615488559",
      "pull_request_review_id": 3564457615,
      "id": 2615488559,
      "node_id": "PRRC_kwDOABII586b5TAv",
      "diff_hunk": "@@ -328,18 +328,22 @@ SetType ReadTopologicalSet(const DepGraph<SetType>& depgraph, const SetType& tod\n \n /** Given a dependency graph, construct any valid linearization for it, reading from a SpanReader. */\n template<typename BS>\n-std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader)\n+std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader, bool topological=true)\n {\n     std::vector<DepGraphIndex> linearization;\n     TestBitSet todo = depgraph.Positions();\n     // In every iteration one topologically-valid transaction is appended to linearization.\n     while (todo.Any()) {\n         // Compute the set of transactions with no not-yet-included ancestors.\n         TestBitSet potential_next;\n-        for (auto j : todo) {\n-            if ((depgraph.Ancestors(j) & todo) == TestBitSet::Singleton(j)) {\n-                potential_next.Set(j);\n+        if (topological) {\n+            for (auto j : todo) {\n+                if ((depgraph.Ancestors(j) & todo) == TestBitSet::Singleton(j)) {\n+                    potential_next.Set(j);\n+                }\n             }\n+        } else {\n+            potential_next = todo;",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 123,
      "original_position": 23,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "9f7f80f9407d10c95c2690e34dfa918c6a361f21",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "9f7f80f9407d10c95c2690e34dfa918c6a361f21\r\n\r\nnit\r\n\r\n```Suggestion\r\n            // Allow any element to be selected next, regardless of topology\r\n            potential_next = todo;\r\n```",
      "created_at": "2025-12-12T20:29:04Z",
      "updated_at": "2025-12-12T20:56:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615488559",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615488559"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 336,
      "original_line": 336,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615504240",
      "pull_request_review_id": 3564457615,
      "id": 2615504240,
      "node_id": "PRRC_kwDOABII586b5W1w",
      "diff_hunk": "@@ -1192,13 +1196,11 @@ FUZZ_TARGET(clusterlin_sfl)\n         auto lin = sfl.GetLinearization();\n         // Which must be valid.\n         SanityCheck(depgraph, lin);\n-        // If we started from a topological input, the resulting feerate diagram must be at least",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 31,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "9f7f80f9407d10c95c2690e34dfa918c6a361f21",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "9f7f80f9407d10c95c2690e34dfa918c6a361f21\r\n\r\nUnnecessary code movement? This moves right back after f7e0857b97afe30d9a2c0a9ceb49ddd798ad5642",
      "created_at": "2025-12-12T20:33:19Z",
      "updated_at": "2025-12-12T20:57:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615504240",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615504240"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1195,
      "side": "LEFT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615788225",
      "pull_request_review_id": 3573851566,
      "id": 2615788225,
      "node_id": "PRRC_kwDOABII586b6cLB",
      "diff_hunk": "@@ -53,7 +53,7 @@ static const uint32_t MEMPOOL_HEIGHT = 0x7FFFFFFF;\n /** How many linearization iterations required for TxGraph clusters to have\n  * \"acceptable\" quality, if they cannot be optimally linearized with fewer\n  * iterations. */\n-static constexpr uint64_t ACCEPTABLE_ITERS = 1'700;\n+static constexpr uint64_t ACCEPTABLE_ITERS = 1'000;",
      "path": "src/txmempool.h",
      "position": 1,
      "original_position": 5,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "9a22b41a7988ae297b2c240ff41bb60954c0a73b",
      "in_reply_to_id": 2608193810,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I have reverted this change. My benchmarks show that the time per cost is quite similar to before, which I'm now mentioning in the commit message. This will be overhauled in #34023.",
      "created_at": "2025-12-12T22:55:08Z",
      "updated_at": "2025-12-12T22:55:08Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615788225",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615788225"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 56,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615788367",
      "pull_request_review_id": 3573851716,
      "id": 2615788367,
      "node_id": "PRRC_kwDOABII586b6cNP",
      "diff_hunk": "@@ -52,6 +54,63 @@ void TestDepGraphSerialization(const std::vector<std::pair<FeeFrac, SetType>>& c\n     BOOST_CHECK(depgraph == depgraph_read);\n }\n \n+void TestOptimalLinearization(const std::vector<uint8_t>& enc, const std::vector<FeeFrac>& diagram)",
      "path": "src/test/cluster_linearize_tests.cpp",
      "position": 1,
      "original_position": 20,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "1c008c063df383aff64c564b116802b427a228ce",
      "in_reply_to_id": 2611075318,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-12T22:55:15Z",
      "updated_at": "2025-12-12T22:55:15Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615788367",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615788367"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 57,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615788964",
      "pull_request_review_id": 3573852253,
      "id": 2615788964,
      "node_id": "PRRC_kwDOABII586b6cWk",
      "diff_hunk": "@@ -52,6 +54,63 @@ void TestDepGraphSerialization(const std::vector<std::pair<FeeFrac, SetType>>& c\n     BOOST_CHECK(depgraph == depgraph_read);\n }\n \n+void TestOptimalLinearization(const std::vector<uint8_t>& enc, const std::vector<FeeFrac>& diagram)\n+{\n+    DepGraphIndex tx_count = 0;\n+    FastRandomContext rng;\n+\n+    auto test_fn = [&]<typename SetType>() {\n+        DepGraph<SetType> depgraph;\n+        SpanReader reader(enc);\n+        reader >> Using<DepGraphFormatter>(depgraph);\n+        SanityCheck(depgraph);\n+        std::vector<DepGraphIndex> lin;\n+        for (int iter = 0; iter < 200; ++iter) {\n+            bool opt;\n+            uint64_t cost{0};\n+            switch (rng.randrange(3)) {\n+            case 0:\n+                // Use empty input linearization.\n+                lin.clear();\n+                break;\n+            case 1:\n+                // Reuse previous optimal linearization as input.\n+                break;\n+            case 2:\n+                // Construct random input linearization.\n+                std::shuffle(lin.begin(), lin.end(), rng);\n+                FixLinearization(depgraph, lin);\n+                break;\n+            }\n+            std::tie(lin, opt, cost) = Linearize(depgraph, 1000000, rng.rand64(), lin);",
      "path": "src/test/cluster_linearize_tests.cpp",
      "position": 1,
      "original_position": 48,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "1c008c063df383aff64c564b116802b427a228ce",
      "in_reply_to_id": 2611100880,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I have just increased it to 1T iterations, which ought to be enough for anyone.",
      "created_at": "2025-12-12T22:55:42Z",
      "updated_at": "2025-12-12T22:55:43Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615788964",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615788964"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 85,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615789740",
      "pull_request_review_id": 3573852957,
      "id": 2615789740,
      "node_id": "PRRC_kwDOABII586b6cis",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 187,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611697771,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done, except renaming to `m_transaction_idxs`, because I'm too lazy to update all the affected commits right now. Will leave this open.",
      "created_at": "2025-12-12T22:56:13Z",
      "updated_at": "2025-12-12T22:56:13Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615789740",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615789740"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 639,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615790625",
      "pull_request_review_id": 3573853836,
      "id": 2615790625,
      "node_id": "PRRC_kwDOABII586b6cwh",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 416,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611720199,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "It's to avoid reallocating; this formula gives the maximum number of dependencies a cluster with a given number of transactions can have. I have added a comment. Does this suffice?",
      "created_at": "2025-12-12T22:56:53Z",
      "updated_at": "2025-12-12T22:56:54Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615790625",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615790625"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 916,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615790818",
      "pull_request_review_id": 3573854104,
      "id": 2615790818,
      "node_id": "PRRC_kwDOABII586b6czi",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 311,
      "commit_id": "ab94844ff0c3040d3c11ee1d12297bb0358a70ad",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611854913,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Indeed! Added as comment.",
      "created_at": "2025-12-12T22:57:05Z",
      "updated_at": "2025-12-12T22:57:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615790818",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615790818"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 965,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615791108",
      "pull_request_review_id": 3573854393,
      "id": 2615791108,
      "node_id": "PRRC_kwDOABII586b6c4E",
      "diff_hunk": "@@ -662,6 +678,707 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_effect` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_effect.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_effect;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_effect;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(top_part.transactions, dep_data.parent, top_rep, bottom_part);",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 266,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": 2614950800,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I was considering that already, done.",
      "created_at": "2025-12-12T22:57:19Z",
      "updated_at": "2025-12-12T22:57:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615791108",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615791108"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 920,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615793339",
      "pull_request_review_id": 3573856647,
      "id": 2615793339,
      "node_id": "PRRC_kwDOABII586b6da7",
      "diff_hunk": "@@ -1230,6 +1054,13 @@ FUZZ_TARGET(clusterlin_sfl)\n             }\n         }\n     }\n+\n+    //\n+    // Verify that optimality is reached within an expected amount of work.\n+    //\n+    if (sfl.GetCost() > MaxOptimalLinearizationIters(depgraph.TxCount())) {\n+        assert(is_optimal);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 312,
      "commit_id": "5e16783d973a93a8691ebf8853748cadee38162c",
      "original_commit_id": "ab1416bb471c9326bb77ee464be6aeebf663e024",
      "in_reply_to_id": 2615051275,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "The point here is to prevent against potential bugs added in the future, which result in optimality just never being reached anymore. Absent bounds on expected iteration count, this would render a large portion of this test powerless (because anything in `is_optimal`, which includes all quality checks, won't be reached anymore).\r\n\r\nAdded a comment. Does this explain it?",
      "created_at": "2025-12-12T22:58:39Z",
      "updated_at": "2025-12-12T23:09:30Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615793339",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615793339"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 999,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615794234",
      "pull_request_review_id": 3573857468,
      "id": 2615794234,
      "node_id": "PRRC_kwDOABII586b6do6",
      "diff_hunk": "@@ -1130,6 +1130,85 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the behavior of SpanningForestState.\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    try {\n+        reader >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    /** Whether to make the depgraph connected. */\n+    const bool make_connected = flags & 1;\n+    /** Whether to make the SFL state topological. */\n+    const bool make_topological = flags & 2;\n+    /** Whether to do any optimization steps to the SFL state (only if state is topological\n+     *  then). */\n+    const bool try_optimize = flags & 4;\n+\n+    //\n+    // Construct the depgraph and SFL state for it.\n+    //\n+    bool is_topological = false;\n+    if (make_connected) MakeConnected(depgraph);\n+    SpanningForestState sfl(depgraph);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 62,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": 2615112761,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I have not done this (yet), because it's hard to maintain in #34023, where the cost function becomes a lot more complicated.",
      "created_at": "2025-12-12T22:59:17Z",
      "updated_at": "2025-12-12T22:59:17Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615794234",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615794234"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1155,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615794420",
      "pull_request_review_id": 3573857657,
      "id": 2615794420,
      "node_id": "PRRC_kwDOABII586b6dr0",
      "diff_hunk": "@@ -662,6 +678,707 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_effect` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_effect.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_effect;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_effect;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the represenative for the merged chunk.\n+        UpdateChunk<false>(bottom_part.transactions, dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(bottom_part.transactions, dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n+            }\n+        }\n+    }\n+\n+    /** Make state topological. Can be called after constructing. */\n+    void MakeTopological() noexcept\n+    {\n+        while (true) {\n+            bool done = true;\n+            // Iterate over all transactions (only processing those which are chunk representatives).\n+            for (auto chunk : m_transactions) {\n+                auto& chunk_data = m_tx_data[chunk];\n+                // If this is not a chunk representative, skip.\n+                if (chunk_data.chunk_rep != chunk) continue;\n+                // Attempt to merge the chunk upwards.\n+                auto result_up = MergeStep<false>(chunk);\n+                if (result_up != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+                // Attempt to merge the chunk downwards.\n+                auto result_down = MergeStep<true>(chunk);\n+                if (result_down != TxIdx(-1)) {\n+                    done = false;\n+                    continue;\n+                }\n+            }\n+            // Stop if no changes were made anymore.\n+            if (done) break;\n+        }\n+    }\n+\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n+    {\n+        // Iterate over all transactions (only processing those which are chunk representatives).\n+        for (auto chunk : m_transactions) {\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If this is not a chunk representative, skip.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Iterate over all transactions of the chunk.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    if (!(dep_data.top_setinfo.feerate >> chunk_data.chunk_setinfo.feerate)) continue;\n+                    // Deactivate it otherwise.",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 500,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": 2615138367,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-12T22:59:23Z",
      "updated_at": "2025-12-12T22:59:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615794420",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615794420"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1154,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615795954",
      "pull_request_review_id": 3573859182,
      "id": 2615795954,
      "node_id": "PRRC_kwDOABII586b6eDy",
      "diff_hunk": "@@ -662,6 +678,707 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_effect` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_effect.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_effect;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_effect;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the represenative for the merged chunk.\n+        UpdateChunk<false>(bottom_part.transactions, dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(top_part.transactions, dep_data.parent, top_rep, bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(bottom_part.transactions, dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);",
      "path": "src/cluster_linearize.h",
      "position": 666,
      "original_position": 414,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "a0cb73b4257f771353f6732e7afdaf2d03b51efe",
      "in_reply_to_id": 2615158883,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Good observation, I have added a comment.\r\n\r\n(historically, `MakeTopological` was actually using `MergeSequence` before an overhaul, which may explain why this wasn't explained already)",
      "created_at": "2025-12-12T23:00:24Z",
      "updated_at": "2025-12-12T23:00:25Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615795954",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615795954"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 901,
      "original_line": 901,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615796069",
      "pull_request_review_id": 3573859316,
      "id": 2615796069,
      "node_id": "PRRC_kwDOABII586b6eFl",
      "diff_hunk": "@@ -328,18 +328,22 @@ SetType ReadTopologicalSet(const DepGraph<SetType>& depgraph, const SetType& tod\n \n /** Given a dependency graph, construct any valid linearization for it, reading from a SpanReader. */\n template<typename BS>\n-std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader)\n+std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader, bool topological=true)\n {\n     std::vector<DepGraphIndex> linearization;\n     TestBitSet todo = depgraph.Positions();\n     // In every iteration one topologically-valid transaction is appended to linearization.\n     while (todo.Any()) {\n         // Compute the set of transactions with no not-yet-included ancestors.\n         TestBitSet potential_next;\n-        for (auto j : todo) {\n-            if ((depgraph.Ancestors(j) & todo) == TestBitSet::Singleton(j)) {\n-                potential_next.Set(j);\n+        if (topological) {\n+            for (auto j : todo) {\n+                if ((depgraph.Ancestors(j) & todo) == TestBitSet::Singleton(j)) {\n+                    potential_next.Set(j);\n+                }\n             }\n+        } else {\n+            potential_next = todo;",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 123,
      "original_position": 23,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "9f7f80f9407d10c95c2690e34dfa918c6a361f21",
      "in_reply_to_id": 2615488559,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-12T23:00:31Z",
      "updated_at": "2025-12-12T23:00:31Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615796069",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615796069"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 336,
      "original_line": 336,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615796436",
      "pull_request_review_id": 3573859645,
      "id": 2615796436,
      "node_id": "PRRC_kwDOABII586b6eLU",
      "diff_hunk": "@@ -1192,13 +1196,11 @@ FUZZ_TARGET(clusterlin_sfl)\n         auto lin = sfl.GetLinearization();\n         // Which must be valid.\n         SanityCheck(depgraph, lin);\n-        // If we started from a topological input, the resulting feerate diagram must be at least",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 31,
      "commit_id": "5259f95b70a77749ced95091454c355803adcf24",
      "original_commit_id": "9f7f80f9407d10c95c2690e34dfa918c6a361f21",
      "in_reply_to_id": 2615504240,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "This was a result of commit surgery gone wrong. Fixed.",
      "created_at": "2025-12-12T23:00:48Z",
      "updated_at": "2025-12-12T23:00:48Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2615796436",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2615796436"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1195,
      "side": "LEFT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619408180",
      "pull_request_review_id": 3578155054,
      "id": 2619408180,
      "node_id": "PRRC_kwDOABII586cIP80",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 416,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611720199,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I was more asking about the specific number; I'm guessing it's related to the maximum number of \"reduced\" relations with their transitive reductions. \r\n\r\nThe \"worst\" I can naively do is split up N into two sets of nodes, half each, then fully connect the two sets -> `floor(N^2 / 4)` , I think",
      "created_at": "2025-12-15T13:18:54Z",
      "updated_at": "2025-12-15T13:18:54Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2619408180",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619408180"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 916,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619414858",
      "pull_request_review_id": 3578163917,
      "id": 2619414858,
      "node_id": "PRRC_kwDOABII586cIRlK",
      "diff_hunk": "@@ -1230,6 +1054,13 @@ FUZZ_TARGET(clusterlin_sfl)\n             }\n         }\n     }\n+\n+    //\n+    // Verify that optimality is reached within an expected amount of work.\n+    //\n+    if (sfl.GetCost() > MaxOptimalLinearizationIters(depgraph.TxCount())) {\n+        assert(is_optimal);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 312,
      "commit_id": "5e16783d973a93a8691ebf8853748cadee38162c",
      "original_commit_id": "ab1416bb471c9326bb77ee464be6aeebf663e024",
      "in_reply_to_id": 2615051275,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "The new assert is more in-line with my expectations, yes",
      "created_at": "2025-12-15T13:21:01Z",
      "updated_at": "2025-12-15T13:21:01Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2619414858",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619414858"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 999,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619415224",
      "pull_request_review_id": 3578164320,
      "id": 2619415224,
      "node_id": "PRRC_kwDOABII586cIRq4",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 416,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611720199,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "That's exactly it.\r\n\r\nIf the graph has an odd number of elements, you need to divide it into a group of size (n-1)/2 and a group of (n+1)/2, though. This formula covers both even and odd cases.",
      "created_at": "2025-12-15T13:21:08Z",
      "updated_at": "2025-12-15T13:21:08Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2619415224",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619415224"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 916,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619568865",
      "pull_request_review_id": 3578357148,
      "id": 2619568865,
      "node_id": "PRRC_kwDOABII586cI3Lh",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {",
      "path": "src/cluster_linearize.h",
      "position": 764,
      "original_position": 758,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": null,
      "user": {
        "login": "brunoerg",
        "id": 19480819,
        "node_id": "MDQ6VXNlcjE5NDgwODE5",
        "avatar_url": "https://avatars.githubusercontent.com/u/19480819?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/brunoerg",
        "html_url": "https://github.com/brunoerg",
        "followers_url": "https://api.github.com/users/brunoerg/followers",
        "following_url": "https://api.github.com/users/brunoerg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/brunoerg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/brunoerg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/brunoerg/subscriptions",
        "organizations_url": "https://api.github.com/users/brunoerg/orgs",
        "repos_url": "https://api.github.com/users/brunoerg/repos",
        "events_url": "https://api.github.com/users/brunoerg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/brunoerg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Unkilled mutant:\r\n```diff\r\ndiff --git a/src/cluster_linearize.h b/src/cluster_linearize.h\r\nindex dc7d0e8495..1a894033e8 100644\r\n--- a/src/cluster_linearize.h\r\n+++ b/src/cluster_linearize.h\r\n@@ -983,7 +983,7 @@ public:\r\n             // happen when it was merged with something else since being added.\r\n             if (chunk_data.chunk_rep != chunk) continue;\r\n             int flip = m_rng.randbool();\r\n-            for (int i = 0; i < 2; ++i) {\r\n+            for (int i = 0; i <= 2; ++i) {\r\n                 if (i ^ flip) {\r\n                     // Attempt to merge the chunk upwards.\r\n                     auto result_up = MergeStep<false>(chunk);\r\n```",
      "created_at": "2025-12-15T14:02:56Z",
      "updated_at": "2025-12-15T15:06:31Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2619568865",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619568865"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 986,
      "original_line": 986,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619663299",
      "pull_request_review_id": 3578357148,
      "id": 2619663299,
      "node_id": "PRRC_kwDOABII586cJOPD",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {\n+                if (i ^ flip) {\n+                    // Attempt to merge the chunk upwards.\n+                    auto result_up = MergeStep<false>(chunk);\n+                    if (result_up != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_up);\n+                        break;\n+                    }\n+                } else {\n+                    // Attempt to merge the chunk downwards.\n+                    auto result_down = MergeStep<true>(chunk);\n+                    if (result_down != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_down);\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n     }\n \n-    /** Find the best (highest-feerate, smallest among those in case of a tie) ancestor set\n-     *  among the remaining transactions. Requires !AllDone().\n-     *\n-     * Complexity: O(N) where N=depgraph.TxCount();\n-     */\n-    SetInfo<SetType> FindCandidateSet() const noexcept\n+    /** Initialize the data structure for optimization. It must be topological already. */\n+    void StartOptimizing() noexcept\n     {\n-        Assume(!AllDone());\n-        std::optional<DepGraphIndex> best;\n-        for (auto i : m_todo) {\n-            if (best.has_value()) {\n-                Assume(!m_ancestor_set_feerates[i].IsEmpty());\n-                if (!(m_ancestor_set_feerates[i] > m_ancestor_set_feerates[*best])) continue;\n+        // Mark chunks suboptimal.\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.push_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n             }\n-            best = i;\n         }\n-        Assume(best.has_value());\n-        return {m_depgraph.Ancestors(*best) & m_todo, m_ancestor_set_feerates[*best]};\n     }\n-};\n \n-/** Class encapsulating the state needed to perform search for good candidate sets.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone().\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called to perform a search\n- * over the set of topologically-valid subsets of that remainder, with a limit on how many\n- * combinations are tried.\n- */\n-template<typename SetType>\n-class SearchCandidateFinder\n-{\n-    /** Internal RNG. */\n-    InsecureRandomContext m_rng;\n-    /** m_sorted_to_original[i] is the original position that sorted transaction position i had. */\n-    std::vector<DepGraphIndex> m_sorted_to_original;\n-    /** m_original_to_sorted[i] is the sorted position original transaction position i has. */\n-    std::vector<DepGraphIndex> m_original_to_sorted;\n-    /** Internal dependency graph for the cluster (with transactions in decreasing individual\n-     *  feerate order). */\n-    DepGraph<SetType> m_sorted_depgraph;\n-    /** Which transactions are left to do (indices in m_sorted_depgraph's order). */\n-    SetType m_todo;\n-\n-    /** Given a set of transactions with sorted indices, get their original indices. */\n-    SetType SortedToOriginal(const SetType& arg) const noexcept\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_sorted_to_original[pos]);\n-        return ret;\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when a split chunk merges in Improve() with one or more existing chunks that\n+            // are themselves on the suboptimal queue already.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Remember the best dependency seen so far.\n+            DepIdx candidate_dep = DepIdx(-1);\n+            uint64_t candidate_tiebreak = 0;\n+            // Iterate over all transactions.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n+                }\n+            }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;\n+        }\n+        // No improvable chunk was found, we are done.\n+        return false;\n     }\n \n-    /** Given a set of transactions with original indices, get their sorted indices. */\n-    SetType OriginalToSorted(const SetType& arg) const noexcept\n+    /** Construct a topologically-valid linearization from the current forest state. Must be\n+     *  topological. */\n+    std::vector<DepGraphIndex> GetLinearization() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_original_to_sorted[pos]);\n+        /** The output linearization. */\n+        std::vector<DepGraphIndex> ret;\n+        ret.reserve(m_transactions.Count());\n+        /** A heap with all chunks (by representative) that can currently be included, sorted by\n+         *  chunk feerate and a random tie-breaker. */\n+        std::vector<std::pair<TxIdx, uint64_t>> ready_chunks;\n+        /** Information about chunks:\n+         *  - The first value is only used for chunk representatives, and counts the number of\n+         *    unmet dependencies this chunk has on other chunks (not including dependencies within\n+         *    the chunk itself).\n+         *  - The second value is the number of unmet dependencies overall.\n+         */\n+        std::vector<std::pair<TxIdx, TxIdx>> chunk_deps(m_tx_data.size(), {0, 0});\n+        /** The set of all chunk representatives. */\n+        SetType chunk_reps;\n+        /** A list with all transactions within the current chunk that can be included. */\n+        std::vector<TxIdx> ready_tx;\n+        // Populate chunk_deps[c] with the number of {out-of-chunk dependencies, dependencies} the\n+        // child has.\n+        for (TxIdx chl_idx : m_transactions) {\n+            const auto& chl_data = m_tx_data[chl_idx];\n+            chunk_deps[chl_idx].second = chl_data.parents.Count();\n+            auto chl_chunk_rep = chl_data.chunk_rep;\n+            chunk_reps.Set(chl_chunk_rep);\n+            for (auto par_idx : chl_data.parents) {\n+                auto par_chunk_rep = m_tx_data[par_idx].chunk_rep;\n+                chunk_deps[chl_chunk_rep].first += (par_chunk_rep != chl_chunk_rep);\n+            }\n+        }\n+        // Construct a heap with all chunks that have no out-of-chunk dependencies.\n+        /** Comparison function for the heap. */\n+        auto chunk_cmp_fn = [&](const std::pair<TxIdx, uint64_t>& a, const std::pair<TxIdx, uint64_t>& b) noexcept {\n+            auto& chunk_a = m_tx_data[a.first];\n+            auto& chunk_b = m_tx_data[b.first];\n+            Assume(chunk_a.chunk_rep == a.first);\n+            Assume(chunk_b.chunk_rep == b.first);\n+            // First sort by chunk feerate.\n+            if (chunk_a.chunk_setinfo.feerate != chunk_b.chunk_setinfo.feerate) {\n+                return chunk_a.chunk_setinfo.feerate < chunk_b.chunk_setinfo.feerate;\n+            }\n+            // Tie-break randomly.\n+            if (a.second != b.second) return a.second < b.second;\n+            // Lastly, tie-break by chunk representative.\n+            return a.first < b.first;\n+        };\n+        for (TxIdx chunk_rep : chunk_reps) {\n+            if (chunk_deps[chunk_rep].first == 0) ready_chunks.emplace_back(chunk_rep, m_rng.rand64());\n+        }\n+        std::make_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+        // Pop chunks off the heap, highest-feerate ones first.\n+        while (!ready_chunks.empty()) {\n+            auto [chunk_rep, _rnd] = ready_chunks.front();\n+            std::pop_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+            ready_chunks.pop_back();\n+            Assume(m_tx_data[chunk_rep].chunk_rep == chunk_rep);\n+            Assume(chunk_deps[chunk_rep].first == 0);\n+            const auto& chunk_txn = m_tx_data[chunk_rep].chunk_setinfo.transactions;\n+            // Build heap of all includable transactions in chunk.\n+            for (TxIdx tx_idx : chunk_txn) {\n+                if (chunk_deps[tx_idx].second == 0) {\n+                    ready_tx.push_back(tx_idx);\n+                }\n+            }\n+            Assume(!ready_tx.empty());\n+            // Pick transactions from the ready queue, append them to linearization, and decrement\n+            // dependency counts.\n+            while (!ready_tx.empty()) {\n+                // Move a random queue element to the back.\n+                auto pos = m_rng.randrange(ready_tx.size());\n+                if (pos != ready_tx.size() - 1) std::swap(ready_tx.back(), ready_tx[pos]);\n+                // Pop from the back.\n+                auto tx_idx = ready_tx.back();\n+                Assume(chunk_txn[tx_idx]);\n+                ready_tx.pop_back();\n+                // Append to linearization.\n+                ret.push_back(tx_idx);\n+                // Decrement dependency counts.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                for (TxIdx chl_idx : tx_data.children) {\n+                    auto& chl_data = m_tx_data[chl_idx];\n+                    // Decrement tx dependency count.\n+                    Assume(chunk_deps[chl_idx].second > 0);\n+                    if (--chunk_deps[chl_idx].second == 0 && chunk_txn[chl_idx]) {\n+                        // Child tx has no dependencies left, and is in this chunk. Add it to the tx queue.\n+                        ready_tx.push_back(chl_idx);\n+                    }\n+                    // Decrement chunk dependency count if this is out-of-chunk dependency.\n+                    if (chl_data.chunk_rep != chunk_rep) {\n+                        Assume(chunk_deps[chl_data.chunk_rep].first > 0);\n+                        if (--chunk_deps[chl_data.chunk_rep].first == 0) {\n+                            // Child chunk has no dependencies left. Add it to the chunk heap.\n+                            ready_chunks.emplace_back(chl_data.chunk_rep, m_rng.rand64());\n+                            std::push_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        Assume(ret.size() == m_transactions.Count());\n         return ret;\n     }\n \n-public:\n-    /** Construct a candidate finder for a graph.\n+    /** Get the diagram for the current state, which must be topological. Test-only.\n      *\n-     * @param[in] depgraph   Dependency graph for the to-be-linearized cluster.\n-     * @param[in] rng_seed   A random seed to control the search order.\n+     * The linearization produced by GetLinearization() is always at least as good (in the\n+     * CompareChunks() sense) as this diagram, but may be better.\n      *\n-     * Complexity: O(N^2) where N=depgraph.Count().\n+     * After an OptimizeStep(), the diagram will always be at least as good as before. Once\n+     * OptimizeStep() returns false, the diagram will be equivalent to that produced by\n+     * GetLinearization(), and optimal.\n      */\n-    SearchCandidateFinder(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept :\n-        m_rng(rng_seed),\n-        m_sorted_to_original(depgraph.TxCount()),\n-        m_original_to_sorted(depgraph.PositionRange())\n+    std::vector<FeeFrac> GetDiagram() const noexcept\n     {\n-        // Determine reordering mapping, by sorting by decreasing feerate. Unused positions are\n-        // not included, as they will never be looked up anyway.\n-        DepGraphIndex sorted_pos{0};\n-        for (auto i : depgraph.Positions()) {\n-            m_sorted_to_original[sorted_pos++] = i;\n-        }\n-        std::sort(m_sorted_to_original.begin(), m_sorted_to_original.end(), [&](auto a, auto b) {\n-            auto feerate_cmp = depgraph.FeeRate(a) <=> depgraph.FeeRate(b);\n-            if (feerate_cmp == 0) return a < b;\n-            return feerate_cmp > 0;\n-        });\n-        // Compute reverse mapping.\n-        for (DepGraphIndex i = 0; i < m_sorted_to_original.size(); ++i) {\n-            m_original_to_sorted[m_sorted_to_original[i]] = i;\n+        std::vector<FeeFrac> ret;\n+        for (auto tx : m_transactions) {\n+            if (m_tx_data[tx].chunk_rep == tx) {\n+                ret.push_back(m_tx_data[tx].chunk_setinfo.feerate);\n+            }\n         }\n-        // Compute reordered dependency graph.\n-        m_sorted_depgraph = DepGraph(depgraph, m_original_to_sorted, m_sorted_to_original.size());\n-        m_todo = m_sorted_depgraph.Positions();\n+        std::sort(ret.begin(), ret.end(), std::greater{});\n+        return ret;\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n-    {\n-        return m_todo.None();\n-    }\n+    /** Determine how much work was performed so far. */\n+    uint64_t GetCost() const noexcept { return m_cost; }\n \n-    /** Find a high-feerate topologically-valid subset of what remains of the cluster.\n-     *  Requires !AllDone().\n-     *\n-     * @param[in] max_iterations  The maximum number of optimization steps that will be performed.\n-     * @param[in] best            A set/feerate pair with an already-known good candidate. This may\n-     *                            be empty.\n-     * @return                    A pair of:\n-     *                            - The best (highest feerate, smallest size as tiebreaker)\n-     *                              topologically valid subset (and its feerate) that was\n-     *                              encountered during search. It will be at least as good as the\n-     *                              best passed in (if not empty).\n-     *                            - The number of optimization steps that were performed. This will\n-     *                              be <= max_iterations. If strictly < max_iterations, the\n-     *                              returned subset is optimal.\n-     *\n-     * Complexity: possibly O(N * min(max_iterations, sqrt(2^N))) where N=depgraph.TxCount().\n-     */\n-    std::pair<SetInfo<SetType>, uint64_t> FindCandidateSet(uint64_t max_iterations, SetInfo<SetType> best) noexcept\n+    /** Verify internal consistency of the data structure. */\n+    void SanityCheck(const DepGraph<SetType>& depgraph) const\n     {\n-        Assume(!AllDone());\n-\n-        // Convert the provided best to internal sorted indices.\n-        best.transactions = OriginalToSorted(best.transactions);\n-\n-        /** Type for work queue items. */\n-        struct WorkItem\n-        {\n-            /** Set of transactions definitely included (and its feerate). This must be a subset\n-             *  of m_todo, and be topologically valid (includes all in-m_todo ancestors of\n-             *  itself). */\n-            SetInfo<SetType> inc;\n-            /** Set of undecided transactions. This must be a subset of m_todo, and have no overlap\n-             *  with inc. The set (inc | und) must be topologically valid. */\n-            SetType und;\n-            /** (Only when inc is not empty) The best feerate of any superset of inc that is also a\n-             *  subset of (inc | und), without requiring it to be topologically valid. It forms a\n-             *  conservative upper bound on how good a set this work item can give rise to.\n-             *  Transactions whose feerate is below best's are ignored when determining this value,\n-             *  which means it may technically be an underestimate, but if so, this work item\n-             *  cannot result in something that beats best anyway. */\n-            FeeFrac pot_feerate;\n-\n-            /** Construct a new work item. */\n-            WorkItem(SetInfo<SetType>&& i, SetType&& u, FeeFrac&& p_f) noexcept :\n-                inc(std::move(i)), und(std::move(u)), pot_feerate(std::move(p_f))\n-            {\n-                Assume(pot_feerate.IsEmpty() == inc.feerate.IsEmpty());\n+        //\n+        // Verify dependency parent/child information, and build list of (active) dependencies.\n+        //\n+        std::vector<std::pair<TxIdx, TxIdx>> expected_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> all_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> active_dependencies;\n+        for (auto parent_idx : depgraph.Positions()) {\n+            for (auto child_idx : depgraph.GetReducedChildren(parent_idx)) {\n+                expected_dependencies.emplace_back(parent_idx, child_idx);\n             }\n-\n-            /** Swap two WorkItems. */\n-            void Swap(WorkItem& other) noexcept\n-            {\n-                swap(inc, other.inc);\n-                swap(und, other.und);\n-                swap(pot_feerate, other.pot_feerate);\n+        }\n+        for (DepIdx dep_idx = 0; dep_idx < m_dep_data.size(); ++dep_idx) {\n+            const auto& dep_data = m_dep_data[dep_idx];\n+            all_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n+            // Also add to active_dependencies if it is active.\n+            if (m_dep_data[dep_idx].active) {\n+                active_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n             }\n-        };\n-\n-        /** The queue of work items. */\n-        VecDeque<WorkItem> queue;\n-        queue.reserve(std::max<size_t>(256, 2 * m_todo.Count()));\n-\n-        // Create initial entries per connected component of m_todo. While clusters themselves are\n-        // generally connected, this is not necessarily true after some parts have already been\n-        // removed from m_todo. Without this, effort can be wasted on searching \"inc\" sets that\n-        // span multiple components.\n-        auto to_cover = m_todo;\n-        do {\n-            auto component = m_sorted_depgraph.FindConnectedComponent(to_cover);\n-            to_cover -= component;\n-            // If best is not provided, set it to the first component, so that during the work\n-            // processing loop below, and during the add_fn/split_fn calls, we do not need to deal\n-            // with the best=empty case.\n-            if (best.feerate.IsEmpty()) best = SetInfo(m_sorted_depgraph, component);\n-            queue.emplace_back(/*inc=*/SetInfo<SetType>{},\n-                               /*und=*/std::move(component),\n-                               /*pot_feerate=*/FeeFrac{});\n-        } while (to_cover.Any());\n-\n-        /** Local copy of the iteration limit. */\n-        uint64_t iterations_left = max_iterations;\n-\n-        /** The set of transactions in m_todo which have feerate > best's. */\n-        SetType imp = m_todo;\n-        while (imp.Any()) {\n-            DepGraphIndex check = imp.Last();\n-            if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-            imp.Reset(check);\n+        }\n+        std::sort(expected_dependencies.begin(), expected_dependencies.end());\n+        std::sort(all_dependencies.begin(), all_dependencies.end());\n+        assert(expected_dependencies.size() == all_dependencies.size());\n+        for (size_t i = 0; i < expected_dependencies.size(); ++i) {\n+            assert(expected_dependencies[i] ==\n+                   std::make_pair(std::get<0>(all_dependencies[i]),\n+                                  std::get<1>(all_dependencies[i])));\n         }\n \n-        /** Internal function to add an item to the queue of elements to explore if there are any\n-         *  transactions left to split on, possibly improving it before doing so, and to update\n-         *  best/imp.\n-         *\n-         * - inc: the \"inc\" value for the new work item (must be topological).\n-         * - und: the \"und\" value for the new work item ((inc | und) must be topological).\n-         */\n-        auto add_fn = [&](SetInfo<SetType> inc, SetType und) noexcept {\n-            /** SetInfo object with the set whose feerate will become the new work item's\n-             *  pot_feerate. It starts off equal to inc. */\n-            auto pot = inc;\n-            if (!inc.feerate.IsEmpty()) {\n-                // Add entries to pot. We iterate over all undecided transactions whose feerate is\n-                // higher than best. While undecided transactions of lower feerate may improve pot,\n-                // the resulting pot feerate cannot possibly exceed best's (and this item will be\n-                // skipped in split_fn anyway).\n-                for (auto pos : imp & und) {\n-                    // Determine if adding transaction pos to pot (ignoring topology) would improve\n-                    // it. If not, we're done updating pot. This relies on the fact that\n-                    // m_sorted_depgraph, and thus the transactions iterated over, are in decreasing\n-                    // individual feerate order.\n-                    if (!(m_sorted_depgraph.FeeRate(pos) >> pot.feerate)) break;\n-                    pot.Set(m_sorted_depgraph, pos);\n-                }\n-\n-                // The \"jump ahead\" optimization: whenever pot has a topologically-valid subset,\n-                // that subset can be added to inc. Any subset of (pot - inc) has the property that\n-                // its feerate exceeds that of any set compatible with this work item (superset of\n-                // inc, subset of (inc | und)). Thus, if T is a topological subset of pot, and B is\n-                // the best topologically-valid set compatible with this work item, and (T - B) is\n-                // non-empty, then (T | B) is better than B and also topological. This is in\n-                // contradiction with the assumption that B is best. Thus, (T - B) must be empty,\n-                // or T must be a subset of B.\n-                //\n-                // See https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303 section 2.4.\n-                const auto init_inc = inc.transactions;\n-                for (auto pos : pot.transactions - inc.transactions) {\n-                    // If the transaction's ancestors are a subset of pot, we can add it together\n-                    // with its ancestors to inc. Just update the transactions here; the feerate\n-                    // update happens below.\n-                    auto anc_todo = m_sorted_depgraph.Ancestors(pos) & m_todo;\n-                    if (anc_todo.IsSubsetOf(pot.transactions)) inc.transactions |= anc_todo;\n+        //\n+        // Verify the chunks against the list of active dependencies\n+        //\n+        for (auto tx_idx: depgraph.Positions()) {\n+            // Only process chunks for now.\n+            if (m_tx_data[tx_idx].chunk_rep == tx_idx) {\n+                const auto& chunk_data = m_tx_data[tx_idx];\n+                // Verify that transactions in the chunk point back to it. This guarantees\n+                // that chunks are non-overlapping.\n+                for (auto chunk_tx : chunk_data.chunk_setinfo.transactions) {\n+                    assert(m_tx_data[chunk_tx].chunk_rep == tx_idx);\n                 }\n-                // Finally update und and inc's feerate to account for the added transactions.\n-                und -= inc.transactions;\n-                inc.feerate += m_sorted_depgraph.FeeRate(inc.transactions - init_inc);\n-\n-                // If inc's feerate is better than best's, remember it as our new best.\n-                if (inc.feerate > best.feerate) {\n-                    best = inc;\n-                    // See if we can remove any entries from imp now.\n-                    while (imp.Any()) {\n-                        DepGraphIndex check = imp.Last();\n-                        if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-                        imp.Reset(check);\n+                // Verify the chunk's transaction set: it must contain the representative, and for\n+                // every active dependency, if it contains the parent or child, it must contain\n+                // both. It must have exactly N-1 active dependencies in it, guaranteeing it is\n+                // acyclic.\n+                SetType expected_chunk = SetType::Singleton(tx_idx);\n+                while (true) {",
      "path": "src/cluster_linearize.h",
      "position": 1246,
      "original_position": 1240,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": null,
      "user": {
        "login": "brunoerg",
        "id": 19480819,
        "node_id": "MDQ6VXNlcjE5NDgwODE5",
        "avatar_url": "https://avatars.githubusercontent.com/u/19480819?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/brunoerg",
        "html_url": "https://github.com/brunoerg",
        "followers_url": "https://api.github.com/users/brunoerg/followers",
        "following_url": "https://api.github.com/users/brunoerg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/brunoerg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/brunoerg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/brunoerg/subscriptions",
        "organizations_url": "https://api.github.com/users/brunoerg/orgs",
        "repos_url": "https://api.github.com/users/brunoerg/repos",
        "events_url": "https://api.github.com/users/brunoerg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/brunoerg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Unkilled mutant:\r\n```diff\r\ndiff --git a/src/cluster_linearize.h b/src/cluster_linearize.h\r\nindex 8f5b099ef2..f7d87f048c 100644\r\n--- a/src/cluster_linearize.h\r\n+++ b/src/cluster_linearize.h\r\n@@ -1240,7 +1240,7 @@ public:\r\n                 // both. It must have exactly N-1 active dependencies in it, guaranteeing it is\r\n                 // acyclic.\r\n                 SetType expected_chunk = SetType::Singleton(tx_idx);\r\n-                while (true) {\r\n+                while (1==0) {\r\n                     auto old = expected_chunk;\r\n                     size_t active_dep_count{0};\r\n                     for (const auto& [par, chl, _dep] : active_dependencies) {\r\n```",
      "created_at": "2025-12-15T14:27:21Z",
      "updated_at": "2025-12-15T15:06:31Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2619663299",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619663299"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1249,
      "original_line": 1249,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619990736",
      "pull_request_review_id": 3578969348,
      "id": 2619990736,
      "node_id": "PRRC_kwDOABII586cKeLQ",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {\n+                if (i ^ flip) {\n+                    // Attempt to merge the chunk upwards.\n+                    auto result_up = MergeStep<false>(chunk);\n+                    if (result_up != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_up);\n+                        break;\n+                    }\n+                } else {\n+                    // Attempt to merge the chunk downwards.\n+                    auto result_down = MergeStep<true>(chunk);\n+                    if (result_down != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_down);\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n     }\n \n-    /** Find the best (highest-feerate, smallest among those in case of a tie) ancestor set\n-     *  among the remaining transactions. Requires !AllDone().\n-     *\n-     * Complexity: O(N) where N=depgraph.TxCount();\n-     */\n-    SetInfo<SetType> FindCandidateSet() const noexcept\n+    /** Initialize the data structure for optimization. It must be topological already. */\n+    void StartOptimizing() noexcept\n     {\n-        Assume(!AllDone());\n-        std::optional<DepGraphIndex> best;\n-        for (auto i : m_todo) {\n-            if (best.has_value()) {\n-                Assume(!m_ancestor_set_feerates[i].IsEmpty());\n-                if (!(m_ancestor_set_feerates[i] > m_ancestor_set_feerates[*best])) continue;\n+        // Mark chunks suboptimal.\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.push_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n             }\n-            best = i;\n         }\n-        Assume(best.has_value());\n-        return {m_depgraph.Ancestors(*best) & m_todo, m_ancestor_set_feerates[*best]};\n     }\n-};\n \n-/** Class encapsulating the state needed to perform search for good candidate sets.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone().\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called to perform a search\n- * over the set of topologically-valid subsets of that remainder, with a limit on how many\n- * combinations are tried.\n- */\n-template<typename SetType>\n-class SearchCandidateFinder\n-{\n-    /** Internal RNG. */\n-    InsecureRandomContext m_rng;\n-    /** m_sorted_to_original[i] is the original position that sorted transaction position i had. */\n-    std::vector<DepGraphIndex> m_sorted_to_original;\n-    /** m_original_to_sorted[i] is the sorted position original transaction position i has. */\n-    std::vector<DepGraphIndex> m_original_to_sorted;\n-    /** Internal dependency graph for the cluster (with transactions in decreasing individual\n-     *  feerate order). */\n-    DepGraph<SetType> m_sorted_depgraph;\n-    /** Which transactions are left to do (indices in m_sorted_depgraph's order). */\n-    SetType m_todo;\n-\n-    /** Given a set of transactions with sorted indices, get their original indices. */\n-    SetType SortedToOriginal(const SetType& arg) const noexcept\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_sorted_to_original[pos]);\n-        return ret;\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when a split chunk merges in Improve() with one or more existing chunks that\n+            // are themselves on the suboptimal queue already.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Remember the best dependency seen so far.\n+            DepIdx candidate_dep = DepIdx(-1);\n+            uint64_t candidate_tiebreak = 0;\n+            // Iterate over all transactions.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n+                }\n+            }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;\n+        }\n+        // No improvable chunk was found, we are done.\n+        return false;\n     }\n \n-    /** Given a set of transactions with original indices, get their sorted indices. */\n-    SetType OriginalToSorted(const SetType& arg) const noexcept\n+    /** Construct a topologically-valid linearization from the current forest state. Must be\n+     *  topological. */\n+    std::vector<DepGraphIndex> GetLinearization() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_original_to_sorted[pos]);\n+        /** The output linearization. */\n+        std::vector<DepGraphIndex> ret;\n+        ret.reserve(m_transactions.Count());\n+        /** A heap with all chunks (by representative) that can currently be included, sorted by\n+         *  chunk feerate and a random tie-breaker. */\n+        std::vector<std::pair<TxIdx, uint64_t>> ready_chunks;\n+        /** Information about chunks:\n+         *  - The first value is only used for chunk representatives, and counts the number of\n+         *    unmet dependencies this chunk has on other chunks (not including dependencies within\n+         *    the chunk itself).\n+         *  - The second value is the number of unmet dependencies overall.\n+         */\n+        std::vector<std::pair<TxIdx, TxIdx>> chunk_deps(m_tx_data.size(), {0, 0});\n+        /** The set of all chunk representatives. */\n+        SetType chunk_reps;\n+        /** A list with all transactions within the current chunk that can be included. */\n+        std::vector<TxIdx> ready_tx;\n+        // Populate chunk_deps[c] with the number of {out-of-chunk dependencies, dependencies} the\n+        // child has.\n+        for (TxIdx chl_idx : m_transactions) {\n+            const auto& chl_data = m_tx_data[chl_idx];\n+            chunk_deps[chl_idx].second = chl_data.parents.Count();\n+            auto chl_chunk_rep = chl_data.chunk_rep;\n+            chunk_reps.Set(chl_chunk_rep);\n+            for (auto par_idx : chl_data.parents) {\n+                auto par_chunk_rep = m_tx_data[par_idx].chunk_rep;\n+                chunk_deps[chl_chunk_rep].first += (par_chunk_rep != chl_chunk_rep);\n+            }\n+        }\n+        // Construct a heap with all chunks that have no out-of-chunk dependencies.\n+        /** Comparison function for the heap. */\n+        auto chunk_cmp_fn = [&](const std::pair<TxIdx, uint64_t>& a, const std::pair<TxIdx, uint64_t>& b) noexcept {\n+            auto& chunk_a = m_tx_data[a.first];\n+            auto& chunk_b = m_tx_data[b.first];\n+            Assume(chunk_a.chunk_rep == a.first);\n+            Assume(chunk_b.chunk_rep == b.first);\n+            // First sort by chunk feerate.\n+            if (chunk_a.chunk_setinfo.feerate != chunk_b.chunk_setinfo.feerate) {\n+                return chunk_a.chunk_setinfo.feerate < chunk_b.chunk_setinfo.feerate;\n+            }\n+            // Tie-break randomly.\n+            if (a.second != b.second) return a.second < b.second;\n+            // Lastly, tie-break by chunk representative.\n+            return a.first < b.first;\n+        };\n+        for (TxIdx chunk_rep : chunk_reps) {\n+            if (chunk_deps[chunk_rep].first == 0) ready_chunks.emplace_back(chunk_rep, m_rng.rand64());\n+        }\n+        std::make_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+        // Pop chunks off the heap, highest-feerate ones first.\n+        while (!ready_chunks.empty()) {\n+            auto [chunk_rep, _rnd] = ready_chunks.front();\n+            std::pop_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+            ready_chunks.pop_back();\n+            Assume(m_tx_data[chunk_rep].chunk_rep == chunk_rep);\n+            Assume(chunk_deps[chunk_rep].first == 0);\n+            const auto& chunk_txn = m_tx_data[chunk_rep].chunk_setinfo.transactions;\n+            // Build heap of all includable transactions in chunk.\n+            for (TxIdx tx_idx : chunk_txn) {\n+                if (chunk_deps[tx_idx].second == 0) {\n+                    ready_tx.push_back(tx_idx);\n+                }\n+            }\n+            Assume(!ready_tx.empty());\n+            // Pick transactions from the ready queue, append them to linearization, and decrement\n+            // dependency counts.\n+            while (!ready_tx.empty()) {\n+                // Move a random queue element to the back.\n+                auto pos = m_rng.randrange(ready_tx.size());\n+                if (pos != ready_tx.size() - 1) std::swap(ready_tx.back(), ready_tx[pos]);\n+                // Pop from the back.\n+                auto tx_idx = ready_tx.back();\n+                Assume(chunk_txn[tx_idx]);\n+                ready_tx.pop_back();\n+                // Append to linearization.\n+                ret.push_back(tx_idx);\n+                // Decrement dependency counts.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                for (TxIdx chl_idx : tx_data.children) {\n+                    auto& chl_data = m_tx_data[chl_idx];\n+                    // Decrement tx dependency count.\n+                    Assume(chunk_deps[chl_idx].second > 0);\n+                    if (--chunk_deps[chl_idx].second == 0 && chunk_txn[chl_idx]) {\n+                        // Child tx has no dependencies left, and is in this chunk. Add it to the tx queue.\n+                        ready_tx.push_back(chl_idx);\n+                    }\n+                    // Decrement chunk dependency count if this is out-of-chunk dependency.\n+                    if (chl_data.chunk_rep != chunk_rep) {\n+                        Assume(chunk_deps[chl_data.chunk_rep].first > 0);\n+                        if (--chunk_deps[chl_data.chunk_rep].first == 0) {\n+                            // Child chunk has no dependencies left. Add it to the chunk heap.\n+                            ready_chunks.emplace_back(chl_data.chunk_rep, m_rng.rand64());\n+                            std::push_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        Assume(ret.size() == m_transactions.Count());\n         return ret;\n     }\n \n-public:\n-    /** Construct a candidate finder for a graph.\n+    /** Get the diagram for the current state, which must be topological. Test-only.\n      *\n-     * @param[in] depgraph   Dependency graph for the to-be-linearized cluster.\n-     * @param[in] rng_seed   A random seed to control the search order.\n+     * The linearization produced by GetLinearization() is always at least as good (in the\n+     * CompareChunks() sense) as this diagram, but may be better.\n      *\n-     * Complexity: O(N^2) where N=depgraph.Count().\n+     * After an OptimizeStep(), the diagram will always be at least as good as before. Once\n+     * OptimizeStep() returns false, the diagram will be equivalent to that produced by\n+     * GetLinearization(), and optimal.\n      */\n-    SearchCandidateFinder(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept :\n-        m_rng(rng_seed),\n-        m_sorted_to_original(depgraph.TxCount()),\n-        m_original_to_sorted(depgraph.PositionRange())\n+    std::vector<FeeFrac> GetDiagram() const noexcept\n     {\n-        // Determine reordering mapping, by sorting by decreasing feerate. Unused positions are\n-        // not included, as they will never be looked up anyway.\n-        DepGraphIndex sorted_pos{0};\n-        for (auto i : depgraph.Positions()) {\n-            m_sorted_to_original[sorted_pos++] = i;\n-        }\n-        std::sort(m_sorted_to_original.begin(), m_sorted_to_original.end(), [&](auto a, auto b) {\n-            auto feerate_cmp = depgraph.FeeRate(a) <=> depgraph.FeeRate(b);\n-            if (feerate_cmp == 0) return a < b;\n-            return feerate_cmp > 0;\n-        });\n-        // Compute reverse mapping.\n-        for (DepGraphIndex i = 0; i < m_sorted_to_original.size(); ++i) {\n-            m_original_to_sorted[m_sorted_to_original[i]] = i;\n+        std::vector<FeeFrac> ret;\n+        for (auto tx : m_transactions) {\n+            if (m_tx_data[tx].chunk_rep == tx) {\n+                ret.push_back(m_tx_data[tx].chunk_setinfo.feerate);\n+            }\n         }\n-        // Compute reordered dependency graph.\n-        m_sorted_depgraph = DepGraph(depgraph, m_original_to_sorted, m_sorted_to_original.size());\n-        m_todo = m_sorted_depgraph.Positions();\n+        std::sort(ret.begin(), ret.end(), std::greater{});\n+        return ret;\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n-    {\n-        return m_todo.None();\n-    }\n+    /** Determine how much work was performed so far. */\n+    uint64_t GetCost() const noexcept { return m_cost; }\n \n-    /** Find a high-feerate topologically-valid subset of what remains of the cluster.\n-     *  Requires !AllDone().\n-     *\n-     * @param[in] max_iterations  The maximum number of optimization steps that will be performed.\n-     * @param[in] best            A set/feerate pair with an already-known good candidate. This may\n-     *                            be empty.\n-     * @return                    A pair of:\n-     *                            - The best (highest feerate, smallest size as tiebreaker)\n-     *                              topologically valid subset (and its feerate) that was\n-     *                              encountered during search. It will be at least as good as the\n-     *                              best passed in (if not empty).\n-     *                            - The number of optimization steps that were performed. This will\n-     *                              be <= max_iterations. If strictly < max_iterations, the\n-     *                              returned subset is optimal.\n-     *\n-     * Complexity: possibly O(N * min(max_iterations, sqrt(2^N))) where N=depgraph.TxCount().\n-     */\n-    std::pair<SetInfo<SetType>, uint64_t> FindCandidateSet(uint64_t max_iterations, SetInfo<SetType> best) noexcept\n+    /** Verify internal consistency of the data structure. */\n+    void SanityCheck(const DepGraph<SetType>& depgraph) const\n     {\n-        Assume(!AllDone());\n-\n-        // Convert the provided best to internal sorted indices.\n-        best.transactions = OriginalToSorted(best.transactions);\n-\n-        /** Type for work queue items. */\n-        struct WorkItem\n-        {\n-            /** Set of transactions definitely included (and its feerate). This must be a subset\n-             *  of m_todo, and be topologically valid (includes all in-m_todo ancestors of\n-             *  itself). */\n-            SetInfo<SetType> inc;\n-            /** Set of undecided transactions. This must be a subset of m_todo, and have no overlap\n-             *  with inc. The set (inc | und) must be topologically valid. */\n-            SetType und;\n-            /** (Only when inc is not empty) The best feerate of any superset of inc that is also a\n-             *  subset of (inc | und), without requiring it to be topologically valid. It forms a\n-             *  conservative upper bound on how good a set this work item can give rise to.\n-             *  Transactions whose feerate is below best's are ignored when determining this value,\n-             *  which means it may technically be an underestimate, but if so, this work item\n-             *  cannot result in something that beats best anyway. */\n-            FeeFrac pot_feerate;\n-\n-            /** Construct a new work item. */\n-            WorkItem(SetInfo<SetType>&& i, SetType&& u, FeeFrac&& p_f) noexcept :\n-                inc(std::move(i)), und(std::move(u)), pot_feerate(std::move(p_f))\n-            {\n-                Assume(pot_feerate.IsEmpty() == inc.feerate.IsEmpty());\n+        //\n+        // Verify dependency parent/child information, and build list of (active) dependencies.\n+        //\n+        std::vector<std::pair<TxIdx, TxIdx>> expected_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> all_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> active_dependencies;\n+        for (auto parent_idx : depgraph.Positions()) {\n+            for (auto child_idx : depgraph.GetReducedChildren(parent_idx)) {\n+                expected_dependencies.emplace_back(parent_idx, child_idx);\n             }\n-\n-            /** Swap two WorkItems. */\n-            void Swap(WorkItem& other) noexcept\n-            {\n-                swap(inc, other.inc);\n-                swap(und, other.und);\n-                swap(pot_feerate, other.pot_feerate);\n+        }\n+        for (DepIdx dep_idx = 0; dep_idx < m_dep_data.size(); ++dep_idx) {\n+            const auto& dep_data = m_dep_data[dep_idx];\n+            all_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n+            // Also add to active_dependencies if it is active.\n+            if (m_dep_data[dep_idx].active) {\n+                active_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n             }\n-        };\n-\n-        /** The queue of work items. */\n-        VecDeque<WorkItem> queue;\n-        queue.reserve(std::max<size_t>(256, 2 * m_todo.Count()));\n-\n-        // Create initial entries per connected component of m_todo. While clusters themselves are\n-        // generally connected, this is not necessarily true after some parts have already been\n-        // removed from m_todo. Without this, effort can be wasted on searching \"inc\" sets that\n-        // span multiple components.\n-        auto to_cover = m_todo;\n-        do {\n-            auto component = m_sorted_depgraph.FindConnectedComponent(to_cover);\n-            to_cover -= component;\n-            // If best is not provided, set it to the first component, so that during the work\n-            // processing loop below, and during the add_fn/split_fn calls, we do not need to deal\n-            // with the best=empty case.\n-            if (best.feerate.IsEmpty()) best = SetInfo(m_sorted_depgraph, component);\n-            queue.emplace_back(/*inc=*/SetInfo<SetType>{},\n-                               /*und=*/std::move(component),\n-                               /*pot_feerate=*/FeeFrac{});\n-        } while (to_cover.Any());\n-\n-        /** Local copy of the iteration limit. */\n-        uint64_t iterations_left = max_iterations;\n-\n-        /** The set of transactions in m_todo which have feerate > best's. */\n-        SetType imp = m_todo;\n-        while (imp.Any()) {\n-            DepGraphIndex check = imp.Last();\n-            if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-            imp.Reset(check);\n+        }\n+        std::sort(expected_dependencies.begin(), expected_dependencies.end());\n+        std::sort(all_dependencies.begin(), all_dependencies.end());\n+        assert(expected_dependencies.size() == all_dependencies.size());\n+        for (size_t i = 0; i < expected_dependencies.size(); ++i) {\n+            assert(expected_dependencies[i] ==\n+                   std::make_pair(std::get<0>(all_dependencies[i]),\n+                                  std::get<1>(all_dependencies[i])));\n         }\n \n-        /** Internal function to add an item to the queue of elements to explore if there are any\n-         *  transactions left to split on, possibly improving it before doing so, and to update\n-         *  best/imp.\n-         *\n-         * - inc: the \"inc\" value for the new work item (must be topological).\n-         * - und: the \"und\" value for the new work item ((inc | und) must be topological).\n-         */\n-        auto add_fn = [&](SetInfo<SetType> inc, SetType und) noexcept {\n-            /** SetInfo object with the set whose feerate will become the new work item's\n-             *  pot_feerate. It starts off equal to inc. */\n-            auto pot = inc;\n-            if (!inc.feerate.IsEmpty()) {\n-                // Add entries to pot. We iterate over all undecided transactions whose feerate is\n-                // higher than best. While undecided transactions of lower feerate may improve pot,\n-                // the resulting pot feerate cannot possibly exceed best's (and this item will be\n-                // skipped in split_fn anyway).\n-                for (auto pos : imp & und) {\n-                    // Determine if adding transaction pos to pot (ignoring topology) would improve\n-                    // it. If not, we're done updating pot. This relies on the fact that\n-                    // m_sorted_depgraph, and thus the transactions iterated over, are in decreasing\n-                    // individual feerate order.\n-                    if (!(m_sorted_depgraph.FeeRate(pos) >> pot.feerate)) break;\n-                    pot.Set(m_sorted_depgraph, pos);\n-                }\n-\n-                // The \"jump ahead\" optimization: whenever pot has a topologically-valid subset,\n-                // that subset can be added to inc. Any subset of (pot - inc) has the property that\n-                // its feerate exceeds that of any set compatible with this work item (superset of\n-                // inc, subset of (inc | und)). Thus, if T is a topological subset of pot, and B is\n-                // the best topologically-valid set compatible with this work item, and (T - B) is\n-                // non-empty, then (T | B) is better than B and also topological. This is in\n-                // contradiction with the assumption that B is best. Thus, (T - B) must be empty,\n-                // or T must be a subset of B.\n-                //\n-                // See https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303 section 2.4.\n-                const auto init_inc = inc.transactions;\n-                for (auto pos : pot.transactions - inc.transactions) {\n-                    // If the transaction's ancestors are a subset of pot, we can add it together\n-                    // with its ancestors to inc. Just update the transactions here; the feerate\n-                    // update happens below.\n-                    auto anc_todo = m_sorted_depgraph.Ancestors(pos) & m_todo;\n-                    if (anc_todo.IsSubsetOf(pot.transactions)) inc.transactions |= anc_todo;\n+        //\n+        // Verify the chunks against the list of active dependencies\n+        //\n+        for (auto tx_idx: depgraph.Positions()) {\n+            // Only process chunks for now.\n+            if (m_tx_data[tx_idx].chunk_rep == tx_idx) {\n+                const auto& chunk_data = m_tx_data[tx_idx];\n+                // Verify that transactions in the chunk point back to it. This guarantees\n+                // that chunks are non-overlapping.\n+                for (auto chunk_tx : chunk_data.chunk_setinfo.transactions) {\n+                    assert(m_tx_data[chunk_tx].chunk_rep == tx_idx);\n                 }\n-                // Finally update und and inc's feerate to account for the added transactions.\n-                und -= inc.transactions;\n-                inc.feerate += m_sorted_depgraph.FeeRate(inc.transactions - init_inc);\n-\n-                // If inc's feerate is better than best's, remember it as our new best.\n-                if (inc.feerate > best.feerate) {\n-                    best = inc;\n-                    // See if we can remove any entries from imp now.\n-                    while (imp.Any()) {\n-                        DepGraphIndex check = imp.Last();\n-                        if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-                        imp.Reset(check);\n+                // Verify the chunk's transaction set: it must contain the representative, and for\n+                // every active dependency, if it contains the parent or child, it must contain\n+                // both. It must have exactly N-1 active dependencies in it, guaranteeing it is\n+                // acyclic.\n+                SetType expected_chunk = SetType::Singleton(tx_idx);\n+                while (true) {",
      "path": "src/cluster_linearize.h",
      "position": 1246,
      "original_position": 1240,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2619663299,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "This instantly (~2000 fuzz iterations from empty corpus) crashes for me.",
      "created_at": "2025-12-15T15:59:53Z",
      "updated_at": "2025-12-15T16:00:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2619990736",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2619990736"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1249,
      "original_line": 1249,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620012540",
      "pull_request_review_id": 3579004664,
      "id": 2620012540,
      "node_id": "PRRC_kwDOABII586cKjf8",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {\n+                if (i ^ flip) {\n+                    // Attempt to merge the chunk upwards.\n+                    auto result_up = MergeStep<false>(chunk);\n+                    if (result_up != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_up);\n+                        break;\n+                    }\n+                } else {\n+                    // Attempt to merge the chunk downwards.\n+                    auto result_down = MergeStep<true>(chunk);\n+                    if (result_down != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_down);\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n     }\n \n-    /** Find the best (highest-feerate, smallest among those in case of a tie) ancestor set\n-     *  among the remaining transactions. Requires !AllDone().\n-     *\n-     * Complexity: O(N) where N=depgraph.TxCount();\n-     */\n-    SetInfo<SetType> FindCandidateSet() const noexcept\n+    /** Initialize the data structure for optimization. It must be topological already. */\n+    void StartOptimizing() noexcept\n     {\n-        Assume(!AllDone());\n-        std::optional<DepGraphIndex> best;\n-        for (auto i : m_todo) {\n-            if (best.has_value()) {\n-                Assume(!m_ancestor_set_feerates[i].IsEmpty());\n-                if (!(m_ancestor_set_feerates[i] > m_ancestor_set_feerates[*best])) continue;\n+        // Mark chunks suboptimal.\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.push_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n             }\n-            best = i;\n         }\n-        Assume(best.has_value());\n-        return {m_depgraph.Ancestors(*best) & m_todo, m_ancestor_set_feerates[*best]};\n     }\n-};\n \n-/** Class encapsulating the state needed to perform search for good candidate sets.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone().\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called to perform a search\n- * over the set of topologically-valid subsets of that remainder, with a limit on how many\n- * combinations are tried.\n- */\n-template<typename SetType>\n-class SearchCandidateFinder\n-{\n-    /** Internal RNG. */\n-    InsecureRandomContext m_rng;\n-    /** m_sorted_to_original[i] is the original position that sorted transaction position i had. */\n-    std::vector<DepGraphIndex> m_sorted_to_original;\n-    /** m_original_to_sorted[i] is the sorted position original transaction position i has. */\n-    std::vector<DepGraphIndex> m_original_to_sorted;\n-    /** Internal dependency graph for the cluster (with transactions in decreasing individual\n-     *  feerate order). */\n-    DepGraph<SetType> m_sorted_depgraph;\n-    /** Which transactions are left to do (indices in m_sorted_depgraph's order). */\n-    SetType m_todo;\n-\n-    /** Given a set of transactions with sorted indices, get their original indices. */\n-    SetType SortedToOriginal(const SetType& arg) const noexcept\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_sorted_to_original[pos]);\n-        return ret;\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when a split chunk merges in Improve() with one or more existing chunks that\n+            // are themselves on the suboptimal queue already.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Remember the best dependency seen so far.\n+            DepIdx candidate_dep = DepIdx(-1);\n+            uint64_t candidate_tiebreak = 0;\n+            // Iterate over all transactions.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n+                }\n+            }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;\n+        }\n+        // No improvable chunk was found, we are done.\n+        return false;\n     }\n \n-    /** Given a set of transactions with original indices, get their sorted indices. */\n-    SetType OriginalToSorted(const SetType& arg) const noexcept\n+    /** Construct a topologically-valid linearization from the current forest state. Must be\n+     *  topological. */\n+    std::vector<DepGraphIndex> GetLinearization() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_original_to_sorted[pos]);\n+        /** The output linearization. */\n+        std::vector<DepGraphIndex> ret;\n+        ret.reserve(m_transactions.Count());\n+        /** A heap with all chunks (by representative) that can currently be included, sorted by\n+         *  chunk feerate and a random tie-breaker. */\n+        std::vector<std::pair<TxIdx, uint64_t>> ready_chunks;\n+        /** Information about chunks:\n+         *  - The first value is only used for chunk representatives, and counts the number of\n+         *    unmet dependencies this chunk has on other chunks (not including dependencies within\n+         *    the chunk itself).\n+         *  - The second value is the number of unmet dependencies overall.\n+         */\n+        std::vector<std::pair<TxIdx, TxIdx>> chunk_deps(m_tx_data.size(), {0, 0});\n+        /** The set of all chunk representatives. */\n+        SetType chunk_reps;\n+        /** A list with all transactions within the current chunk that can be included. */\n+        std::vector<TxIdx> ready_tx;\n+        // Populate chunk_deps[c] with the number of {out-of-chunk dependencies, dependencies} the\n+        // child has.\n+        for (TxIdx chl_idx : m_transactions) {\n+            const auto& chl_data = m_tx_data[chl_idx];\n+            chunk_deps[chl_idx].second = chl_data.parents.Count();\n+            auto chl_chunk_rep = chl_data.chunk_rep;\n+            chunk_reps.Set(chl_chunk_rep);\n+            for (auto par_idx : chl_data.parents) {\n+                auto par_chunk_rep = m_tx_data[par_idx].chunk_rep;\n+                chunk_deps[chl_chunk_rep].first += (par_chunk_rep != chl_chunk_rep);\n+            }\n+        }\n+        // Construct a heap with all chunks that have no out-of-chunk dependencies.\n+        /** Comparison function for the heap. */\n+        auto chunk_cmp_fn = [&](const std::pair<TxIdx, uint64_t>& a, const std::pair<TxIdx, uint64_t>& b) noexcept {\n+            auto& chunk_a = m_tx_data[a.first];\n+            auto& chunk_b = m_tx_data[b.first];\n+            Assume(chunk_a.chunk_rep == a.first);\n+            Assume(chunk_b.chunk_rep == b.first);\n+            // First sort by chunk feerate.\n+            if (chunk_a.chunk_setinfo.feerate != chunk_b.chunk_setinfo.feerate) {\n+                return chunk_a.chunk_setinfo.feerate < chunk_b.chunk_setinfo.feerate;\n+            }\n+            // Tie-break randomly.\n+            if (a.second != b.second) return a.second < b.second;\n+            // Lastly, tie-break by chunk representative.\n+            return a.first < b.first;\n+        };\n+        for (TxIdx chunk_rep : chunk_reps) {\n+            if (chunk_deps[chunk_rep].first == 0) ready_chunks.emplace_back(chunk_rep, m_rng.rand64());\n+        }\n+        std::make_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+        // Pop chunks off the heap, highest-feerate ones first.\n+        while (!ready_chunks.empty()) {\n+            auto [chunk_rep, _rnd] = ready_chunks.front();\n+            std::pop_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+            ready_chunks.pop_back();\n+            Assume(m_tx_data[chunk_rep].chunk_rep == chunk_rep);\n+            Assume(chunk_deps[chunk_rep].first == 0);\n+            const auto& chunk_txn = m_tx_data[chunk_rep].chunk_setinfo.transactions;\n+            // Build heap of all includable transactions in chunk.\n+            for (TxIdx tx_idx : chunk_txn) {\n+                if (chunk_deps[tx_idx].second == 0) {\n+                    ready_tx.push_back(tx_idx);\n+                }\n+            }\n+            Assume(!ready_tx.empty());\n+            // Pick transactions from the ready queue, append them to linearization, and decrement\n+            // dependency counts.\n+            while (!ready_tx.empty()) {\n+                // Move a random queue element to the back.\n+                auto pos = m_rng.randrange(ready_tx.size());\n+                if (pos != ready_tx.size() - 1) std::swap(ready_tx.back(), ready_tx[pos]);\n+                // Pop from the back.\n+                auto tx_idx = ready_tx.back();\n+                Assume(chunk_txn[tx_idx]);\n+                ready_tx.pop_back();\n+                // Append to linearization.\n+                ret.push_back(tx_idx);\n+                // Decrement dependency counts.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                for (TxIdx chl_idx : tx_data.children) {\n+                    auto& chl_data = m_tx_data[chl_idx];\n+                    // Decrement tx dependency count.\n+                    Assume(chunk_deps[chl_idx].second > 0);\n+                    if (--chunk_deps[chl_idx].second == 0 && chunk_txn[chl_idx]) {\n+                        // Child tx has no dependencies left, and is in this chunk. Add it to the tx queue.\n+                        ready_tx.push_back(chl_idx);\n+                    }\n+                    // Decrement chunk dependency count if this is out-of-chunk dependency.\n+                    if (chl_data.chunk_rep != chunk_rep) {\n+                        Assume(chunk_deps[chl_data.chunk_rep].first > 0);\n+                        if (--chunk_deps[chl_data.chunk_rep].first == 0) {\n+                            // Child chunk has no dependencies left. Add it to the chunk heap.\n+                            ready_chunks.emplace_back(chl_data.chunk_rep, m_rng.rand64());\n+                            std::push_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        Assume(ret.size() == m_transactions.Count());\n         return ret;\n     }\n \n-public:\n-    /** Construct a candidate finder for a graph.\n+    /** Get the diagram for the current state, which must be topological. Test-only.\n      *\n-     * @param[in] depgraph   Dependency graph for the to-be-linearized cluster.\n-     * @param[in] rng_seed   A random seed to control the search order.\n+     * The linearization produced by GetLinearization() is always at least as good (in the\n+     * CompareChunks() sense) as this diagram, but may be better.\n      *\n-     * Complexity: O(N^2) where N=depgraph.Count().\n+     * After an OptimizeStep(), the diagram will always be at least as good as before. Once\n+     * OptimizeStep() returns false, the diagram will be equivalent to that produced by\n+     * GetLinearization(), and optimal.\n      */\n-    SearchCandidateFinder(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept :\n-        m_rng(rng_seed),\n-        m_sorted_to_original(depgraph.TxCount()),\n-        m_original_to_sorted(depgraph.PositionRange())\n+    std::vector<FeeFrac> GetDiagram() const noexcept\n     {\n-        // Determine reordering mapping, by sorting by decreasing feerate. Unused positions are\n-        // not included, as they will never be looked up anyway.\n-        DepGraphIndex sorted_pos{0};\n-        for (auto i : depgraph.Positions()) {\n-            m_sorted_to_original[sorted_pos++] = i;\n-        }\n-        std::sort(m_sorted_to_original.begin(), m_sorted_to_original.end(), [&](auto a, auto b) {\n-            auto feerate_cmp = depgraph.FeeRate(a) <=> depgraph.FeeRate(b);\n-            if (feerate_cmp == 0) return a < b;\n-            return feerate_cmp > 0;\n-        });\n-        // Compute reverse mapping.\n-        for (DepGraphIndex i = 0; i < m_sorted_to_original.size(); ++i) {\n-            m_original_to_sorted[m_sorted_to_original[i]] = i;\n+        std::vector<FeeFrac> ret;\n+        for (auto tx : m_transactions) {\n+            if (m_tx_data[tx].chunk_rep == tx) {\n+                ret.push_back(m_tx_data[tx].chunk_setinfo.feerate);\n+            }\n         }\n-        // Compute reordered dependency graph.\n-        m_sorted_depgraph = DepGraph(depgraph, m_original_to_sorted, m_sorted_to_original.size());\n-        m_todo = m_sorted_depgraph.Positions();\n+        std::sort(ret.begin(), ret.end(), std::greater{});\n+        return ret;\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n-    {\n-        return m_todo.None();\n-    }\n+    /** Determine how much work was performed so far. */\n+    uint64_t GetCost() const noexcept { return m_cost; }\n \n-    /** Find a high-feerate topologically-valid subset of what remains of the cluster.\n-     *  Requires !AllDone().\n-     *\n-     * @param[in] max_iterations  The maximum number of optimization steps that will be performed.\n-     * @param[in] best            A set/feerate pair with an already-known good candidate. This may\n-     *                            be empty.\n-     * @return                    A pair of:\n-     *                            - The best (highest feerate, smallest size as tiebreaker)\n-     *                              topologically valid subset (and its feerate) that was\n-     *                              encountered during search. It will be at least as good as the\n-     *                              best passed in (if not empty).\n-     *                            - The number of optimization steps that were performed. This will\n-     *                              be <= max_iterations. If strictly < max_iterations, the\n-     *                              returned subset is optimal.\n-     *\n-     * Complexity: possibly O(N * min(max_iterations, sqrt(2^N))) where N=depgraph.TxCount().\n-     */\n-    std::pair<SetInfo<SetType>, uint64_t> FindCandidateSet(uint64_t max_iterations, SetInfo<SetType> best) noexcept\n+    /** Verify internal consistency of the data structure. */\n+    void SanityCheck(const DepGraph<SetType>& depgraph) const\n     {\n-        Assume(!AllDone());\n-\n-        // Convert the provided best to internal sorted indices.\n-        best.transactions = OriginalToSorted(best.transactions);\n-\n-        /** Type for work queue items. */\n-        struct WorkItem\n-        {\n-            /** Set of transactions definitely included (and its feerate). This must be a subset\n-             *  of m_todo, and be topologically valid (includes all in-m_todo ancestors of\n-             *  itself). */\n-            SetInfo<SetType> inc;\n-            /** Set of undecided transactions. This must be a subset of m_todo, and have no overlap\n-             *  with inc. The set (inc | und) must be topologically valid. */\n-            SetType und;\n-            /** (Only when inc is not empty) The best feerate of any superset of inc that is also a\n-             *  subset of (inc | und), without requiring it to be topologically valid. It forms a\n-             *  conservative upper bound on how good a set this work item can give rise to.\n-             *  Transactions whose feerate is below best's are ignored when determining this value,\n-             *  which means it may technically be an underestimate, but if so, this work item\n-             *  cannot result in something that beats best anyway. */\n-            FeeFrac pot_feerate;\n-\n-            /** Construct a new work item. */\n-            WorkItem(SetInfo<SetType>&& i, SetType&& u, FeeFrac&& p_f) noexcept :\n-                inc(std::move(i)), und(std::move(u)), pot_feerate(std::move(p_f))\n-            {\n-                Assume(pot_feerate.IsEmpty() == inc.feerate.IsEmpty());\n+        //\n+        // Verify dependency parent/child information, and build list of (active) dependencies.\n+        //\n+        std::vector<std::pair<TxIdx, TxIdx>> expected_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> all_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> active_dependencies;\n+        for (auto parent_idx : depgraph.Positions()) {\n+            for (auto child_idx : depgraph.GetReducedChildren(parent_idx)) {\n+                expected_dependencies.emplace_back(parent_idx, child_idx);\n             }\n-\n-            /** Swap two WorkItems. */\n-            void Swap(WorkItem& other) noexcept\n-            {\n-                swap(inc, other.inc);\n-                swap(und, other.und);\n-                swap(pot_feerate, other.pot_feerate);\n+        }\n+        for (DepIdx dep_idx = 0; dep_idx < m_dep_data.size(); ++dep_idx) {\n+            const auto& dep_data = m_dep_data[dep_idx];\n+            all_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n+            // Also add to active_dependencies if it is active.\n+            if (m_dep_data[dep_idx].active) {\n+                active_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n             }\n-        };\n-\n-        /** The queue of work items. */\n-        VecDeque<WorkItem> queue;\n-        queue.reserve(std::max<size_t>(256, 2 * m_todo.Count()));\n-\n-        // Create initial entries per connected component of m_todo. While clusters themselves are\n-        // generally connected, this is not necessarily true after some parts have already been\n-        // removed from m_todo. Without this, effort can be wasted on searching \"inc\" sets that\n-        // span multiple components.\n-        auto to_cover = m_todo;\n-        do {\n-            auto component = m_sorted_depgraph.FindConnectedComponent(to_cover);\n-            to_cover -= component;\n-            // If best is not provided, set it to the first component, so that during the work\n-            // processing loop below, and during the add_fn/split_fn calls, we do not need to deal\n-            // with the best=empty case.\n-            if (best.feerate.IsEmpty()) best = SetInfo(m_sorted_depgraph, component);\n-            queue.emplace_back(/*inc=*/SetInfo<SetType>{},\n-                               /*und=*/std::move(component),\n-                               /*pot_feerate=*/FeeFrac{});\n-        } while (to_cover.Any());\n-\n-        /** Local copy of the iteration limit. */\n-        uint64_t iterations_left = max_iterations;\n-\n-        /** The set of transactions in m_todo which have feerate > best's. */\n-        SetType imp = m_todo;\n-        while (imp.Any()) {\n-            DepGraphIndex check = imp.Last();\n-            if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-            imp.Reset(check);\n+        }\n+        std::sort(expected_dependencies.begin(), expected_dependencies.end());\n+        std::sort(all_dependencies.begin(), all_dependencies.end());\n+        assert(expected_dependencies.size() == all_dependencies.size());\n+        for (size_t i = 0; i < expected_dependencies.size(); ++i) {\n+            assert(expected_dependencies[i] ==\n+                   std::make_pair(std::get<0>(all_dependencies[i]),\n+                                  std::get<1>(all_dependencies[i])));\n         }\n \n-        /** Internal function to add an item to the queue of elements to explore if there are any\n-         *  transactions left to split on, possibly improving it before doing so, and to update\n-         *  best/imp.\n-         *\n-         * - inc: the \"inc\" value for the new work item (must be topological).\n-         * - und: the \"und\" value for the new work item ((inc | und) must be topological).\n-         */\n-        auto add_fn = [&](SetInfo<SetType> inc, SetType und) noexcept {\n-            /** SetInfo object with the set whose feerate will become the new work item's\n-             *  pot_feerate. It starts off equal to inc. */\n-            auto pot = inc;\n-            if (!inc.feerate.IsEmpty()) {\n-                // Add entries to pot. We iterate over all undecided transactions whose feerate is\n-                // higher than best. While undecided transactions of lower feerate may improve pot,\n-                // the resulting pot feerate cannot possibly exceed best's (and this item will be\n-                // skipped in split_fn anyway).\n-                for (auto pos : imp & und) {\n-                    // Determine if adding transaction pos to pot (ignoring topology) would improve\n-                    // it. If not, we're done updating pot. This relies on the fact that\n-                    // m_sorted_depgraph, and thus the transactions iterated over, are in decreasing\n-                    // individual feerate order.\n-                    if (!(m_sorted_depgraph.FeeRate(pos) >> pot.feerate)) break;\n-                    pot.Set(m_sorted_depgraph, pos);\n-                }\n-\n-                // The \"jump ahead\" optimization: whenever pot has a topologically-valid subset,\n-                // that subset can be added to inc. Any subset of (pot - inc) has the property that\n-                // its feerate exceeds that of any set compatible with this work item (superset of\n-                // inc, subset of (inc | und)). Thus, if T is a topological subset of pot, and B is\n-                // the best topologically-valid set compatible with this work item, and (T - B) is\n-                // non-empty, then (T | B) is better than B and also topological. This is in\n-                // contradiction with the assumption that B is best. Thus, (T - B) must be empty,\n-                // or T must be a subset of B.\n-                //\n-                // See https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303 section 2.4.\n-                const auto init_inc = inc.transactions;\n-                for (auto pos : pot.transactions - inc.transactions) {\n-                    // If the transaction's ancestors are a subset of pot, we can add it together\n-                    // with its ancestors to inc. Just update the transactions here; the feerate\n-                    // update happens below.\n-                    auto anc_todo = m_sorted_depgraph.Ancestors(pos) & m_todo;\n-                    if (anc_todo.IsSubsetOf(pot.transactions)) inc.transactions |= anc_todo;\n+        //\n+        // Verify the chunks against the list of active dependencies\n+        //\n+        for (auto tx_idx: depgraph.Positions()) {\n+            // Only process chunks for now.\n+            if (m_tx_data[tx_idx].chunk_rep == tx_idx) {\n+                const auto& chunk_data = m_tx_data[tx_idx];\n+                // Verify that transactions in the chunk point back to it. This guarantees\n+                // that chunks are non-overlapping.\n+                for (auto chunk_tx : chunk_data.chunk_setinfo.transactions) {\n+                    assert(m_tx_data[chunk_tx].chunk_rep == tx_idx);\n                 }\n-                // Finally update und and inc's feerate to account for the added transactions.\n-                und -= inc.transactions;\n-                inc.feerate += m_sorted_depgraph.FeeRate(inc.transactions - init_inc);\n-\n-                // If inc's feerate is better than best's, remember it as our new best.\n-                if (inc.feerate > best.feerate) {\n-                    best = inc;\n-                    // See if we can remove any entries from imp now.\n-                    while (imp.Any()) {\n-                        DepGraphIndex check = imp.Last();\n-                        if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-                        imp.Reset(check);\n+                // Verify the chunk's transaction set: it must contain the representative, and for\n+                // every active dependency, if it contains the parent or child, it must contain\n+                // both. It must have exactly N-1 active dependencies in it, guaranteeing it is\n+                // acyclic.\n+                SetType expected_chunk = SetType::Singleton(tx_idx);\n+                while (true) {",
      "path": "src/cluster_linearize.h",
      "position": 1246,
      "original_position": 1240,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2619663299,
      "user": {
        "login": "brunoerg",
        "id": 19480819,
        "node_id": "MDQ6VXNlcjE5NDgwODE5",
        "avatar_url": "https://avatars.githubusercontent.com/u/19480819?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/brunoerg",
        "html_url": "https://github.com/brunoerg",
        "followers_url": "https://api.github.com/users/brunoerg/followers",
        "following_url": "https://api.github.com/users/brunoerg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/brunoerg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/brunoerg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/brunoerg/subscriptions",
        "organizations_url": "https://api.github.com/users/brunoerg/orgs",
        "repos_url": "https://api.github.com/users/brunoerg/repos",
        "events_url": "https://api.github.com/users/brunoerg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/brunoerg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Which target? ",
      "created_at": "2025-12-15T16:07:59Z",
      "updated_at": "2025-12-15T16:07:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620012540",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620012540"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1249,
      "original_line": 1249,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620013310",
      "pull_request_review_id": 3579005832,
      "id": 2620013310,
      "node_id": "PRRC_kwDOABII586cKjr-",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {",
      "path": "src/cluster_linearize.h",
      "position": 764,
      "original_position": 758,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2619568865,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "That's expected; the loop is there to try merging both upwards and downwards, but more iterations will just cause it to re-attempt the same direction again.",
      "created_at": "2025-12-15T16:08:12Z",
      "updated_at": "2025-12-15T16:08:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620013310",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620013310"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 986,
      "original_line": 986,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620018687",
      "pull_request_review_id": 3579014402,
      "id": 2620018687,
      "node_id": "PRRC_kwDOABII586cKk__",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {\n+                if (i ^ flip) {\n+                    // Attempt to merge the chunk upwards.\n+                    auto result_up = MergeStep<false>(chunk);\n+                    if (result_up != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_up);\n+                        break;\n+                    }\n+                } else {\n+                    // Attempt to merge the chunk downwards.\n+                    auto result_down = MergeStep<true>(chunk);\n+                    if (result_down != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_down);\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n     }\n \n-    /** Find the best (highest-feerate, smallest among those in case of a tie) ancestor set\n-     *  among the remaining transactions. Requires !AllDone().\n-     *\n-     * Complexity: O(N) where N=depgraph.TxCount();\n-     */\n-    SetInfo<SetType> FindCandidateSet() const noexcept\n+    /** Initialize the data structure for optimization. It must be topological already. */\n+    void StartOptimizing() noexcept\n     {\n-        Assume(!AllDone());\n-        std::optional<DepGraphIndex> best;\n-        for (auto i : m_todo) {\n-            if (best.has_value()) {\n-                Assume(!m_ancestor_set_feerates[i].IsEmpty());\n-                if (!(m_ancestor_set_feerates[i] > m_ancestor_set_feerates[*best])) continue;\n+        // Mark chunks suboptimal.\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.push_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n             }\n-            best = i;\n         }\n-        Assume(best.has_value());\n-        return {m_depgraph.Ancestors(*best) & m_todo, m_ancestor_set_feerates[*best]};\n     }\n-};\n \n-/** Class encapsulating the state needed to perform search for good candidate sets.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone().\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called to perform a search\n- * over the set of topologically-valid subsets of that remainder, with a limit on how many\n- * combinations are tried.\n- */\n-template<typename SetType>\n-class SearchCandidateFinder\n-{\n-    /** Internal RNG. */\n-    InsecureRandomContext m_rng;\n-    /** m_sorted_to_original[i] is the original position that sorted transaction position i had. */\n-    std::vector<DepGraphIndex> m_sorted_to_original;\n-    /** m_original_to_sorted[i] is the sorted position original transaction position i has. */\n-    std::vector<DepGraphIndex> m_original_to_sorted;\n-    /** Internal dependency graph for the cluster (with transactions in decreasing individual\n-     *  feerate order). */\n-    DepGraph<SetType> m_sorted_depgraph;\n-    /** Which transactions are left to do (indices in m_sorted_depgraph's order). */\n-    SetType m_todo;\n-\n-    /** Given a set of transactions with sorted indices, get their original indices. */\n-    SetType SortedToOriginal(const SetType& arg) const noexcept\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_sorted_to_original[pos]);\n-        return ret;\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when a split chunk merges in Improve() with one or more existing chunks that\n+            // are themselves on the suboptimal queue already.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Remember the best dependency seen so far.\n+            DepIdx candidate_dep = DepIdx(-1);\n+            uint64_t candidate_tiebreak = 0;\n+            // Iterate over all transactions.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n+                }\n+            }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;\n+        }\n+        // No improvable chunk was found, we are done.\n+        return false;\n     }\n \n-    /** Given a set of transactions with original indices, get their sorted indices. */\n-    SetType OriginalToSorted(const SetType& arg) const noexcept\n+    /** Construct a topologically-valid linearization from the current forest state. Must be\n+     *  topological. */\n+    std::vector<DepGraphIndex> GetLinearization() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_original_to_sorted[pos]);\n+        /** The output linearization. */\n+        std::vector<DepGraphIndex> ret;\n+        ret.reserve(m_transactions.Count());\n+        /** A heap with all chunks (by representative) that can currently be included, sorted by\n+         *  chunk feerate and a random tie-breaker. */\n+        std::vector<std::pair<TxIdx, uint64_t>> ready_chunks;\n+        /** Information about chunks:\n+         *  - The first value is only used for chunk representatives, and counts the number of\n+         *    unmet dependencies this chunk has on other chunks (not including dependencies within\n+         *    the chunk itself).\n+         *  - The second value is the number of unmet dependencies overall.\n+         */\n+        std::vector<std::pair<TxIdx, TxIdx>> chunk_deps(m_tx_data.size(), {0, 0});\n+        /** The set of all chunk representatives. */\n+        SetType chunk_reps;\n+        /** A list with all transactions within the current chunk that can be included. */\n+        std::vector<TxIdx> ready_tx;\n+        // Populate chunk_deps[c] with the number of {out-of-chunk dependencies, dependencies} the\n+        // child has.\n+        for (TxIdx chl_idx : m_transactions) {\n+            const auto& chl_data = m_tx_data[chl_idx];\n+            chunk_deps[chl_idx].second = chl_data.parents.Count();\n+            auto chl_chunk_rep = chl_data.chunk_rep;\n+            chunk_reps.Set(chl_chunk_rep);\n+            for (auto par_idx : chl_data.parents) {\n+                auto par_chunk_rep = m_tx_data[par_idx].chunk_rep;\n+                chunk_deps[chl_chunk_rep].first += (par_chunk_rep != chl_chunk_rep);\n+            }\n+        }\n+        // Construct a heap with all chunks that have no out-of-chunk dependencies.\n+        /** Comparison function for the heap. */\n+        auto chunk_cmp_fn = [&](const std::pair<TxIdx, uint64_t>& a, const std::pair<TxIdx, uint64_t>& b) noexcept {\n+            auto& chunk_a = m_tx_data[a.first];\n+            auto& chunk_b = m_tx_data[b.first];\n+            Assume(chunk_a.chunk_rep == a.first);\n+            Assume(chunk_b.chunk_rep == b.first);\n+            // First sort by chunk feerate.\n+            if (chunk_a.chunk_setinfo.feerate != chunk_b.chunk_setinfo.feerate) {\n+                return chunk_a.chunk_setinfo.feerate < chunk_b.chunk_setinfo.feerate;\n+            }\n+            // Tie-break randomly.\n+            if (a.second != b.second) return a.second < b.second;\n+            // Lastly, tie-break by chunk representative.\n+            return a.first < b.first;\n+        };\n+        for (TxIdx chunk_rep : chunk_reps) {\n+            if (chunk_deps[chunk_rep].first == 0) ready_chunks.emplace_back(chunk_rep, m_rng.rand64());\n+        }\n+        std::make_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+        // Pop chunks off the heap, highest-feerate ones first.\n+        while (!ready_chunks.empty()) {\n+            auto [chunk_rep, _rnd] = ready_chunks.front();\n+            std::pop_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+            ready_chunks.pop_back();\n+            Assume(m_tx_data[chunk_rep].chunk_rep == chunk_rep);\n+            Assume(chunk_deps[chunk_rep].first == 0);\n+            const auto& chunk_txn = m_tx_data[chunk_rep].chunk_setinfo.transactions;\n+            // Build heap of all includable transactions in chunk.\n+            for (TxIdx tx_idx : chunk_txn) {\n+                if (chunk_deps[tx_idx].second == 0) {\n+                    ready_tx.push_back(tx_idx);\n+                }\n+            }\n+            Assume(!ready_tx.empty());\n+            // Pick transactions from the ready queue, append them to linearization, and decrement\n+            // dependency counts.\n+            while (!ready_tx.empty()) {\n+                // Move a random queue element to the back.\n+                auto pos = m_rng.randrange(ready_tx.size());\n+                if (pos != ready_tx.size() - 1) std::swap(ready_tx.back(), ready_tx[pos]);\n+                // Pop from the back.\n+                auto tx_idx = ready_tx.back();\n+                Assume(chunk_txn[tx_idx]);\n+                ready_tx.pop_back();\n+                // Append to linearization.\n+                ret.push_back(tx_idx);\n+                // Decrement dependency counts.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                for (TxIdx chl_idx : tx_data.children) {\n+                    auto& chl_data = m_tx_data[chl_idx];\n+                    // Decrement tx dependency count.\n+                    Assume(chunk_deps[chl_idx].second > 0);\n+                    if (--chunk_deps[chl_idx].second == 0 && chunk_txn[chl_idx]) {\n+                        // Child tx has no dependencies left, and is in this chunk. Add it to the tx queue.\n+                        ready_tx.push_back(chl_idx);\n+                    }\n+                    // Decrement chunk dependency count if this is out-of-chunk dependency.\n+                    if (chl_data.chunk_rep != chunk_rep) {\n+                        Assume(chunk_deps[chl_data.chunk_rep].first > 0);\n+                        if (--chunk_deps[chl_data.chunk_rep].first == 0) {\n+                            // Child chunk has no dependencies left. Add it to the chunk heap.\n+                            ready_chunks.emplace_back(chl_data.chunk_rep, m_rng.rand64());\n+                            std::push_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        Assume(ret.size() == m_transactions.Count());\n         return ret;\n     }\n \n-public:\n-    /** Construct a candidate finder for a graph.\n+    /** Get the diagram for the current state, which must be topological. Test-only.\n      *\n-     * @param[in] depgraph   Dependency graph for the to-be-linearized cluster.\n-     * @param[in] rng_seed   A random seed to control the search order.\n+     * The linearization produced by GetLinearization() is always at least as good (in the\n+     * CompareChunks() sense) as this diagram, but may be better.\n      *\n-     * Complexity: O(N^2) where N=depgraph.Count().\n+     * After an OptimizeStep(), the diagram will always be at least as good as before. Once\n+     * OptimizeStep() returns false, the diagram will be equivalent to that produced by\n+     * GetLinearization(), and optimal.\n      */\n-    SearchCandidateFinder(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept :\n-        m_rng(rng_seed),\n-        m_sorted_to_original(depgraph.TxCount()),\n-        m_original_to_sorted(depgraph.PositionRange())\n+    std::vector<FeeFrac> GetDiagram() const noexcept\n     {\n-        // Determine reordering mapping, by sorting by decreasing feerate. Unused positions are\n-        // not included, as they will never be looked up anyway.\n-        DepGraphIndex sorted_pos{0};\n-        for (auto i : depgraph.Positions()) {\n-            m_sorted_to_original[sorted_pos++] = i;\n-        }\n-        std::sort(m_sorted_to_original.begin(), m_sorted_to_original.end(), [&](auto a, auto b) {\n-            auto feerate_cmp = depgraph.FeeRate(a) <=> depgraph.FeeRate(b);\n-            if (feerate_cmp == 0) return a < b;\n-            return feerate_cmp > 0;\n-        });\n-        // Compute reverse mapping.\n-        for (DepGraphIndex i = 0; i < m_sorted_to_original.size(); ++i) {\n-            m_original_to_sorted[m_sorted_to_original[i]] = i;\n+        std::vector<FeeFrac> ret;\n+        for (auto tx : m_transactions) {\n+            if (m_tx_data[tx].chunk_rep == tx) {\n+                ret.push_back(m_tx_data[tx].chunk_setinfo.feerate);\n+            }\n         }\n-        // Compute reordered dependency graph.\n-        m_sorted_depgraph = DepGraph(depgraph, m_original_to_sorted, m_sorted_to_original.size());\n-        m_todo = m_sorted_depgraph.Positions();\n+        std::sort(ret.begin(), ret.end(), std::greater{});\n+        return ret;\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n-    {\n-        return m_todo.None();\n-    }\n+    /** Determine how much work was performed so far. */\n+    uint64_t GetCost() const noexcept { return m_cost; }\n \n-    /** Find a high-feerate topologically-valid subset of what remains of the cluster.\n-     *  Requires !AllDone().\n-     *\n-     * @param[in] max_iterations  The maximum number of optimization steps that will be performed.\n-     * @param[in] best            A set/feerate pair with an already-known good candidate. This may\n-     *                            be empty.\n-     * @return                    A pair of:\n-     *                            - The best (highest feerate, smallest size as tiebreaker)\n-     *                              topologically valid subset (and its feerate) that was\n-     *                              encountered during search. It will be at least as good as the\n-     *                              best passed in (if not empty).\n-     *                            - The number of optimization steps that were performed. This will\n-     *                              be <= max_iterations. If strictly < max_iterations, the\n-     *                              returned subset is optimal.\n-     *\n-     * Complexity: possibly O(N * min(max_iterations, sqrt(2^N))) where N=depgraph.TxCount().\n-     */\n-    std::pair<SetInfo<SetType>, uint64_t> FindCandidateSet(uint64_t max_iterations, SetInfo<SetType> best) noexcept\n+    /** Verify internal consistency of the data structure. */\n+    void SanityCheck(const DepGraph<SetType>& depgraph) const\n     {\n-        Assume(!AllDone());\n-\n-        // Convert the provided best to internal sorted indices.\n-        best.transactions = OriginalToSorted(best.transactions);\n-\n-        /** Type for work queue items. */\n-        struct WorkItem\n-        {\n-            /** Set of transactions definitely included (and its feerate). This must be a subset\n-             *  of m_todo, and be topologically valid (includes all in-m_todo ancestors of\n-             *  itself). */\n-            SetInfo<SetType> inc;\n-            /** Set of undecided transactions. This must be a subset of m_todo, and have no overlap\n-             *  with inc. The set (inc | und) must be topologically valid. */\n-            SetType und;\n-            /** (Only when inc is not empty) The best feerate of any superset of inc that is also a\n-             *  subset of (inc | und), without requiring it to be topologically valid. It forms a\n-             *  conservative upper bound on how good a set this work item can give rise to.\n-             *  Transactions whose feerate is below best's are ignored when determining this value,\n-             *  which means it may technically be an underestimate, but if so, this work item\n-             *  cannot result in something that beats best anyway. */\n-            FeeFrac pot_feerate;\n-\n-            /** Construct a new work item. */\n-            WorkItem(SetInfo<SetType>&& i, SetType&& u, FeeFrac&& p_f) noexcept :\n-                inc(std::move(i)), und(std::move(u)), pot_feerate(std::move(p_f))\n-            {\n-                Assume(pot_feerate.IsEmpty() == inc.feerate.IsEmpty());\n+        //\n+        // Verify dependency parent/child information, and build list of (active) dependencies.\n+        //\n+        std::vector<std::pair<TxIdx, TxIdx>> expected_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> all_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> active_dependencies;\n+        for (auto parent_idx : depgraph.Positions()) {\n+            for (auto child_idx : depgraph.GetReducedChildren(parent_idx)) {\n+                expected_dependencies.emplace_back(parent_idx, child_idx);\n             }\n-\n-            /** Swap two WorkItems. */\n-            void Swap(WorkItem& other) noexcept\n-            {\n-                swap(inc, other.inc);\n-                swap(und, other.und);\n-                swap(pot_feerate, other.pot_feerate);\n+        }\n+        for (DepIdx dep_idx = 0; dep_idx < m_dep_data.size(); ++dep_idx) {\n+            const auto& dep_data = m_dep_data[dep_idx];\n+            all_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n+            // Also add to active_dependencies if it is active.\n+            if (m_dep_data[dep_idx].active) {\n+                active_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n             }\n-        };\n-\n-        /** The queue of work items. */\n-        VecDeque<WorkItem> queue;\n-        queue.reserve(std::max<size_t>(256, 2 * m_todo.Count()));\n-\n-        // Create initial entries per connected component of m_todo. While clusters themselves are\n-        // generally connected, this is not necessarily true after some parts have already been\n-        // removed from m_todo. Without this, effort can be wasted on searching \"inc\" sets that\n-        // span multiple components.\n-        auto to_cover = m_todo;\n-        do {\n-            auto component = m_sorted_depgraph.FindConnectedComponent(to_cover);\n-            to_cover -= component;\n-            // If best is not provided, set it to the first component, so that during the work\n-            // processing loop below, and during the add_fn/split_fn calls, we do not need to deal\n-            // with the best=empty case.\n-            if (best.feerate.IsEmpty()) best = SetInfo(m_sorted_depgraph, component);\n-            queue.emplace_back(/*inc=*/SetInfo<SetType>{},\n-                               /*und=*/std::move(component),\n-                               /*pot_feerate=*/FeeFrac{});\n-        } while (to_cover.Any());\n-\n-        /** Local copy of the iteration limit. */\n-        uint64_t iterations_left = max_iterations;\n-\n-        /** The set of transactions in m_todo which have feerate > best's. */\n-        SetType imp = m_todo;\n-        while (imp.Any()) {\n-            DepGraphIndex check = imp.Last();\n-            if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-            imp.Reset(check);\n+        }\n+        std::sort(expected_dependencies.begin(), expected_dependencies.end());\n+        std::sort(all_dependencies.begin(), all_dependencies.end());\n+        assert(expected_dependencies.size() == all_dependencies.size());\n+        for (size_t i = 0; i < expected_dependencies.size(); ++i) {\n+            assert(expected_dependencies[i] ==\n+                   std::make_pair(std::get<0>(all_dependencies[i]),\n+                                  std::get<1>(all_dependencies[i])));\n         }\n \n-        /** Internal function to add an item to the queue of elements to explore if there are any\n-         *  transactions left to split on, possibly improving it before doing so, and to update\n-         *  best/imp.\n-         *\n-         * - inc: the \"inc\" value for the new work item (must be topological).\n-         * - und: the \"und\" value for the new work item ((inc | und) must be topological).\n-         */\n-        auto add_fn = [&](SetInfo<SetType> inc, SetType und) noexcept {\n-            /** SetInfo object with the set whose feerate will become the new work item's\n-             *  pot_feerate. It starts off equal to inc. */\n-            auto pot = inc;\n-            if (!inc.feerate.IsEmpty()) {\n-                // Add entries to pot. We iterate over all undecided transactions whose feerate is\n-                // higher than best. While undecided transactions of lower feerate may improve pot,\n-                // the resulting pot feerate cannot possibly exceed best's (and this item will be\n-                // skipped in split_fn anyway).\n-                for (auto pos : imp & und) {\n-                    // Determine if adding transaction pos to pot (ignoring topology) would improve\n-                    // it. If not, we're done updating pot. This relies on the fact that\n-                    // m_sorted_depgraph, and thus the transactions iterated over, are in decreasing\n-                    // individual feerate order.\n-                    if (!(m_sorted_depgraph.FeeRate(pos) >> pot.feerate)) break;\n-                    pot.Set(m_sorted_depgraph, pos);\n-                }\n-\n-                // The \"jump ahead\" optimization: whenever pot has a topologically-valid subset,\n-                // that subset can be added to inc. Any subset of (pot - inc) has the property that\n-                // its feerate exceeds that of any set compatible with this work item (superset of\n-                // inc, subset of (inc | und)). Thus, if T is a topological subset of pot, and B is\n-                // the best topologically-valid set compatible with this work item, and (T - B) is\n-                // non-empty, then (T | B) is better than B and also topological. This is in\n-                // contradiction with the assumption that B is best. Thus, (T - B) must be empty,\n-                // or T must be a subset of B.\n-                //\n-                // See https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303 section 2.4.\n-                const auto init_inc = inc.transactions;\n-                for (auto pos : pot.transactions - inc.transactions) {\n-                    // If the transaction's ancestors are a subset of pot, we can add it together\n-                    // with its ancestors to inc. Just update the transactions here; the feerate\n-                    // update happens below.\n-                    auto anc_todo = m_sorted_depgraph.Ancestors(pos) & m_todo;\n-                    if (anc_todo.IsSubsetOf(pot.transactions)) inc.transactions |= anc_todo;\n+        //\n+        // Verify the chunks against the list of active dependencies\n+        //\n+        for (auto tx_idx: depgraph.Positions()) {\n+            // Only process chunks for now.\n+            if (m_tx_data[tx_idx].chunk_rep == tx_idx) {\n+                const auto& chunk_data = m_tx_data[tx_idx];\n+                // Verify that transactions in the chunk point back to it. This guarantees\n+                // that chunks are non-overlapping.\n+                for (auto chunk_tx : chunk_data.chunk_setinfo.transactions) {\n+                    assert(m_tx_data[chunk_tx].chunk_rep == tx_idx);\n                 }\n-                // Finally update und and inc's feerate to account for the added transactions.\n-                und -= inc.transactions;\n-                inc.feerate += m_sorted_depgraph.FeeRate(inc.transactions - init_inc);\n-\n-                // If inc's feerate is better than best's, remember it as our new best.\n-                if (inc.feerate > best.feerate) {\n-                    best = inc;\n-                    // See if we can remove any entries from imp now.\n-                    while (imp.Any()) {\n-                        DepGraphIndex check = imp.Last();\n-                        if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-                        imp.Reset(check);\n+                // Verify the chunk's transaction set: it must contain the representative, and for\n+                // every active dependency, if it contains the parent or child, it must contain\n+                // both. It must have exactly N-1 active dependencies in it, guaranteeing it is\n+                // acyclic.\n+                SetType expected_chunk = SetType::Singleton(tx_idx);\n+                while (true) {",
      "path": "src/cluster_linearize.h",
      "position": 1246,
      "original_position": 1240,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2619663299,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "`clusterlin_sfl`, which is the only one that invokes `SpanningForestState::SanityCheck`.",
      "created_at": "2025-12-15T16:10:10Z",
      "updated_at": "2025-12-15T16:10:10Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620018687",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620018687"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1249,
      "original_line": 1249,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620019751",
      "pull_request_review_id": 3579016166,
      "id": 2620019751,
      "node_id": "PRRC_kwDOABII586cKlQn",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {",
      "path": "src/cluster_linearize.h",
      "position": 764,
      "original_position": 758,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2619568865,
      "user": {
        "login": "brunoerg",
        "id": 19480819,
        "node_id": "MDQ6VXNlcjE5NDgwODE5",
        "avatar_url": "https://avatars.githubusercontent.com/u/19480819?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/brunoerg",
        "html_url": "https://github.com/brunoerg",
        "followers_url": "https://api.github.com/users/brunoerg/followers",
        "following_url": "https://api.github.com/users/brunoerg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/brunoerg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/brunoerg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/brunoerg/subscriptions",
        "organizations_url": "https://api.github.com/users/brunoerg/orgs",
        "repos_url": "https://api.github.com/users/brunoerg/repos",
        "events_url": "https://api.github.com/users/brunoerg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/brunoerg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Cool, thanks.",
      "created_at": "2025-12-15T16:10:35Z",
      "updated_at": "2025-12-15T16:10:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620019751",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620019751"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 986,
      "original_line": 986,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620025357",
      "pull_request_review_id": 3579024964,
      "id": 2620025357,
      "node_id": "PRRC_kwDOABII586cKmoN",
      "diff_hunk": "@@ -423,620 +461,874 @@ std::vector<FeeFrac> ChunkLinearization(const DepGraph<SetType>& depgraph, std::\n     return ret;\n }\n \n-/** Data structure encapsulating the chunking of a linearization, permitting removal of subsets. */\n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * Instead of performing merges arbitrarily to make the initial state topological, it is possible\n+ * to do so guided by an existing linearization. This has the advantage that the state's would-be\n+ * output linearization is immediately as good as the existing linearization it was based on:\n+ * - Start with all dependencies inactive.\n+ * - For each transaction t in the existing linearization:\n+ *   - Find the chunk C that transaction is in (which will be singleton).\n+ *   - Do an upwards merge of C, if possible. If so, repeat the same with the merged result.\n+ * No downwards merges are needed in this case.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, a uniformly random one among them is picked.\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), a uniformly random dependency between the\n+ *     two chunks is activated.\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - A round-robin queue of chunks to improve is maintained. The initial ordering of this queue\n+ *     is uniformly randomly permuted.\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, a uniformly random dependency\n+ *     is deactivated.\n+ *\n+ * - How to decide the exact output linearization:\n+ *   - When there are multiple equal-feerate chunks with no dependencies between them, output a\n+ *     uniformly random one among the ones with no missing dependent chunks first.\n+ *   - Within chunks, repeatedly pick a uniformly random transaction among those with no missing\n+ *     dependencies.\n+ */\n template<typename SetType>\n-class LinearizationChunking\n+class SpanningForestState\n {\n-    /** The depgraph this linearization is for. */\n-    const DepGraph<SetType>& m_depgraph;\n-\n-    /** The linearization we started from, possibly with removed prefix stripped. */\n-    std::span<const DepGraphIndex> m_linearization;\n-\n-    /** Chunk sets and their feerates, of what remains of the linearization. */\n-    std::vector<SetInfo<SetType>> m_chunks;\n+private:\n+    /** Internal RNG. */\n+    InsecureRandomContext m_rng;\n \n-    /** How large a prefix of m_chunks corresponds to removed transactions. */\n-    DepGraphIndex m_chunks_skip{0};\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n \n-    /** Which transactions remain in the linearization. */\n-    SetType m_todo;\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n \n-    /** Fill the m_chunks variable, and remove the done prefix of m_linearization. */\n-    void BuildChunks() noexcept\n+    /** The set of all TxIdx's of transactions in the cluster indexing into m_tx_data. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Keeps the \"holes\" from DepGraph during\n+     *  construction. Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+    /** A FIFO of chunk representatives of chunks that may be improved still. */\n+    VecDeque<TxIdx> m_suboptimal_chunks;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk:\n+     *  - All transactions have their chunk representative set to `chunk_rep`.\n+     *  - All dependencies which have `query` in their top_setinfo get `dep_change` added to it\n+     *    (if `!Subtract`) or removed from it (if `Subtract`).\n+     */\n+    template<bool Subtract>\n+    void UpdateChunk(const SetType& chunk, TxIdx query, TxIdx chunk_rep, const SetInfo<SetType>& dep_change) noexcept\n     {\n-        // Caller must clear m_chunks.\n-        Assume(m_chunks.empty());\n-\n-        // Chop off the initial part of m_linearization that is already done.\n-        while (!m_linearization.empty() && !m_todo[m_linearization.front()]) {\n-            m_linearization = m_linearization.subspan(1);\n-        }\n-\n-        // Iterate over the remaining entries in m_linearization. This is effectively the same\n-        // algorithm as ChunkLinearization, but supports skipping parts of the linearization and\n-        // keeps track of the sets themselves instead of just their feerates.\n-        for (auto idx : m_linearization) {\n-            if (!m_todo[idx]) continue;\n-            // Start with an initial chunk containing just element idx.\n-            SetInfo add(m_depgraph, idx);\n-            // Absorb existing final chunks into add while they have lower feerate.\n-            while (!m_chunks.empty() && add.feerate >> m_chunks.back().feerate) {\n-                add |= m_chunks.back();\n-                m_chunks.pop_back();\n+        // Iterate over all the chunk's transactions.\n+        for (auto tx_idx : chunk) {\n+            auto& tx_data = m_tx_data[tx_idx];\n+            // Update the chunk representative.\n+            tx_data.chunk_rep = chunk_rep;\n+            // Iterate over all active dependencies with tx_idx as parent. Combined with the outer\n+            // loop this iterates over all internal active dependencies of the chunk.\n+            auto child_deps = std::span{tx_data.child_deps};\n+            for (auto dep_idx : child_deps) {\n+                auto& dep_entry = m_dep_data[dep_idx];\n+                Assume(dep_entry.parent == tx_idx);\n+                // Skip inactive dependencies.\n+                if (!dep_entry.active) continue;\n+                // If this dependency's top_setinfo contains query, update it to add/remove\n+                // dep_change.\n+                if (dep_entry.top_setinfo.transactions[query]) {\n+                    if constexpr (Subtract) {\n+                        dep_entry.top_setinfo -= dep_change;\n+                    } else {\n+                        dep_entry.top_setinfo |= dep_change;\n+                    }\n+                }\n             }\n-            // Remember new chunk.\n-            m_chunks.push_back(std::move(add));\n         }\n     }\n \n-public:\n-    /** Initialize a LinearizationSubset object for a given length of linearization. */\n-    explicit LinearizationChunking(const DepGraph<SetType>& depgraph LIFETIMEBOUND, std::span<const DepGraphIndex> lin LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph), m_linearization(lin)\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n     {\n-        // Mark everything in lin as todo still.\n-        for (auto i : m_linearization) m_todo.Set(i);\n-        // Compute the initial chunking.\n-        m_chunks.reserve(depgraph.TxCount());\n-        BuildChunks();\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+\n+        // Consider the following example:\n+        //\n+        //    A           A     There are two chunks, ABC and DEF, and the inactive E->C dependency\n+        //   / \\         / \\    is activated, resulting in a single chunk ABCDEF.\n+        //  B   C       B   C\n+        //      :  ==>      |   Dependency | top set before | top set after | change\n+        //  D   E       D   E   B->A       | AC             | ACDEF         | +DEF\n+        //   \\ /         \\ /    C->A       | AB             | AB            |\n+        //    F           F     F->D       | D              | D             |\n+        //                      F->E       | E              | ABCE          | +ABC\n+        //\n+        // The common pattern here is that any dependency which has the parent or child of the\n+        // dependency being activated (E->C here) in its top set, will have the opposite part added\n+        // to it. This is true for B->A and F->E, but not for C->A and F->D.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part (ABC in example), and add\n+        // bottom_part (DEF) to every dependency's top_set which has the parent (C) in it. The\n+        // representative of each of these transactions was already top_rep, so that is not being\n+        // changed here.\n+        UpdateChunk<false>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part (DEF in example), and add\n+        // top_part (ABC) to every dependency's top_set which has the child (E) in it. At the same\n+        // time, change the representative of each of these transactions to be top_rep, which\n+        // becomes the representative for the merged chunk.\n+        UpdateChunk<false>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                           /*chunk_rep=*/top_rep, /*dep_change=*/top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n     }\n \n-    /** Determine how many chunks remain in the linearization. */\n-    DepGraphIndex NumChunksLeft() const noexcept { return m_chunks.size() - m_chunks_skip; }\n-\n-    /** Access a chunk. Chunk 0 is the highest-feerate prefix of what remains. */\n-    const SetInfo<SetType>& GetChunk(DepGraphIndex n) const noexcept\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n     {\n-        Assume(n + m_chunks_skip < m_chunks.size());\n-        return m_chunks[n + m_chunks_skip];\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+\n+        // See the comment above in Activate(). We perform the opposite operations here,\n+        // removing instead of adding.\n+        //\n+        // Let UpdateChunk traverse the old parent chunk top_part, and remove bottom_part from\n+        // every dependency's top_set which has the parent in it. At the same time, change the\n+        // representative of each of these transactions to be top_rep.\n+        UpdateChunk<true>(/*chunk=*/top_part.transactions, /*query=*/dep_data.parent,\n+                          /*chunk_rep=*/top_rep, /*dep_change=*/bottom_part);\n+        // Let UpdateChunk traverse the old child chunk bottom_part, and remove top_part from every\n+        // dependency's top_set which has the child in it. At the same time, change the\n+        // representative of each of these transactions to be bottom_rep.\n+        UpdateChunk<true>(/*chunk=*/bottom_part.transactions, /*query=*/dep_data.child,\n+                          /*chunk_rep=*/bottom_rep, /*dep_change=*/top_part);\n     }\n \n-    /** Remove some subset of transactions from the linearization. */\n-    void MarkDone(SetType subset) noexcept\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n     {\n-        Assume(subset.Any());\n-        Assume(subset.IsSubsetOf(m_todo));\n-        m_todo -= subset;\n-        if (GetChunk(0).transactions == subset) {\n-            // If the newly done transactions exactly match the first chunk of the remainder of\n-            // the linearization, we do not need to rechunk; just remember to skip one\n-            // additional chunk.\n-            ++m_chunks_skip;\n-            // With subset marked done, some prefix of m_linearization will be done now. How long\n-            // that prefix is depends on how many done elements were interspersed with subset,\n-            // but at least as many transactions as there are in subset.\n-            m_linearization = m_linearization.subspan(subset.Count());\n-        } else {\n-            // Otherwise rechunk what remains of m_linearization.\n-            m_chunks.clear();\n-            m_chunks_skip = 0;\n-            BuildChunks();\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Count the number of dependencies between bottom_chunk and top_chunk.\n+        TxIdx num_deps{0};\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            num_deps += (tx_data.children & bottom_chunk.chunk_setinfo.transactions).Count();\n         }\n+        Assume(num_deps > 0);\n+        // Uniformly randomly pick one of them and activate it.\n+        TxIdx pick = m_rng.randrange(num_deps);\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            auto intersect = tx_data.children & bottom_chunk.chunk_setinfo.transactions;\n+            auto count = intersect.Count();\n+            if (pick < count) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        if (pick == 0) return Activate(dep);\n+                        --pick;\n+                    }\n+                }\n+                break;\n+            }\n+            pick -= count;\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n     }\n \n-    /** Find the shortest intersection between subset and the prefixes of remaining chunks\n-     *  of the linearization that has a feerate not below subset's.\n-     *\n-     * This is a crucial operation in guaranteeing improvements to linearizations. If subset has\n-     * a feerate not below GetChunk(0)'s, then moving IntersectPrefixes(subset) to the front of\n-     * (what remains of) the linearization is guaranteed not to make it worse at any point.\n-     *\n-     * See https://delvingbitcoin.org/t/introduction-to-cluster-linearization/1032 for background.\n-     */\n-    SetInfo<SetType> IntersectPrefixes(const SetInfo<SetType>& subset) const noexcept\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n     {\n-        Assume(subset.transactions.IsSubsetOf(m_todo));\n-        SetInfo<SetType> accumulator;\n-        // Iterate over all chunks of the remaining linearization.\n-        for (DepGraphIndex i = 0; i < NumChunksLeft(); ++i) {\n-            // Find what (if any) intersection the chunk has with subset.\n-            const SetType to_add = GetChunk(i).transactions & subset.transactions;\n-            if (to_add.Any()) {\n-                // If adding that to accumulator makes us hit all of subset, we are done as no\n-                // shorter intersection with higher/equal feerate exists.\n-                accumulator.transactions |= to_add;\n-                if (accumulator.transactions == subset.transactions) break;\n-                // Otherwise update the accumulator feerate.\n-                accumulator.feerate += m_depgraph.FeeRate(to_add);\n-                // If that does result in something better, or something with the same feerate but\n-                // smaller, return that. Even if a longer, higher-feerate intersection exists, it\n-                // does not hurt to return the shorter one (the remainder of the longer intersection\n-                // will generally be found in the next call to Intersect, but even if not, it is not\n-                // required for the improvement guarantee this function makes).\n-                if (!(accumulator.feerate << subset.feerate)) return accumulator;\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick a random one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        /** We generate random tiebreak values to pick between equal-feerate candidate chunks.\n+         *  This variable stores the tiebreak of the current best candidate. */\n+        uint64_t best_other_chunk_tiebreak{0};\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp > 0) continue;\n+                uint64_t tiebreak = m_rng.rand64();\n+                if (cmp < 0 || tiebreak >= best_other_chunk_tiebreak) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                    best_other_chunk_tiebreak = tiebreak;\n+                }\n             }\n         }\n-        return subset;\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n     }\n-};\n \n-/** Class encapsulating the state needed to find the best remaining ancestor set.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone.\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called which will return a\n- * SetInfo with the highest-feerate ancestor set that remains (an ancestor set is a single\n- * transaction together with all its remaining ancestors).\n- */\n-template<typename SetType>\n-class AncestorCandidateFinder\n-{\n-    /** Internal dependency graph. */\n-    const DepGraph<SetType>& m_depgraph;\n-    /** Which transaction are left to include. */\n-    SetType m_todo;\n-    /** Precomputed ancestor-set feerates (only kept up-to-date for indices in m_todo). */\n-    std::vector<FeeFrac> m_ancestor_set_feerates;\n \n-public:\n-    /** Construct an AncestorCandidateFinder for a given cluster.\n-     *\n-     * Complexity: O(N^2) where N=depgraph.TxCount().\n-     */\n-    AncestorCandidateFinder(const DepGraph<SetType>& depgraph LIFETIMEBOUND) noexcept :\n-        m_depgraph(depgraph),\n-        m_todo{depgraph.Positions()},\n-        m_ancestor_set_feerates(depgraph.PositionRange())\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n     {\n-        // Precompute ancestor-set feerates.\n-        for (DepGraphIndex i : m_depgraph.Positions()) {\n-            /** The remaining ancestors for transaction i. */\n-            SetType anc_to_add = m_depgraph.Ancestors(i);\n-            FeeFrac anc_feerate;\n-            // Reuse accumulated feerate from first ancestor, if usable.\n-            Assume(anc_to_add.Any());\n-            DepGraphIndex first = anc_to_add.First();\n-            if (first < i) {\n-                anc_feerate = m_ancestor_set_feerates[first];\n-                Assume(!anc_feerate.IsEmpty());\n-                anc_to_add -= m_depgraph.Ancestors(first);\n-            }\n-            // Add in other ancestors (which necessarily include i itself).\n-            Assume(anc_to_add[i]);\n-            anc_feerate += m_depgraph.FeeRate(anc_to_add);\n-            // Store the result.\n-            m_ancestor_set_feerates[i] = anc_feerate;\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n         }\n+        // Add the chunk to the queue of improvable chunks.\n+        m_suboptimal_chunks.push_back(chunk_rep);\n     }\n \n-    /** Remove a set of transactions from the set of to-be-linearized ones.\n-     *\n-     * The same transaction may not be MarkDone()'d twice.\n-     *\n-     * Complexity: O(N*M) where N=depgraph.TxCount(), M=select.Count().\n-     */\n-    void MarkDone(SetType select) noexcept\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+\n+        // At this point we have exactly two chunks which may violate topology constraints (the\n+        // parent chunk and child chunk that were produced by deactivating dep_idx). We can fix\n+        // these using just merge sequences, one upwards and one downwards, avoiding the need for a\n+        // full MakeTopological.\n+\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept : m_rng(rng_seed)\n     {\n-        Assume(select.Any());\n-        Assume(select.IsSubsetOf(m_todo));\n-        m_todo -= select;\n-        for (auto i : select) {\n-            auto feerate = m_depgraph.FeeRate(i);\n-            for (auto j : m_depgraph.Descendants(i) & m_todo) {\n-                m_ancestor_set_feerates[j] -= feerate;\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        // Reserve the maximum number of dependencies the cluster can have, so m_dep_data won't\n+        // need any reallocations.\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));\n+        for (auto tx : m_transactions) {\n+            // Fill in transaction data.\n+            auto& tx_data = m_tx_data[tx];\n+            tx_data.chunk_rep = tx;\n+            tx_data.chunk_setinfo.transactions = SetType::Singleton(tx);\n+            tx_data.chunk_setinfo.feerate = depgraph.FeeRate(tx);\n+            // Add its dependencies.\n+            SetType parents = depgraph.GetReducedParents(tx);\n+            for (auto par : parents) {\n+                auto& par_tx_data = m_tx_data[par];\n+                auto dep_idx = m_dep_data.size();\n+                // Construct new dependency.\n+                auto& dep = m_dep_data.emplace_back();\n+                dep.active = false;\n+                dep.parent = par;\n+                dep.child = tx;\n+                // Add it as parent of the child.\n+                tx_data.parents.Set(par);\n+                // Add it as child of the parent.\n+                par_tx_data.child_deps.push_back(dep_idx);\n+                par_tx_data.children.Set(tx);\n             }\n         }\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n     {\n-        return m_todo.None();\n+        // Add transactions one by one, in order of existing linearization.\n+        for (DepGraphIndex tx : old_linearization) {\n+            auto chunk_rep = m_tx_data[tx].chunk_rep;\n+            while (true) {\n+                chunk_rep = MergeStep<false>(chunk_rep);\n+                if (chunk_rep == TxIdx(-1)) break;\n+            }\n+        }\n     }\n \n-    /** Count the number of remaining unlinearized transactions. */\n-    DepGraphIndex NumRemaining() const noexcept\n+    /** Make state topological. Can be called after constructing, or after LoadLinearization. */\n+    void MakeTopological() noexcept\n     {\n-        return m_todo.Count();\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.emplace_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n+            }\n+        }\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when it was merged with something else since being added.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            int flip = m_rng.randbool();\n+            for (int i = 0; i < 2; ++i) {\n+                if (i ^ flip) {\n+                    // Attempt to merge the chunk upwards.\n+                    auto result_up = MergeStep<false>(chunk);\n+                    if (result_up != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_up);\n+                        break;\n+                    }\n+                } else {\n+                    // Attempt to merge the chunk downwards.\n+                    auto result_down = MergeStep<true>(chunk);\n+                    if (result_down != TxIdx(-1)) {\n+                        m_suboptimal_chunks.push_back(result_down);\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n     }\n \n-    /** Find the best (highest-feerate, smallest among those in case of a tie) ancestor set\n-     *  among the remaining transactions. Requires !AllDone().\n-     *\n-     * Complexity: O(N) where N=depgraph.TxCount();\n-     */\n-    SetInfo<SetType> FindCandidateSet() const noexcept\n+    /** Initialize the data structure for optimization. It must be topological already. */\n+    void StartOptimizing() noexcept\n     {\n-        Assume(!AllDone());\n-        std::optional<DepGraphIndex> best;\n-        for (auto i : m_todo) {\n-            if (best.has_value()) {\n-                Assume(!m_ancestor_set_feerates[i].IsEmpty());\n-                if (!(m_ancestor_set_feerates[i] > m_ancestor_set_feerates[*best])) continue;\n+        // Mark chunks suboptimal.\n+        for (auto tx : m_transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.chunk_rep == tx) {\n+                m_suboptimal_chunks.push_back(tx);\n+                // Randomize the initial order of suboptimal chunks in the queue.\n+                TxIdx j = m_rng.randrange<TxIdx>(m_suboptimal_chunks.size());\n+                if (j != m_suboptimal_chunks.size() - 1) {\n+                    std::swap(m_suboptimal_chunks.back(), m_suboptimal_chunks[j]);\n+                }\n             }\n-            best = i;\n         }\n-        Assume(best.has_value());\n-        return {m_depgraph.Ancestors(*best) & m_todo, m_ancestor_set_feerates[*best]};\n     }\n-};\n \n-/** Class encapsulating the state needed to perform search for good candidate sets.\n- *\n- * It is initialized for an entire DepGraph, and parts of the graph can be dropped by calling\n- * MarkDone().\n- *\n- * As long as any part of the graph remains, FindCandidateSet() can be called to perform a search\n- * over the set of topologically-valid subsets of that remainder, with a limit on how many\n- * combinations are tried.\n- */\n-template<typename SetType>\n-class SearchCandidateFinder\n-{\n-    /** Internal RNG. */\n-    InsecureRandomContext m_rng;\n-    /** m_sorted_to_original[i] is the original position that sorted transaction position i had. */\n-    std::vector<DepGraphIndex> m_sorted_to_original;\n-    /** m_original_to_sorted[i] is the sorted position original transaction position i has. */\n-    std::vector<DepGraphIndex> m_original_to_sorted;\n-    /** Internal dependency graph for the cluster (with transactions in decreasing individual\n-     *  feerate order). */\n-    DepGraph<SetType> m_sorted_depgraph;\n-    /** Which transactions are left to do (indices in m_sorted_depgraph's order). */\n-    SetType m_todo;\n-\n-    /** Given a set of transactions with sorted indices, get their original indices. */\n-    SetType SortedToOriginal(const SetType& arg) const noexcept\n+    /** Try to improve the forest. Returns false if it is optimal, true otherwise. */\n+    bool OptimizeStep() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_sorted_to_original[pos]);\n-        return ret;\n+        while (!m_suboptimal_chunks.empty()) {\n+            // Pop an entry from the potentially-suboptimal chunk queue.\n+            TxIdx chunk = m_suboptimal_chunks.front();\n+            m_suboptimal_chunks.pop_front();\n+            auto& chunk_data = m_tx_data[chunk];\n+            // If what was popped is not currently a chunk representative, continue. This may\n+            // happen when a split chunk merges in Improve() with one or more existing chunks that\n+            // are themselves on the suboptimal queue already.\n+            if (chunk_data.chunk_rep != chunk) continue;\n+            // Remember the best dependency seen so far.\n+            DepIdx candidate_dep = DepIdx(-1);\n+            uint64_t candidate_tiebreak = 0;\n+            // Iterate over all transactions.\n+            for (auto tx : chunk_data.chunk_setinfo.transactions) {\n+                const auto& tx_data = m_tx_data[tx];\n+                // Iterate over all active child dependencies of the transaction.\n+                const auto children = std::span{tx_data.child_deps};\n+                for (DepIdx dep_idx : children) {\n+                    const auto& dep_data = m_dep_data[dep_idx];\n+                    if (!dep_data.active) continue;\n+                    // Skip if this dependency is ineligible (the top chunk that would be created\n+                    // does not have higher feerate than the chunk it is currently part of).\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n+                }\n+            }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;\n+        }\n+        // No improvable chunk was found, we are done.\n+        return false;\n     }\n \n-    /** Given a set of transactions with original indices, get their sorted indices. */\n-    SetType OriginalToSorted(const SetType& arg) const noexcept\n+    /** Construct a topologically-valid linearization from the current forest state. Must be\n+     *  topological. */\n+    std::vector<DepGraphIndex> GetLinearization() noexcept\n     {\n-        SetType ret;\n-        for (auto pos : arg) ret.Set(m_original_to_sorted[pos]);\n+        /** The output linearization. */\n+        std::vector<DepGraphIndex> ret;\n+        ret.reserve(m_transactions.Count());\n+        /** A heap with all chunks (by representative) that can currently be included, sorted by\n+         *  chunk feerate and a random tie-breaker. */\n+        std::vector<std::pair<TxIdx, uint64_t>> ready_chunks;\n+        /** Information about chunks:\n+         *  - The first value is only used for chunk representatives, and counts the number of\n+         *    unmet dependencies this chunk has on other chunks (not including dependencies within\n+         *    the chunk itself).\n+         *  - The second value is the number of unmet dependencies overall.\n+         */\n+        std::vector<std::pair<TxIdx, TxIdx>> chunk_deps(m_tx_data.size(), {0, 0});\n+        /** The set of all chunk representatives. */\n+        SetType chunk_reps;\n+        /** A list with all transactions within the current chunk that can be included. */\n+        std::vector<TxIdx> ready_tx;\n+        // Populate chunk_deps[c] with the number of {out-of-chunk dependencies, dependencies} the\n+        // child has.\n+        for (TxIdx chl_idx : m_transactions) {\n+            const auto& chl_data = m_tx_data[chl_idx];\n+            chunk_deps[chl_idx].second = chl_data.parents.Count();\n+            auto chl_chunk_rep = chl_data.chunk_rep;\n+            chunk_reps.Set(chl_chunk_rep);\n+            for (auto par_idx : chl_data.parents) {\n+                auto par_chunk_rep = m_tx_data[par_idx].chunk_rep;\n+                chunk_deps[chl_chunk_rep].first += (par_chunk_rep != chl_chunk_rep);\n+            }\n+        }\n+        // Construct a heap with all chunks that have no out-of-chunk dependencies.\n+        /** Comparison function for the heap. */\n+        auto chunk_cmp_fn = [&](const std::pair<TxIdx, uint64_t>& a, const std::pair<TxIdx, uint64_t>& b) noexcept {\n+            auto& chunk_a = m_tx_data[a.first];\n+            auto& chunk_b = m_tx_data[b.first];\n+            Assume(chunk_a.chunk_rep == a.first);\n+            Assume(chunk_b.chunk_rep == b.first);\n+            // First sort by chunk feerate.\n+            if (chunk_a.chunk_setinfo.feerate != chunk_b.chunk_setinfo.feerate) {\n+                return chunk_a.chunk_setinfo.feerate < chunk_b.chunk_setinfo.feerate;\n+            }\n+            // Tie-break randomly.\n+            if (a.second != b.second) return a.second < b.second;\n+            // Lastly, tie-break by chunk representative.\n+            return a.first < b.first;\n+        };\n+        for (TxIdx chunk_rep : chunk_reps) {\n+            if (chunk_deps[chunk_rep].first == 0) ready_chunks.emplace_back(chunk_rep, m_rng.rand64());\n+        }\n+        std::make_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+        // Pop chunks off the heap, highest-feerate ones first.\n+        while (!ready_chunks.empty()) {\n+            auto [chunk_rep, _rnd] = ready_chunks.front();\n+            std::pop_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+            ready_chunks.pop_back();\n+            Assume(m_tx_data[chunk_rep].chunk_rep == chunk_rep);\n+            Assume(chunk_deps[chunk_rep].first == 0);\n+            const auto& chunk_txn = m_tx_data[chunk_rep].chunk_setinfo.transactions;\n+            // Build heap of all includable transactions in chunk.\n+            for (TxIdx tx_idx : chunk_txn) {\n+                if (chunk_deps[tx_idx].second == 0) {\n+                    ready_tx.push_back(tx_idx);\n+                }\n+            }\n+            Assume(!ready_tx.empty());\n+            // Pick transactions from the ready queue, append them to linearization, and decrement\n+            // dependency counts.\n+            while (!ready_tx.empty()) {\n+                // Move a random queue element to the back.\n+                auto pos = m_rng.randrange(ready_tx.size());\n+                if (pos != ready_tx.size() - 1) std::swap(ready_tx.back(), ready_tx[pos]);\n+                // Pop from the back.\n+                auto tx_idx = ready_tx.back();\n+                Assume(chunk_txn[tx_idx]);\n+                ready_tx.pop_back();\n+                // Append to linearization.\n+                ret.push_back(tx_idx);\n+                // Decrement dependency counts.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                for (TxIdx chl_idx : tx_data.children) {\n+                    auto& chl_data = m_tx_data[chl_idx];\n+                    // Decrement tx dependency count.\n+                    Assume(chunk_deps[chl_idx].second > 0);\n+                    if (--chunk_deps[chl_idx].second == 0 && chunk_txn[chl_idx]) {\n+                        // Child tx has no dependencies left, and is in this chunk. Add it to the tx queue.\n+                        ready_tx.push_back(chl_idx);\n+                    }\n+                    // Decrement chunk dependency count if this is out-of-chunk dependency.\n+                    if (chl_data.chunk_rep != chunk_rep) {\n+                        Assume(chunk_deps[chl_data.chunk_rep].first > 0);\n+                        if (--chunk_deps[chl_data.chunk_rep].first == 0) {\n+                            // Child chunk has no dependencies left. Add it to the chunk heap.\n+                            ready_chunks.emplace_back(chl_data.chunk_rep, m_rng.rand64());\n+                            std::push_heap(ready_chunks.begin(), ready_chunks.end(), chunk_cmp_fn);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        Assume(ret.size() == m_transactions.Count());\n         return ret;\n     }\n \n-public:\n-    /** Construct a candidate finder for a graph.\n+    /** Get the diagram for the current state, which must be topological. Test-only.\n      *\n-     * @param[in] depgraph   Dependency graph for the to-be-linearized cluster.\n-     * @param[in] rng_seed   A random seed to control the search order.\n+     * The linearization produced by GetLinearization() is always at least as good (in the\n+     * CompareChunks() sense) as this diagram, but may be better.\n      *\n-     * Complexity: O(N^2) where N=depgraph.Count().\n+     * After an OptimizeStep(), the diagram will always be at least as good as before. Once\n+     * OptimizeStep() returns false, the diagram will be equivalent to that produced by\n+     * GetLinearization(), and optimal.\n      */\n-    SearchCandidateFinder(const DepGraph<SetType>& depgraph, uint64_t rng_seed) noexcept :\n-        m_rng(rng_seed),\n-        m_sorted_to_original(depgraph.TxCount()),\n-        m_original_to_sorted(depgraph.PositionRange())\n+    std::vector<FeeFrac> GetDiagram() const noexcept\n     {\n-        // Determine reordering mapping, by sorting by decreasing feerate. Unused positions are\n-        // not included, as they will never be looked up anyway.\n-        DepGraphIndex sorted_pos{0};\n-        for (auto i : depgraph.Positions()) {\n-            m_sorted_to_original[sorted_pos++] = i;\n-        }\n-        std::sort(m_sorted_to_original.begin(), m_sorted_to_original.end(), [&](auto a, auto b) {\n-            auto feerate_cmp = depgraph.FeeRate(a) <=> depgraph.FeeRate(b);\n-            if (feerate_cmp == 0) return a < b;\n-            return feerate_cmp > 0;\n-        });\n-        // Compute reverse mapping.\n-        for (DepGraphIndex i = 0; i < m_sorted_to_original.size(); ++i) {\n-            m_original_to_sorted[m_sorted_to_original[i]] = i;\n+        std::vector<FeeFrac> ret;\n+        for (auto tx : m_transactions) {\n+            if (m_tx_data[tx].chunk_rep == tx) {\n+                ret.push_back(m_tx_data[tx].chunk_setinfo.feerate);\n+            }\n         }\n-        // Compute reordered dependency graph.\n-        m_sorted_depgraph = DepGraph(depgraph, m_original_to_sorted, m_sorted_to_original.size());\n-        m_todo = m_sorted_depgraph.Positions();\n+        std::sort(ret.begin(), ret.end(), std::greater{});\n+        return ret;\n     }\n \n-    /** Check whether any unlinearized transactions remain. */\n-    bool AllDone() const noexcept\n-    {\n-        return m_todo.None();\n-    }\n+    /** Determine how much work was performed so far. */\n+    uint64_t GetCost() const noexcept { return m_cost; }\n \n-    /** Find a high-feerate topologically-valid subset of what remains of the cluster.\n-     *  Requires !AllDone().\n-     *\n-     * @param[in] max_iterations  The maximum number of optimization steps that will be performed.\n-     * @param[in] best            A set/feerate pair with an already-known good candidate. This may\n-     *                            be empty.\n-     * @return                    A pair of:\n-     *                            - The best (highest feerate, smallest size as tiebreaker)\n-     *                              topologically valid subset (and its feerate) that was\n-     *                              encountered during search. It will be at least as good as the\n-     *                              best passed in (if not empty).\n-     *                            - The number of optimization steps that were performed. This will\n-     *                              be <= max_iterations. If strictly < max_iterations, the\n-     *                              returned subset is optimal.\n-     *\n-     * Complexity: possibly O(N * min(max_iterations, sqrt(2^N))) where N=depgraph.TxCount().\n-     */\n-    std::pair<SetInfo<SetType>, uint64_t> FindCandidateSet(uint64_t max_iterations, SetInfo<SetType> best) noexcept\n+    /** Verify internal consistency of the data structure. */\n+    void SanityCheck(const DepGraph<SetType>& depgraph) const\n     {\n-        Assume(!AllDone());\n-\n-        // Convert the provided best to internal sorted indices.\n-        best.transactions = OriginalToSorted(best.transactions);\n-\n-        /** Type for work queue items. */\n-        struct WorkItem\n-        {\n-            /** Set of transactions definitely included (and its feerate). This must be a subset\n-             *  of m_todo, and be topologically valid (includes all in-m_todo ancestors of\n-             *  itself). */\n-            SetInfo<SetType> inc;\n-            /** Set of undecided transactions. This must be a subset of m_todo, and have no overlap\n-             *  with inc. The set (inc | und) must be topologically valid. */\n-            SetType und;\n-            /** (Only when inc is not empty) The best feerate of any superset of inc that is also a\n-             *  subset of (inc | und), without requiring it to be topologically valid. It forms a\n-             *  conservative upper bound on how good a set this work item can give rise to.\n-             *  Transactions whose feerate is below best's are ignored when determining this value,\n-             *  which means it may technically be an underestimate, but if so, this work item\n-             *  cannot result in something that beats best anyway. */\n-            FeeFrac pot_feerate;\n-\n-            /** Construct a new work item. */\n-            WorkItem(SetInfo<SetType>&& i, SetType&& u, FeeFrac&& p_f) noexcept :\n-                inc(std::move(i)), und(std::move(u)), pot_feerate(std::move(p_f))\n-            {\n-                Assume(pot_feerate.IsEmpty() == inc.feerate.IsEmpty());\n+        //\n+        // Verify dependency parent/child information, and build list of (active) dependencies.\n+        //\n+        std::vector<std::pair<TxIdx, TxIdx>> expected_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> all_dependencies;\n+        std::vector<std::tuple<TxIdx, TxIdx, DepIdx>> active_dependencies;\n+        for (auto parent_idx : depgraph.Positions()) {\n+            for (auto child_idx : depgraph.GetReducedChildren(parent_idx)) {\n+                expected_dependencies.emplace_back(parent_idx, child_idx);\n             }\n-\n-            /** Swap two WorkItems. */\n-            void Swap(WorkItem& other) noexcept\n-            {\n-                swap(inc, other.inc);\n-                swap(und, other.und);\n-                swap(pot_feerate, other.pot_feerate);\n+        }\n+        for (DepIdx dep_idx = 0; dep_idx < m_dep_data.size(); ++dep_idx) {\n+            const auto& dep_data = m_dep_data[dep_idx];\n+            all_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n+            // Also add to active_dependencies if it is active.\n+            if (m_dep_data[dep_idx].active) {\n+                active_dependencies.emplace_back(dep_data.parent, dep_data.child, dep_idx);\n             }\n-        };\n-\n-        /** The queue of work items. */\n-        VecDeque<WorkItem> queue;\n-        queue.reserve(std::max<size_t>(256, 2 * m_todo.Count()));\n-\n-        // Create initial entries per connected component of m_todo. While clusters themselves are\n-        // generally connected, this is not necessarily true after some parts have already been\n-        // removed from m_todo. Without this, effort can be wasted on searching \"inc\" sets that\n-        // span multiple components.\n-        auto to_cover = m_todo;\n-        do {\n-            auto component = m_sorted_depgraph.FindConnectedComponent(to_cover);\n-            to_cover -= component;\n-            // If best is not provided, set it to the first component, so that during the work\n-            // processing loop below, and during the add_fn/split_fn calls, we do not need to deal\n-            // with the best=empty case.\n-            if (best.feerate.IsEmpty()) best = SetInfo(m_sorted_depgraph, component);\n-            queue.emplace_back(/*inc=*/SetInfo<SetType>{},\n-                               /*und=*/std::move(component),\n-                               /*pot_feerate=*/FeeFrac{});\n-        } while (to_cover.Any());\n-\n-        /** Local copy of the iteration limit. */\n-        uint64_t iterations_left = max_iterations;\n-\n-        /** The set of transactions in m_todo which have feerate > best's. */\n-        SetType imp = m_todo;\n-        while (imp.Any()) {\n-            DepGraphIndex check = imp.Last();\n-            if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-            imp.Reset(check);\n+        }\n+        std::sort(expected_dependencies.begin(), expected_dependencies.end());\n+        std::sort(all_dependencies.begin(), all_dependencies.end());\n+        assert(expected_dependencies.size() == all_dependencies.size());\n+        for (size_t i = 0; i < expected_dependencies.size(); ++i) {\n+            assert(expected_dependencies[i] ==\n+                   std::make_pair(std::get<0>(all_dependencies[i]),\n+                                  std::get<1>(all_dependencies[i])));\n         }\n \n-        /** Internal function to add an item to the queue of elements to explore if there are any\n-         *  transactions left to split on, possibly improving it before doing so, and to update\n-         *  best/imp.\n-         *\n-         * - inc: the \"inc\" value for the new work item (must be topological).\n-         * - und: the \"und\" value for the new work item ((inc | und) must be topological).\n-         */\n-        auto add_fn = [&](SetInfo<SetType> inc, SetType und) noexcept {\n-            /** SetInfo object with the set whose feerate will become the new work item's\n-             *  pot_feerate. It starts off equal to inc. */\n-            auto pot = inc;\n-            if (!inc.feerate.IsEmpty()) {\n-                // Add entries to pot. We iterate over all undecided transactions whose feerate is\n-                // higher than best. While undecided transactions of lower feerate may improve pot,\n-                // the resulting pot feerate cannot possibly exceed best's (and this item will be\n-                // skipped in split_fn anyway).\n-                for (auto pos : imp & und) {\n-                    // Determine if adding transaction pos to pot (ignoring topology) would improve\n-                    // it. If not, we're done updating pot. This relies on the fact that\n-                    // m_sorted_depgraph, and thus the transactions iterated over, are in decreasing\n-                    // individual feerate order.\n-                    if (!(m_sorted_depgraph.FeeRate(pos) >> pot.feerate)) break;\n-                    pot.Set(m_sorted_depgraph, pos);\n-                }\n-\n-                // The \"jump ahead\" optimization: whenever pot has a topologically-valid subset,\n-                // that subset can be added to inc. Any subset of (pot - inc) has the property that\n-                // its feerate exceeds that of any set compatible with this work item (superset of\n-                // inc, subset of (inc | und)). Thus, if T is a topological subset of pot, and B is\n-                // the best topologically-valid set compatible with this work item, and (T - B) is\n-                // non-empty, then (T | B) is better than B and also topological. This is in\n-                // contradiction with the assumption that B is best. Thus, (T - B) must be empty,\n-                // or T must be a subset of B.\n-                //\n-                // See https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303 section 2.4.\n-                const auto init_inc = inc.transactions;\n-                for (auto pos : pot.transactions - inc.transactions) {\n-                    // If the transaction's ancestors are a subset of pot, we can add it together\n-                    // with its ancestors to inc. Just update the transactions here; the feerate\n-                    // update happens below.\n-                    auto anc_todo = m_sorted_depgraph.Ancestors(pos) & m_todo;\n-                    if (anc_todo.IsSubsetOf(pot.transactions)) inc.transactions |= anc_todo;\n+        //\n+        // Verify the chunks against the list of active dependencies\n+        //\n+        for (auto tx_idx: depgraph.Positions()) {\n+            // Only process chunks for now.\n+            if (m_tx_data[tx_idx].chunk_rep == tx_idx) {\n+                const auto& chunk_data = m_tx_data[tx_idx];\n+                // Verify that transactions in the chunk point back to it. This guarantees\n+                // that chunks are non-overlapping.\n+                for (auto chunk_tx : chunk_data.chunk_setinfo.transactions) {\n+                    assert(m_tx_data[chunk_tx].chunk_rep == tx_idx);\n                 }\n-                // Finally update und and inc's feerate to account for the added transactions.\n-                und -= inc.transactions;\n-                inc.feerate += m_sorted_depgraph.FeeRate(inc.transactions - init_inc);\n-\n-                // If inc's feerate is better than best's, remember it as our new best.\n-                if (inc.feerate > best.feerate) {\n-                    best = inc;\n-                    // See if we can remove any entries from imp now.\n-                    while (imp.Any()) {\n-                        DepGraphIndex check = imp.Last();\n-                        if (m_sorted_depgraph.FeeRate(check) >> best.feerate) break;\n-                        imp.Reset(check);\n+                // Verify the chunk's transaction set: it must contain the representative, and for\n+                // every active dependency, if it contains the parent or child, it must contain\n+                // both. It must have exactly N-1 active dependencies in it, guaranteeing it is\n+                // acyclic.\n+                SetType expected_chunk = SetType::Singleton(tx_idx);\n+                while (true) {",
      "path": "src/cluster_linearize.h",
      "position": 1246,
      "original_position": 1240,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2619663299,
      "user": {
        "login": "brunoerg",
        "id": 19480819,
        "node_id": "MDQ6VXNlcjE5NDgwODE5",
        "avatar_url": "https://avatars.githubusercontent.com/u/19480819?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/brunoerg",
        "html_url": "https://github.com/brunoerg",
        "followers_url": "https://api.github.com/users/brunoerg/followers",
        "following_url": "https://api.github.com/users/brunoerg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/brunoerg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/brunoerg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/brunoerg/subscriptions",
        "organizations_url": "https://api.github.com/users/brunoerg/orgs",
        "repos_url": "https://api.github.com/users/brunoerg/repos",
        "events_url": "https://api.github.com/users/brunoerg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/brunoerg/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Yes, confirmed. Not sure what happened during the analysis, but anyway, it's resolved.\r\n\r\n```sh\r\n#1703\tNEW    cov: 524 ft: 678 corp: 27/330b lim: 14 exec/s: 0 rss: 75Mb L: 14/14 MS: 1 ChangeBit-\r\n#1711\tNEW    cov: 524 ft: 681 corp: 28/344b lim: 14 exec/s: 0 rss: 75Mb L: 14/14 MS: 3 ShuffleBytes-PersAutoDict-CrossOver- DE: \"\\377\\377\\377\\377\\377\\377\\377\\000\"-\r\n#1722\tNEW    cov: 524 ft: 683 corp: 29/358b lim: 14 exec/s: 0 rss: 75Mb L: 14/14 MS: 1 ChangeBinInt-\r\nAssertion failed: (chunk_data.chunk_setinfo.transactions == expected_chunk), function SanityCheck, file cluster_linearize.h, line 1258.\r\n==41593== ERROR: libFuzzer: deadly signal\r\n    #0 0x0001060facd4 in __sanitizer_print_stack_trace+0x28 (libclang_rt.asan_osx_dynamic.dylib:arm64+0x5ecd4)\r\n    #1 0x000103de12a4 in fuzzer::PrintStackTrace()+0x2c (fuzz:arm64+0x101d5d2a4)\r\n    #2 0x000103dd4590 in fuzzer::Fuzzer::CrashCallback()+0x54 (fuzz:arm64+0x101d50590)\r\n    #3 0x000186575a20 in _sigtramp+0x34 (libsystem_platform.dylib:arm64+0x3a20)\r\n    #4 0xfa78800186545cbc  (<unknown module>)\r\n    #5 0xcf04800186451a3c  (<unknown module>)\r\n    #6 0x9f16800186450d2c  (<unknown module>)\r\n    #7 0x5c2f0001021e39bc  (<unknown module>)\r\n    #8 0x0001021d6564 in clusterlin_sfl_fuzz_target(std::__1::span<unsigned char const, 18446744073709551615ul>)::$_0::operator()(bool) const+0x29c (fuzz:arm64+0x100152564)\r\n    #9 0x0001021d437c in clusterlin_sfl_fuzz_target(std::__1::span<unsigned char const, 18446744073709551615ul>)+0x6d4 (fuzz:arm64+0x10015037c)\r\n    #10 0x0001027bed70 in LLVMFuzzerTestOneInput+0x1d4 (fuzz:arm64+0x10073ad70)\r\n    #11 0x000103dd5c24 in fuzzer::Fuzzer::ExecuteCallback(unsigned char const*, unsigned long)+0x134 (fuzz:arm64+0x101d51c24)\r\n    #12 0x000103dd53b0 in fuzzer::Fuzzer::RunOne(unsigned char const*, unsigned long, bool, fuzzer::InputInfo*, bool, bool*)+0x3c (fuzz:arm64+0x101d513b0)\r\n    #13 0x000103dd6d10 in fuzzer::Fuzzer::MutateAndTestOne()+0x1f0 (fuzz:arm64+0x101d52d10)\r\n    #14 0x000103dd79a0 in fuzzer::Fuzzer::Loop(std::__1::vector<fuzzer::SizedFile, std::__1::allocator<fuzzer::SizedFile>>&)+0x3c4 (fuzz:arm64+0x101d539a0)\r\n    #15 0x000103dcdf78 in fuzzer::FuzzerDriver(int*, char***, int (*)(unsigned char const*, unsigned long))+0x1ee8 (fuzz:arm64+0x101d49f78)\r\n    #16 0x000103de1ca4 in main+0x24 (fuzz:arm64+0x101d5dca4)\r\n    #17 0x0001861c50dc  (<unknown module>)\r\n    #18 0x5c35fffffffffffc  (<unknown module>)\r\n\r\nNOTE: libFuzzer has rudimentary signal handlers.\r\n      Combine libFuzzer with AddressSanitizer or similar for better crash reports.\r\nSUMMARY: libFuzzer: deadly signal\r\nMS: 1 CopyPart-; base unit: 099984ad01f124eca6b78d4273cfc601591ca6b3\r\n0x1f,0xb5,0x0,0x0,0x0,0x0,0x0,0x0,0x5d,0x1f,0x1f,0xd,0x1f,0x26,\r\n\\037\\265\\000\\000\\000\\000\\000\\000]\\037\\037\\015\\037&\r\nartifact_prefix='./'; Test unit written to ./crash-6f59a9d6a7f236e8a4a6da57b7c1b2426b7fec10\r\nBase64: H7UAAAAAAABdHx8NHyY=\r\n```",
      "created_at": "2025-12-15T16:12:35Z",
      "updated_at": "2025-12-15T16:12:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620025357",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620025357"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 1249,
      "original_line": 1249,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620290372",
      "pull_request_review_id": 3579423256,
      "id": 2620290372,
      "node_id": "PRRC_kwDOABII586cLnVE",
      "diff_hunk": "@@ -1103,13 +1141,24 @@ class SpanningForestState\n                     if (!dep_data.active) continue;\n                     // Skip if this dependency is ineligible (the top chunk that would be created\n                     // does not have higher feerate than the chunk it is currently part of).\n-                    if (!(dep_data.top_setinfo.feerate >> chunk_data.chunk_setinfo.feerate)) continue;\n-                    // Otherwise, deactivate it and then make the state topological again with a\n-                    // sequence of merges.\n-                    Improve(dep_idx);\n-                    return true;\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n                 }\n             }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 211,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "7b2a7106b12a8eb9d0c7a345c275dc3e4b919a5f",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "7b2a7106b12a8eb9d0c7a345c275dc3e4b919a5f\r\n\r\nnit: probably not worth doing but noting that if `m_suboptimal_chunks` is empty here then we should be optimal and could return false",
      "created_at": "2025-12-15T17:39:48Z",
      "updated_at": "2025-12-15T21:08:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620290372",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620290372"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1161,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620350994",
      "pull_request_review_id": 3579423256,
      "id": 2620350994,
      "node_id": "PRRC_kwDOABII586cL2IS",
      "diff_hunk": "@@ -1053,7 +1053,6 @@ FUZZ_TARGET(clusterlin_sfl)\n     if (load_linearization) {\n         auto input_lin = ReadLinearization(depgraph, reader, load_topological);\n         sfl.LoadLinearization(input_lin);\n-        sfl.SanityCheck(depgraph);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 13,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "7b2a7106b12a8eb9d0c7a345c275dc3e4b919a5f",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "7b2a7106b12a8eb9d0c7a345c275dc3e4b919a5f\r\n\r\nWhy is this removed?",
      "created_at": "2025-12-15T18:01:44Z",
      "updated_at": "2025-12-15T21:08:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620350994",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620350994"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1056,
      "side": "LEFT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620713676",
      "pull_request_review_id": 3579423256,
      "id": 2620713676,
      "node_id": "PRRC_kwDOABII586cNOrM",
      "diff_hunk": "@@ -54,7 +54,6 @@\n  *   - clusterlin_components\n  * - ChunkLinearization and LinearizationChunking tests:",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 2,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "dangling LinearizationChunking",
      "created_at": "2025-12-15T20:20:35Z",
      "updated_at": "2025-12-15T21:08:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620713676",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620713676"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 55,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620842293",
      "pull_request_review_id": 3579423256,
      "id": 2620842293,
      "node_id": "PRRC_kwDOABII586cNuE1",
      "diff_hunk": "@@ -1311,13 +1311,13 @@ void SingletonClusterImpl::AppendChunkFeerates(std::vector<FeeFrac>& ret) const\n \n uint64_t GenericClusterImpl::AppendTrimData(std::vector<TrimTxData>& ret, std::vector<std::pair<GraphIndex, GraphIndex>>& deps) const noexcept\n {\n-    const LinearizationChunking linchunking(m_depgraph, m_linearization);\n+    auto linchunking = ChunkLinearizationInfo(m_depgraph, m_linearization);\n     LinearizationIndex pos{0};\n     uint64_t size{0};\n     auto prev_index = GraphIndex(-1);\n     // Iterate over the chunks of this cluster's linearization.\n-    for (unsigned i = 0; i < linchunking.NumChunksLeft(); ++i) {\n-        const auto& [chunk, chunk_feerate] = linchunking.GetChunk(i);\n+    for (unsigned i = 0; i < linchunking.size(); ++i) {",
      "path": "src/txgraph.cpp",
      "position": 1,
      "original_position": 36,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "26661a6c655ad148d3ecf200c64b89c439b6d44a\r\n\r\nnit: while we're here (we also arent using `j` below anywhere, but meh)\r\n\r\n```Suggestion\r\n    for (const auto& [chunk, chunk_feerate] : linchunking) {\r\n```",
      "created_at": "2025-12-15T21:04:18Z",
      "updated_at": "2025-12-15T21:08:35Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620842293",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620842293"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1319,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620891939",
      "pull_request_review_id": 3580207175,
      "id": 2620891939,
      "node_id": "PRRC_kwDOABII586cN6Mj",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 187,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611697771,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Renamed now.",
      "created_at": "2025-12-15T21:21:07Z",
      "updated_at": "2025-12-15T21:21:07Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620891939",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620891939"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 639,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620893564",
      "pull_request_review_id": 3580207461,
      "id": 2620893564,
      "node_id": "PRRC_kwDOABII586cN6l8",
      "diff_hunk": "@@ -1169,6 +890,104 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the individual steps of the SFL algorithm.\n+\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    uint64_t rng_seed{0};\n+    try {\n+        reader >> rng_seed >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    if (depgraph.TxCount() <= 1) return;",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 515,
      "original_position": 514,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "382cf0ed5f4a4335ada6d4d2d5367db4fa9ca3b4",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Feel like we should still cover size 1, even if it's trivial. Thoughts?",
      "created_at": "2025-12-15T21:21:40Z",
      "updated_at": "2025-12-15T21:21:43Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620893564",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620893564"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 904,
      "original_line": 904,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620893639",
      "pull_request_review_id": 3580209364,
      "id": 2620893639,
      "node_id": "PRRC_kwDOABII586cN6nH",
      "diff_hunk": "@@ -662,6 +678,697 @@ class AncestorCandidateFinder\n     }\n };\n \n+/** Class to represent the internal state of the spanning-forest linearization (SFL) algorithm.\n+ *\n+ * At all times, each dependency is marked as either \"active\" or \"inactive\". The subset of active\n+ * dependencies is the state of the SFL algorithm. The implementation maintains several other\n+ * values to speed up operations, but everything is ultimately a function of what that subset of\n+ * active dependencies is.\n+ *\n+ * Given such a subset, define a chunk as the set of transactions that are connected through active\n+ * dependencies (ignoring their parent/child direction). Thus, every state implies a particular\n+ * partitioning of the graph into chunks (including potential singletons). In the extreme, each\n+ * transaction may be in its own chunk, or in the other extreme all transactions may form a single\n+ * chunk. A chunk's feerate is its total fee divided by its total size.\n+ *\n+ * The algorithm consists of switching dependencies between active and inactive. The final\n+ * linearization that is produced at the end consists of these chunks, sorted from high to low\n+ * feerate, each individually sorted in an arbitrary but topological (= no child before parent)\n+ * way.\n+ *\n+ * We define three quality properties the state can have, each being stronger than the previous:\n+ *\n+ * - acyclic: The state is acyclic whenever no cycle of active dependencies exists within the\n+ *            graph, ignoring the parent/child direction. This is equivalent to saying that within\n+ *            each chunk the set of active dependencies form a tree, and thus the overall set of\n+ *            active dependencies in the graph form a spanning forest, giving the algorithm its\n+ *            name. Being acyclic is also equivalent to every chunk of N transactions having\n+ *            exactly N-1 active dependencies.\n+ *\n+ *            For example in a diamond graph, D->{B,C}->A, the 4 dependencies cannot be\n+ *            simultaneously active. If at least one is inactive, the state is acyclic.\n+ *\n+ *            The algorithm maintains an acyclic state at *all* times as an invariant. This implies\n+ *            that activating a dependency always corresponds to merging two chunks, and that\n+ *            deactivating one always corresponds to splitting two chunks.\n+ *\n+ * - topological: We say the state is topological whenever it is acyclic and no inactive dependency\n+ *                exists between two distinct chunks such that the child chunk has higher or equal\n+ *                feerate than the parent chunk.\n+ *\n+ *                The relevance is that whenever the state is topological, the produced output\n+ *                linearization will be topological too (i.e., not have children before parents).\n+ *                Note that the \"or equal\" part of the definition matters: if not, one can end up\n+ *                in a situation with mutually-dependent equal-feerate chunks that cannot be\n+ *                linearized. For example C->{A,B} and D->{A,B}, with C->A and D->B active. The AC\n+ *                chunk depends on DB through C->B, and the BD chunk depends on AC though D->A.\n+ *                Merging them into a single ABCD chunk fixes this.\n+ *\n+ *                The algorithm attempts to keep the state topological as much as possible, so it\n+ *                can be interrupted to produce an output whenever, but will sometimes need to\n+ *                temporarily deviate from it when improving the state.\n+ *\n+ * - optimal: For every active dependency, define its top and bottom set as the set of transactions\n+ *            in the chunks that would result if the dependency were deactivated; the top being the\n+ *            one with the dependency's parent, and the bottom being the one with the child. Note\n+ *            that due to acyclicity, every deactivation splits a chunk exactly in two.\n+ *\n+ *            We say the state is optimal whenever it is topological and it has no active\n+ *            dependency whose top feerate is strictly higher than its bottom feerate. The\n+ *            relevance is that it can be proven that whenever the state is optimal, the produced\n+ *            linearization will also be optimal (in the convexified feerate diagram sense). It can\n+ *            also be proven that for every graph at least one optimal state exists.\n+ *\n+ *            Note that it is possible for the SFL state to not be optimal, but the produced\n+ *            linearization to still be optimal. This happens when the chunks of a state are\n+ *            identical to those of an optimal state, but the exact set of active dependencies\n+ *            within a chunk differ in such a way that the state optimality condition is not\n+ *            satisfied. Thus, the state being optimal is more a \"the eventual output is *known*\n+ *            to be optimal\".\n+ *\n+ *            The algorithm terminates whenever an optimal state is reached.\n+ *\n+ *\n+ * This leads to the following high-level algorithm:\n+ * - Start with all dependencies inactive, and thus all transactions in their own chunk. This is\n+ *   definitely acyclic.\n+ * - Activate dependencies (merging chunks) until the state is topological.\n+ * - Loop until optimal (no dependencies with higher-feerate top than bottom), or time runs out:\n+ *   - Deactivate a violating dependency, potentially making the state non-topological.\n+ *   - Activate other dependencies to make the state topological again.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * When merging, we always either:\n+ * - Merge upwards: merge a chunk with the lowest-feerate other chunk it depends on, among those\n+ *                  with lower or equal feerate than itself.\n+ * - Merge downwards: merge a chunk with the highest-feerate other chunk that depends on it, among\n+ *                    those with higher or equal feerate than itself.\n+ *\n+ * Using these strategies in the improvement loop above guarantees that the output linearization\n+ * after a deactivate + merge step is never worse or incomparable (in the convexified feerate\n+ * diagram sense) than the output linearization that would be produced before the step. With that,\n+ * we can refine the high-level algorithm to:\n+ * - Start with all dependencies inactive.\n+ * - Perform merges as described until none are possible anymore, making the state topological.\n+ * - Loop until optimal or times runs out:\n+ *   - Pick a dependency D to deactivate among those with higher feerate top than bottom.\n+ *   - Deactivate D, causing the chunk it is in to split into top T and bottom B.\n+ *   - Do an upwards merge of T, if possible. If so, repeat the same with the merged result.\n+ *   - Do a downwards merge of B, if possible. If so, repeat the same with the merged result.\n+ * - Output the chunks from high to low feerate, each internally sorted topologically.\n+ *\n+ * What remains to be specified are a number of heuristics:\n+ *\n+ * - How to decide which chunks to merge:\n+ *   - The merge upwards and downward rules specify that the lowest-feerate respectively\n+ *     highest-feerate candidate chunk is merged with, but if there are multiple equal-feerate\n+ *     candidates, the chunk with the highest-index transaction involving a relevant dependency is\n+ *     picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to activate (when merging chunks):\n+ *   - After picking two chunks to be merged (see above), the dependency with the lowest-index\n+ *     transaction in the other chunk is activated (this will be changed in a later commit).\n+ *\n+ * - How to decide which chunk to find a dependency to split in:\n+ *   - The chunk with the lowest-index representative (an implementation detail) that can be split\n+ *     is picked (this will be changed in a later commit).\n+ *\n+ * - How to decide what dependency to deactivate (when splitting chunks):\n+ *   - Inside the selected chunk (see above), among the dependencies whose top feerate is strictly\n+ *     higher than its bottom feerate in the selected chunk, if any, the one with the lowest-index\n+ *     child is deactivated (this will be changed in a later commit).\n+ */\n+template<typename SetType>\n+class SpanningForestState\n+{\n+private:\n+    /** Data type to represent indexing into m_tx_data. */\n+    using TxIdx = uint32_t;\n+    /** Data type to represent indexing into m_dep_data. */\n+    using DepIdx = uint32_t;\n+\n+    /** Structure with information about a single transaction. For transactions that are the\n+     *  representative for the chunk they are in, this also stores chunk information. */\n+    struct TxData {\n+        /** The dependencies to parents of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> parent_deps;\n+        /** The dependencies to children of this transaction. Immutable after construction. */\n+        std::vector<DepIdx> child_deps;\n+        /** The set of parent transactions of this transaction. Immutable after construction. */\n+        SetType parents;\n+        /** The set of child transactions of this transaction. Immutable after construction. */\n+        SetType children;\n+        /** Which transaction holds the chunk_setinfo for the chunk this transaction is in\n+         *  (the representative for the chunk). */\n+        TxIdx chunk_rep;\n+        /** (Only if this transaction is the representative for the chunk it is in) the total\n+         *  chunk set and feerate. */\n+        SetInfo<SetType> chunk_setinfo;\n+    };\n+\n+    /** Structure with information about a single dependency. */\n+    struct DepData {\n+        /** Whether this dependency is active. */\n+        bool active;\n+        /** What the parent and child transactions are. Immutable after construction. */\n+        TxIdx parent, child;\n+        /** (Only if this dependency is active) the would-be top chunk and its feerate that would\n+         *  be formed if this dependency were to be deactivated. */\n+        SetInfo<SetType> top_setinfo;\n+    };\n+\n+    /** The set of all transactions in the cluster. */\n+    SetType m_transactions;\n+    /** Information about each transaction (and chunks). Indexed by TxIdx. */\n+    std::vector<TxData> m_tx_data;\n+    /** Information about each dependency. Indexed by DepIdx. */\n+    std::vector<DepData> m_dep_data;\n+\n+    /** The number of updated transactions in activations/deactivations. */\n+    uint64_t m_cost{0};\n+\n+    /** Update a chunk by starting at start and walking all its transactions and active\n+     *  dependencies. In the process all chunk representatives are set to chunk_rep, and all\n+     *  dependencies which have start in their top set (i.e., which are explored in downward\n+     *  direction) get dep_effect added or (if Subtract) subtracted. */\n+    template<bool Subtract>\n+    void UpdateChunk(TxIdx start, TxIdx chunk_rep, const SetInfo<SetType>& dep_effect) noexcept\n+    {\n+        /** The set of transactions we still have to process. */\n+        SetType todo = SetType::Singleton(start);\n+        /** The set of transactions we have already processed. */\n+        SetType done;\n+        do {\n+            for (auto tx_idx : todo - done) {\n+                // Mark the transaction as processed, and update its chunk representative.\n+                auto& tx_data = m_tx_data[tx_idx];\n+                done.Set(tx_idx);\n+                tx_data.chunk_rep = chunk_rep;\n+                // Iterate over all its active parent dependencies.\n+                auto parent_deps = std::span{tx_data.parent_deps};\n+                for (auto dep_idx : parent_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.child == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // Mark the parent as todo.\n+                    todo.Set(dep_entry.parent);\n+                }\n+                // Iterate over all its active child dependencies.\n+                auto child_deps = std::span{tx_data.child_deps};\n+                for (auto dep_idx : child_deps) {\n+                    auto& dep_entry = m_dep_data[dep_idx];\n+                    Assume(dep_entry.parent == tx_idx);\n+                    if (!dep_entry.active) continue;\n+                    // If this is the first time reaching the child, mark it as todo, and update\n+                    // the dependency's top set info. We need to check if the child was not done\n+                    // already to prevent traveling in reverse along an already processed\n+                    // dependency.\n+                    if (!done[dep_entry.child]) {\n+                        todo.Set(dep_entry.child);\n+                        if constexpr (Subtract) {\n+                            dep_entry.top_setinfo -= dep_effect;\n+                        } else {\n+                            dep_entry.top_setinfo |= dep_effect;\n+                        }\n+                    }\n+                }\n+            }\n+        } while (todo != done);\n+    }\n+\n+    /** Make a specified inactive dependency active. Returns the merged chunk representative. */\n+    TxIdx Activate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(!dep_data.active);\n+        auto& child_tx_data = m_tx_data[dep_data.child];\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+\n+        // Gather information about the parent and child chunks.\n+        Assume(parent_tx_data.chunk_rep != child_tx_data.chunk_rep);\n+        auto& par_chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        auto& chl_chunk_data = m_tx_data[child_tx_data.chunk_rep];\n+        TxIdx top_rep = parent_tx_data.chunk_rep;\n+        auto top_part = par_chunk_data.chunk_setinfo;\n+        auto bottom_part = chl_chunk_data.chunk_setinfo;\n+        // Update the parent chunk to also contain the child.\n+        par_chunk_data.chunk_setinfo |= bottom_part;\n+        m_cost += par_chunk_data.chunk_setinfo.transactions.Count();\n+        // Add bottom component to top transactions.\n+        UpdateChunk<false>(dep_data.parent, top_rep, bottom_part);\n+        // Add top component to bottom transactions.\n+        UpdateChunk<false>(dep_data.child, top_rep, top_part);\n+        // Make active.\n+        dep_data.active = true;\n+        dep_data.top_setinfo = top_part;\n+        return top_rep;\n+    }\n+\n+    /** Make a specified active dependency inactive. */\n+    void Deactivate(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        auto& parent_tx_data = m_tx_data[dep_data.parent];\n+        // Make inactive.\n+        dep_data.active = false;\n+        // Update representatives.\n+        auto& chunk_data = m_tx_data[parent_tx_data.chunk_rep];\n+        m_cost += chunk_data.chunk_setinfo.transactions.Count();\n+        auto top_part = dep_data.top_setinfo;\n+        auto bottom_part = chunk_data.chunk_setinfo - top_part;\n+        TxIdx bottom_rep = dep_data.child;\n+        auto& bottom_chunk_data = m_tx_data[bottom_rep];\n+        bottom_chunk_data.chunk_setinfo = bottom_part;\n+        TxIdx top_rep = dep_data.parent;\n+        auto& top_chunk_data = m_tx_data[top_rep];\n+        top_chunk_data.chunk_setinfo = top_part;\n+        // Remove bottom component from top transactions, and make top_rep the representative for\n+        // all of them.\n+        UpdateChunk<true>(dep_data.parent, top_rep, bottom_part);\n+        // Remove top component from bottom transactions, and make bottom_rep the representative\n+        // for all of them.\n+        UpdateChunk<true>(dep_data.child, bottom_rep, top_part);\n+    }\n+\n+    /** Activate a dependency from the chunk represented by bottom_rep to the chunk represented by\n+     *  top_rep, which must exist. Return the representative of the merged chunk. */\n+    TxIdx MergeChunks(TxIdx top_rep, TxIdx bottom_rep) noexcept\n+    {\n+        auto& top_chunk = m_tx_data[top_rep];\n+        Assume(top_chunk.chunk_rep == top_rep);\n+        auto& bottom_chunk = m_tx_data[bottom_rep];\n+        Assume(bottom_chunk.chunk_rep == bottom_rep);\n+        // Activate the first dependency between bottom_chunk and top_chunk.\n+        for (auto tx : top_chunk.chunk_setinfo.transactions) {\n+            auto& tx_data = m_tx_data[tx];\n+            if (tx_data.children.Overlaps(bottom_chunk.chunk_setinfo.transactions)) {\n+                for (auto dep : tx_data.child_deps) {\n+                    auto& dep_data = m_dep_data[dep];\n+                    if (bottom_chunk.chunk_setinfo.transactions[dep_data.child]) {\n+                        return Activate(dep);\n+                    }\n+                }\n+                break;\n+            }\n+        }\n+        Assume(false);\n+        return TxIdx(-1);\n+    }\n+\n+    /** Perform an upward or downward merge step, on the specified chunk representative. Returns\n+     *  the representative of the merged chunk, or TxIdx(-1) if no merge took place. */\n+    template<bool DownWard>\n+    TxIdx MergeStep(TxIdx chunk_rep) noexcept\n+    {\n+        /** Information about the chunk that tx_idx is currently in. */\n+        auto& chunk_data = m_tx_data[chunk_rep];\n+        SetType chunk_txn = chunk_data.chunk_setinfo.transactions;\n+        // Iterate over all transactions in the chunk, figuring out which other chunk each\n+        // depends on, but only testing each other chunk once. For those depended-on chunks,\n+        // remember the highest-feerate (if DownWard) or lowest-feerate (if !DownWard) one.\n+        // If multiple equal-feerate candidate chunks to merge with exist, pick the last one\n+        // among them.\n+\n+        /** Which transactions have been reached from this chunk already. Initialize with the\n+         *  chunk itself, so internal dependencies within the chunk are ignored. */\n+        SetType explored = chunk_txn;\n+        /** The minimum feerate (if downward) or maximum feerate (if upward) to consider when\n+         *  looking for candidate chunks to merge with. Initially, this is the original chunk's\n+         *  feerate, but is updated to be the current best candidate whenever one is found. */\n+        FeeFrac best_other_chunk_feerate = chunk_data.chunk_setinfo.feerate;\n+        /** The representative for the best candidate chunk to merge with. -1 if none. */\n+        TxIdx best_other_chunk_rep = TxIdx(-1);\n+        for (auto tx : chunk_txn) {\n+            auto& tx_data = m_tx_data[tx];\n+            /** The transactions reached by following dependencies from tx that have not been\n+             *  explored before. */\n+            auto newly_reached = (DownWard ? tx_data.children : tx_data.parents) - explored;\n+            explored |= newly_reached;\n+            while (newly_reached.Any()) {\n+                // Find a chunk inside newly_reached, and remove it from newly_reached.\n+                auto reached_chunk_rep = m_tx_data[newly_reached.First()].chunk_rep;\n+                auto& reached_chunk = m_tx_data[reached_chunk_rep].chunk_setinfo;\n+                newly_reached -= reached_chunk.transactions;\n+                // See if it has an acceptable feerate.\n+                auto cmp = DownWard ? FeeRateCompare(best_other_chunk_feerate, reached_chunk.feerate)\n+                                    : FeeRateCompare(reached_chunk.feerate, best_other_chunk_feerate);\n+                if (cmp <= 0) {\n+                    best_other_chunk_feerate = reached_chunk.feerate;\n+                    best_other_chunk_rep = reached_chunk_rep;\n+                }\n+            }\n+        }\n+        // Stop if there are no candidate chunks to merge with.\n+        if (best_other_chunk_rep == TxIdx(-1)) return TxIdx(-1);\n+        if constexpr (DownWard) {\n+            chunk_rep = MergeChunks(chunk_rep, best_other_chunk_rep);\n+        } else {\n+            chunk_rep = MergeChunks(best_other_chunk_rep, chunk_rep);\n+        }\n+        Assume(chunk_rep != TxIdx(-1));\n+        return chunk_rep;\n+    }\n+\n+\n+    /** Perform an upward or downward merge sequence on the specified transaction. */\n+    template<bool DownWard>\n+    void MergeSequence(TxIdx tx_idx) noexcept\n+    {\n+        auto chunk_rep = m_tx_data[tx_idx].chunk_rep;\n+        while (true) {\n+            auto merged_rep = MergeStep<DownWard>(chunk_rep);\n+            if (merged_rep == TxIdx(-1)) break;\n+            chunk_rep = merged_rep;\n+        }\n+    }\n+\n+    /** Split a chunk, and then merge the resulting two chunks to make the graph topological\n+     *  again. */\n+    void Improve(DepIdx dep_idx) noexcept\n+    {\n+        auto& dep_data = m_dep_data[dep_idx];\n+        Assume(dep_data.active);\n+        // Deactivate the specified dependency, splitting it into two new chunks: a top containing\n+        // the parent, and a bottom containing the child. The top should have a higher feerate.\n+        Deactivate(dep_idx);\n+        // Merge the top chunk with lower-feerate chunks it depends on (which may be the bottom it\n+        // was just split from, or other pre-existing chunks).\n+        MergeSequence<false>(dep_data.parent);\n+        // Merge the bottom chunk with higher-feerate chunks that depend on it.\n+        MergeSequence<true>(dep_data.child);\n+    }\n+\n+public:\n+    /** Construct a spanning forest for the given DepGraph, with every transaction in its own chunk\n+     *  (not topological). */\n+    explicit SpanningForestState(const DepGraph<SetType>& depgraph) noexcept\n+    {\n+        m_transactions = depgraph.Positions();\n+        auto num_transactions = m_transactions.Count();\n+        m_tx_data.resize(depgraph.PositionRange());\n+        m_dep_data.reserve(((num_transactions + 1) / 2) * (num_transactions / 2));",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 416,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "c2eaf22503f7af057599f02ecb5f24a267ea33e2",
      "in_reply_to_id": 2611720199,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I added a comment explaining the formula. Also, simplified it to `N^2 / 4`, which is actually also correct for the odd-numbered case.",
      "created_at": "2025-12-15T21:21:42Z",
      "updated_at": "2025-12-15T21:21:42Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620893639",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620893639"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 916,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620894913",
      "pull_request_review_id": 3580211245,
      "id": 2620894913,
      "node_id": "PRRC_kwDOABII586cN67B",
      "diff_hunk": "@@ -1103,13 +1141,24 @@ class SpanningForestState\n                     if (!dep_data.active) continue;\n                     // Skip if this dependency is ineligible (the top chunk that would be created\n                     // does not have higher feerate than the chunk it is currently part of).\n-                    if (!(dep_data.top_setinfo.feerate >> chunk_data.chunk_setinfo.feerate)) continue;\n-                    // Otherwise, deactivate it and then make the state topological again with a\n-                    // sequence of merges.\n-                    Improve(dep_idx);\n-                    return true;\n+                    auto cmp = FeeRateCompare(dep_data.top_setinfo.feerate, chunk_data.chunk_setinfo.feerate);\n+                    if (cmp <= 0) continue;\n+                    // Generate a random tiebreak for this dependency, and reject it if its tiebreak\n+                    // is worse than the best so far. This means that among all eligible\n+                    // dependencies, a uniformly random one will be chosen.\n+                    uint64_t tiebreak = m_rng.rand64();\n+                    if (tiebreak < candidate_tiebreak) continue;\n+                    // Remember this as our (new) candidate dependency.\n+                    candidate_dep = dep_idx;\n+                    candidate_tiebreak = tiebreak;\n                 }\n             }\n+            // If a candidate with positive gain was found, deactivate it and then make the state\n+            // topological again with a sequence of merges.\n+            if (candidate_dep != DepIdx(-1)) Improve(candidate_dep);\n+            // Stop processing for now, even if nothing was activated, as the loop above may have\n+            // had a nontrivial cost.\n+            return true;",
      "path": "src/cluster_linearize.h",
      "position": 1,
      "original_position": 211,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "7b2a7106b12a8eb9d0c7a345c275dc3e4b919a5f",
      "in_reply_to_id": 2620290372,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Doesn't hurt. Done.",
      "created_at": "2025-12-15T21:22:12Z",
      "updated_at": "2025-12-15T21:22:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620894913",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620894913"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1161,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620895789",
      "pull_request_review_id": 3580212427,
      "id": 2620895789,
      "node_id": "PRRC_kwDOABII586cN7It",
      "diff_hunk": "@@ -1053,7 +1053,6 @@ FUZZ_TARGET(clusterlin_sfl)\n     if (load_linearization) {\n         auto input_lin = ReadLinearization(depgraph, reader, load_topological);\n         sfl.LoadLinearization(input_lin);\n-        sfl.SanityCheck(depgraph);",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 13,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "7b2a7106b12a8eb9d0c7a345c275dc3e4b919a5f",
      "in_reply_to_id": 2620350994,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "I've moved it to remove it in the initial commit now.",
      "created_at": "2025-12-15T21:22:34Z",
      "updated_at": "2025-12-15T21:22:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620895789",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620895789"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1056,
      "side": "LEFT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620896198",
      "pull_request_review_id": 3580213089,
      "id": 2620896198,
      "node_id": "PRRC_kwDOABII586cN7PG",
      "diff_hunk": "@@ -54,7 +54,6 @@\n  *   - clusterlin_components\n  * - ChunkLinearization and LinearizationChunking tests:",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 2,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2620713676,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Fixed.",
      "created_at": "2025-12-15T21:22:39Z",
      "updated_at": "2025-12-15T21:22:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620896198",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620896198"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 55,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620896507",
      "pull_request_review_id": 3580213483,
      "id": 2620896507,
      "node_id": "PRRC_kwDOABII586cN7T7",
      "diff_hunk": "@@ -1311,13 +1311,13 @@ void SingletonClusterImpl::AppendChunkFeerates(std::vector<FeeFrac>& ret) const\n \n uint64_t GenericClusterImpl::AppendTrimData(std::vector<TrimTxData>& ret, std::vector<std::pair<GraphIndex, GraphIndex>>& deps) const noexcept\n {\n-    const LinearizationChunking linchunking(m_depgraph, m_linearization);\n+    auto linchunking = ChunkLinearizationInfo(m_depgraph, m_linearization);\n     LinearizationIndex pos{0};\n     uint64_t size{0};\n     auto prev_index = GraphIndex(-1);\n     // Iterate over the chunks of this cluster's linearization.\n-    for (unsigned i = 0; i < linchunking.NumChunksLeft(); ++i) {\n-        const auto& [chunk, chunk_feerate] = linchunking.GetChunk(i);\n+    for (unsigned i = 0; i < linchunking.size(); ++i) {",
      "path": "src/txgraph.cpp",
      "position": 1,
      "original_position": 36,
      "commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "original_commit_id": "26661a6c655ad148d3ecf200c64b89c439b6d44a",
      "in_reply_to_id": 2620842293,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Done.",
      "created_at": "2025-12-15T21:22:45Z",
      "updated_at": "2025-12-15T21:22:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620896507",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620896507"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1319,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620899023",
      "pull_request_review_id": 3580217191,
      "id": 2620899023,
      "node_id": "PRRC_kwDOABII586cN77P",
      "diff_hunk": "@@ -1169,6 +890,104 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the individual steps of the SFL algorithm.\n+\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    uint64_t rng_seed{0};\n+    try {\n+        reader >> rng_seed >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    if (depgraph.TxCount() <= 1) return;",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 515,
      "original_position": 514,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "382cf0ed5f4a4335ada6d4d2d5367db4fa9ca3b4",
      "in_reply_to_id": 2620893564,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Clusters of size 1 only have one possible linearization, and `TxGraphImpl` doesn't even invoke `Linearize` for them. But happy to keep them in if you feel strongly.",
      "created_at": "2025-12-15T21:23:47Z",
      "updated_at": "2025-12-15T21:23:47Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620899023",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620899023"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 904,
      "original_line": 904,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620902534",
      "pull_request_review_id": 3580222259,
      "id": 2620902534,
      "node_id": "PRRC_kwDOABII586cN8yG",
      "diff_hunk": "@@ -1169,6 +890,104 @@ FUZZ_TARGET(clusterlin_simple_linearize)\n     }\n }\n \n+FUZZ_TARGET(clusterlin_sfl)\n+{\n+    // Verify the individual steps of the SFL algorithm.\n+\n+    SpanReader reader(buffer);\n+    DepGraph<TestBitSet> depgraph;\n+    uint8_t flags{1};\n+    uint64_t rng_seed{0};\n+    try {\n+        reader >> rng_seed >> flags >> Using<DepGraphFormatter>(depgraph);\n+    } catch (const std::ios_base::failure&) {}\n+    if (depgraph.TxCount() <= 1) return;",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 515,
      "original_position": 514,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "382cf0ed5f4a4335ada6d4d2d5367db4fa9ca3b4",
      "in_reply_to_id": 2620893564,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "> TxGraphImpl doesn't even invoke Linearize for them\r\n\r\ncompelling, mark as resolved",
      "created_at": "2025-12-15T21:25:09Z",
      "updated_at": "2025-12-15T21:25:10Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2620902534",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2620902534"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 904,
      "original_line": 904,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632170854",
      "pull_request_review_id": 3594428615,
      "id": 2632170854,
      "node_id": "PRRC_kwDOABII586c471m",
      "diff_hunk": "@@ -328,18 +328,24 @@ SetType ReadTopologicalSet(const DepGraph<SetType>& depgraph, const SetType& tod\n \n /** Given a dependency graph, construct any valid linearization for it, reading from a SpanReader. */\n template<typename BS>\n-std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader)\n+std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader, bool topological=true)\n {\n     std::vector<DepGraphIndex> linearization;\n     TestBitSet todo = depgraph.Positions();\n     // In every iteration one topologically-valid transaction is appended to linearization.",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 9,
      "commit_id": "e2ae52b523651cb5f47cbc18447796b30f7b6aef",
      "original_commit_id": "e2ae52b523651cb5f47cbc18447796b30f7b6aef",
      "in_reply_to_id": null,
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "nit: This comment isn't accurate anymore if `topological=false`.",
      "created_at": "2025-12-18T18:30:42Z",
      "updated_at": "2025-12-18T19:04:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2632170854",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632170854"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 335,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632240081",
      "pull_request_review_id": 3594428615,
      "id": 2632240081,
      "node_id": "PRRC_kwDOABII586c5MvR",
      "diff_hunk": "@@ -1124,7 +1133,22 @@ class SpanningForestState\n         }\n     }\n \n-    /** Make state topological. Can be called after constructing. */\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n+    {",
      "path": "src/cluster_linearize.h",
      "position": 725,
      "original_position": 25,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "2446fc6878cd5bee868b37599d7ea17ad0f151fe",
      "in_reply_to_id": null,
      "user": {
        "login": "marcofleon",
        "id": 95179662,
        "node_id": "U_kgDOBaxTjg",
        "avatar_url": "https://avatars.githubusercontent.com/u/95179662?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/marcofleon",
        "html_url": "https://github.com/marcofleon",
        "followers_url": "https://api.github.com/users/marcofleon/followers",
        "following_url": "https://api.github.com/users/marcofleon/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/marcofleon/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/marcofleon/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/marcofleon/subscriptions",
        "organizations_url": "https://api.github.com/users/marcofleon/orgs",
        "repos_url": "https://api.github.com/users/marcofleon/repos",
        "events_url": "https://api.github.com/users/marcofleon/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/marcofleon/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "To enforce the \"must be called immediately after constructor\", could add an assume here checking that we're in the initial state (no dependencies active or something like that). It's only called in two places right now so it's not critical, but could serve as a defensive check.",
      "created_at": "2025-12-18T18:43:39Z",
      "updated_at": "2025-12-18T19:04:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2632240081",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632240081"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 951,
      "original_line": 951,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632378226",
      "pull_request_review_id": 3594707566,
      "id": 2632378226,
      "node_id": "PRRC_kwDOABII586c5udy",
      "diff_hunk": "@@ -328,18 +328,24 @@ SetType ReadTopologicalSet(const DepGraph<SetType>& depgraph, const SetType& tod\n \n /** Given a dependency graph, construct any valid linearization for it, reading from a SpanReader. */\n template<typename BS>\n-std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader)\n+std::vector<DepGraphIndex> ReadLinearization(const DepGraph<BS>& depgraph, SpanReader& reader, bool topological=true)\n {\n     std::vector<DepGraphIndex> linearization;\n     TestBitSet todo = depgraph.Positions();\n     // In every iteration one topologically-valid transaction is appended to linearization.",
      "path": "src/test/fuzz/cluster_linearize.cpp",
      "position": 1,
      "original_position": 9,
      "commit_id": "e2ae52b523651cb5f47cbc18447796b30f7b6aef",
      "original_commit_id": "e2ae52b523651cb5f47cbc18447796b30f7b6aef",
      "in_reply_to_id": 2632170854,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Fixed.",
      "created_at": "2025-12-18T19:27:49Z",
      "updated_at": "2025-12-18T19:27:49Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2632378226",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632378226"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 335,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632380284",
      "pull_request_review_id": 3594710359,
      "id": 2632380284,
      "node_id": "PRRC_kwDOABII586c5u98",
      "diff_hunk": "@@ -1124,7 +1133,22 @@ class SpanningForestState\n         }\n     }\n \n-    /** Make state topological. Can be called after constructing. */\n+    /** Load an existing linearization. Must be called immediately after constructor. The result is\n+     *  topological if the linearization is valid. Otherwise, MakeTopological still needs to be\n+     *  called. */\n+    void LoadLinearization(std::span<const DepGraphIndex> old_linearization) noexcept\n+    {",
      "path": "src/cluster_linearize.h",
      "position": 725,
      "original_position": 25,
      "commit_id": "75bdb925f404f41874adf0fcefca0f1641fcb4e6",
      "original_commit_id": "2446fc6878cd5bee868b37599d7ea17ad0f151fe",
      "in_reply_to_id": 2632240081,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "name": null,
        "patch_url": null
      },
      "body": "Good point, and actually this also allows a tiny optimization, as `m_tx_data[tx].chunk_rep == tx` for every iteration in the loop. Made use of that, and added an `Assume`.",
      "created_at": "2025-12-18T19:28:40Z",
      "updated_at": "2025-12-18T19:28:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/32545#discussion_r2632380284",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2632380284"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/32545"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 951,
      "original_line": 951,
      "side": "RIGHT"
    }
  ]
}