{
  "type": "pull",
  "pull": {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829",
    "id": 2324761179,
    "node_id": "PR_kwDOABII586KkQpb",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/31829",
    "diff_url": "https://github.com/bitcoin/bitcoin/pull/31829.diff",
    "patch_url": "https://github.com/bitcoin/bitcoin/pull/31829.patch",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829",
    "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829/commits",
    "review_comments_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829/comments",
    "review_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments%7B/number%7D",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829/comments",
    "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/6093300bfcb9be7f76a662d1bb29dbeec60816a2",
    "number": 31829,
    "state": "open",
    "locked": false,
    "maintainer_can_modify": true,
    "title": "p2p: improve TxOrphanage denial of service bounds",
    "user": {
      "login": "glozow",
      "id": 25183001,
      "node_id": "MDQ6VXNlcjI1MTgzMDAx",
      "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/glozow",
      "html_url": "https://github.com/glozow",
      "followers_url": "https://api.github.com/users/glozow/followers",
      "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
      "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
      "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
      "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
      "organizations_url": "https://api.github.com/users/glozow/orgs",
      "repos_url": "https://api.github.com/users/glozow/repos",
      "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
      "received_events_url": "https://api.github.com/users/glozow/received_events",
      "type": "User",
      "site_admin": false,
      "patch_url": null
    },
    "body": "This PR is part of the orphan resolution project, see #27463.\r\n\r\nThis design came from collaboration with sipa - thanks.\r\n\r\nWe want to limit the CPU work and memory used by `TxOrphanage` to avoid denial of service attacks. On master, this is achieved by limiting the number of transactions in this data structure to 100, and the weight of each transaction to 400KWu (the largest standard tx) [0]. We always allow new orphans, but if the addition causes us to exceed 100, we evict one randomly. This is dead simple, but has problems:\r\n- It makes the orphanage trivially churnable: any one peer can render it useless by spamming us with lots of orphans. It's possible this is happening: \"Looking at data from node alice on 2024-09-14 shows that weâ€™re sometimes removing more than 100k orphans per minute. This feels like someone flooding us with orphans.\" [1]\r\n- Effectively, opportunistic 1p1c is useless in the presence of adversaries: it is *opportunistic* and pairs a low feerate tx with a child that happens to be in the orphanage. So if nothing is able to stay in orphanages, we can't expect 1p1cs to propagate.\r\n- This number is also often insufficient for the volume of orphans we handle: historical data show that overflows are pretty common, and there are times where \"it seems like [the node] forgot about the orphans and re-requested them multiple times.\" [1] \r\n \r\nJust jacking up the `-maxorphantxs` number is not a good enough solution, because it doesn't solve the churnability problem, and the effective resource bounds scale poorly.\r\n\r\nThis PR introduces numbers for {global, per-peer} {memory usage, announcements}, representing resource limits:\r\n- The (constant) **global announcement limit** is the number of unique (wtxid, peer) pairs in the orphanage [2]. This represents a cap on CPU, and does not change with the number of peers we have. Evictions must happen whenever this limit is reached.\r\n- The (variable) **per-peer announcement limit** is the global announcement limit divided by the number of peers. Peers are allowed to exceed this limit provided the global announcement limit has not been reached. The per-peer announcement limit decreases with more peers.\r\n- The (constant) **per-peer memory usage reservation** is the amount of orphan weight [3] reserved per peer [4]. Reservation means that peers are effectively guaranteed this amount of space. It is not a limit; peers are allowed to exceed this limit provided the global usage limit is not reached.\r\n- The (variable) **global memory usage limit** is the number of peers multiplied by the per-peer reservation [5]. As such, the global memory usage limit scales up with the number of peers we have. Evictions must happen whenever this limit is reached.\r\n- We introduce a \"Peer DoS Score\" which is the maximum between its \"CPU Score\" and \"Memory Score.\" The CPU score is the ratio between the number of orphans announced by this peer / peer announcement limit. The memory score is the total usage of all orphans announced by this peer / peer usage reservation.\r\n\r\nEviction changes in a few ways:\r\n- It is triggered if the global announcement limit or global memory usage limit is exceeded.\r\n- On each iteration of the loop, instead of selecting a random orphan, we select a peer and delete 1 of its announcements. Specifically, we select the peer with the highest DoS score, which is the maximum between its CPU DoS score (based on announcements) and Memory DoS score (based on tx weight). After the peer has been selected, we evict the oldest orphan (non-reconsiderable sorted before reconsiderable).\r\n- Instead of evicting orphans, we evict announcements. An orphan is still in the orphanage as long as there is 1 peer announcer. Of course, over the course of several iteration loops, we may erase all announcers, thus erasing the orphan itself. The purpose of this change is to prevent a peer from being able to trigger eviction of another peer's orphans.\r\n\r\nThis PR also:\r\n- Reimplements `TxOrphanage` as single multi-index container.\r\n- Effectively bounds the number of transactions that can be in a peer's work set by ensuring it is a subset of the peer's announcements.\r\n- Removes the `-maxorphantxs` config option, as the orphanage no longer limits by unique orphans.\r\n\r\nThis means we can receive 1p1c packages in the presence of spammy peers. It also makes the orphanage more useful and increases our download capacity without drastically increasing orphanage resource usage.\r\n\r\n[0]: This means the effective memory limit in orphan weight is 100 * 400KWu = 40MWu\r\n[1]: https://delvingbitcoin.org/t/stats-on-orphanage-overflows/1421\r\n[2]: Limit is 3000, which is equivalent to one max size ancestor package (24 transactions can be missing inputs) for each peer (default max connections is 125).\r\n[3]: Orphan weight is used in place of actual memory usage because something like \"one maximally sized standard tx\" is easier to reason about than \"considering the bytes allocated for vin and vout vectors, it needs to be within N bytes...\" etc. We can also consider a different formula to encapsulate more the memory overhead but still have an interface that is easy to reason about.\r\n[4]: The limit is 404KWu, which is the maximum size of an ancestor package.\r\n[5]: With 125 peers, this is 50.5MWu, which is a small increase from the existing limit of 40MWu. While the actual memory usage limit is higher (this number does not include the other memory used by `TxOrphanage` to store the outpoints map, etc.), this is within the same ballpark as the old limit.",
    "labels": [
      {
        "id": 98298007,
        "node_id": "MDU6TGFiZWw5ODI5ODAwNw==",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/P2P",
        "name": "P2P",
        "color": "006b75",
        "default": false
      },
      {
        "id": 5334691551,
        "node_id": "LA_kwDOABII588AAAABPfju3w",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/labels/CI%20failed",
        "name": "CI failed",
        "description": "",
        "color": "cccccc",
        "default": false
      }
    ],
    "milestone": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/milestones/72",
      "html_url": "https://github.com/bitcoin/bitcoin/milestone/72",
      "labels_url": "https://api.github.com/repos/bitcoin/bitcoin/milestones/72/labels",
      "id": 12172984,
      "node_id": "MI_kwDOABII584Aub64",
      "number": 72,
      "state": "open",
      "title": "30.0",
      "description": "",
      "creator": {
        "login": "fanquake",
        "id": 863730,
        "node_id": "MDQ6VXNlcjg2MzczMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/863730?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/fanquake",
        "html_url": "https://github.com/fanquake",
        "followers_url": "https://api.github.com/users/fanquake/followers",
        "following_url": "https://api.github.com/users/fanquake/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/fanquake/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/fanquake/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/fanquake/subscriptions",
        "organizations_url": "https://api.github.com/users/fanquake/orgs",
        "repos_url": "https://api.github.com/users/fanquake/repos",
        "events_url": "https://api.github.com/users/fanquake/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/fanquake/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "open_issues": 10,
      "closed_issues": 26,
      "created_at": "2025-01-15T19:21:36Z",
      "updated_at": "2025-06-18T15:33:46Z"
    },
    "created_at": "2025-02-09T21:14:45Z",
    "updated_at": "2025-06-23T20:33:01Z",
    "mergeable": true,
    "mergeable_state": "blocked",
    "merged": false,
    "merge_commit_sha": "74b5933ebd9efcdad7d37ee25b47a39fd87d39da",
    "assignees": [],
    "requested_reviewers": [
      {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      {
        "login": "sr-gi",
        "id": 6665628,
        "node_id": "MDQ6VXNlcjY2NjU2Mjg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6665628?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sr-gi",
        "html_url": "https://github.com/sr-gi",
        "followers_url": "https://api.github.com/users/sr-gi/followers",
        "following_url": "https://api.github.com/users/sr-gi/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sr-gi/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sr-gi/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sr-gi/subscriptions",
        "organizations_url": "https://api.github.com/users/sr-gi/orgs",
        "repos_url": "https://api.github.com/users/sr-gi/repos",
        "events_url": "https://api.github.com/users/sr-gi/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sr-gi/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      {
        "login": "stickies-v",
        "id": 69010457,
        "node_id": "MDQ6VXNlcjY5MDEwNDU3",
        "avatar_url": "https://avatars.githubusercontent.com/u/69010457?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/stickies-v",
        "html_url": "https://github.com/stickies-v",
        "followers_url": "https://api.github.com/users/stickies-v/followers",
        "following_url": "https://api.github.com/users/stickies-v/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/stickies-v/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/stickies-v/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/stickies-v/subscriptions",
        "organizations_url": "https://api.github.com/users/stickies-v/orgs",
        "repos_url": "https://api.github.com/users/stickies-v/repos",
        "events_url": "https://api.github.com/users/stickies-v/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/stickies-v/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      }
    ],
    "requested_teams": [],
    "rebaseable": true,
    "head": {
      "label": "glozow:2025-01-orphanage-peer-dos",
      "ref": "2025-01-orphanage-peer-dos",
      "sha": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "repo": {
        "id": 244262754,
        "node_id": "MDEwOlJlcG9zaXRvcnkyNDQyNjI3NTQ=",
        "name": "bitcoin",
        "full_name": "glozow/bitcoin",
        "owner": {
          "login": "glozow",
          "id": 25183001,
          "node_id": "MDQ6VXNlcjI1MTgzMDAx",
          "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/glozow",
          "html_url": "https://github.com/glozow",
          "followers_url": "https://api.github.com/users/glozow/followers",
          "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
          "organizations_url": "https://api.github.com/users/glozow/orgs",
          "repos_url": "https://api.github.com/users/glozow/repos",
          "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/glozow/received_events",
          "type": "User",
          "site_admin": false,
          "patch_url": null
        },
        "private": false,
        "html_url": "https://github.com/glozow/bitcoin",
        "description": "Bitcoin Core integration/staging tree",
        "fork": true,
        "url": "https://api.github.com/repos/glozow/bitcoin",
        "archive_url": "https://api.github.com/repos/glozow/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/glozow/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/glozow/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/glozow/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/glozow/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/glozow/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/glozow/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/glozow/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/glozow/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/glozow/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/glozow/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/glozow/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/glozow/bitcoin/events",
        "forks_url": "https://api.github.com/repos/glozow/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/glozow/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/glozow/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/glozow/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/glozow/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/glozow/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/glozow/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/glozow/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/glozow/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/glozow/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/glozow/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/glozow/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/glozow/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/glozow/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/glozow/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/glozow/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:glozow/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/glozow/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/glozow/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/glozow/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/glozow/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/glozow/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/glozow/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/glozow/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/glozow/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/glozow/bitcoin/hooks",
        "svn_url": "https://github.com/glozow/bitcoin",
        "homepage": "https://bitcoincore.org/en/download",
        "language": "C++",
        "forks_count": 4,
        "stargazers_count": 15,
        "watchers_count": 15,
        "size": 274635,
        "default_branch": "master",
        "open_issues_count": 0,
        "is_template": false,
        "topics": [],
        "has_issues": false,
        "has_projects": true,
        "has_wiki": true,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2025-06-23T20:32:57Z",
        "created_at": "2020-03-02T02:31:56Z",
        "updated_at": "2025-06-17T18:05:12Z",
        "allow_forking": true,
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "base": {
      "label": "bitcoin:master",
      "ref": "master",
      "sha": "c5849663baa925a5291731e4e4013a08c811c646",
      "user": {
        "login": "bitcoin",
        "id": 528860,
        "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/bitcoin",
        "html_url": "https://github.com/bitcoin",
        "followers_url": "https://api.github.com/users/bitcoin/followers",
        "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
        "organizations_url": "https://api.github.com/users/bitcoin/orgs",
        "repos_url": "https://api.github.com/users/bitcoin/repos",
        "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/bitcoin/received_events",
        "type": "Organization",
        "site_admin": false,
        "patch_url": null
      },
      "repo": {
        "id": 1181927,
        "node_id": "MDEwOlJlcG9zaXRvcnkxMTgxOTI3",
        "name": "bitcoin",
        "full_name": "bitcoin/bitcoin",
        "owner": {
          "login": "bitcoin",
          "id": 528860,
          "node_id": "MDEyOk9yZ2FuaXphdGlvbjUyODg2MA==",
          "avatar_url": "https://avatars.githubusercontent.com/u/528860?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/bitcoin",
          "html_url": "https://github.com/bitcoin",
          "followers_url": "https://api.github.com/users/bitcoin/followers",
          "following_url": "https://api.github.com/users/bitcoin/following%7B/other_user%7D",
          "gists_url": "https://api.github.com/users/bitcoin/gists%7B/gist_id%7D",
          "starred_url": "https://api.github.com/users/bitcoin/starred%7B/owner%7D%7B/repo%7D",
          "subscriptions_url": "https://api.github.com/users/bitcoin/subscriptions",
          "organizations_url": "https://api.github.com/users/bitcoin/orgs",
          "repos_url": "https://api.github.com/users/bitcoin/repos",
          "events_url": "https://api.github.com/users/bitcoin/events%7B/privacy%7D",
          "received_events_url": "https://api.github.com/users/bitcoin/received_events",
          "type": "Organization",
          "site_admin": false,
          "patch_url": null
        },
        "private": false,
        "html_url": "https://github.com/bitcoin/bitcoin",
        "description": "Bitcoin Core integration/staging tree",
        "fork": false,
        "url": "https://api.github.com/repos/bitcoin/bitcoin",
        "archive_url": "https://api.github.com/repos/bitcoin/bitcoin/%7Barchive_format%7D%7B/ref%7D",
        "assignees_url": "https://api.github.com/repos/bitcoin/bitcoin/assignees%7B/user%7D",
        "blobs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/blobs%7B/sha%7D",
        "branches_url": "https://api.github.com/repos/bitcoin/bitcoin/branches%7B/branch%7D",
        "collaborators_url": "https://api.github.com/repos/bitcoin/bitcoin/collaborators%7B/collaborator%7D",
        "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/comments%7B/number%7D",
        "commits_url": "https://api.github.com/repos/bitcoin/bitcoin/commits%7B/sha%7D",
        "compare_url": "https://api.github.com/repos/bitcoin/bitcoin/compare/%7Bbase%7D...%7Bhead%7D",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/%7B+path%7D",
        "contributors_url": "https://api.github.com/repos/bitcoin/bitcoin/contributors",
        "deployments_url": "https://api.github.com/repos/bitcoin/bitcoin/deployments",
        "downloads_url": "https://api.github.com/repos/bitcoin/bitcoin/downloads",
        "events_url": "https://api.github.com/repos/bitcoin/bitcoin/events",
        "forks_url": "https://api.github.com/repos/bitcoin/bitcoin/forks",
        "git_commits_url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits%7B/sha%7D",
        "git_refs_url": "https://api.github.com/repos/bitcoin/bitcoin/git/refs%7B/sha%7D",
        "git_tags_url": "https://api.github.com/repos/bitcoin/bitcoin/git/tags%7B/sha%7D",
        "git_url": "git://github.com/bitcoin/bitcoin.git",
        "issue_comment_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments%7B/number%7D",
        "issue_events_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events%7B/number%7D",
        "issues_url": "https://api.github.com/repos/bitcoin/bitcoin/issues%7B/number%7D",
        "keys_url": "https://api.github.com/repos/bitcoin/bitcoin/keys%7B/key_id%7D",
        "labels_url": "https://api.github.com/repos/bitcoin/bitcoin/labels%7B/name%7D",
        "languages_url": "https://api.github.com/repos/bitcoin/bitcoin/languages",
        "merges_url": "https://api.github.com/repos/bitcoin/bitcoin/merges",
        "milestones_url": "https://api.github.com/repos/bitcoin/bitcoin/milestones%7B/number%7D",
        "notifications_url": "https://api.github.com/repos/bitcoin/bitcoin/notifications%7B?since,all,participating}",
        "pulls_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls%7B/number%7D",
        "releases_url": "https://api.github.com/repos/bitcoin/bitcoin/releases%7B/id%7D",
        "ssh_url": "git@github.com:bitcoin/bitcoin.git",
        "stargazers_url": "https://api.github.com/repos/bitcoin/bitcoin/stargazers",
        "statuses_url": "https://api.github.com/repos/bitcoin/bitcoin/statuses/%7Bsha%7D",
        "subscribers_url": "https://api.github.com/repos/bitcoin/bitcoin/subscribers",
        "subscription_url": "https://api.github.com/repos/bitcoin/bitcoin/subscription",
        "tags_url": "https://api.github.com/repos/bitcoin/bitcoin/tags",
        "teams_url": "https://api.github.com/repos/bitcoin/bitcoin/teams",
        "trees_url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees%7B/sha%7D",
        "clone_url": "https://github.com/bitcoin/bitcoin.git",
        "hooks_url": "https://api.github.com/repos/bitcoin/bitcoin/hooks",
        "svn_url": "https://github.com/bitcoin/bitcoin",
        "homepage": "https://bitcoincore.org/en/download",
        "language": "C++",
        "forks_count": 37407,
        "stargazers_count": 84291,
        "watchers_count": 84291,
        "size": 284330,
        "default_branch": "master",
        "open_issues_count": 754,
        "is_template": false,
        "topics": [
          "bitcoin",
          "c-plus-plus",
          "cryptocurrency",
          "cryptography",
          "p2p"
        ],
        "has_issues": true,
        "has_projects": true,
        "has_wiki": false,
        "has_pages": false,
        "has_downloads": false,
        "archived": false,
        "disabled": false,
        "visibility": "public",
        "pushed_at": "2025-06-23T08:53:39Z",
        "created_at": "2010-12-19T15:16:43Z",
        "updated_at": "2025-06-23T19:35:58Z",
        "allow_forking": true,
        "license": {
          "key": "mit",
          "name": "MIT License",
          "node_id": "MDc6TGljZW5zZTEz",
          "spdx_id": "MIT",
          "url": "https://api.github.com/licenses/mit",
          "html_url": null,
          "description": null,
          "implementation": null,
          "permissions": null,
          "conditions": null,
          "limitations": null,
          "body": null,
          "featured": null
        }
      }
    },
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
      }
    },
    "author_association": "MEMBER",
    "draft": false,
    "additions": 1810,
    "deletions": 878,
    "changed_files": 22,
    "commits": 18,
    "review_comments": 333,
    "comments": 31
  },
  "events": [
    {
      "event": "labeled",
      "id": 16239377177,
      "node_id": "LE_lADOABII586pVaFFzwAAAAPH8TsZ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16239377177",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-09T21:14:45Z",
      "label": {
        "name": "P2P",
        "color": "006b75"
      }
    },
    {
      "event": "commented",
      "id": 2646604015,
      "node_id": "IC_kwDOABII586dv_jv",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2646604015",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-09T21:14:49Z",
      "updated_at": "2025-06-23T20:09:25Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/31829.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| Concept ACK | [theStack](https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2944177234) |\n| Approach ACK | [sipa](https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2612094405), [jsarenik](https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2988173273) |\n| Stale ACK | [monlovesmango](https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2941377198) |\n\nIf your review is incorrectly listed, please react with ðŸ‘Ž to this comment and the bot will ignore it on the next update.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#32730](https://github.com/bitcoin/bitcoin/pull/32730) (p2p: avoid traversing blocks (twice) during IBD by furszy)\n* [#32631](https://github.com/bitcoin/bitcoin/pull/32631) (refactor: Convert GenTxid to `std::variant` by marcofleon)\n* [#32189](https://github.com/bitcoin/bitcoin/pull/32189) (refactor: Txid type safety (parent PR) by marcofleon)\n* [#29415](https://github.com/bitcoin/bitcoin/pull/29415) (Broadcast own transactions only via short-lived Tor or I2P connections by vasild)\n* [#28690](https://github.com/bitcoin/bitcoin/pull/28690) (build: Introduce internal kernel library by TheCharlatan)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2646604015",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16239389279,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPH8Wpf",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16239389279",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "765fcdf42418581061f9d01d24594d915be6f1a6",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/765fcdf42418581061f9d01d24594d915be6f1a6",
      "created_at": "2025-02-09T21:20:42Z"
    },
    {
      "event": "labeled",
      "id": 16239389767,
      "node_id": "LE_lADOABII586pVaFFzwAAAAPH8WxH",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16239389767",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-09T21:20:52Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2646606231,
      "node_id": "IC_kwDOABII586dwAGX",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2646606231",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-09T21:20:53Z",
      "updated_at": "2025-02-09T21:20:53Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Debug: https://github.com/bitcoin/bitcoin/runs/36925040096</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2646606231",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16239406371,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPH8a0j",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16239406371",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "d302324edcff648574c5df467435abee05e62a2e",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/d302324edcff648574c5df467435abee05e62a2e",
      "created_at": "2025-02-09T21:28:54Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16247362012,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPIaxHc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16247362012",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "0ccf21e7dff269450a9dc844250a919add997db9",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/0ccf21e7dff269450a9dc844250a919add997db9",
      "created_at": "2025-02-10T13:12:37Z"
    },
    {
      "event": "commented",
      "id": 2647951114,
      "node_id": "IC_kwDOABII586d1IcK",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2647951114",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-10T13:13:07Z",
      "updated_at": "2025-02-10T13:13:07Z",
      "author_association": "MEMBER",
      "body": "Rebased",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2647951114",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "ready_for_review",
      "id": 16247573394,
      "node_id": "RFRE_lADOABII586pVaFFzwAAAAPIbkuS",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16247573394",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-10T13:27:13Z"
    },
    {
      "event": "unlabeled",
      "id": 16250124243,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAPIlTfT",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16250124243",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-10T15:45:55Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "reviewed",
      "id": 2606517127,
      "node_id": "PRR_kwDOABII586bXEuH",
      "url": null,
      "actor": null,
      "commit_id": "0ccf21e7dff269450a9dc844250a919add997db9",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "The resource bounds additions seem to make sense, still working through the workset change implications.\r\n\r\nI've got a minimal fuzz harness checking that the \"honest\" peer cannot be evicted, please feel free to take it: https://github.com/instagibbs/bitcoin/tree/2025-01-orphanage-peer-dos_greg_2",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2606517127",
      "submitted_at": "2025-02-10T21:27:22Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16268223946,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPJqWXK",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16268223946",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "7aaf390a5a24857f7ced443a2739e43b4f4ade95",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/7aaf390a5a24857f7ced443a2739e43b4f4ade95",
      "created_at": "2025-02-11T17:03:24Z"
    },
    {
      "event": "commented",
      "id": 2651478837,
      "node_id": "IC_kwDOABII586eCls1",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2651478837",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-11T17:04:51Z",
      "updated_at": "2025-02-11T17:04:51Z",
      "author_association": "MEMBER",
      "body": "Thanks @instagibbs for the testing and review, added your fuzz commits and took comments. Still need to write the p2p_orphan_handling test.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2651478837",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "mentioned",
      "id": 16268244528,
      "node_id": "MEE_lADOABII586pVaFFzwAAAAPJqbYw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16268244528",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-11T17:04:52Z"
    },
    {
      "event": "subscribed",
      "id": 16268244548,
      "node_id": "SE_lADOABII586pVaFFzwAAAAPJqbZE",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16268244548",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-11T17:04:52Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16268286279,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPJqllH",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16268286279",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "61b40f0c97bde7b4f8b96a8520869e12f5abe01e",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/61b40f0c97bde7b4f8b96a8520869e12f5abe01e",
      "created_at": "2025-02-11T17:08:01Z"
    },
    {
      "event": "labeled",
      "id": 16268288502,
      "node_id": "LE_lADOABII586pVaFFzwAAAAPJqmH2",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16268288502",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-11T17:08:12Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2651487529,
      "node_id": "IC_kwDOABII586eCn0p",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2651487529",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-11T17:08:13Z",
      "updated_at": "2025-02-11T17:08:13Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Debug: https://github.com/bitcoin/bitcoin/runs/37041607307</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2651487529",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16268530016,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPJrhFg",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16268530016",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "ff826769d8f3b4a1d87e970d7bb9ea9cf8133f9b",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/ff826769d8f3b4a1d87e970d7bb9ea9cf8133f9b",
      "created_at": "2025-02-11T17:25:15Z"
    },
    {
      "event": "reviewed",
      "id": 2607117435,
      "node_id": "PRR_kwDOABII586bZXR7",
      "url": null,
      "actor": null,
      "commit_id": "ff826769d8f3b4a1d87e970d7bb9ea9cf8133f9b",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "body": "Halfway through, some minor points below - my main conceptual question is why `m_total_announcements` is a meaningful metric in limiting the orphanage.\r\n\r\nMy understanding is that  `m_total_orphan_usage` exists to limit memory usage, and `m_total_announcements` to limit CPU usage - but why the number of announcements instead of number of orphans?\r\nWhy would it make the situation any less DoSy if we remove an announcer but keep the orphan? Since we only assign the tx to one peer's workset after 7426afbe62414fa575f91b4f8d3ea63bcc653e8b, more announcers for the same number of orphans doesn't really mean any additional work.",
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2607117435",
      "submitted_at": "2025-02-11T19:33:02Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "commented",
      "id": 2652236274,
      "node_id": "IC_kwDOABII586eFeny",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2652236274",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-11T22:49:32Z",
      "updated_at": "2025-02-11T22:49:32Z",
      "author_association": "MEMBER",
      "body": "> My understanding is that m_total_orphan_usage exists to limit memory usage, and m_total_announcements to limit CPU usage - but why the number of announcements instead of number of orphans?\r\n\r\nYep, to limit CPU usage. The complexity of eviction for example is bounded by the total number of announcements: in the worst case, each orphan has many announcers and the `MaybeTrimOrphans` loop first removes announcements until each orphan just has 1 left, and then finally can remove transactions. See comment above declaration, \"The loop can run a maximum of m_max_global_announcement times\"\r\n\r\n> Why would it make the situation any less DoSy if we remove an announcer but keep the orphan?\r\n\r\nPerhaps I should have stated this in the OP more explicitly, but a major motivation for this eviction strategy is to prevent any peer from being to evict any announcements of another peer, hence the per-peer limits. If we changed the eviction code to remove orphans wholesale instead of just announcements, we'd have a similar situation to today's: an attacker can cause churn of an honest orphan by announcing it along with a lot of other orphans.\r\n\r\nSo evicting announcements instead of orphans isn't less DoSy, but it does make the orphanage less churnable.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2652236274",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16274745383,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPKDOgn",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16274745383",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "19194f243d9f67c3f0a7b1cd729a7a35feb14ae7",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/19194f243d9f67c3f0a7b1cd729a7a35feb14ae7",
      "created_at": "2025-02-12T04:25:16Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16274826885,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPKDiaF",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16274826885",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "3903310e059c80be671ae6f94e51b8a1afef7b2f",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/3903310e059c80be671ae6f94e51b8a1afef7b2f",
      "created_at": "2025-02-12T04:37:14Z"
    },
    {
      "event": "reviewed",
      "id": 2612094405,
      "node_id": "PRR_kwDOABII586bsWXF",
      "url": null,
      "actor": null,
      "commit_id": "3903310e059c80be671ae6f94e51b8a1afef7b2f",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Approach ACK",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2612094405",
      "submitted_at": "2025-02-12T14:35:40Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2612036122,
      "node_id": "PRR_kwDOABII586bsIIa",
      "url": null,
      "actor": null,
      "commit_id": "3903310e059c80be671ae6f94e51b8a1afef7b2f",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "combing through tests a bit, think I spotted the CI failure cause",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2612036122",
      "submitted_at": "2025-02-12T15:34:46Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "milestoned",
      "id": 16283646539,
      "node_id": "MIE_lADOABII586pVaFFzwAAAAPKlLpL",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16283646539",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-12T16:14:01Z",
      "milestone": {
        "title": "29.0"
      }
    },
    {
      "event": "review_requested",
      "id": 16299895751,
      "node_id": "RRE_lADOABII586pVaFFzwAAAAPLjKvH",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16299895751",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-13T16:59:40Z",
      "requested_reviewer": {
        "login": "sr-gi",
        "id": 6665628,
        "node_id": "MDQ6VXNlcjY2NjU2Mjg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6665628?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sr-gi",
        "html_url": "https://github.com/sr-gi",
        "followers_url": "https://api.github.com/users/sr-gi/followers",
        "following_url": "https://api.github.com/users/sr-gi/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sr-gi/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sr-gi/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sr-gi/subscriptions",
        "organizations_url": "https://api.github.com/users/sr-gi/orgs",
        "repos_url": "https://api.github.com/users/sr-gi/repos",
        "events_url": "https://api.github.com/users/sr-gi/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sr-gi/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "review_requester": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      }
    },
    {
      "event": "review_requested",
      "id": 16299895803,
      "node_id": "RRE_lADOABII586pVaFFzwAAAAPLjKv7",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16299895803",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-13T16:59:40Z",
      "requested_reviewer": {
        "login": "stickies-v",
        "id": 69010457,
        "node_id": "MDQ6VXNlcjY5MDEwNDU3",
        "avatar_url": "https://avatars.githubusercontent.com/u/69010457?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/stickies-v",
        "html_url": "https://github.com/stickies-v",
        "followers_url": "https://api.github.com/users/stickies-v/followers",
        "following_url": "https://api.github.com/users/stickies-v/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/stickies-v/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/stickies-v/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/stickies-v/subscriptions",
        "organizations_url": "https://api.github.com/users/stickies-v/orgs",
        "repos_url": "https://api.github.com/users/stickies-v/repos",
        "events_url": "https://api.github.com/users/stickies-v/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/stickies-v/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "review_requester": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16311325654,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPMOxPW",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16311325654",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "cbdabb2c2a74312f4e843af71851adf4aa052f85",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/cbdabb2c2a74312f4e843af71851adf4aa052f85",
      "created_at": "2025-02-14T12:52:35Z"
    },
    {
      "event": "unlabeled",
      "id": 16312587947,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAPMTlar",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16312587947",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-14T14:24:19Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16316092200,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPMg88o",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16316092200",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "fea6057abb77e6a411eded64fe6c65b0c95f809c",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/fea6057abb77e6a411eded64fe6c65b0c95f809c",
      "created_at": "2025-02-14T18:37:26Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16316310011,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPMhyH7",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16316310011",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "a704b8a9596c83968a732e26e44061c7347cecef",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/a704b8a9596c83968a732e26e44061c7347cecef",
      "created_at": "2025-02-14T18:59:22Z"
    },
    {
      "event": "labeled",
      "id": 16316310589,
      "node_id": "LE_lADOABII586pVaFFzwAAAAPMhyQ9",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16316310589",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-14T18:59:26Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "reviewed",
      "id": 2618600336,
      "node_id": "PRR_kwDOABII586cFKuQ",
      "url": null,
      "actor": null,
      "commit_id": "a704b8a9596c83968a732e26e44061c7347cecef",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2618600336",
      "submitted_at": "2025-02-14T19:05:39Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16316554612,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPMit10",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16316554612",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "2404ae2a7f2a816292d9be8adc32c82a68d2ae03",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/2404ae2a7f2a816292d9be8adc32c82a68d2ae03",
      "created_at": "2025-02-14T19:23:29Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16317236203,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPMlUPr",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16317236203",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "212e1ea50cc229483cbdde04ed2b22b9e7e5dfc6",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/212e1ea50cc229483cbdde04ed2b22b9e7e5dfc6",
      "created_at": "2025-02-14T20:43:32Z"
    },
    {
      "event": "reviewed",
      "id": 2618794047,
      "node_id": "PRR_kwDOABII586cF6A_",
      "url": null,
      "actor": null,
      "commit_id": "212e1ea50cc229483cbdde04ed2b22b9e7e5dfc6",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2618794047",
      "submitted_at": "2025-02-14T22:07:18Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "unlabeled",
      "id": 16318318396,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAPMpcc8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16318318396",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-14T23:13:56Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "reviewed",
      "id": 2619421638,
      "node_id": "PRR_kwDOABII586cITPG",
      "url": null,
      "actor": null,
      "commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2619421638",
      "submitted_at": "2025-02-15T14:32:17Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2619531521,
      "node_id": "PRR_kwDOABII586cIuEB",
      "url": null,
      "actor": null,
      "commit_id": "212e1ea50cc229483cbdde04ed2b22b9e7e5dfc6",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "kevkevinpal",
        "id": 15950706,
        "node_id": "MDQ6VXNlcjE1OTUwNzA2",
        "avatar_url": "https://avatars.githubusercontent.com/u/15950706?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/kevkevinpal",
        "html_url": "https://github.com/kevkevinpal",
        "followers_url": "https://api.github.com/users/kevkevinpal/followers",
        "following_url": "https://api.github.com/users/kevkevinpal/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/kevkevinpal/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/kevkevinpal/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/kevkevinpal/subscriptions",
        "organizations_url": "https://api.github.com/users/kevkevinpal/orgs",
        "repos_url": "https://api.github.com/users/kevkevinpal/repos",
        "events_url": "https://api.github.com/users/kevkevinpal/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/kevkevinpal/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2619531521",
      "submitted_at": "2025-02-16T03:25:07Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16341227248,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPOA1bw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16341227248",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "108fade768c37643e846489da76e1b46dfe61f89",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/108fade768c37643e846489da76e1b46dfe61f89",
      "created_at": "2025-02-18T02:55:57Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16348504061,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPOcl_9",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16348504061",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "6862a4993a32d2e3cf39db1cb0d2901cae19a2f1",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/6862a4993a32d2e3cf39db1cb0d2901cae19a2f1",
      "created_at": "2025-02-18T13:36:20Z"
    },
    {
      "event": "reviewed",
      "id": 2623681622,
      "node_id": "PRR_kwDOABII586cYjRW",
      "url": null,
      "actor": null,
      "commit_id": "6862a4993a32d2e3cf39db1cb0d2901cae19a2f1",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2623681622",
      "submitted_at": "2025-02-18T15:24:21Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "labeled",
      "id": 16351016474,
      "node_id": "LE_lADOABII586pVaFFzwAAAAPOmLYa",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16351016474",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-18T16:03:29Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 16355496092,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAPO3RCc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16355496092",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "8e3b80924e17bfe079f25d6d6db080a0112ea6d0",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/8e3b80924e17bfe079f25d6d6db080a0112ea6d0",
      "created_at": "2025-02-18T20:56:45Z"
    },
    {
      "event": "unlabeled",
      "id": 16356760604,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAPO8Fwc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16356760604",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-18T23:13:16Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "reviewed",
      "id": 2625405683,
      "node_id": "PRR_kwDOABII586cfILz",
      "url": null,
      "actor": null,
      "commit_id": "8e3b80924e17bfe079f25d6d6db080a0112ea6d0",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2625405683",
      "submitted_at": "2025-02-19T04:27:05Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "commented",
      "id": 2668766678,
      "node_id": "IC_kwDOABII586fEiXW",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2668766678",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-19T14:09:11Z",
      "updated_at": "2025-02-19T14:09:11Z",
      "author_association": "MEMBER",
      "body": "The changes here have surprisingly little effect on the included benchmarks:\r\n\r\n* [bench] TxOrphanage::LimitOrphans\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|       68,742,718.06 |               14.55 |    0.2% |     10.59 | `OrphanageEraseForBlockSinglePeer`\r\n|            8,857.40 |          112,899.93 |    0.3% |     10.86 | `OrphanageEvictionManyPeers`\r\n|        1,544,919.67 |              647.28 |    0.2% |     10.97 | `OrphanageWorksetManyPeers`\r\n|       11,444,367.17 |               87.38 |    0.1% |     11.00 | `OrphanageWorksetSinglePeer`\r\n\r\n* [txorphanage] when full, evict from the DoSiest peers first\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|       65,643,925.00 |               15.23 |    1.7% |     10.32 | `OrphanageEraseForBlockSinglePeer`\r\n|            8,657.19 |          115,510.91 |    0.1% |     10.83 | `OrphanageEvictionManyPeers`\r\n|        1,472,007.25 |              679.34 |    0.6% |     10.96 | `OrphanageWorksetManyPeers`\r\n|       10,034,423.77 |               99.66 |    0.3% |     11.05 | `OrphanageWorksetSinglePeer`\r\n\r\n* [txorphanage] limit EraseForBlock iterations and use set instead of vec\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|       59,924,050.19 |               16.69 |    1.1% |     10.98 | `OrphanageEraseForBlockSinglePeer`\r\n|            8,684.76 |          115,144.26 |    0.3% |     10.80 | `OrphanageEvictionManyPeers`\r\n|        1,500,899.95 |              666.27 |    0.2% |     11.10 | `OrphanageWorksetManyPeers`\r\n|       10,619,315.89 |               94.17 |    0.3% |     10.99 | `OrphanageWorksetSinglePeer`\r\n\r\n* [txorphanage] when orphans are erased, delete them from worksets\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|       59,404,692.72 |               16.83 |    1.6% |     10.70 | `OrphanageEraseForBlockSinglePeer`\r\n|            8,824.15 |          113,325.33 |    0.1% |     10.82 | `OrphanageEvictionManyPeers`\r\n|        1,481,787.75 |              674.86 |    0.2% |     10.96 | `OrphanageWorksetManyPeers`\r\n|       10,452,273.40 |               95.67 |    0.5% |     11.10 | `OrphanageWorksetSinglePeer`\r\n\r\n* Increase default -maxorphantx to 3000\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|       59,868,390.44 |               16.70 |    1.8% |     11.29 | `OrphanageEraseForBlockSinglePeer`\r\n|            9,275.98 |          107,805.36 |    0.3% |     10.97 | `OrphanageEvictionManyPeers`\r\n|        1,538,763.63 |              649.87 |    0.2% |     11.01 | `OrphanageWorksetManyPeers`\r\n|       10,657,836.93 |               93.83 |    0.4% |     11.03 | `OrphanageWorksetSinglePeer`\r\n",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2668766678",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2668811890,
      "node_id": "IC_kwDOABII586fEtZy",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2668811890",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-19T14:25:47Z",
      "updated_at": "2025-02-19T14:25:47Z",
      "author_association": "MEMBER",
      "body": "> The changes here have surprisingly little effect on the included benchmarks:\r\n\r\nMy expectation was that the time would go up with these changes, but hopefully not by too much.\r\n\r\nI am pretty surprised that \"[txorphanage] when full, evict from the DoSiest peers first\" doesn't make `OrphanageEvictionManyPeers` slower, but I guess it's because there are only 24 transactions.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2668811890",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2669192468,
      "node_id": "IC_kwDOABII586fGKUU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2669192468",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-19T16:43:55Z",
      "updated_at": "2025-02-19T16:43:55Z",
      "author_association": "MEMBER",
      "body": "Will add something like this as comments as well but here's the thinking around these benches:\r\n\r\n- The `EraseForBlock` bench exists to test the worst case `EraseForBlock` time, which is every orphan conflicting the maximum amount with the block. That's (very roughly) ~2000 inputs per tx (within 400KWu), times the max number of orphans.\r\n  - We're kind of cheating in \"limit EraseForBlock iterations and use set instead of vec\" which forces it to stop at 100 orphans, even if the max number of orphans is increased.\r\n  - There is also memory, which what changing to a `set` helps with. Due to the way the loops work, we would have 2000 * max number of orphans iterators in the vector.\r\n- The workset benches exist to test the worst case `AddChildrenToWorkSet` time. Similarly, worst case is when all orphans spend an output of the transaction. The complexity can also increase when there are multiple announcers for the orphans. \r\n- The eviction bench exists to test the worst case `LimitOrphans` time. Note it artificially uses `max_orphans=0` even though that doesn't happen in real life. The worst case is when every orphan has been announced by every peer, and we need to remove all announcers one by one before we actually erase anything. This would have been pretty bad before we set a global announcement limit.\r\n\r\nSo for all of these benches, we primarily want them to not blow up when we increase the `DEFAULT_MAX_ORPHAN_TRANSACTIONS`.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2669192468",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "demilestoned",
      "id": 16384547570,
      "node_id": "DEME_lADOABII586pVaFFzwAAAAPQmFry",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16384547570",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-20T15:31:50Z",
      "milestone": {
        "title": "29.0"
      }
    },
    {
      "event": "milestoned",
      "id": 16384548760,
      "node_id": "MIE_lADOABII586pVaFFzwAAAAPQmF-Y",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16384548760",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-20T15:31:54Z",
      "milestone": {
        "title": "30.0"
      }
    },
    {
      "event": "commented",
      "id": 2671888414,
      "node_id": "IC_kwDOABII586fQcge",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2671888414",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-20T15:44:14Z",
      "updated_at": "2025-02-20T15:44:14Z",
      "author_association": "MEMBER",
      "body": "Sad to see this slip, but given the amount of changes and discoveries that necessitated them even in just the last week, it's probably the right decision.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2671888414",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2671912617,
      "node_id": "IC_kwDOABII586fQiap",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2671912617",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-02-20T15:52:47Z",
      "updated_at": "2025-02-20T15:52:47Z",
      "author_association": "MEMBER",
      "body": "I'm sad too! Seeing the stats from https://delvingbitcoin.org/t/stats-on-orphanage-overflows/1421 made this more pressing in my opinion, but it's not a regression. I think we can still try to consider small, obviously safe changes for v29, but this feels too big. I don't want to risk creating new DoS problems.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2671912617",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2630943858,
      "node_id": "PRR_kwDOABII586c0QRy",
      "url": null,
      "actor": null,
      "commit_id": "8e3b80924e17bfe079f25d6d6db080a0112ea6d0",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2630943858",
      "submitted_at": "2025-02-20T21:27:19Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2630852607,
      "node_id": "PRR_kwDOABII586cz5__",
      "url": null,
      "actor": null,
      "commit_id": "8e3b80924e17bfe079f25d6d6db080a0112ea6d0",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2630852607",
      "submitted_at": "2025-02-20T22:48:56Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "commented",
      "id": 2698920711,
      "node_id": "IC_kwDOABII586g3kMH",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2698920711",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-03-04T21:13:17Z",
      "updated_at": "2025-03-04T21:13:17Z",
      "author_association": "MEMBER",
      "body": "Following coredev discussions, I'm working on a few things:\r\n- given selected peer, evict by entry/announcement time instead of randomly\r\n- shorten expiry time (and GETDATA interval)\r\n- rewrite as boost multi-index\r\n- clarify benches",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2698920711",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2698974332,
      "node_id": "IC_kwDOABII586g3xR8",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2698974332",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-03-04T21:29:58Z",
      "updated_at": "2025-03-04T21:29:58Z",
      "author_association": "MEMBER",
      "body": "> shorten expiry time (and GETDATA interval)\r\n\r\nIs this worth splitting out as its own PR?",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2698974332",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2699010480,
      "node_id": "IC_kwDOABII586g36Gw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2699010480",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-03-04T21:45:33Z",
      "updated_at": "2025-03-04T21:45:33Z",
      "author_association": "MEMBER",
      "body": "Yes! I think multi index could also be its own PR. But wanted to give a\nstatus update here.\n",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2699010480",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "convert_to_draft",
      "id": 16645165383,
      "node_id": "CTDE_lADOABII586pVaFFzwAAAAPgIRFH",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16645165383",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-03-09T15:03:44Z"
    },
    {
      "event": "labeled",
      "id": 16790307775,
      "node_id": "LE_lADOABII586pVaFFzwAAAAPox8O_",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/16790307775",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-03-16T09:47:34Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17716880679,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQgAiUn",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17716880679",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "49c4b32a3f0abfb3a07ba29b11873f8ee8564429",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/49c4b32a3f0abfb3a07ba29b11873f8ee8564429",
      "created_at": "2025-05-19T14:57:14Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17717426278,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQgCnhm",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17717426278",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "e6a5720116a08a4bdad72bfdb933358186eebf53",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/e6a5720116a08a4bdad72bfdb933358186eebf53",
      "created_at": "2025-05-19T15:25:04Z"
    },
    {
      "event": "labeled",
      "id": 17717474696,
      "node_id": "LE_lADOABII586pVaFFzwAAAAQgCzWI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17717474696",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-19T15:27:29Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2891445881,
      "node_id": "IC_kwDOABII586sV_Z5",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2891445881",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-19T15:27:31Z",
      "updated_at": "2025-05-19T15:27:31Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `lint`: https://github.com/bitcoin/bitcoin/runs/42487913320</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is due to multiple linting errors, including circular dependencies, missing include guards, and spelling mistakes.\n</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2891445881",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17717695408,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQgDpOw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17717695408",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "c0d7b4f60fbb19b8cc3ef2ee383cff313f58153f",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/c0d7b4f60fbb19b8cc3ef2ee383cff313f58153f",
      "created_at": "2025-05-19T15:37:30Z"
    },
    {
      "event": "unlabeled",
      "id": 17718458882,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQgGjoC",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17718458882",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-19T16:22:30Z",
      "label": {
        "name": "Needs rebase",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17732731896,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQg9AP4",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17732731896",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "c89b37b94574bbf4b97f86430ebac33c5d8f7319",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/c89b37b94574bbf4b97f86430ebac33c5d8f7319",
      "created_at": "2025-05-20T11:50:53Z"
    },
    {
      "event": "unlabeled",
      "id": 17737704010,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQhP-JK",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17737704010",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-20T16:08:13Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17771401356,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQjQhCM",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17771401356",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/ea3a65e698f519afee23484ce1b399e9a4c62529",
      "created_at": "2025-05-22T12:19:19Z"
    },
    {
      "event": "ready_for_review",
      "id": 17772165148,
      "node_id": "RFRE_lADOABII586pVaFFzwAAAAQjTbgc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17772165148",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-22T13:04:23Z"
    },
    {
      "event": "commented",
      "id": 2901169323,
      "node_id": "IC_kwDOABII586s7FSr",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2901169323",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-22T13:07:39Z",
      "updated_at": "2025-05-22T13:07:39Z",
      "author_association": "MEMBER",
      "body": "This is ready for review again. Main changes from February: it includes the rewrite as a boost::multi_index container, removes `-maxorphantxs` entirely, and drops the benches that weren't demonstrating anything. I've updated the PR description.\r\n\r\nRewrite and eviction changes are in the same commit. I didn't think it made sense to first reimplement the old design as a multi_index, because the old eviction strategy requires twice as many indexes. If you are familiar with the old design and just want to see the behavior changes applied to it before comparing it with the new impl, I have a copy of the original PR [here](https://github.com/glozow/bitcoin/tree/2025-05-copy-31829).",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2901169323",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "unsubscribed",
      "id": 17795020464,
      "node_id": "UE_lADOABII586pVaFFzwAAAAQkqnaw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17795020464",
      "actor": {
        "login": "deehochberg",
        "id": 185879065,
        "node_id": "U_kgDOCxRKGQ",
        "avatar_url": "https://avatars.githubusercontent.com/u/185879065?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/deehochberg",
        "html_url": "https://github.com/deehochberg",
        "followers_url": "https://api.github.com/users/deehochberg/followers",
        "following_url": "https://api.github.com/users/deehochberg/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/deehochberg/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/deehochberg/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/deehochberg/subscriptions",
        "organizations_url": "https://api.github.com/users/deehochberg/orgs",
        "repos_url": "https://api.github.com/users/deehochberg/repos",
        "events_url": "https://api.github.com/users/deehochberg/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/deehochberg/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-23T18:59:26Z"
    },
    {
      "event": "commented",
      "id": 2917545576,
      "node_id": "IC_kwDOABII586t5jZo",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2917545576",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-05-28T20:35:16Z",
      "updated_at": "2025-05-28T20:35:16Z",
      "author_association": "MEMBER",
      "body": "The PR title may need updating, as `-maxorphantxs` is gone now.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2917545576",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2876188083,
      "node_id": "PRR_kwDOABII586rbyWz",
      "url": null,
      "actor": null,
      "commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Some comments already.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2876188083",
      "submitted_at": "2025-05-28T21:31:59Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2871976352,
      "node_id": "PRR_kwDOABII586rLuGg",
      "url": null,
      "actor": null,
      "commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "reviewed through 455b4b817884f860cd4467f0a9be4a459e89891c\r\n\r\napologies if later commits clear up my confusion",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2871976352",
      "submitted_at": "2025-05-28T21:45:23Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2878472725,
      "node_id": "PRR_kwDOABII586rkgIV",
      "url": null,
      "actor": null,
      "commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "reviewed through ea3a65e698f519afee23484ce1b399e9a4c62529",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2878472725",
      "submitted_at": "2025-05-29T15:09:58Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2878764858,
      "node_id": "PRR_kwDOABII586rlnc6",
      "url": null,
      "actor": null,
      "commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2878764858",
      "submitted_at": "2025-05-29T15:46:52Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "renamed",
      "id": 17912912468,
      "node_id": "RTE_lADOABII586pVaFFzwAAAAQrsVpU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17912912468",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-01T11:00:21Z",
      "rename": {
        "from": "p2p: improve TxOrphanage denial of service bounds and increase -maxorphantxs",
        "to": "p2p: improve TxOrphanage denial of service bounds"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17938390714,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQtNh66",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17938390714",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "c7a7e762241344b7b88528310f716376426d9601",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/c7a7e762241344b7b88528310f716376426d9601",
      "created_at": "2025-06-02T16:35:29Z"
    },
    {
      "event": "reviewed",
      "id": 2888547849,
      "node_id": "PRR_kwDOABII586sK74J",
      "url": null,
      "actor": null,
      "commit_id": "c7a7e762241344b7b88528310f716376426d9601",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Thanks for the review! Just addressed most comments, still have a few more to get to",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2888547849",
      "submitted_at": "2025-06-02T16:36:09Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17938490397,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQtN6Qd",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17938490397",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "c864e0d45f9fdb9fbf0cf8e6e7c6f45754c5578a",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/c864e0d45f9fdb9fbf0cf8e6e7c6f45754c5578a",
      "created_at": "2025-06-02T16:40:56Z"
    },
    {
      "event": "labeled",
      "id": 17938502116,
      "node_id": "LE_lADOABII586pVaFFzwAAAAQtN9Hk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17938502116",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-02T16:41:28Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2931540814,
      "node_id": "IC_kwDOABII586uu8NO",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2931540814",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-02T16:41:30Z",
      "updated_at": "2025-06-02T16:41:30Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `lint`: https://github.com/bitcoin/bitcoin/runs/43322556029</sub>\n<sub>LLM reason (âœ¨ experimental): Lint check failed due to trailing whitespace in src/test/orphanage_tests.cpp.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2931540814",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2889242365,
      "node_id": "PRR_kwDOABII586sNlb9",
      "url": null,
      "actor": null,
      "commit_id": "3da112f33b11dffbfcc6cf1b01783501f5790a16",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2889242365",
      "submitted_at": "2025-06-02T16:53:05Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17967741073,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQu9fiR",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17967741073",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "243c2b8084ead35c9659a685bc95490d285e3e9b",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/243c2b8084ead35c9659a685bc95490d285e3e9b",
      "created_at": "2025-06-03T20:52:23Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 17968230516,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQu_XB0",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17968230516",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "9d4f8531fe9126dc0eea808db2d0d449cc3f129f",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/9d4f8531fe9126dc0eea808db2d0d449cc3f129f",
      "created_at": "2025-06-03T21:30:59Z"
    },
    {
      "event": "unlabeled",
      "id": 17969104473,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQvCsZZ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/17969104473",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-03T22:48:05Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "reviewed",
      "id": 2900619885,
      "node_id": "PRR_kwDOABII586s4_Jt",
      "url": null,
      "actor": null,
      "commit_id": "3322f9301e2ccb54678d32257fcedcd710aebe65",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2900619885",
      "submitted_at": "2025-06-05T14:37:05Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18008098816,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQxXcgA",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18008098816",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "70d326bdd508b1adf42f269d32a8dc0f1af27884",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/70d326bdd508b1adf42f269d32a8dc0f1af27884",
      "created_at": "2025-06-05T19:10:21Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18008214369,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQxX4th",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18008214369",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "0d511965c9175823ee602f02856cdb007d2036ea",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/0d511965c9175823ee602f02856cdb007d2036ea",
      "created_at": "2025-06-05T19:16:31Z"
    },
    {
      "event": "labeled",
      "id": 18008216578,
      "node_id": "LE_lADOABII586pVaFFzwAAAAQxX5QC",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18008216578",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-05T19:16:42Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2945796699,
      "node_id": "IC_kwDOABII586vlUpb",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2945796699",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-05T19:16:44Z",
      "updated_at": "2025-06-05T19:16:44Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `ARM, unit tests, no functional tests`: https://github.com/bitcoin/bitcoin/runs/43568906845</sub>\n<sub>LLM reason (âœ¨ experimental): The failure is due to a missing include of `<bitset>` in the source file.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2945796699",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "unlabeled",
      "id": 18010219203,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQxfiLD",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18010219203",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-05T21:07:45Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2949722160,
      "node_id": "IC_kwDOABII586v0TAw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2949722160",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-06T15:54:05Z",
      "updated_at": "2025-06-06T15:54:05Z",
      "author_association": "MEMBER",
      "body": "All comments addressed, ready for review. Will write up some notes for a review club soon.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2949722160",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2905651896,
      "node_id": "PRR_kwDOABII586tMLq4",
      "url": null,
      "actor": null,
      "commit_id": "0d511965c9175823ee602f02856cdb007d2036ea",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Made it through most of the big commit.",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2905651896",
      "submitted_at": "2025-06-06T21:16:39Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18063221415,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ0puKn",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18063221415",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "9f4f6057af74dcbce9211104fe19297aa34f61be",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/9f4f6057af74dcbce9211104fe19297aa34f61be",
      "created_at": "2025-06-09T21:35:47Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18063689403,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ0rga7",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18063689403",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "cde222ffb8d2f9e07e9b2ba05cafff3d023b95b0",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/cde222ffb8d2f9e07e9b2ba05cafff3d023b95b0",
      "created_at": "2025-06-09T22:21:24Z"
    },
    {
      "event": "labeled",
      "id": 18063691132,
      "node_id": "LE_lADOABII586pVaFFzwAAAAQ0rg18",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18063691132",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-09T22:21:34Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2957170296,
      "node_id": "IC_kwDOABII586wQtZ4",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2957170296",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-09T22:22:46Z",
      "updated_at": "2025-06-09T22:22:46Z",
      "author_association": "MEMBER",
      "body": "Rebased for silent merge conflict with #32406",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2957170296",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18063870066,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ0sMhy",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18063870066",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "890f1d6eb72b5571b5ff01feee16235365e096e0",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/890f1d6eb72b5571b5ff01feee16235365e096e0",
      "created_at": "2025-06-09T22:37:21Z"
    },
    {
      "event": "unlabeled",
      "id": 18064552557,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQ0uzJt",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18064552557",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-09T23:48:36Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18077868255,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ1hmDf",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18077868255",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "529b4fe4fca60b7653a2dfa8b208576eccf389a1",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/529b4fe4fca60b7653a2dfa8b208576eccf389a1",
      "created_at": "2025-06-10T15:19:26Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18079704671,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ1omZf",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18079704671",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "128ad62cd68038641ac7c3308ceb40c6c84d325e",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/128ad62cd68038641ac7c3308ceb40c6c84d325e",
      "created_at": "2025-06-10T17:11:49Z"
    },
    {
      "event": "labeled",
      "id": 18079711304,
      "node_id": "LE_lADOABII586pVaFFzwAAAAQ1ooBI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18079711304",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-10T17:12:21Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2960033904,
      "node_id": "IC_kwDOABII586wbohw",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2960033904",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-10T17:12:23Z",
      "updated_at": "2025-06-10T17:12:23Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `multiprocess, i686, DEBUG`: https://github.com/bitcoin/bitcoin/runs/43821676297</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is caused by an assertion failure in boost's safe iterator during the orphanage_tests.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2960033904",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2913790240,
      "node_id": "PRR_kwDOABII586trOkg",
      "url": null,
      "actor": null,
      "commit_id": "128ad62cd68038641ac7c3308ceb40c6c84d325e",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2913790240",
      "submitted_at": "2025-06-10T18:22:26Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2910938872,
      "node_id": "PRR_kwDOABII586tgWb4",
      "url": null,
      "actor": null,
      "commit_id": "128ad62cd68038641ac7c3308ceb40c6c84d325e",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "reviewed through 128ad62cd68038641ac7c3308ceb40c6c84d325e\r\n\r\nCI failure seems unrelated\r\n\r\nI'm going to think more about how evicting peers completely interacts with the behavior.",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2910938872",
      "submitted_at": "2025-06-10T19:44:26Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "unlabeled",
      "id": 18082954187,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQ10_vL",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18082954187",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-10T21:17:37Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18122251009,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ4K5sB",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18122251009",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "bc9844aaa53dedf5c723c91a13cc00fbbeaed089",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/bc9844aaa53dedf5c723c91a13cc00fbbeaed089",
      "created_at": "2025-06-12T20:19:47Z"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDJhNWQ4YmUwZDY5ODk4ZTY5ODU3MmMxMWNkYjUyZWRlZWQ4NDhiNDg",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/2a5d8be0d69898e698572c11cdb52edeed848b48",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/2a5d8be0d69898e698572c11cdb52edeed848b48",
      "tree": {
        "sha": "5867cafaec651e61789beb5a3b863489b9100b2f",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/5867cafaec651e61789beb5a3b863489b9100b2f"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/5757de4ddd37f9321ee6b338b40888fd3561fc00",
          "sha": "5757de4ddd37f9321ee6b338b40888fd3561fc00",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/5757de4ddd37f9321ee6b338b40888fd3561fc00"
        }
      ],
      "message": "[txorphanage] change type of usage to int64_t\n\nSince this field holds a total number of bytes, overflow is within the\nrealm of possibility. Use int64 to be safe.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-02-08T16:52:35Z"
      },
      "sha": "2a5d8be0d69898e698572c11cdb52edeed848b48"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGMyZGE4NmYwMWRmZWIyZjZiMGFjYmZmMzljZWFkNGIwYzRhNzM5MDY",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c2da86f01dfeb2f6b0acbff39cead4b0c4a73906",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/c2da86f01dfeb2f6b0acbff39cead4b0c4a73906",
      "tree": {
        "sha": "fa7d115a11dd6efebd2f6d842258bf4521cbb53a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/fa7d115a11dd6efebd2f6d842258bf4521cbb53a"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/2a5d8be0d69898e698572c11cdb52edeed848b48",
          "sha": "2a5d8be0d69898e698572c11cdb52edeed848b48",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/2a5d8be0d69898e698572c11cdb52edeed848b48"
        }
      ],
      "message": "[prep/refactor] move txorphanage to node namespace and directory\n\nThis is move-only.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-15T14:09:10Z"
      },
      "sha": "c2da86f01dfeb2f6b0acbff39cead4b0c4a73906"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDQxNTlkZWQwNWU0MWQyMjE0NWM1NWMzMzQ4MzZkYmZmMWU1OGUxNTk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/4159ded05e41d22145c55c334836dbff1e58e159",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/4159ded05e41d22145c55c334836dbff1e58e159",
      "tree": {
        "sha": "912f60d9e9b593cecf1bc5cfd16ffa0fa5484348",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/912f60d9e9b593cecf1bc5cfd16ffa0fa5484348"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c2da86f01dfeb2f6b0acbff39cead4b0c4a73906",
          "sha": "c2da86f01dfeb2f6b0acbff39cead4b0c4a73906",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/c2da86f01dfeb2f6b0acbff39cead4b0c4a73906"
        }
      ],
      "message": "[prep/rpc] remove entry and expiry time from getorphantxs\n\nExpiry is going away in a later commit.\nThis is only an RPC change. Behavior of the orphanage does not change.\nNote that getorphantxs is marked experimental.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-15T13:59:23Z"
      },
      "sha": "4159ded05e41d22145c55c334836dbff1e58e159"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDViNGZlZjNmNTcwMzY1MThhZjc0ZDZlNTQzOTI2ZTZjODBhYjExMDc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/5b4fef3f57036518af74d6e543926e6c80ab1107",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/5b4fef3f57036518af74d6e543926e6c80ab1107",
      "tree": {
        "sha": "a2586bbc4aad14448705d2a7f0f7b0e5210a1f32",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/a2586bbc4aad14448705d2a7f0f7b0e5210a1f32"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/4159ded05e41d22145c55c334836dbff1e58e159",
          "sha": "4159ded05e41d22145c55c334836dbff1e58e159",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/4159ded05e41d22145c55c334836dbff1e58e159"
        }
      ],
      "message": "[prep/test] modify test to not access TxOrphanage internals\n\nThese internals should and will be private.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-15T15:05:39Z"
      },
      "sha": "5b4fef3f57036518af74d6e543926e6c80ab1107"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDUxZThlZWZiMDYzN2ZhMWUwYTVlODkxZmEyOGFhNWQxNWZmMDM2ZWY",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/51e8eefb0637fa1e0a5e891fa28aa5d15ff036ef",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/51e8eefb0637fa1e0a5e891fa28aa5d15ff036ef",
      "tree": {
        "sha": "c3c994181f5ac21c04230b1abe442ab61912349d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/c3c994181f5ac21c04230b1abe442ab61912349d"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/5b4fef3f57036518af74d6e543926e6c80ab1107",
          "sha": "5b4fef3f57036518af74d6e543926e6c80ab1107",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/5b4fef3f57036518af74d6e543926e6c80ab1107"
        }
      ],
      "message": "[prep/config] remove -maxorphantx\n\nThe orphanage will no longer have a maximum number of unique orphans.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-15T15:36:37Z"
      },
      "sha": "51e8eefb0637fa1e0a5e891fa28aa5d15ff036ef"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDA1NzI4MDRlNzllMGU4MTA3MmFhYWEzMWI2NWVkOGI2NDc0OGQ5OTg",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/0572804e79e0e81072aaaa31b65ed8b64748d998",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/0572804e79e0e81072aaaa31b65ed8b64748d998",
      "tree": {
        "sha": "d886ecdf24d5f1afc3863ecaa346f6ea0d445236",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/d886ecdf24d5f1afc3863ecaa346f6ea0d445236"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/51e8eefb0637fa1e0a5e891fa28aa5d15ff036ef",
          "sha": "51e8eefb0637fa1e0a5e891fa28aa5d15ff036ef",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/51e8eefb0637fa1e0a5e891fa28aa5d15ff036ef"
        }
      ],
      "message": "[prep/refactor] move DEFAULT_MAX_ORPHAN_TRANSACTIONS to txorphanage.h\n\nThis is move only.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-16T14:27:35Z"
      },
      "sha": "0572804e79e0e81072aaaa31b65ed8b64748d998"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDFkMjJhYmQ0MjY5OTA4MGJjMDE3Yjk4NDI5YzRlYTkxOWQzMjk0Zjg",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/1d22abd42699080bc017b98429c4ea919d3294f8",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/1d22abd42699080bc017b98429c4ea919d3294f8",
      "tree": {
        "sha": "f6d9661509013b3e2c1d488764fc314873a5048b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/f6d9661509013b3e2c1d488764fc314873a5048b"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/0572804e79e0e81072aaaa31b65ed8b64748d998",
          "sha": "0572804e79e0e81072aaaa31b65ed8b64748d998",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/0572804e79e0e81072aaaa31b65ed8b64748d998"
        }
      ],
      "message": "[prep/test] have TxOrphanage remember its own limits in LimitOrphans\n\nMove towards a model where TxOrphanage is initialized with limits that\nit remembers throughout its lifetime.\nRemove the param. Limiting by number of unique orphans will be removed\nin a later commit.\nNow that -maxorphantx is gone, this does not change the node behavior.\nThe parameter is only used in tests.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-16T14:36:05Z"
      },
      "sha": "1d22abd42699080bc017b98429c4ea919d3294f8"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGNmYjY1NDM4Mzg5OTM2NGY4MDA0ZTIwMDkzMWEwMDA2N2U3YzIxZmU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/cfb654383899364f8004e200931a00067e7c21fe",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/cfb654383899364f8004e200931a00067e7c21fe",
      "tree": {
        "sha": "b654c0272b1aebb99038e181424ffdb98989fe83",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/b654c0272b1aebb99038e181424ffdb98989fe83"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/1d22abd42699080bc017b98429c4ea919d3294f8",
          "sha": "1d22abd42699080bc017b98429c4ea919d3294f8",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/1d22abd42699080bc017b98429c4ea919d3294f8"
        }
      ],
      "message": "[prep/refactor] make TxOrphanage a virtual class implemented by TxOrphanageImpl",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-03T17:54:06Z"
      },
      "sha": "cfb654383899364f8004e200931a00067e7c21fe"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDQyZTU5Y2Q1YTRhMTE5YmExNTk5MTE3OGYwNDM4YjRhN2ZmYjViYWI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/42e59cd5a4a119ba15991178f0438b4a7ffb5bab",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/42e59cd5a4a119ba15991178f0438b4a7ffb5bab",
      "tree": {
        "sha": "ac1fcf5f5e979da6a6eb428e13198cc682004e5d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/ac1fcf5f5e979da6a6eb428e13198cc682004e5d"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/cfb654383899364f8004e200931a00067e7c21fe",
          "sha": "cfb654383899364f8004e200931a00067e7c21fe",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/cfb654383899364f8004e200931a00067e7c21fe"
        }
      ],
      "message": "[prep] change return type of EraseTx to bool\n\nThis function only ever returns 0 or 1 (number of unique orphans\nerased).",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-12T21:03:15Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-09T20:01:15Z"
      },
      "sha": "42e59cd5a4a119ba15991178f0438b4a7ffb5bab"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18122907085,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ4NZ3N",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18122907085",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "2e80c33466eef6da2fefbeb3e3915bd344db65d9",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/2e80c33466eef6da2fefbeb3e3915bd344db65d9",
      "created_at": "2025-06-12T21:13:10Z"
    },
    {
      "event": "commented",
      "id": 2968171612,
      "node_id": "IC_kwDOABII586w6rRc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2968171612",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-12T21:13:34Z",
      "updated_at": "2025-06-12T21:13:34Z",
      "author_association": "MEMBER",
      "body": "Rebased and edited the functional tests for silent merge conflict with #32421",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2968171612",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18122977986,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ4NrLC",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18122977986",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "dd52ffbc60b45a3c38f0816c5cb2609a9cb106a0",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/dd52ffbc60b45a3c38f0816c5cb2609a9cb106a0",
      "created_at": "2025-06-12T21:19:23Z"
    },
    {
      "event": "labeled",
      "id": 18122981177,
      "node_id": "LE_lADOABII586pVaFFzwAAAAQ4Nr85",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18122981177",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-12T21:19:38Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2968183742,
      "node_id": "IC_kwDOABII586w6uO-",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2968183742",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-12T21:19:40Z",
      "updated_at": "2025-06-12T21:19:40Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `lint`: https://github.com/bitcoin/bitcoin/runs/44005354921</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is caused by lint errors detected by ruff due to unused variables in Python test code.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2968183742",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18123249295,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ4OtaP",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18123249295",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "dbde259191aa0ffc3c3c630b2a68f2bf36e77746",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/dbde259191aa0ffc3c3c630b2a68f2bf36e77746",
      "created_at": "2025-06-12T21:41:03Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18134825687,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAAQ463rX",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18134825687",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/d4b787b25f07b212bedb26433e64378673a27f6a",
      "created_at": "2025-06-13T13:59:18Z"
    },
    {
      "event": "unlabeled",
      "id": 18141009792,
      "node_id": "UNLE_lADOABII586pVaFFzwAAAAQ5SdeA",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18141009792",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-13T20:36:22Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "reviewed",
      "id": 2939536398,
      "node_id": "PRR_kwDOABII586vNcQO",
      "url": null,
      "actor": null,
      "commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2939536398",
      "submitted_at": "2025-06-18T15:23:37Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "reviewed",
      "id": 2941377198,
      "node_id": "PRR_kwDOABII586vUdqu",
      "url": null,
      "actor": null,
      "commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "body": "ACK d4b787b25f07b212bedb26433e64378673a27f6a\r\n\r\nThis is a strict improvement over the existing tx orphanage's DOS protection mechanism which can be manipulated by a malicious peer to probabilistically evict orphans from honest peers. With this approach, any honest peer that stays within the bounds of the defined orphan announcement count and usage is guaranteed to never have their orphan evicted by a malicious peer. This also strictly confines the total resources any one peer can consume in the tx orphanage and defines a deterministic method of resolving instances of peers exceeding the global orphan announcement limits/reservations.\r\n\r\nCouple small suggestions included.",
      "user": {
        "login": "monlovesmango",
        "id": 96307647,
        "node_id": "U_kgDOBb2Jvw",
        "avatar_url": "https://avatars.githubusercontent.com/u/96307647?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/monlovesmango",
        "html_url": "https://github.com/monlovesmango",
        "followers_url": "https://api.github.com/users/monlovesmango/followers",
        "following_url": "https://api.github.com/users/monlovesmango/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/monlovesmango/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/monlovesmango/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/monlovesmango/subscriptions",
        "organizations_url": "https://api.github.com/users/monlovesmango/orgs",
        "repos_url": "https://api.github.com/users/monlovesmango/repos",
        "events_url": "https://api.github.com/users/monlovesmango/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/monlovesmango/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2941377198",
      "submitted_at": "2025-06-19T04:37:26Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "review_requested",
      "id": 18222518609,
      "node_id": "RRE_lADOABII586pVaFFzwAAAAQ-JZFR",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18222518609",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-19T04:37:31Z",
      "requested_reviewer": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "review_requester": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      }
    },
    {
      "event": "commented",
      "id": 2987950049,
      "node_id": "IC_kwDOABII586yGH_h",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2987950049",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-19T12:35:57Z",
      "updated_at": "2025-06-19T12:38:32Z",
      "author_association": "MEMBER",
      "body": "Did a bit of rough benchmarking here https://github.com/instagibbs/bitcoin/tree/2025-06-bench-txorphanage-multiindex\r\n\r\nI built two scenarios to try and maximize the number of announcements evicted, while only allowing `DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS+1` announcements to be added before calling `LimitOrphans`. It's actually oversized in bytes terms early, but I consider this out of scope for the benchmark.\r\n\r\nNote that \"OrphanageManyWithManyPeers\" and \"OrphanageManyWithOnePeer\" are the same as the \"Eviction\" ones, they just don't evict so they're used to estimate the cost of constructing the full orphanage. I'm guessing there's a downside to estimating performance this way, but maybe an ok ballpark?\r\n```\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|       10,521,107.00 |               95.05 |    3.9% |      0.12 | `OrphanageEvictionManyWithManyPeers`\r\n|        2,792,771.00 |              358.07 |    0.2% |      0.03 | `OrphanageEvictionManyWithOnePeer`\r\n|       10,113,276.00 |               98.88 |    3.1% |      0.11 | `OrphanageManyWithManyPeers`\r\n|        2,214,154.00 |              451.64 |    0.4% |      0.02 | `OrphanageManyWithOnePeer`\r\n```\r\n\r\n~.4ms and ~.58ms the two scenarios, if monkey math is correct?",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2987950049",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2988173273,
      "node_id": "IC_kwDOABII586yG-fZ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2988173273",
      "actor": {
        "login": "jsarenik",
        "id": 244565,
        "node_id": "MDQ6VXNlcjI0NDU2NQ==",
        "avatar_url": "https://avatars.githubusercontent.com/u/244565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jsarenik",
        "html_url": "https://github.com/jsarenik",
        "followers_url": "https://api.github.com/users/jsarenik/followers",
        "following_url": "https://api.github.com/users/jsarenik/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jsarenik/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jsarenik/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jsarenik/subscriptions",
        "organizations_url": "https://api.github.com/users/jsarenik/orgs",
        "repos_url": "https://api.github.com/users/jsarenik/repos",
        "events_url": "https://api.github.com/users/jsarenik/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jsarenik/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-19T13:48:05Z",
      "updated_at": "2025-06-19T13:48:05Z",
      "author_association": "NONE",
      "body": "Approach ACK",
      "user": {
        "login": "jsarenik",
        "id": 244565,
        "node_id": "MDQ6VXNlcjI0NDU2NQ==",
        "avatar_url": "https://avatars.githubusercontent.com/u/244565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jsarenik",
        "html_url": "https://github.com/jsarenik",
        "followers_url": "https://api.github.com/users/jsarenik/followers",
        "following_url": "https://api.github.com/users/jsarenik/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jsarenik/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jsarenik/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jsarenik/subscriptions",
        "organizations_url": "https://api.github.com/users/jsarenik/orgs",
        "repos_url": "https://api.github.com/users/jsarenik/repos",
        "events_url": "https://api.github.com/users/jsarenik/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jsarenik/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2988173273",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2943147997,
      "node_id": "PRR_kwDOABII586vbN_d",
      "url": null,
      "actor": null,
      "commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "commit_url": null,
      "created_at": null,
      "author_association": "NONE",
      "user": {
        "login": "jsarenik",
        "id": 244565,
        "node_id": "MDQ6VXNlcjI0NDU2NQ==",
        "avatar_url": "https://avatars.githubusercontent.com/u/244565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jsarenik",
        "html_url": "https://github.com/jsarenik",
        "followers_url": "https://api.github.com/users/jsarenik/followers",
        "following_url": "https://api.github.com/users/jsarenik/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jsarenik/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jsarenik/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jsarenik/subscriptions",
        "organizations_url": "https://api.github.com/users/jsarenik/orgs",
        "repos_url": "https://api.github.com/users/jsarenik/repos",
        "events_url": "https://api.github.com/users/jsarenik/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jsarenik/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2943147997",
      "submitted_at": "2025-06-19T13:58:24Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "commented",
      "id": 2988441861,
      "node_id": "IC_kwDOABII586yIAEF",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2988441861",
      "actor": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-19T15:08:01Z",
      "updated_at": "2025-06-19T15:59:32Z",
      "author_association": "MEMBER",
      "body": "@instagibbs Ran your benchmarks with `-min-time=1000000` (so for ~18 minutes each) on a Ryzen 9 5950X CPU:\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|        8,005,268.73 |              124.92 |    0.1% |  1,074.80 | `OrphanageEvictionManyWithManyPeers`\r\n|        2,748,469.35 |              363.84 |    0.1% |  1,101.19 | `OrphanageEvictionManyWithOnePeer`\r\n|        7,783,037.34 |              128.48 |    0.1% |  1,073.93 | `OrphanageManyWithManyPeers`\r\n|        2,156,225.22 |              463.77 |    0.3% |  1,104.91 | `OrphanageManyWithOnePeer`\r\n\r\nI also ran them once with all 4 in parallel (slower, but any temperature-related CPU speed fluctuations would affect all equally):\r\n\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|        9,601,227.92 |              104.15 |    0.2% |  1,105.00 | `OrphanageEvictionManyWithManyPeers`\r\n|        2,928,013.47 |              341.53 |    0.2% |  1,103.20 | `OrphanageEvictionManyWithOnePeer`\r\n|        9,237,659.67 |              108.25 |    0.6% |  1,105.15 | `OrphanageManyWithManyPeers`\r\n|        2,274,349.94 |              439.69 |    0.7% |  1,106.91 | `OrphanageManyWithOnePeer`\r\n\r\nSo 0.22-0.36 ms for many peers, and 0.59-0.65 ms for one peer?\r\n\r\nIf so, I'd say we can tolerate 5x-10x more?",
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2988441861",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "mentioned",
      "id": 18232516865,
      "node_id": "MEE_lADOABII586pVaFFzwAAAAQ-viEB",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18232516865",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-19T15:08:02Z"
    },
    {
      "event": "subscribed",
      "id": 18232516893,
      "node_id": "SE_lADOABII586pVaFFzwAAAAQ-viEd",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18232516893",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-19T15:08:02Z"
    },
    {
      "event": "reviewed",
      "id": 2944177234,
      "node_id": "PRR_kwDOABII586vfJRS",
      "url": null,
      "actor": null,
      "commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "commit_url": null,
      "created_at": null,
      "author_association": "CONTRIBUTOR",
      "body": "Concept ACK\r\n\r\nLeft some mostly test-related nits I found from the first review round, haven't looked in-depth at the main commit a1bdebf370bf2fc43c0204ca2d6291e73fc7f91f yet.",
      "user": {
        "login": "theStack",
        "id": 91535,
        "node_id": "MDQ6VXNlcjkxNTM1",
        "avatar_url": "https://avatars.githubusercontent.com/u/91535?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theStack",
        "html_url": "https://github.com/theStack",
        "followers_url": "https://api.github.com/users/theStack/followers",
        "following_url": "https://api.github.com/users/theStack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theStack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theStack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theStack/subscriptions",
        "organizations_url": "https://api.github.com/users/theStack/orgs",
        "repos_url": "https://api.github.com/users/theStack/repos",
        "events_url": "https://api.github.com/users/theStack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theStack/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2944177234",
      "submitted_at": "2025-06-19T23:44:39Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "commented",
      "id": 2991971681,
      "node_id": "IC_kwDOABII586yVd1h",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2991971681",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-20T15:08:48Z",
      "updated_at": "2025-06-20T15:08:48Z",
      "author_association": "MEMBER",
      "body": "Trying not to derail the conversation but I spent a bit of time around thinking what the pessimal case for \"real\" traffic is. Let's assume there's an attacker who is  watching on the network for a victim's 1p1c package to be broadcast onto the network.\r\n\r\nLet's assume a \"quiet\" network, so announcements are capped at 3,000, and one peer at each hop ends up being fast enough relaying all parent-child pairs so the max memory in orphanage total is capped at 404kWU.\r\n\r\nAs soon as the victim package is spotted, the attacker sends their own \"honest\"-yet-evil cpfp packages, 404kWU total, at mempool minfee. The FIFO behavior kicks in, and the victim's child is dropped from orphanage.\r\n\r\nI'm not sure how practical this is, but I hope the scenario is clear and would demonstrate where larger reservation sizes (or total size) may come into play. The status quo is also likely worse in that the attacker can do a couple hundred tiny packages and accomplish the same censorship. ",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2991971681",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "commented",
      "id": 2997336575,
      "node_id": "IC_kwDOABII586yp7n_",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2997336575",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-23T17:43:10Z",
      "updated_at": "2025-06-23T17:43:10Z",
      "author_association": "MEMBER",
      "body": "> As soon as the victim package is spotted, the attacker sends their own \"honest\"-yet-evil cpfp packages, 404kWU total, at mempool minfee. The FIFO behavior kicks in, and the victim's child is dropped from orphanage.\r\n\r\nI think @mzumsande made this point a few months ago as well - we don't have many guarantees if new orphans arrive much faster than we can process them. An attacker would need to pay fees for real transactions so that other peers are also sending these transactions. TLDR you could end up dropping transactions simply because the traffic is beyond the size of each peer's buffer.\r\n\r\nHigher limits would help here (noted on 5-10x). But also, it seems like a good followup to assign different limits for outbounds vs inbounds? It seems advantageous for outbounds to take much longer to forget orphans.",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2997336575",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "mentioned",
      "id": 18278311182,
      "node_id": "MEE_lADOABII586pVaFFzwAAAARBeOUO",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18278311182",
      "actor": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-23T17:43:11Z"
    },
    {
      "event": "subscribed",
      "id": 18278311209,
      "node_id": "SE_lADOABII586pVaFFzwAAAARBeOUp",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18278311209",
      "actor": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-23T17:43:11Z"
    },
    {
      "event": "commented",
      "id": 2997379361,
      "node_id": "IC_kwDOABII586yqGEh",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2997379361",
      "actor": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-23T17:59:28Z",
      "updated_at": "2025-06-23T17:59:28Z",
      "author_association": "MEMBER",
      "body": "Higher limits result in multiplicative cost for said attackers, so maybe that's enough for practical issues until sender-initiated is implemented, which should mitigate this issue entirely.\r\n\r\nEither way, I believe this PR is strictly superior against this attack vs status quo.",
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2997379361",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDc4OTM5YzA5NGZjYmYzNDVkMzViNGFiZTEwNmNjN2ZlOGUxMzk2NTk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/78939c094fcbf345d35b4abe106cc7fe8e139659",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/78939c094fcbf345d35b4abe106cc7fe8e139659",
      "tree": {
        "sha": "7cf5e0b19eb13e2ed5bd32a2845dbdc7c2b5c088",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/7cf5e0b19eb13e2ed5bd32a2845dbdc7c2b5c088"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/42e59cd5a4a119ba15991178f0438b4a7ffb5bab",
          "sha": "42e59cd5a4a119ba15991178f0438b4a7ffb5bab",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/42e59cd5a4a119ba15991178f0438b4a7ffb5bab"
        }
      ],
      "message": "[p2p] overhaul TxOrphanage with smarter limits\n\nThis is largely a reimplementation using boost::multi_index_container.\nAll the same public methods are available. It has an index by outpoint,\nper-peer tracking, peer worksets, etc.\n\nA few differences:\n- Limits have changed: instead of a global limit of 100 unique orphans,\n  we have a maximum number of announcements (which can include duplicate\norphans) and a global memory limit which scales with the number of\npeers.\n- The maximum announcements limit is 100 to match the original limit,\n  but this is actually a stricter limit because the announcement count\nis not de-duplicated.\n- Eviction strategy: when global limits are reached, a per-peer limit\n  comes into play. While limits are exceeded, we choose the peer whose\nâ€œDoS scoreâ€ (max usage / limit ratio for announcements and memory\nlimits) is highest and evict announcements by entry time, sorting\nnon-reconsiderable ones before reconsiderable ones. Since announcements\nare unique by (wtxid, peer), as long as 1 announcement remains for a\ntransaction, it remains in the orphanage.\n- This eviction strategy means no peer can influence the eviction of\n  another peerâ€™s orphans.\n- Also, since global limits are a multiple of per-peer limits, as long\n  as a peer does not exceed its limits, its orphans are protected from\neviction.\n- Orphans no longer expire, since older announcements are generally\n  removed before newer ones.\n- GetChildrenFromSamePeer returns the transactions from newest to\n  oldest.\n\nCo-authored-by: Pieter Wuille <pieter@wuille.net>",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T18:47:21Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-04-02T21:29:38Z"
      },
      "sha": "78939c094fcbf345d35b4abe106cc7fe8e139659"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGRjYjBjZTU1NDI1ZWQyODE4YzdkNzRhNjYyN2M2Y2RhZmU3MWNiZjU",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/dcb0ce55425ed2818c7d74a6627c6cdafe71cbf5",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/dcb0ce55425ed2818c7d74a6627c6cdafe71cbf5",
      "tree": {
        "sha": "e874320c71a2f758d7bf7440480bca250d003eb8",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/e874320c71a2f758d7bf7440480bca250d003eb8"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/78939c094fcbf345d35b4abe106cc7fe8e139659",
          "sha": "78939c094fcbf345d35b4abe106cc7fe8e139659",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/78939c094fcbf345d35b4abe106cc7fe8e139659"
        }
      ],
      "message": "[cleanup] remove unused rng param from LimitOrphans",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T18:47:21Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-16T19:16:47Z"
      },
      "sha": "dcb0ce55425ed2818c7d74a6627c6cdafe71cbf5"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDIzODhkOWY1MDA2NTRiZGFlN2IxZWEwZWFhMzlkZjU5NzI0ZWFjMDk",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/2388d9f500654bdae7b1ea0eaa39df59724eac09",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/2388d9f500654bdae7b1ea0eaa39df59724eac09",
      "tree": {
        "sha": "4d86e7126bac809f93c033473713136967370cee",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/4d86e7126bac809f93c033473713136967370cee"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/dcb0ce55425ed2818c7d74a6627c6cdafe71cbf5",
          "sha": "dcb0ce55425ed2818c7d74a6627c6cdafe71cbf5",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/dcb0ce55425ed2818c7d74a6627c6cdafe71cbf5"
        }
      ],
      "message": "[cleanup] replace TxOrphanage::Size() with CountUniqueOrphans",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T18:47:21Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-05T18:13:28Z"
      },
      "sha": "2388d9f500654bdae7b1ea0eaa39df59724eac09"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGNkNWJlMGIzMmE5MGUxZjI3YzBmNjE1OGVkZjdkZTMyYzQyMzA5ODc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/cd5be0b32a90e1f27c0f6158edf7de32c4230987",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/cd5be0b32a90e1f27c0f6158edf7de32c4230987",
      "tree": {
        "sha": "08e96501e27b812780b45971c11643800d1f783f",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/08e96501e27b812780b45971c11643800d1f783f"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/2388d9f500654bdae7b1ea0eaa39df59724eac09",
          "sha": "2388d9f500654bdae7b1ea0eaa39df59724eac09",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/2388d9f500654bdae7b1ea0eaa39df59724eac09"
        }
      ],
      "message": "[unit test] basic TxOrphanageImpl eviction and protection",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T18:47:21Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-13T19:27:02Z"
      },
      "sha": "cd5be0b32a90e1f27c0f6158edf7de32c4230987"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDg3NTJiYmJlMGQ4OTZhMGZmMWQ4MTJkNTlmNmQ1MWRlZTNkYTFmM2U",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/8752bbbe0d896a0ff1d812d59f6d51dee3da1f3e",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/8752bbbe0d896a0ff1d812d59f6d51dee3da1f3e",
      "tree": {
        "sha": "dcaea85867cce0bffee4b58e10da2f7b52b1703e",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/dcaea85867cce0bffee4b58e10da2f7b52b1703e"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/cd5be0b32a90e1f27c0f6158edf7de32c4230987",
          "sha": "cd5be0b32a90e1f27c0f6158edf7de32c4230987",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/cd5be0b32a90e1f27c0f6158edf7de32c4230987"
        }
      ],
      "message": "[unit test] strengthen GetChildrenFromSamePeer tests: results are in recency order",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T18:47:21Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-15T14:30:12Z"
      },
      "sha": "8752bbbe0d896a0ff1d812d59f6d51dee3da1f3e"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGU2MzRhMjA3YzkyNWY4YTNkNzE0NWRhYWUwYWY5YjU2NTRlN2M3Mzc",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/e634a207c925f8a3d7145daae0af9b5654e7c737",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/e634a207c925f8a3d7145daae0af9b5654e7c737",
      "tree": {
        "sha": "b5363966ea24225e90433763700c5e40908f3ae6",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/b5363966ea24225e90433763700c5e40908f3ae6"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/8752bbbe0d896a0ff1d812d59f6d51dee3da1f3e",
          "sha": "8752bbbe0d896a0ff1d812d59f6d51dee3da1f3e",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/8752bbbe0d896a0ff1d812d59f6d51dee3da1f3e"
        }
      ],
      "message": "[fuzz] txorphanage_impl protection harness\n\nThis fuzzer specifically tests protection of an honest peer's orphans.\n\nCo-authored-by: Greg Sanders <gsanders87@gmail.com>",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T18:47:21Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-19T15:13:51Z"
      },
      "sha": "e634a207c925f8a3d7145daae0af9b5654e7c737"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKGYyM2Y1YjU5OTMwYzg2ZmUxMTA4MjQ0OWQzMWFhN2E3NDRmMGY2MDI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/f23f5b59930c86fe11082449d31aa7a744f0f602",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/f23f5b59930c86fe11082449d31aa7a744f0f602",
      "tree": {
        "sha": "b9014da0804988257c03f1edd58a94b1c062b446",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/b9014da0804988257c03f1edd58a94b1c062b446"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/e634a207c925f8a3d7145daae0af9b5654e7c737",
          "sha": "e634a207c925f8a3d7145daae0af9b5654e7c737",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/e634a207c925f8a3d7145daae0af9b5654e7c737"
        }
      ],
      "message": "[p2p] bump DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS to 3000\n\nFor the default number of peers (125), allows each to relay a default\ndescendant package of transactions (up to 25-1=24 can be missing inputs)\nout of order.\n\nFunctional tests aren't changed to check for larger cap because it would\nmake the runtime too long.\n\nAlso deletes the now-unused DEFAULT_MAX_ORPHAN_TRANSACTIONS.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T19:39:58Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-05-16T15:16:04Z"
      },
      "sha": "f23f5b59930c86fe11082449d31aa7a744f0f602"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDRjYmVhMWU0NDEzMDdkYmFmOWYzZjBhNjc5NDQ5ZDhiZmY2MDBmYWM",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/4cbea1e441307dbaf9f3f0a679449d8bff600fac",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/4cbea1e441307dbaf9f3f0a679449d8bff600fac",
      "tree": {
        "sha": "90b4699423375e55397ca7ec5bcfffe96b890660",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/90b4699423375e55397ca7ec5bcfffe96b890660"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/f23f5b59930c86fe11082449d31aa7a744f0f602",
          "sha": "f23f5b59930c86fe11082449d31aa7a744f0f602",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/f23f5b59930c86fe11082449d31aa7a744f0f602"
        }
      ],
      "message": "[prep/test] restart instead of bumpmocktime between p2p_orphan_handling subtests\n\nIf we want to restart at all during the tests, we can't have future timestamps.",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T19:40:09Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-01-28T13:28:23Z"
      },
      "sha": "4cbea1e441307dbaf9f3f0a679449d8bff600fac"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18280173397,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAARBlU9V",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18280173397",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "3f326f458e8e1afc03f75bb17a154e0a4b7cf5ca",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/3f326f458e8e1afc03f75bb17a154e0a4b7cf5ca",
      "created_at": "2025-06-23T19:46:21Z"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18280335129,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAARBl8cZ",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18280335129",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "dcff3685919e31355e25212c5c16c931f3db9a12",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/dcff3685919e31355e25212c5c16c931f3db9a12",
      "created_at": "2025-06-23T19:58:21Z"
    },
    {
      "event": "labeled",
      "id": 18280339319,
      "node_id": "LE_lADOABII586pVaFFzwAAAARBl9d3",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18280339319",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-23T19:58:41Z",
      "label": {
        "name": "CI failed",
        "color": "cccccc"
      }
    },
    {
      "event": "commented",
      "id": 2997776415,
      "node_id": "IC_kwDOABII586yrnAf",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/2997776415",
      "actor": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": null,
      "commit_url": null,
      "created_at": "2025-06-23T19:58:44Z",
      "updated_at": "2025-06-23T19:58:44Z",
      "author_association": "CONTRIBUTOR",
      "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `lint`: https://github.com/bitcoin/bitcoin/runs/44632073375</sub>\n<sub>LLM reason (âœ¨ experimental): The CI failure is caused by lint errors detected by 'ruff' that found 7 fixable issues, leading to a failure in the lint check.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
      "user": {
        "login": "DrahtBot",
        "id": 39886733,
        "node_id": "MDQ6VXNlcjM5ODg2NzMz",
        "avatar_url": "https://avatars.githubusercontent.com/u/39886733?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/DrahtBot",
        "html_url": "https://github.com/DrahtBot",
        "followers_url": "https://api.github.com/users/DrahtBot/followers",
        "following_url": "https://api.github.com/users/DrahtBot/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/DrahtBot/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/DrahtBot/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
        "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
        "repos_url": "https://api.github.com/users/DrahtBot/repos",
        "events_url": "https://api.github.com/users/DrahtBot/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#issuecomment-2997776415",
      "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/31829"
    },
    {
      "event": "reviewed",
      "id": 2951201583,
      "node_id": "PRR_kwDOABII586v58Mv",
      "url": null,
      "actor": null,
      "commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "commit_url": null,
      "created_at": null,
      "author_association": "MEMBER",
      "body": "Just addressing the comments on this push.\r\n\r\nI bumped max announcements locally and got some slow benchmarks, so will investigate. It's clear to me why this scenario (many tiny until you're just under memory limit, the 1 huge one) is the worst case `LimitOrphans` for 1 peer. For multiple peers, the number of announcements is still based on how many tiny transactions match the size of a max size one (otherwise `LimitOrphans` should have already triggered evictions), so the primary difference should just be heap operations, no?",
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#pullrequestreview-2951201583",
      "submitted_at": "2025-06-23T20:07:05Z",
      "state": "COMMENTED",
      "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18280488703,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAARBmh7_",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18280488703",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "e9085dbe968e9dcc09df6778846724f3eebfd4bd",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/e9085dbe968e9dcc09df6778846724f3eebfd4bd",
      "created_at": "2025-06-23T20:09:07Z"
    },
    {
      "event": "committed",
      "id": null,
      "node_id": "C_kwDOABII59oAKDYwOTMzMDBiZmNiOWJlN2Y3NmE2NjJkMWJiMjlkYmVlYzYwODE2YTI",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "actor": null,
      "commit_id": null,
      "commit_url": null,
      "created_at": null,
      "html_url": "https://github.com/bitcoin/bitcoin/commit/6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "tree": {
        "sha": "deb782d354b1bf2dc626ecde92e4c2bcab4314ac",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/deb782d354b1bf2dc626ecde92e4c2bcab4314ac"
      },
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "payload": null,
        "signature": null
      },
      "parents": [
        {
          "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/4cbea1e441307dbaf9f3f0a679449d8bff600fac",
          "sha": "4cbea1e441307dbaf9f3f0a679449d8bff600fac",
          "html_url": "https://github.com/bitcoin/bitcoin/commit/4cbea1e441307dbaf9f3f0a679449d8bff600fac"
        }
      ],
      "message": "[functional test] orphan resolution works in the presence of DoSy peers\n\nCo-authored-by: Greg Sanders <gsanders87@gmail.com>",
      "committer": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-06-23T20:32:54Z"
      },
      "author": {
        "name": "glozow",
        "email": "gloriajzhao@gmail.com",
        "date": "2025-01-29T13:26:23Z"
      },
      "sha": "6093300bfcb9be7f76a662d1bb29dbeec60816a2"
    },
    {
      "event": "head_ref_force_pushed",
      "id": 18280807799,
      "node_id": "HRFPE_lADOABII586pVaFFzwAAAARBnv13",
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/events/18280807799",
      "actor": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "commit_url": "https://api.github.com/repos/glozow/bitcoin/commits/6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "created_at": "2025-06-23T20:33:01Z"
    }
  ],
  "comments": [
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949498021",
      "pull_request_review_id": 2606517127,
      "id": 1949498021,
      "node_id": "PRRC_kwDOABII5850Mvql",
      "diff_hunk": "@@ -36,9 +36,10 @@ bool TxOrphanage::AddTx(const CTransactionRef& tx, NodeId peer)\n         return false;\n     }\n ",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 3,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212\r\n\r\n`MAX_GLOBAL_ORPHAN_ANNOUNCEMENTS` doesn't occur in the PR, should be `DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS`?",
      "created_at": "2025-02-10T16:43:36Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949498021",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949498021"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 55,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949514690",
      "pull_request_review_id": 2606517127,
      "id": 1949514690,
      "node_id": "PRRC_kwDOABII5850MzvC",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** The maximum number of announcements across all peers, representing a computational upper bound,\n+     * i.e. the maximum number of evictions we might do at a time. There is no per-peer announcement\n+     * limit until the global limit is reached. Also, this limit is constant regardless of how many\n+     * peers we have: if we only have 1 peer, this is the number of orphans they may provide. As",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 40,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "s/may provide/may provide without risking eviction/?",
      "created_at": "2025-02-10T16:50:22Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949514690",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949514690"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 47,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949514831",
      "pull_request_review_id": 2606517127,
      "id": 1949514831,
      "node_id": "PRRC_kwDOABII5850MzxP",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** The maximum number of announcements across all peers, representing a computational upper bound,\n+     * i.e. the maximum number of evictions we might do at a time. There is no per-peer announcement\n+     * limit until the global limit is reached. Also, this limit is constant regardless of how many\n+     * peers we have: if we only have 1 peer, this is the number of orphans they may provide. As\n+     * more peers are added, each peer's allocation is reduced. */",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 41,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "s/allocation/protected allocation/?\r\n\r\n",
      "created_at": "2025-02-10T16:50:24Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949514831",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949514831"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 48,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949519057",
      "pull_request_review_id": 2606517127,
      "id": 1949519057,
      "node_id": "PRRC_kwDOABII5850M0zR",
      "diff_hunk": "@@ -111,7 +137,6 @@ class TxOrphanage {\n \n protected:\n     struct OrphanTx : public OrphanTxBase {",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 56,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "do we think we'll end up using the derived class in a meaningful way later?",
      "created_at": "2025-02-10T16:51:18Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949519057",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949519057"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 148,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949538646",
      "pull_request_review_id": 2606517127,
      "id": 1949538646,
      "node_id": "PRRC_kwDOABII5850M5lW",
      "diff_hunk": "@@ -156,18 +201,47 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    unsigned int GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    unsigned int GetGlobalMaxUsage() const {\n+        return std::max<unsigned int>(m_peer_orphanage_info.size() * m_reserved_weight_per_peer, 1);\n+    }\n+\n+    unsigned int GetPerPeerMaxAnnouncements() const {",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 138,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "note: this is use to \"normalize\" the one DoS score metric against the other only. If this wasn't used, trimming would heavily favor announcement trimming scores first.",
      "created_at": "2025-02-10T17:02:50Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949538646",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949538646"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 247,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949554535",
      "pull_request_review_id": 2606517127,
      "id": 1949554535,
      "node_id": "PRRC_kwDOABII5850M9dn",
      "diff_hunk": "@@ -138,10 +165,28 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions in vector for quick random eviction */\n+        std::vector<OrphanMap::iterator> m_iter_list;\n+\n+        /** There are 2 DoS scores:\n+         * - CPU score (ratio of num announcements / max allowed announcements)\n+         * - Memory score (ratio of total usage / max allowed usage).\n+         *\n+         * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+         * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+         * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+         * be selected for trimming sooner. If the orphanage NeedsTrim(), it must be that at least\n+         * one peer has a DoS score > 1. */\n+        FeeFrac GetDoSScore(unsigned int peer_max_ann, unsigned int peer_max_mem) {\n+            FeeFrac cpu_score(m_iter_list.size(), peer_max_ann);\n+            FeeFrac mem_score(m_total_usage, peer_max_mem);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n     };\n     std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 93,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "re:global memory limits, they won't be increased until each connected peer offers up their own orphan or announcement (which makes sense)\r\n\r\nwould be good to have test/fuzz coverage that there isn't some bug where this continuously grows, raising the global limits to unsafe levels? Arg in `SanityCheck`?",
      "created_at": "2025-02-10T17:11:47Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949554535",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949554535"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 196,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949568939",
      "pull_request_review_id": 2606517127,
      "id": 1949568939,
      "node_id": "PRRC_kwDOABII5850NA-r",
      "diff_hunk": "@@ -87,29 +89,32 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n         }\n-    }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+        // Find this orphan iter's position in the list, and delete it.\n+        auto& orphan_list = peer_it->second.m_iter_list;\n+        size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));\n+\n+        if (!Assume(old_pos < orphan_list.size())) continue;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Maybe a bit too paranoid since it was just computed explicitly from the underlying list?",
      "created_at": "2025-02-10T17:21:10Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949568939",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949568939"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 103,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949583127",
      "pull_request_review_id": 2606517127,
      "id": 1949583127,
      "node_id": "PRRC_kwDOABII5850NEcX",
      "diff_hunk": "@@ -165,13 +170,68 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim() && m_orphans.size() <= max_orphans) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());\n+\n+    // Sort peers that have the highest ratio of DoSiness first\n+    auto compare_peer = [this](PeerMap::iterator left, PeerMap::iterator right) {\n+        const auto max_ann{GetPerPeerMaxAnnouncements()};\n+        const auto max_mem{GetPerPeerMaxUsage()};\n+        return left->second.GetDoSScore(max_ann, max_mem) < right->second.GetDoSScore(max_ann, max_mem);\n+    };\n+\n+    std::make_heap(peer_it_heap.begin(), peer_it_heap.end(), compare_peer);\n+\n     unsigned int nEvicted = 0;\n-    while (m_orphans.size() > max_orphans)\n+\n+    // Since each iteration should remove 1 announcement, this loop runs at most m_total_announcements times.\n+    // Note that we don't necessarily delete an orphan on each iteration. We might only be deleting\n+    // a peer from its announcers list.\n+    while (NeedsTrim() || m_orphans.size() > max_orphans)\n     {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+        if (!Assume(!peer_it_heap.empty())) break;\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used\n+        // over the allowance. This metric causes us to naturally select peers who have exceeded\n+        // their limits (i.e. a DoS score > 1) before peers who haven't. We may choose the same peer\n+        // change since the last iteration of this loop.",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 101,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "wording confusion: same peer change?",
      "created_at": "2025-02-10T17:29:13Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949583127",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949583127"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 200,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949610086",
      "pull_request_review_id": 2606517127,
      "id": 1949610086,
      "node_id": "PRRC_kwDOABII5850NLBm",
      "diff_hunk": "@@ -220,6 +220,42 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n     BOOST_CHECK_EQUAL(orphanage.CountOrphans(), 0);\n }\n \n+BOOST_AUTO_TEST_CASE(eviction)\n+{\n+    FastRandomContext det_rand{true};\n+    TxOrphanage orphanage;\n+\n+    // Send 10 orphans from 15 other peers\n+    NodeId max_peer{15};\n+    std::vector<unsigned int> peer_usages;\n+    for (NodeId peer{0}; peer < max_peer; ++peer) {\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+            orphanage.AddTx(ptx, peer);\n+        }\n+        peer_usages.emplace_back(orphanage.UsageByPeer(peer));\n+    }\n+\n+    NodeId dos_peer{max_peer};\n+    // Send max orphans from 1 peer\n+    for (unsigned int i{0}; i < DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS; ++i) {\n+        auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+        orphanage.AddTx(ptx, dos_peer);\n+    }\n+    peer_usages.emplace_back(orphanage.UsageByPeer(dos_peer));\n+\n+    // Force an eviction. Note that no limiting has happened yet at this point. LimitOrphans may",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 28,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "95b61662e51622292649cd15a61b9caa113cb2fc",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "> happened yet at this point\r\n\r\nDo you mean prior to LimitOrphans? ",
      "created_at": "2025-02-10T17:44:54Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949610086",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949610086"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 247,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949612609",
      "pull_request_review_id": 2606517127,
      "id": 1949612609,
      "node_id": "PRRC_kwDOABII5850NLpB",
      "diff_hunk": "@@ -220,6 +220,42 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n     BOOST_CHECK_EQUAL(orphanage.CountOrphans(), 0);\n }\n \n+BOOST_AUTO_TEST_CASE(eviction)\n+{\n+    FastRandomContext det_rand{true};\n+    TxOrphanage orphanage;\n+\n+    // Send 10 orphans from 15 other peers\n+    NodeId max_peer{15};\n+    std::vector<unsigned int> peer_usages;\n+    for (NodeId peer{0}; peer < max_peer; ++peer) {\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+            orphanage.AddTx(ptx, peer);\n+        }\n+        peer_usages.emplace_back(orphanage.UsageByPeer(peer));\n+    }\n+\n+    NodeId dos_peer{max_peer};\n+    // Send max orphans from 1 peer\n+    for (unsigned int i{0}; i < DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS; ++i) {\n+        auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+        orphanage.AddTx(ptx, dos_peer);\n+    }\n+    peer_usages.emplace_back(orphanage.UsageByPeer(dos_peer));\n+\n+    // Force an eviction. Note that no limiting has happened yet at this point. LimitOrphans may\n+    // evict more than 1 transaction. All evictions will be from the dos_peer's transactions.\n+    const auto prev_count = orphanage.Size();\n+    orphanage.LimitOrphans(prev_count - 1, det_rand);\n+    BOOST_CHECK(orphanage.Size() <= prev_count - 1);\n+\n+    // The DoS peer's orphans have been evicted, nobody else's have.\n+    for (NodeId peer{0}; peer <= dos_peer; ++peer) {\n+        BOOST_CHECK_EQUAL(peer == dos_peer, peer_usages.at(peer) != orphanage.UsageByPeer(peer));",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 36,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "95b61662e51622292649cd15a61b9caa113cb2fc",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nit: would rather we check that we evicted the dos'y peer and somehow didn't *add* more resources allocated to him",
      "created_at": "2025-02-10T17:46:45Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949612609",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949612609"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 256,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949641427",
      "pull_request_review_id": 2606517127,
      "id": 1949641427,
      "node_id": "PRRC_kwDOABII5850NSrT",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": 118,
      "original_position": 124,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "could do this for both cases\r\n```Suggestion  \r\n       # Something was evicted\r\n        assert_greater_than(len(large_orphans), len(node.getorphantxs()))\r\n```",
      "created_at": "2025-02-10T18:04:45Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949641427",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949641427"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 465,
      "original_line": 465,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949655371",
      "pull_request_review_id": 2606517127,
      "id": 1949655371,
      "node_id": "PRRC_kwDOABII5850NWFL",
      "diff_hunk": "@@ -0,0 +1,137 @@\n+// Copyright (c) 2011-2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <bench/bench.h>\n+#include <consensus/amount.h>\n+#include <net.h>\n+#include <primitives/transaction.h>\n+#include <pubkey.h>\n+#include <script/sign.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <util/check.h>\n+\n+#include <cstdint>\n+#include <memory>\n+\n+// Creates a transaction spending outpoints (or 1 randomly generated input if none are given), with num_outputs outputs.\n+static CTransactionRef MakeTransactionSpending(const std::vector<COutPoint>& outpoints, unsigned int num_outputs, FastRandomContext& det_rand)\n+{\n+    CMutableTransaction tx;\n+\n+    // Build vin\n+    // If no outpoints are given, create a random one.\n+    if (outpoints.empty()) {\n+        tx.vin.emplace_back(Txid::FromUint256(det_rand.rand256()), 0);\n+    } else {\n+        for (const auto& outpoint : outpoints) {\n+            tx.vin.emplace_back(outpoint);\n+        }\n+    }\n+    // Ensure txid != wtxid\n+    assert(tx.vin.size() > 0);\n+    tx.vin[0].scriptWitness.stack.push_back({1});\n+\n+    // Build vout\n+    assert(num_outputs > 0);\n+    tx.vout.resize(num_outputs);\n+    for (unsigned int o = 0; o < num_outputs; ++o) {\n+        tx.vout[o].nValue = det_rand.randrange(100) * CENT;\n+        tx.vout[o].scriptPubKey = CScript() << CScriptNum(det_rand.randrange(o + 100)) << OP_EQUAL;\n+    }\n+    return MakeTransactionRef(tx);\n+}\n+\n+static void OrphanageEvictionMany(benchmark::Bench& bench)\n+{\n+    NodeId NUM_PEERS{125};\n+    unsigned int NUM_TRANSACTIONS(DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / NUM_PEERS);",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 49,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3ce9ef7dd3c231976454e8c836640507bdb7e111",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "seems wrong, you're sending 3000/125=24 transactions *total*?",
      "created_at": "2025-02-10T18:15:47Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949655371",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949655371"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 103,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949834394",
      "pull_request_review_id": 2606517127,
      "id": 1949834394,
      "node_id": "PRRC_kwDOABII5850OBya",
      "diff_hunk": "@@ -264,10 +266,24 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\n                 // Get this source peer's work set, emplacing an empty set if it didn't exist\n                 // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n                 std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n-                LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+\n+                // If this peer's work set would exceed the maximum allowed size, trim any work\n+                // items that are no longer in the orphanage. We should only do this once per peer\n+                // per call to AddChildrenToWorkSet, so keep track of which peers we have trimmed.\n+                // We also never need to do it more than once since evictions don't happen in this\n+                // function.\n+                if (orphan_work_set.size() + 1 > MAX_ORPHAN_WORK_QUEUE && !peers_workset_trimmed.contains(announcer)) {\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 24,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "33034eaa3b45c815fc595c5d906b38c12602a3df",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "this is backwards. See added unit test:\r\n```\r\ndiff --git a/src/test/orphanage_tests.cpp b/src/test/orphanage_tests.cpp\r\nindex fe0f81fdb4..dde42d9d4a 100644\r\n--- a/src/test/orphanage_tests.cpp\r\n+++ b/src/test/orphanage_tests.cpp\r\n@@ -77,0 +78,24 @@ static CTransactionRef MakeTransactionSpending(const std::vector<COutPoint>& out\r\n+// 101 output transaction\r\n+static CTransactionRef MakeHugeTransactionSpending(const std::vector<COutPoint>& outpoints, FastRandomContext& det_rand)\r\n+{\r\n+    CKey key;\r\n+    MakeNewKeyWithFastRandomContext(key, det_rand);\r\n+    CMutableTransaction tx;\r\n+    // If no outpoints are given, create a random one.\r\n+    if (outpoints.empty()) {\r\n+        tx.vin.emplace_back(Txid::FromUint256(det_rand.rand256()), 0);\r\n+    } else {\r\n+        for (const auto& outpoint : outpoints) {\r\n+            tx.vin.emplace_back(outpoint);\r\n+        }\r\n+    }\r\n+    // Ensure txid != wtxid\r\n+    tx.vin[0].scriptWitness.stack.push_back({1});\r\n+    tx.vout.resize(101);\r\n+    tx.vout[0].nValue = CENT;\r\n+    tx.vout[0].scriptPubKey = GetScriptForDestination(PKHash(key.GetPubKey()));\r\n+    tx.vout[1].nValue = 3 * CENT;\r\n+    tx.vout[1].scriptPubKey = GetScriptForDestination(WitnessV0KeyHash(key.GetPubKey()));\r\n+    return MakeTransactionRef(tx);\r\n+}\r\n+\r\n@@ -598,0 +623,23 @@ BOOST_AUTO_TEST_CASE(peer_worksets)\r\n+\r\n+        {\r\n+            // We will fill the orphanage with a single parent and 101 children\r\n+            // from that single transaction to cause potential deletion of work set\r\n+            // from peer 0.\r\n+            auto tx_missing_parent = MakeHugeTransactionSpending({}, det_rand);\r\n+            std::vector<CTransactionRef> tx_orphans;\r\n+            for (unsigned int i{0}; i < MAX_ORPHAN_WORK_QUEUE + 1; i++) {\r\n+                auto tx_orphan = MakeTransactionSpending({COutPoint{tx_missing_parent->GetHash(), i}}, det_rand);\r\n+                BOOST_CHECK(orphanage.AddTx(tx_orphan, /*peer=*/node0));\r\n+            }\r\n+\r\n+            // 101 transactions in the orphanage (no trimming of orphanage yet), now\r\n+            // add parent to work set, which will all be allocated to peer 0.\r\n+            // work set should get trimmed exactly once down to MAX_ORPHAN_WORK_QUEUE\r\n+            orphanage.AddChildrenToWorkSet(*tx_missing_parent, det_rand);\r\n+            for (unsigned int i{0}; i < MAX_ORPHAN_WORK_QUEUE; i++) {\r\n+                BOOST_CHECK(orphanage.GetTxToReconsider(node0));\r\n+            }\r\n+\r\n+            // We should have emptied the work queue in MAX_ORPHAN_WORK_QUEUE steps\r\n+            BOOST_CHECK(!orphanage.HaveTxToReconsider(node0));\r\n+        }\r\ndiff --git a/src/txorphanage.cpp b/src/txorphanage.cpp\r\nindex 09d50a244a..2a881db669 100644\r\n--- a/src/txorphanage.cpp\r\n+++ b/src/txorphanage.cpp\r\n@@ -276 +276 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\r\n-                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });\r\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return !m_orphans.contains(wtxid); });\r\n```",
      "created_at": "2025-02-10T20:28:08Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949834394",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949834394"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 276,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949852220",
      "pull_request_review_id": 2606517127,
      "id": 1949852220,
      "node_id": "PRRC_kwDOABII5850OGI8",
      "diff_hunk": "@@ -264,10 +266,24 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\n                 // Get this source peer's work set, emplacing an empty set if it didn't exist\n                 // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n                 std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n-                LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+\n+                // If this peer's work set would exceed the maximum allowed size, trim any work\n+                // items that are no longer in the orphanage. We should only do this once per peer\n+                // per call to AddChildrenToWorkSet, so keep track of which peers we have trimmed.\n+                // We also never need to do it more than once since evictions don't happen in this\n+                // function.\n+                if (orphan_work_set.size() + 1 > MAX_ORPHAN_WORK_QUEUE && !peers_workset_trimmed.contains(announcer)) {\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });\n+                    peers_workset_trimmed.insert(announcer);\n+                }\n+\n+                // Add this tx to the work set. If the workset is full, even after trimming, don't\n+                // accept any new work items until the work queue has been flushed.\n+                if (orphan_work_set.size() < MAX_ORPHAN_WORK_QUEUE) {",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 30,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "33034eaa3b45c815fc595c5d906b38c12602a3df",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "should we debug log if we're not adding to work set? might be good to know it's happening",
      "created_at": "2025-02-10T20:40:56Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949852220",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949852220"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 281,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949856455",
      "pull_request_review_id": 2607117435,
      "id": 1949856455,
      "node_id": "PRRC_kwDOABII5850OHLH",
      "diff_hunk": "@@ -140,13 +140,12 @@ void TxOrphanage::EraseForPeer(NodeId peer)\n     if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n }\n \n-void TxOrphanage::LimitOrphans(unsigned int max_orphans, FastRandomContext& rng)\n+unsigned int TxOrphanage::MaybeExpireOrphans()\n {\n-    unsigned int nEvicted = 0;\n+    int nErased = 0;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 8,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ff24c1feeb2878f7f1d31127ea220c788eb6a187",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nit: doesn't really matter if unsigned int (return value) or int is used, but would be nice to make it consistent, also with the %u / %d format specifiers in the logprints.",
      "created_at": "2025-02-10T20:42:26Z",
      "updated_at": "2025-02-11T19:33:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949856455",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949856455"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 149,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949899180",
      "pull_request_review_id": 2607117435,
      "id": 1949899180,
      "node_id": "PRRC_kwDOABII5850ORms",
      "diff_hunk": "@@ -160,15 +159,29 @@ void TxOrphanage::LimitOrphans(unsigned int max_orphans, FastRandomContext& rng)\n         }\n         // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n         m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n     }\n+    return nErased;\n+}\n+\n+unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n+{\n+    unsigned int nEvicted = 0;\n     while (m_orphans.size() > max_orphans)\n     {\n         // Evict a random orphan:\n         size_t randompos = rng.randrange(m_orphan_list.size());\n         EraseTx(m_orphan_list[randompos]->first);\n         ++nEvicted;\n     }\n+    return nEvicted;\n+}\n+\n+void TxOrphanage::LimitOrphans(unsigned int max_orphans, FastRandomContext& rng)",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 38,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ff24c1feeb2878f7f1d31127ea220c788eb6a187",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nit: commit msg of c929d71c0828544be509934312b6a7d11b47ea4d lacks a verb (e.g. \"split\").",
      "created_at": "2025-02-10T21:12:18Z",
      "updated_at": "2025-02-11T19:33:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949899180",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949899180"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 245,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949911002",
      "pull_request_review_id": 2606517127,
      "id": 1949911002,
      "node_id": "PRRC_kwDOABII5850OUfa",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 103,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "the honest orphan should be as large as possible: `target_vsize=100000`",
      "created_at": "2025-02-10T21:22:49Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949911002",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949911002"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 451,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949911352",
      "pull_request_review_id": 2606517127,
      "id": 1949911352,
      "node_id": "PRRC_kwDOABII5850OUk4",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 152,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "the honest orphan should be as large as possible: `target_vsize=100000`",
      "created_at": "2025-02-10T21:23:09Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949911352",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949911352"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 500,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949914892",
      "pull_request_review_id": 2606517127,
      "id": 1949914892,
      "node_id": "PRRC_kwDOABII5850OVcM",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": 127,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "can we get a functional test case that covers the \"protects fully sized ancestor package\" scenario in `p2p_orphan_handling.py`? ",
      "created_at": "2025-02-10T21:26:06Z",
      "updated_at": "2025-02-10T21:27:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949914892",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949914892"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 474,
      "original_line": 474,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949955925",
      "pull_request_review_id": 2607117435,
      "id": 1949955925,
      "node_id": "PRRC_kwDOABII5850OfdV",
      "diff_hunk": "@@ -156,18 +201,47 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    unsigned int GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    unsigned int GetGlobalMaxUsage() const {\n+        return std::max<unsigned int>(m_peer_orphanage_info.size() * m_reserved_weight_per_peer, 1);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 135,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "should this be `int64_t` instead of `int` in the spirit of the first commit?",
      "created_at": "2025-02-10T21:58:01Z",
      "updated_at": "2025-02-11T19:33:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949955925",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949955925"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 236,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949998393",
      "pull_request_review_id": 2607117435,
      "id": 1949998393,
      "node_id": "PRRC_kwDOABII5850Op05",
      "diff_hunk": "@@ -165,13 +170,68 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim() && m_orphans.size() <= max_orphans) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 74,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "should call `reserve` before pushing entries to `peer_it_heap`, not after.",
      "created_at": "2025-02-10T22:35:24Z",
      "updated_at": "2025-02-11T19:33:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1949998393",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1949998393"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 185,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950002603",
      "pull_request_review_id": 2607117435,
      "id": 1950002603,
      "node_id": "PRRC_kwDOABII5850Oq2r",
      "diff_hunk": "@@ -165,13 +170,68 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim() && m_orphans.size() <= max_orphans) return 0;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 70,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Could `m_orphans.size() <= max_orphans` be inside `NeedsTrim`?",
      "created_at": "2025-02-10T22:40:17Z",
      "updated_at": "2025-02-11T19:33:03Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950002603",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950002603"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 173,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950722422",
      "pull_request_review_id": 2608521945,
      "id": 1950722422,
      "node_id": "PRRC_kwDOABII5850Ral2",
      "diff_hunk": "@@ -36,9 +36,10 @@ bool TxOrphanage::AddTx(const CTransactionRef& tx, NodeId peer)\n         return false;\n     }\n ",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 3,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949498021,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "thanks, fixed",
      "created_at": "2025-02-11T12:04:22Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950722422",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950722422"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 55,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950722979",
      "pull_request_review_id": 2608521945,
      "id": 1950722979,
      "node_id": "PRRC_kwDOABII5850Rauj",
      "diff_hunk": "@@ -87,29 +89,32 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n         }\n-    }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+        // Find this orphan iter's position in the list, and delete it.\n+        auto& orphan_list = peer_it->second.m_iter_list;\n+        size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));\n+\n+        if (!Assume(old_pos < orphan_list.size())) continue;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949568939,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "removed",
      "created_at": "2025-02-11T12:04:50Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950722979",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950722979"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 103,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950723636",
      "pull_request_review_id": 2608521945,
      "id": 1950723636,
      "node_id": "PRRC_kwDOABII5850Ra40",
      "diff_hunk": "@@ -165,13 +170,68 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim() && m_orphans.size() <= max_orphans) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());\n+\n+    // Sort peers that have the highest ratio of DoSiness first\n+    auto compare_peer = [this](PeerMap::iterator left, PeerMap::iterator right) {\n+        const auto max_ann{GetPerPeerMaxAnnouncements()};\n+        const auto max_mem{GetPerPeerMaxUsage()};\n+        return left->second.GetDoSScore(max_ann, max_mem) < right->second.GetDoSScore(max_ann, max_mem);\n+    };\n+\n+    std::make_heap(peer_it_heap.begin(), peer_it_heap.end(), compare_peer);\n+\n     unsigned int nEvicted = 0;\n-    while (m_orphans.size() > max_orphans)\n+\n+    // Since each iteration should remove 1 announcement, this loop runs at most m_total_announcements times.\n+    // Note that we don't necessarily delete an orphan on each iteration. We might only be deleting\n+    // a peer from its announcers list.\n+    while (NeedsTrim() || m_orphans.size() > max_orphans)\n     {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+        if (!Assume(!peer_it_heap.empty())) break;\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used\n+        // over the allowance. This metric causes us to naturally select peers who have exceeded\n+        // their limits (i.e. a DoS score > 1) before peers who haven't. We may choose the same peer\n+        // change since the last iteration of this loop.",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 101,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949583127,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "fixed",
      "created_at": "2025-02-11T12:05:22Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950723636",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950723636"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 200,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950724798",
      "pull_request_review_id": 2608521945,
      "id": 1950724798,
      "node_id": "PRRC_kwDOABII5850RbK-",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** The maximum number of announcements across all peers, representing a computational upper bound,\n+     * i.e. the maximum number of evictions we might do at a time. There is no per-peer announcement\n+     * limit until the global limit is reached. Also, this limit is constant regardless of how many\n+     * peers we have: if we only have 1 peer, this is the number of orphans they may provide. As",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 40,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949514690,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "changed",
      "created_at": "2025-02-11T12:06:11Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950724798",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950724798"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 47,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950725244",
      "pull_request_review_id": 2608521945,
      "id": 1950725244,
      "node_id": "PRRC_kwDOABII5850RbR8",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** The maximum number of announcements across all peers, representing a computational upper bound,\n+     * i.e. the maximum number of evictions we might do at a time. There is no per-peer announcement\n+     * limit until the global limit is reached. Also, this limit is constant regardless of how many\n+     * peers we have: if we only have 1 peer, this is the number of orphans they may provide. As\n+     * more peers are added, each peer's allocation is reduced. */",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 41,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949514831,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-02-11T12:06:30Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950725244",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950725244"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 48,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950732547",
      "pull_request_review_id": 2608521945,
      "id": 1950732547,
      "node_id": "PRRC_kwDOABII5850RdED",
      "diff_hunk": "@@ -220,6 +220,42 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n     BOOST_CHECK_EQUAL(orphanage.CountOrphans(), 0);\n }\n \n+BOOST_AUTO_TEST_CASE(eviction)\n+{\n+    FastRandomContext det_rand{true};\n+    TxOrphanage orphanage;\n+\n+    // Send 10 orphans from 15 other peers\n+    NodeId max_peer{15};\n+    std::vector<unsigned int> peer_usages;\n+    for (NodeId peer{0}; peer < max_peer; ++peer) {\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+            orphanage.AddTx(ptx, peer);\n+        }\n+        peer_usages.emplace_back(orphanage.UsageByPeer(peer));\n+    }\n+\n+    NodeId dos_peer{max_peer};\n+    // Send max orphans from 1 peer\n+    for (unsigned int i{0}; i < DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS; ++i) {\n+        auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+        orphanage.AddTx(ptx, dos_peer);\n+    }\n+    peer_usages.emplace_back(orphanage.UsageByPeer(dos_peer));\n+\n+    // Force an eviction. Note that no limiting has happened yet at this point. LimitOrphans may",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 28,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "95b61662e51622292649cd15a61b9caa113cb2fc",
      "in_reply_to_id": 1949610086,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "yes, clarified",
      "created_at": "2025-02-11T12:12:11Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950732547",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950732547"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 247,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950739715",
      "pull_request_review_id": 2608521945,
      "id": 1950739715,
      "node_id": "PRRC_kwDOABII5850Re0D",
      "diff_hunk": "@@ -220,6 +220,42 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n     BOOST_CHECK_EQUAL(orphanage.CountOrphans(), 0);\n }\n \n+BOOST_AUTO_TEST_CASE(eviction)\n+{\n+    FastRandomContext det_rand{true};\n+    TxOrphanage orphanage;\n+\n+    // Send 10 orphans from 15 other peers\n+    NodeId max_peer{15};\n+    std::vector<unsigned int> peer_usages;\n+    for (NodeId peer{0}; peer < max_peer; ++peer) {\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+            orphanage.AddTx(ptx, peer);\n+        }\n+        peer_usages.emplace_back(orphanage.UsageByPeer(peer));\n+    }\n+\n+    NodeId dos_peer{max_peer};\n+    // Send max orphans from 1 peer\n+    for (unsigned int i{0}; i < DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS; ++i) {\n+        auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+        orphanage.AddTx(ptx, dos_peer);\n+    }\n+    peer_usages.emplace_back(orphanage.UsageByPeer(dos_peer));\n+\n+    // Force an eviction. Note that no limiting has happened yet at this point. LimitOrphans may\n+    // evict more than 1 transaction. All evictions will be from the dos_peer's transactions.\n+    const auto prev_count = orphanage.Size();\n+    orphanage.LimitOrphans(prev_count - 1, det_rand);\n+    BOOST_CHECK(orphanage.Size() <= prev_count - 1);\n+\n+    // The DoS peer's orphans have been evicted, nobody else's have.\n+    for (NodeId peer{0}; peer <= dos_peer; ++peer) {\n+        BOOST_CHECK_EQUAL(peer == dos_peer, peer_usages.at(peer) != orphanage.UsageByPeer(peer));",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 36,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "95b61662e51622292649cd15a61b9caa113cb2fc",
      "in_reply_to_id": 1949612609,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added",
      "created_at": "2025-02-11T12:16:22Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950739715",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950739715"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 256,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950745977",
      "pull_request_review_id": 2608521945,
      "id": 1950745977,
      "node_id": "PRRC_kwDOABII5850RgV5",
      "diff_hunk": "@@ -0,0 +1,137 @@\n+// Copyright (c) 2011-2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <bench/bench.h>\n+#include <consensus/amount.h>\n+#include <net.h>\n+#include <primitives/transaction.h>\n+#include <pubkey.h>\n+#include <script/sign.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <util/check.h>\n+\n+#include <cstdint>\n+#include <memory>\n+\n+// Creates a transaction spending outpoints (or 1 randomly generated input if none are given), with num_outputs outputs.\n+static CTransactionRef MakeTransactionSpending(const std::vector<COutPoint>& outpoints, unsigned int num_outputs, FastRandomContext& det_rand)\n+{\n+    CMutableTransaction tx;\n+\n+    // Build vin\n+    // If no outpoints are given, create a random one.\n+    if (outpoints.empty()) {\n+        tx.vin.emplace_back(Txid::FromUint256(det_rand.rand256()), 0);\n+    } else {\n+        for (const auto& outpoint : outpoints) {\n+            tx.vin.emplace_back(outpoint);\n+        }\n+    }\n+    // Ensure txid != wtxid\n+    assert(tx.vin.size() > 0);\n+    tx.vin[0].scriptWitness.stack.push_back({1});\n+\n+    // Build vout\n+    assert(num_outputs > 0);\n+    tx.vout.resize(num_outputs);\n+    for (unsigned int o = 0; o < num_outputs; ++o) {\n+        tx.vout[o].nValue = det_rand.randrange(100) * CENT;\n+        tx.vout[o].scriptPubKey = CScript() << CScriptNum(det_rand.randrange(o + 100)) << OP_EQUAL;\n+    }\n+    return MakeTransactionRef(tx);\n+}\n+\n+static void OrphanageEvictionMany(benchmark::Bench& bench)\n+{\n+    NodeId NUM_PEERS{125};\n+    unsigned int NUM_TRANSACTIONS(DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / NUM_PEERS);",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 49,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3ce9ef7dd3c231976454e8c836640507bdb7e111",
      "in_reply_to_id": 1949655371,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Yes, and they are each announced by every peer. This bench is to test the maximum number of transactions where every peer has 100% overlap. We call `AddTx` `DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS` times, which is the maximum before eviction would trigger. If we increase `DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS`, the bench will scale too.",
      "created_at": "2025-02-11T12:18:35Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950745977",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950745977"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 103,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950778587",
      "pull_request_review_id": 2608521945,
      "id": 1950778587,
      "node_id": "PRRC_kwDOABII5850RoTb",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": 118,
      "original_position": 124,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": 1949641427,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-02-11T12:37:03Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950778587",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950778587"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 465,
      "original_line": 465,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950780338",
      "pull_request_review_id": 2608521945,
      "id": 1950780338,
      "node_id": "PRRC_kwDOABII5850Rouy",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 103,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": 1949911002,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-02-11T12:38:23Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950780338",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950780338"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 451,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950780433",
      "pull_request_review_id": 2608521945,
      "id": 1950780433,
      "node_id": "PRRC_kwDOABII5850RowR",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 152,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": 1949911352,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-02-11T12:38:27Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950780433",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950780433"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 500,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950789783",
      "pull_request_review_id": 2608521945,
      "id": 1950789783,
      "node_id": "PRRC_kwDOABII5850RrCX",
      "diff_hunk": "@@ -264,10 +266,24 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\n                 // Get this source peer's work set, emplacing an empty set if it didn't exist\n                 // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n                 std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n-                LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+\n+                // If this peer's work set would exceed the maximum allowed size, trim any work\n+                // items that are no longer in the orphanage. We should only do this once per peer\n+                // per call to AddChildrenToWorkSet, so keep track of which peers we have trimmed.\n+                // We also never need to do it more than once since evictions don't happen in this\n+                // function.\n+                if (orphan_work_set.size() + 1 > MAX_ORPHAN_WORK_QUEUE && !peers_workset_trimmed.contains(announcer)) {\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 24,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "33034eaa3b45c815fc595c5d906b38c12602a3df",
      "in_reply_to_id": 1949834394,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Wow, very bad bit flip :facepalm: thank you",
      "created_at": "2025-02-11T12:45:06Z",
      "updated_at": "2025-02-11T17:03:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1950789783",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1950789783"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 276,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951246422",
      "pull_request_review_id": 2609431712,
      "id": 1951246422,
      "node_id": "PRRC_kwDOABII5850TahW",
      "diff_hunk": "@@ -264,10 +266,24 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\n                 // Get this source peer's work set, emplacing an empty set if it didn't exist\n                 // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n                 std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n-                LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+\n+                // If this peer's work set would exceed the maximum allowed size, trim any work\n+                // items that are no longer in the orphanage. We should only do this once per peer\n+                // per call to AddChildrenToWorkSet, so keep track of which peers we have trimmed.\n+                // We also never need to do it more than once since evictions don't happen in this\n+                // function.\n+                if (orphan_work_set.size() + 1 > MAX_ORPHAN_WORK_QUEUE && !peers_workset_trimmed.contains(announcer)) {\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 24,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "33034eaa3b45c815fc595c5d906b38c12602a3df",
      "in_reply_to_id": 1949834394,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Wrote a similar test to check that an evicted work item is the one that doesn't exist in `m_orphans` anymore.",
      "created_at": "2025-02-11T17:06:14Z",
      "updated_at": "2025-02-11T17:06:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951246422",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951246422"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 276,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951957283",
      "pull_request_review_id": 2610780552,
      "id": 1951957283,
      "node_id": "PRRC_kwDOABII5850WIEj",
      "diff_hunk": "@@ -160,15 +159,29 @@ void TxOrphanage::LimitOrphans(unsigned int max_orphans, FastRandomContext& rng)\n         }\n         // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n         m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n     }\n+    return nErased;\n+}\n+\n+unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n+{\n+    unsigned int nEvicted = 0;\n     while (m_orphans.size() > max_orphans)\n     {\n         // Evict a random orphan:\n         size_t randompos = rng.randrange(m_orphan_list.size());\n         EraseTx(m_orphan_list[randompos]->first);\n         ++nEvicted;\n     }\n+    return nEvicted;\n+}\n+\n+void TxOrphanage::LimitOrphans(unsigned int max_orphans, FastRandomContext& rng)",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 38,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ff24c1feeb2878f7f1d31127ea220c788eb6a187",
      "in_reply_to_id": 1949899180,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-02-12T04:25:29Z",
      "updated_at": "2025-02-12T04:25:29Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951957283",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951957283"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 245,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951957432",
      "pull_request_review_id": 2610780759,
      "id": 1951957432,
      "node_id": "PRRC_kwDOABII5850WIG4",
      "diff_hunk": "@@ -165,13 +170,68 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim() && m_orphans.size() <= max_orphans) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 74,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949998393,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "fixed",
      "created_at": "2025-02-12T04:25:44Z",
      "updated_at": "2025-02-12T04:25:44Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951957432",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951957432"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 185,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951957531",
      "pull_request_review_id": 2610780943,
      "id": 1951957531,
      "node_id": "PRRC_kwDOABII5850WIIb",
      "diff_hunk": "@@ -165,13 +170,68 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim() && m_orphans.size() <= max_orphans) return 0;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 70,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1950002603,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Moved into `NeedsTrim`",
      "created_at": "2025-02-12T04:25:54Z",
      "updated_at": "2025-02-12T04:25:55Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951957531",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951957531"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 173,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951962043",
      "pull_request_review_id": 2610788295,
      "id": 1951962043,
      "node_id": "PRRC_kwDOABII5850WJO7",
      "diff_hunk": "@@ -111,7 +137,6 @@ class TxOrphanage {\n \n protected:\n     struct OrphanTx : public OrphanTxBase {",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 56,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949519057,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "not entirely sure... could be cleaned up",
      "created_at": "2025-02-12T04:33:12Z",
      "updated_at": "2025-02-12T04:33:13Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951962043",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951962043"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 148,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951964695",
      "pull_request_review_id": 2610793126,
      "id": 1951964695,
      "node_id": "PRRC_kwDOABII5850WJ4X",
      "diff_hunk": "@@ -140,13 +140,12 @@ void TxOrphanage::EraseForPeer(NodeId peer)\n     if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n }\n \n-void TxOrphanage::LimitOrphans(unsigned int max_orphans, FastRandomContext& rng)\n+unsigned int TxOrphanage::MaybeExpireOrphans()\n {\n-    unsigned int nEvicted = 0;\n+    int nErased = 0;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 8,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ff24c1feeb2878f7f1d31127ea220c788eb6a187",
      "in_reply_to_id": 1949856455,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "made consistent + made both logs %u",
      "created_at": "2025-02-12T04:37:30Z",
      "updated_at": "2025-02-12T04:37:30Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951964695",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951964695"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 149,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951964799",
      "pull_request_review_id": 2610793252,
      "id": 1951964799,
      "node_id": "PRRC_kwDOABII5850WJ5_",
      "diff_hunk": "@@ -156,18 +201,47 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    unsigned int GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    unsigned int GetGlobalMaxUsage() const {\n+        return std::max<unsigned int>(m_peer_orphanage_info.size() * m_reserved_weight_per_peer, 1);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 135,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949955925,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "fixed",
      "created_at": "2025-02-12T04:37:39Z",
      "updated_at": "2025-02-12T04:37:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951964799",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951964799"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 236,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951965002",
      "pull_request_review_id": 2610793579,
      "id": 1951965002,
      "node_id": "PRRC_kwDOABII5850WJ9K",
      "diff_hunk": "@@ -375,6 +390,143 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(utxo_to_spend=low_fee_parent[\"new_utxo\"], fee_rate=20*FEERATE_1SAT_VB)\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": 127,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "653f1bb84db59b11ae20489a7ac2fee4cb78778b",
      "in_reply_to_id": 1949914892,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "(thanks, I took your test with just a few tweaks)",
      "created_at": "2025-02-12T04:38:01Z",
      "updated_at": "2025-02-12T04:38:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951965002",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951965002"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 474,
      "original_line": 474,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951966069",
      "pull_request_review_id": 2610795112,
      "id": 1951966069,
      "node_id": "PRRC_kwDOABII5850WKN1",
      "diff_hunk": "@@ -264,10 +266,24 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\n                 // Get this source peer's work set, emplacing an empty set if it didn't exist\n                 // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n                 std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n-                LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+\n+                // If this peer's work set would exceed the maximum allowed size, trim any work\n+                // items that are no longer in the orphanage. We should only do this once per peer\n+                // per call to AddChildrenToWorkSet, so keep track of which peers we have trimmed.\n+                // We also never need to do it more than once since evictions don't happen in this\n+                // function.\n+                if (orphan_work_set.size() + 1 > MAX_ORPHAN_WORK_QUEUE && !peers_workset_trimmed.contains(announcer)) {\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });\n+                    peers_workset_trimmed.insert(announcer);\n+                }\n+\n+                // Add this tx to the work set. If the workset is full, even after trimming, don't\n+                // accept any new work items until the work queue has been flushed.\n+                if (orphan_work_set.size() < MAX_ORPHAN_WORK_QUEUE) {",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 30,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "33034eaa3b45c815fc595c5d906b38c12602a3df",
      "in_reply_to_id": 1949852220,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added a couple pushes ago, but gone again. After a bit of offline discussion with @mzumsande and @sipa, it seemed better to just synchronously remove wtxids from worksets when they are removed as announcements. This means that the work set is always a subset of announcement set (added this to `SanityCheck`). Also, potentially failing to add things to work set seemed to make this less useful.",
      "created_at": "2025-02-12T04:39:47Z",
      "updated_at": "2025-02-12T04:39:48Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951966069",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951966069"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 281,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951966734",
      "pull_request_review_id": 2610796043,
      "id": 1951966734,
      "node_id": "PRRC_kwDOABII5850WKYO",
      "diff_hunk": "@@ -156,18 +201,47 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    unsigned int GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    unsigned int GetGlobalMaxUsage() const {\n+        return std::max<unsigned int>(m_peer_orphanage_info.size() * m_reserved_weight_per_peer, 1);\n+    }\n+\n+    unsigned int GetPerPeerMaxAnnouncements() const {",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 138,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949538646,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Yes, they're both meant to be ratios :+1:",
      "created_at": "2025-02-12T04:40:42Z",
      "updated_at": "2025-02-12T04:40:42Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1951966734",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1951966734"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 247,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952580350",
      "pull_request_review_id": 2611807509,
      "id": 1952580350,
      "node_id": "PRRC_kwDOABII5850YgL-",
      "diff_hunk": "@@ -264,10 +266,24 @@ void TxOrphanage::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext\n                 // Get this source peer's work set, emplacing an empty set if it didn't exist\n                 // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n                 std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n-                LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+\n+                // If this peer's work set would exceed the maximum allowed size, trim any work\n+                // items that are no longer in the orphanage. We should only do this once per peer\n+                // per call to AddChildrenToWorkSet, so keep track of which peers we have trimmed.\n+                // We also never need to do it more than once since evictions don't happen in this\n+                // function.\n+                if (orphan_work_set.size() + 1 > MAX_ORPHAN_WORK_QUEUE && !peers_workset_trimmed.contains(announcer)) {\n+                    std::erase_if(orphan_work_set, [&](const auto& wtxid) { return m_orphans.contains(wtxid); });\n+                    peers_workset_trimmed.insert(announcer);\n+                }\n+\n+                // Add this tx to the work set. If the workset is full, even after trimming, don't\n+                // accept any new work items until the work queue has been flushed.\n+                if (orphan_work_set.size() < MAX_ORPHAN_WORK_QUEUE) {",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 30,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "33034eaa3b45c815fc595c5d906b38c12602a3df",
      "in_reply_to_id": 1949852220,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ok! that was my suggestion offline too. Bounding announcements means we bound the workset :+1: ",
      "created_at": "2025-02-12T12:45:34Z",
      "updated_at": "2025-02-12T12:45:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952580350",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952580350"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 281,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952714733",
      "pull_request_review_id": 2612036122,
      "id": 1952714733,
      "node_id": "PRRC_kwDOABII5850ZA_t",
      "diff_hunk": "@@ -666,6 +687,71 @@ def test_orphan_handling_prefer_outbound(self):\n         peer_inbound.sync_with_ping()\n         peer_inbound.wait_for_parent_requests([int(parent_tx.rehash(), 16)])\n \n+    @cleanup\n+    def test_maximal_package_protected(self):\n+        self.log.info(\"Test that a node only announcing a maximally sized ancestor package is protected in orphanage\")\n+        # Needed for transaction size bulking\n+        self.restart_node(0, extra_args=[\"-datacarriersize=100000\"])\n+        node = self.nodes[0]\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        large_orphans = [self.create_large_orphan() for _ in range(60)]\n+\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        # Now honest peer will send a maximally sized ancestor package of 24 orphans chaining\n+        # off of a single missing transaction, with a total vsize 404,000Wu\n+        ancestor_package = self.wallet.create_self_transfer_chain(chain_length=DEFAULT_ANCESTOR_LIMIT - 1)\n+        sum_ancestor_package_vsize = sum([tx[\"tx\"].get_vsize() for tx in ancestor_package])\n+        final_tx = self.wallet.create_self_transfer(utxo_to_spend=ancestor_package[-1][\"new_utxo\"], target_vsize=101000 - sum_ancestor_package_vsize)\n+        ancestor_package.append(final_tx)\n+\n+        # Peer sends all but first tx to fill up orphange with their orphans\n+        for orphan in ancestor_package[1:]:\n+            peer_normal.send_and_ping(msg_tx(orphan[\"tx\"]))\n+\n+        orphan_set = node.getorphantxs()\n+        for orphan in ancestor_package[1:]:\n+            assert orphan[\"txid\"] in orphan_set\n+\n+        # Wait for ultimate parent request\n+        parent_txid_int = int(ancestor_package[0][\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+\n+        self.wait_until(lambda: \"getdata\" in peer_normal.last_message and parent_txid_int in [inv.hash for inv in peer_normal.last_message.get(\"getdata\").inv])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[num_individual_dosers:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the top ancestor. The whole package should be re-evaluated after enough time.\")\n+        peer_normal.send_and_ping(msg_tx(ancestor_package[0][\"tx\"]))\n+\n+        self.wait_until(lambda: node.getmempoolentry(ancestor_package[-1][\"txid\"])[\"ancestorcount\"] == DEFAULT_ANCESTOR_LIMIT)",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": null,
      "original_position": 115,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "4e17767f4b42559670062ab029ec1ec53f0b0566",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "on second thought, this will probably throw an assertion if the final child isn't in the mempool yet? Probably need to prepend this clause with `ancestor_package[-1][\"txid\"] in node.getrawmempool()`",
      "created_at": "2025-02-12T14:06:29Z",
      "updated_at": "2025-02-12T15:34:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952714733",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952714733"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 753,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952747093",
      "pull_request_review_id": 2612036122,
      "id": 1952747093,
      "node_id": "PRRC_kwDOABII5850ZI5V",
      "diff_hunk": "@@ -45,22 +45,18 @@\n DEFAULT_MAX_ORPHAN_TRANSACTIONS = 100\n \n def cleanup(func):\n-    # Time to fastfoward (using setmocktime) in between subtests to ensure they do not interfere with\n-    # one another, in seconds. Equal to 12 hours, which is enough to expire anything that may exist\n-    # (though nothing should since state should be cleared) in p2p data structures.\n-    LONG_TIME_SKIP = 12 * 60 * 60\n-\n     def wrapper(self):\n         try:\n             func(self)\n         finally:\n             # Clear mempool\n             self.generate(self.nodes[0], 1)\n             self.nodes[0].disconnect_p2ps()\n-            self.nodes[0].bumpmocktime(LONG_TIME_SKIP)\n             # Check that mempool and orphanage have been cleared\n             self.wait_until(lambda: len(self.nodes[0].getorphantxs()) == 0)\n             assert_equal(0, len(self.nodes[0].getrawmempool()))\n+\n+            self.restart_node(0, extra_args=[\"-persistmempool=0\"])",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": 40,
      "original_position": 21,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "889afbadb417e9422c7c06fd074981fa62045568",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "889afbadb417e9422c7c06fd074981fa62045568\r\n\r\nSince we're restarting does this wipe the mocktime on the node? Doesn't seem to affect timings, but I think it's easier to think about the test this way.\r\n\r\nnote that if you set it here, you also need to setmocktime any other time you restart as well",
      "created_at": "2025-02-12T14:20:25Z",
      "updated_at": "2025-02-12T15:34:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952747093",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952747093"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 62,
      "original_line": 62,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952751403",
      "pull_request_review_id": 2612094405,
      "id": 1952751403,
      "node_id": "PRRC_kwDOABII5850ZJ8r",
      "diff_hunk": "@@ -138,10 +170,27 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions in vector for quick random eviction */\n+        std::vector<OrphanMap::iterator> m_iter_list;",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 87,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "8520f1e493079a6ba124f7d35eabafe5740374af",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] when full, evict from the DoSiest peers first\"\r\n\r\nI think it would be helpful to add this variable, and the testing thereof, in a separate commit from the actual eviction changes.",
      "created_at": "2025-02-12T14:21:58Z",
      "updated_at": "2025-02-12T14:35:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952751403",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952751403"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 179,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952759514",
      "pull_request_review_id": 2612094405,
      "id": 1952759514,
      "node_id": "PRRC_kwDOABII5850ZL7a",
      "diff_hunk": "@@ -156,18 +201,47 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    unsigned int GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    unsigned int GetGlobalMaxUsage() const {\n+        return std::max<unsigned int>(m_peer_orphanage_info.size() * m_reserved_weight_per_peer, 1);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 135,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949955925,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] when full, evict from the DoSiest peers first\"\r\n\r\nThe `int64_t` return type won't actually do anything here, because `std::max` is instantiated for `unsigned int`, and also, the `std::map::size()` may return something smaller (particularly on 32-bit systems).\r\n\r\n```c++\r\nint64_t GetGlobalMaxUsage() const {\r\n        return std::max<int64_t>(int64_t(m_peer_orphanage_info.size()) * m_reserved_weight_per_peer, 1);\r\n}\r\n```",
      "created_at": "2025-02-12T14:25:47Z",
      "updated_at": "2025-02-12T14:35:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952759514",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952759514"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 236,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952760531",
      "pull_request_review_id": 2612094405,
      "id": 1952760531,
      "node_id": "PRRC_kwDOABII5850ZMLT",
      "diff_hunk": "@@ -138,10 +170,27 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions in vector for quick random eviction */\n+        std::vector<OrphanMap::iterator> m_iter_list;\n+\n+        /** There are 2 DoS scores:\n+         * - CPU score (ratio of num announcements / max allowed announcements)\n+         * - Memory score (ratio of total usage / max allowed usage).\n+         *\n+         * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+         * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+         * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+         * be selected for trimming sooner. */\n+        FeeFrac GetDoSScore(unsigned int peer_max_ann, unsigned int peer_max_mem) {\n+            FeeFrac cpu_score(m_iter_list.size(), peer_max_ann);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 98,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "8520f1e493079a6ba124f7d35eabafe5740374af",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Huh, neat, I hadn't considered using `FeeFrac` here, but it fits.",
      "created_at": "2025-02-12T14:26:22Z",
      "updated_at": "2025-02-12T14:35:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952760531",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952760531"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 191,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952769273",
      "pull_request_review_id": 2612094405,
      "id": 1952769273,
      "node_id": "PRRC_kwDOABII5850ZOT5",
      "diff_hunk": "@@ -165,13 +169,69 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim(max_orphans)) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+\n+    // Sort peers that have the highest ratio of DoSiness first\n+    auto compare_peer = [this](PeerMap::iterator left, PeerMap::iterator right) {\n+        const auto max_ann{GetPerPeerMaxAnnouncements()};\n+        const auto max_mem{GetPerPeerMaxUsage()};\n+        return left->second.GetDoSScore(max_ann, max_mem) < right->second.GetDoSScore(max_ann, max_mem);",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 79,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "8520f1e493079a6ba124f7d35eabafe5740374af",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] when full, evict from the DoSiest peers first\"\r\n\r\nUsing `FeeFrac::operator<` here, which tiebreaks by biggest denominator first in case the ratios are equal, means that if two peers are equally DoSsy, but one is that due to memory usage, and the other is that due to announcements, the announcements one will be targetted first. That's probably fine, but perhaps worth documenting.",
      "created_at": "2025-02-12T14:31:01Z",
      "updated_at": "2025-02-12T14:35:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952769273",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952769273"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 192,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952818760",
      "pull_request_review_id": 2612036122,
      "id": 1952818760,
      "node_id": "PRRC_kwDOABII5850ZaZI",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "this will trivially pass (and not actually ensure there was an eviction) unless you let the orphans be processed with a send_and_ping.\r\n\r\nIt's also not true, because no evictions will happen with just 1000 orphans\r\n\r\nHere's a suggested patchset which has this subtest run in ~2m30s and actually causes evictions with default parameters: https://github.com/instagibbs/bitcoin/commit/fedea4a17b7fc4c442b0ad98b51b85ff93a55beb",
      "created_at": "2025-02-12T14:56:25Z",
      "updated_at": "2025-02-12T15:34:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952818760",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952818760"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952893131",
      "pull_request_review_id": 2612036122,
      "id": 1952893131,
      "node_id": "PRRC_kwDOABII5850ZsjL",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        shared_orphans = [self.create_small_orphan() for _ in range(batch_size)]\n+        self.log.info(f\"Send the same {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for _ in range(num_peers):\n+            peer_doser_shared = node.add_p2p_connection(P2PInterface())\n+            for orphan in shared_orphans:\n+                peer_doser_shared.send_message(msg_tx(orphan))\n+\n+        # Something was evicted; the orphanage does not contain all DoS orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers + len(shared_orphans) + 1)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 192,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "this is a buggy assertion because no evictions will be happening, you might just front-run validation and slip through on your local machine. see https://github.com/instagibbs/bitcoin/commit/fedea4a17b7fc4c442b0ad98b51b85ff93a55beb for what I think would be a valid assertion",
      "created_at": "2025-02-12T15:33:28Z",
      "updated_at": "2025-02-12T15:34:46Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1952893131",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1952893131"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 540,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1954788703",
      "pull_request_review_id": 2615511540,
      "id": 1954788703,
      "node_id": "PRRC_kwDOABII5850g7Vf",
      "diff_hunk": "@@ -666,6 +687,71 @@ def test_orphan_handling_prefer_outbound(self):\n         peer_inbound.sync_with_ping()\n         peer_inbound.wait_for_parent_requests([int(parent_tx.rehash(), 16)])\n \n+    @cleanup\n+    def test_maximal_package_protected(self):\n+        self.log.info(\"Test that a node only announcing a maximally sized ancestor package is protected in orphanage\")\n+        # Needed for transaction size bulking\n+        self.restart_node(0, extra_args=[\"-datacarriersize=100000\"])\n+        node = self.nodes[0]\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        large_orphans = [self.create_large_orphan() for _ in range(60)]\n+\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        # Now honest peer will send a maximally sized ancestor package of 24 orphans chaining\n+        # off of a single missing transaction, with a total vsize 404,000Wu\n+        ancestor_package = self.wallet.create_self_transfer_chain(chain_length=DEFAULT_ANCESTOR_LIMIT - 1)\n+        sum_ancestor_package_vsize = sum([tx[\"tx\"].get_vsize() for tx in ancestor_package])\n+        final_tx = self.wallet.create_self_transfer(utxo_to_spend=ancestor_package[-1][\"new_utxo\"], target_vsize=101000 - sum_ancestor_package_vsize)\n+        ancestor_package.append(final_tx)\n+\n+        # Peer sends all but first tx to fill up orphange with their orphans\n+        for orphan in ancestor_package[1:]:\n+            peer_normal.send_and_ping(msg_tx(orphan[\"tx\"]))\n+\n+        orphan_set = node.getorphantxs()\n+        for orphan in ancestor_package[1:]:\n+            assert orphan[\"txid\"] in orphan_set\n+\n+        # Wait for ultimate parent request\n+        parent_txid_int = int(ancestor_package[0][\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+\n+        self.wait_until(lambda: \"getdata\" in peer_normal.last_message and parent_txid_int in [inv.hash for inv in peer_normal.last_message.get(\"getdata\").inv])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[num_individual_dosers:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the top ancestor. The whole package should be re-evaluated after enough time.\")\n+        peer_normal.send_and_ping(msg_tx(ancestor_package[0][\"tx\"]))\n+\n+        self.wait_until(lambda: node.getmempoolentry(ancestor_package[-1][\"txid\"])[\"ancestorcount\"] == DEFAULT_ANCESTOR_LIMIT)",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": null,
      "original_position": 115,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "4e17767f4b42559670062ab029ec1ec53f0b0566",
      "in_reply_to_id": 1952714733,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "ah hm, maybe we don't need to wait? I guess if you send a ping, you don't get a pong until all 24 are processed.",
      "created_at": "2025-02-13T16:00:04Z",
      "updated_at": "2025-02-13T16:00:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1954788703",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1954788703"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 753,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1954895162",
      "pull_request_review_id": 2615701598,
      "id": 1954895162,
      "node_id": "PRRC_kwDOABII5850hVU6",
      "diff_hunk": "@@ -666,6 +687,71 @@ def test_orphan_handling_prefer_outbound(self):\n         peer_inbound.sync_with_ping()\n         peer_inbound.wait_for_parent_requests([int(parent_tx.rehash(), 16)])\n \n+    @cleanup\n+    def test_maximal_package_protected(self):\n+        self.log.info(\"Test that a node only announcing a maximally sized ancestor package is protected in orphanage\")\n+        # Needed for transaction size bulking\n+        self.restart_node(0, extra_args=[\"-datacarriersize=100000\"])\n+        node = self.nodes[0]\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        large_orphans = [self.create_large_orphan() for _ in range(60)]\n+\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        # Now honest peer will send a maximally sized ancestor package of 24 orphans chaining\n+        # off of a single missing transaction, with a total vsize 404,000Wu\n+        ancestor_package = self.wallet.create_self_transfer_chain(chain_length=DEFAULT_ANCESTOR_LIMIT - 1)\n+        sum_ancestor_package_vsize = sum([tx[\"tx\"].get_vsize() for tx in ancestor_package])\n+        final_tx = self.wallet.create_self_transfer(utxo_to_spend=ancestor_package[-1][\"new_utxo\"], target_vsize=101000 - sum_ancestor_package_vsize)\n+        ancestor_package.append(final_tx)\n+\n+        # Peer sends all but first tx to fill up orphange with their orphans\n+        for orphan in ancestor_package[1:]:\n+            peer_normal.send_and_ping(msg_tx(orphan[\"tx\"]))\n+\n+        orphan_set = node.getorphantxs()\n+        for orphan in ancestor_package[1:]:\n+            assert orphan[\"txid\"] in orphan_set\n+\n+        # Wait for ultimate parent request\n+        parent_txid_int = int(ancestor_package[0][\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+\n+        self.wait_until(lambda: \"getdata\" in peer_normal.last_message and parent_txid_int in [inv.hash for inv in peer_normal.last_message.get(\"getdata\").inv])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[num_individual_dosers:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the top ancestor. The whole package should be re-evaluated after enough time.\")\n+        peer_normal.send_and_ping(msg_tx(ancestor_package[0][\"tx\"]))\n+\n+        self.wait_until(lambda: node.getmempoolentry(ancestor_package[-1][\"txid\"])[\"ancestorcount\"] == DEFAULT_ANCESTOR_LIMIT)",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": null,
      "original_position": 115,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "4e17767f4b42559670062ab029ec1ec53f0b0566",
      "in_reply_to_id": 1952714733,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I'll defer to you, but IIUC we'll do ~1 orphan processing per message processing step, so it might take a bit more to process all 24 from orphanage? Alternatively we could query the *first* tx and wait until the descendant count hits DEFAULT_ANCESTOR_LIMIT",
      "created_at": "2025-02-13T17:04:05Z",
      "updated_at": "2025-02-13T17:04:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1954895162",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1954895162"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 753,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956103968",
      "pull_request_review_id": 2617719827,
      "id": 1956103968,
      "node_id": "PRRC_kwDOABII5850l8cg",
      "diff_hunk": "@@ -666,6 +687,71 @@ def test_orphan_handling_prefer_outbound(self):\n         peer_inbound.sync_with_ping()\n         peer_inbound.wait_for_parent_requests([int(parent_tx.rehash(), 16)])\n \n+    @cleanup\n+    def test_maximal_package_protected(self):\n+        self.log.info(\"Test that a node only announcing a maximally sized ancestor package is protected in orphanage\")\n+        # Needed for transaction size bulking\n+        self.restart_node(0, extra_args=[\"-datacarriersize=100000\"])\n+        node = self.nodes[0]\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        large_orphans = [self.create_large_orphan() for _ in range(60)]\n+\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        # Now honest peer will send a maximally sized ancestor package of 24 orphans chaining\n+        # off of a single missing transaction, with a total vsize 404,000Wu\n+        ancestor_package = self.wallet.create_self_transfer_chain(chain_length=DEFAULT_ANCESTOR_LIMIT - 1)\n+        sum_ancestor_package_vsize = sum([tx[\"tx\"].get_vsize() for tx in ancestor_package])\n+        final_tx = self.wallet.create_self_transfer(utxo_to_spend=ancestor_package[-1][\"new_utxo\"], target_vsize=101000 - sum_ancestor_package_vsize)\n+        ancestor_package.append(final_tx)\n+\n+        # Peer sends all but first tx to fill up orphange with their orphans\n+        for orphan in ancestor_package[1:]:\n+            peer_normal.send_and_ping(msg_tx(orphan[\"tx\"]))\n+\n+        orphan_set = node.getorphantxs()\n+        for orphan in ancestor_package[1:]:\n+            assert orphan[\"txid\"] in orphan_set\n+\n+        # Wait for ultimate parent request\n+        parent_txid_int = int(ancestor_package[0][\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+\n+        self.wait_until(lambda: \"getdata\" in peer_normal.last_message and parent_txid_int in [inv.hash for inv in peer_normal.last_message.get(\"getdata\").inv])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[num_individual_dosers:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        self.log.info(\"Provide the top ancestor. The whole package should be re-evaluated after enough time.\")\n+        peer_normal.send_and_ping(msg_tx(ancestor_package[0][\"tx\"]))\n+\n+        self.wait_until(lambda: node.getmempoolentry(ancestor_package[-1][\"txid\"])[\"ancestorcount\"] == DEFAULT_ANCESTOR_LIMIT)",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": null,
      "original_position": 115,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "4e17767f4b42559670062ab029ec1ec53f0b0566",
      "in_reply_to_id": 1952714733,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Hold on, I don't see why it'd throw an assertion? `ancestor_package[-1]` is the last child right? Added some more comments but didn't change the code",
      "created_at": "2025-02-14T12:52:47Z",
      "updated_at": "2025-02-14T12:52:48Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956103968",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956103968"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 753,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956104380",
      "pull_request_review_id": 2617720527,
      "id": 1956104380,
      "node_id": "PRRC_kwDOABII5850l8i8",
      "diff_hunk": "@@ -138,10 +170,27 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions in vector for quick random eviction */\n+        std::vector<OrphanMap::iterator> m_iter_list;",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 87,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "8520f1e493079a6ba124f7d35eabafe5740374af",
      "in_reply_to_id": 1952751403,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added a commit before that one, just adding the list and sanity checking",
      "created_at": "2025-02-14T12:53:08Z",
      "updated_at": "2025-02-14T12:53:08Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956104380",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956104380"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 179,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956104543",
      "pull_request_review_id": 2617720788,
      "id": 1956104543,
      "node_id": "PRRC_kwDOABII5850l8lf",
      "diff_hunk": "@@ -165,13 +169,69 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim(max_orphans)) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+\n+    // Sort peers that have the highest ratio of DoSiness first\n+    auto compare_peer = [this](PeerMap::iterator left, PeerMap::iterator right) {\n+        const auto max_ann{GetPerPeerMaxAnnouncements()};\n+        const auto max_mem{GetPerPeerMaxUsage()};\n+        return left->second.GetDoSScore(max_ann, max_mem) < right->second.GetDoSScore(max_ann, max_mem);",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 79,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "8520f1e493079a6ba124f7d35eabafe5740374af",
      "in_reply_to_id": 1952769273,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "good point, added a comment",
      "created_at": "2025-02-14T12:53:17Z",
      "updated_at": "2025-02-14T12:53:17Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956104543",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956104543"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 192,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956105056",
      "pull_request_review_id": 2617721587,
      "id": 1956105056,
      "node_id": "PRRC_kwDOABII5850l8tg",
      "diff_hunk": "@@ -45,22 +45,18 @@\n DEFAULT_MAX_ORPHAN_TRANSACTIONS = 100\n \n def cleanup(func):\n-    # Time to fastfoward (using setmocktime) in between subtests to ensure they do not interfere with\n-    # one another, in seconds. Equal to 12 hours, which is enough to expire anything that may exist\n-    # (though nothing should since state should be cleared) in p2p data structures.\n-    LONG_TIME_SKIP = 12 * 60 * 60\n-\n     def wrapper(self):\n         try:\n             func(self)\n         finally:\n             # Clear mempool\n             self.generate(self.nodes[0], 1)\n             self.nodes[0].disconnect_p2ps()\n-            self.nodes[0].bumpmocktime(LONG_TIME_SKIP)\n             # Check that mempool and orphanage have been cleared\n             self.wait_until(lambda: len(self.nodes[0].getorphantxs()) == 0)\n             assert_equal(0, len(self.nodes[0].getrawmempool()))\n+\n+            self.restart_node(0, extra_args=[\"-persistmempool=0\"])",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": 40,
      "original_position": 21,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "889afbadb417e9422c7c06fd074981fa62045568",
      "in_reply_to_id": 1952747093,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nice, thanks - added a `setmocktime()` after all the restarts",
      "created_at": "2025-02-14T12:53:40Z",
      "updated_at": "2025-02-14T12:53:40Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956105056",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956105056"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 62,
      "original_line": 62,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956106767",
      "pull_request_review_id": 2617724413,
      "id": 1956106767,
      "node_id": "PRRC_kwDOABII5850l9IP",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952818760,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Thanks! Added. It does take a long time but that's the only way to get evictions due to announcements in a functional test.",
      "created_at": "2025-02-14T12:54:58Z",
      "updated_at": "2025-02-14T12:54:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956106767",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956106767"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956106958",
      "pull_request_review_id": 2617724681,
      "id": 1956106958,
      "node_id": "PRRC_kwDOABII5850l9LO",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        shared_orphans = [self.create_small_orphan() for _ in range(batch_size)]\n+        self.log.info(f\"Send the same {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for _ in range(num_peers):\n+            peer_doser_shared = node.add_p2p_connection(P2PInterface())\n+            for orphan in shared_orphans:\n+                peer_doser_shared.send_message(msg_tx(orphan))\n+\n+        # Something was evicted; the orphanage does not contain all DoS orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers + len(shared_orphans) + 1)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 192,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952893131,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added thanks!",
      "created_at": "2025-02-14T12:55:05Z",
      "updated_at": "2025-02-14T12:55:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956106958",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956106958"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 540,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956109943",
      "pull_request_review_id": 2617729694,
      "id": 1956109943,
      "node_id": "PRRC_kwDOABII5850l953",
      "diff_hunk": "@@ -156,18 +201,47 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    unsigned int GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    unsigned int GetGlobalMaxUsage() const {\n+        return std::max<unsigned int>(m_peer_orphanage_info.size() * m_reserved_weight_per_peer, 1);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 135,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949955925,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Thanks! Fixed",
      "created_at": "2025-02-14T12:57:30Z",
      "updated_at": "2025-02-14T12:57:30Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956109943",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956109943"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 236,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956203848",
      "pull_request_review_id": 2617896035,
      "id": 1956203848,
      "node_id": "PRRC_kwDOABII5850mU1I",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952818760,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Hm, one of the CI failures is a timeout for this (the other is a wallet thing). Perhaps it takes a bit too long? A few ideas:\r\n- Change these to batches of 200 * 10 + 101 * 10 and just do the `wait_until` once to make the test faster. \r\n- Use `-maxorphantxs` to reduce the limit.\r\n- Wait after each orphan is sent. This makes the overall test a lot longer, but makes it less likely we'll hit the timeout.\r\n- Keep a lower count of txns and settle for a test that fails on master but not on this PR.",
      "created_at": "2025-02-14T14:07:26Z",
      "updated_at": "2025-02-14T14:10:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956203848",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956203848"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956206594",
      "pull_request_review_id": 2617900805,
      "id": 1956206594,
      "node_id": "PRRC_kwDOABII5850mVgC",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952818760,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Too bad :( \r\n\r\nedit: my guess is we'll need to lower max orphan count to make CI runs happy",
      "created_at": "2025-02-14T14:09:30Z",
      "updated_at": "2025-02-14T14:21:43Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956206594",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956206594"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956527816",
      "pull_request_review_id": 2618467599,
      "id": 1956527816,
      "node_id": "PRRC_kwDOABII5850nj7I",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952818760,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Hm, I don't want to manually change `-maxorphantxs`. But hey, this is the idea for introducing the test prior to increasing the default to 3000. At that commit, the orphanage doesn't go past 100, so it's definitely doing evictions even with just 1010 + 101 orphans.",
      "created_at": "2025-02-14T17:54:15Z",
      "updated_at": "2025-02-14T17:54:38Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956527816",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956527816"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956579091",
      "pull_request_review_id": 2618559447,
      "id": 1956579091,
      "node_id": "PRRC_kwDOABII5850nwcT",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952818760,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "~Ok, I've made it 101 * 30 + 101 = 3131 total. I think the `wait_until` for the 1p1c orphan to be in orphanage kind of achieves what we want (i.e. evictions for each of the previous orphans have already been calculated) even though we don't explicitly wait for each peer.~ this is not true anymore\r\n",
      "created_at": "2025-02-14T18:41:16Z",
      "updated_at": "2025-02-19T14:05:48Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956579091",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956579091"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956602557",
      "pull_request_review_id": 2618600336,
      "id": 1956602557,
      "node_id": "PRRC_kwDOABII5850n2K9",
      "diff_hunk": "@@ -0,0 +1,179 @@\n+// Copyright (c) 2022-present The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <consensus/amount.h>\n+#include <consensus/validation.h>\n+#include <net_processing.h>\n+#include <node/eviction.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <script/script.h>\n+#include <sync.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/fuzz.h>\n+#include <test/fuzz/util.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <uint256.h>\n+#include <util/check.h>\n+#include <util/time.h>\n+\n+#include <cstdint>\n+#include <memory>\n+#include <set>\n+#include <utility>\n+#include <vector>\n+\n+void initialize_protected_orphanage()\n+{\n+    static const auto testing_setup = MakeNoLogFileContext();\n+}\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_protected_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId protect_peer{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 1'000);",
      "path": "src/test/fuzz/txorphan_protected.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a704b8a9596c83968a732e26e44061c7347cecef",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Let's set the upper range to DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS?",
      "created_at": "2025-02-14T19:04:04Z",
      "updated_at": "2025-02-14T19:05:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956602557",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956602557"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 46,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956603725",
      "pull_request_review_id": 2618600336,
      "id": 1956603725,
      "node_id": "PRRC_kwDOABII5850n2dN",
      "diff_hunk": "@@ -0,0 +1,179 @@\n+// Copyright (c) 2022-present The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <consensus/amount.h>\n+#include <consensus/validation.h>\n+#include <net_processing.h>\n+#include <node/eviction.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <script/script.h>\n+#include <sync.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/fuzz.h>\n+#include <test/fuzz/util.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <uint256.h>\n+#include <util/check.h>\n+#include <util/time.h>\n+\n+#include <cstdint>\n+#include <memory>\n+#include <set>\n+#include <utility>\n+#include <vector>\n+\n+void initialize_protected_orphanage()\n+{\n+    static const auto testing_setup = MakeNoLogFileContext();\n+}\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_protected_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId protect_peer{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 1'000);\n+    // This must match announcement limit (or exceed) otherwise \"honest\" peer can be evicted\n+    const unsigned int global_tx_limit = global_announcement_limit;\n+    const unsigned int per_peer_announcements = global_announcement_limit / NUM_PEERS;\n+    const unsigned int per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 4'000);",
      "path": "src/test/fuzz/txorphan_protected.cpp",
      "position": null,
      "original_position": 50,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a704b8a9596c83968a732e26e44061c7347cecef",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "set the upper range to DEFAULT_ANCESTOR_SIZE_LIMIT_KVB * 4000? See no reason to not cover the full range (we could also increase the num_outs range to make larger ranges hit based on a bool?",
      "created_at": "2025-02-14T19:05:24Z",
      "updated_at": "2025-02-14T19:05:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956603725",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956603725"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 50,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956621497",
      "pull_request_review_id": 2618633307,
      "id": 1956621497,
      "node_id": "PRRC_kwDOABII5850n6y5",
      "diff_hunk": "@@ -0,0 +1,179 @@\n+// Copyright (c) 2022-present The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <consensus/amount.h>\n+#include <consensus/validation.h>\n+#include <net_processing.h>\n+#include <node/eviction.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <script/script.h>\n+#include <sync.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/fuzz.h>\n+#include <test/fuzz/util.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <uint256.h>\n+#include <util/check.h>\n+#include <util/time.h>\n+\n+#include <cstdint>\n+#include <memory>\n+#include <set>\n+#include <utility>\n+#include <vector>\n+\n+void initialize_protected_orphanage()\n+{\n+    static const auto testing_setup = MakeNoLogFileContext();\n+}\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_protected_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId protect_peer{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 1'000);",
      "path": "src/test/fuzz/txorphan_protected.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a704b8a9596c83968a732e26e44061c7347cecef",
      "in_reply_to_id": 1956602557,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-02-14T19:23:44Z",
      "updated_at": "2025-02-14T19:23:44Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956621497",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956621497"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 46,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956622416",
      "pull_request_review_id": 2618634542,
      "id": 1956622416,
      "node_id": "PRRC_kwDOABII5850n7BQ",
      "diff_hunk": "@@ -0,0 +1,179 @@\n+// Copyright (c) 2022-present The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <consensus/amount.h>\n+#include <consensus/validation.h>\n+#include <net_processing.h>\n+#include <node/eviction.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <script/script.h>\n+#include <sync.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/fuzz.h>\n+#include <test/fuzz/util.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <uint256.h>\n+#include <util/check.h>\n+#include <util/time.h>\n+\n+#include <cstdint>\n+#include <memory>\n+#include <set>\n+#include <utility>\n+#include <vector>\n+\n+void initialize_protected_orphanage()\n+{\n+    static const auto testing_setup = MakeNoLogFileContext();\n+}\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_protected_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId protect_peer{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 1'000);\n+    // This must match announcement limit (or exceed) otherwise \"honest\" peer can be evicted\n+    const unsigned int global_tx_limit = global_announcement_limit;\n+    const unsigned int per_peer_announcements = global_announcement_limit / NUM_PEERS;\n+    const unsigned int per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 4'000);",
      "path": "src/test/fuzz/txorphan_protected.cpp",
      "position": null,
      "original_position": 50,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a704b8a9596c83968a732e26e44061c7347cecef",
      "in_reply_to_id": 1956603725,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I made it `DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 10`",
      "created_at": "2025-02-14T19:24:11Z",
      "updated_at": "2025-02-14T19:24:11Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956622416",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956622416"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 50,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956712751",
      "pull_request_review_id": 2618794047,
      "id": 1956712751,
      "node_id": "PRRC_kwDOABII5850oREv",
      "diff_hunk": "@@ -220,6 +220,44 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n     BOOST_CHECK_EQUAL(orphanage.CountOrphans(), 0);\n }\n \n+BOOST_AUTO_TEST_CASE(eviction)\n+{\n+    FastRandomContext det_rand{true};\n+    TxOrphanage orphanage;\n+\n+    // Send 10 orphans from 15 other peers\n+    NodeId dos_peer{15};\n+    std::vector<int64_t> peer_usages;\n+    peer_usages.reserve(dos_peer + 1);\n+    for (NodeId peer{0}; peer < dos_peer; ++peer) {\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+            orphanage.AddTx(ptx, peer);\n+        }\n+        peer_usages.emplace_back(orphanage.UsageByPeer(peer));\n+    }\n+\n+    // Send max orphans from 1 peer\n+    for (unsigned int i{0}; i < DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS; ++i) {\n+        auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+        orphanage.AddTx(ptx, dos_peer);\n+    }\n+    peer_usages.emplace_back(orphanage.UsageByPeer(dos_peer));\n+\n+    // Force an eviction. Note that no limiting has happened yet at this point (we haven't called\n+    // LimitOrphans yet) so it may be oversize and LimitOrphans may evict more than 1 transaction.\n+    // All evictions will be from the dos_peer's transactions.\n+    const auto prev_count = orphanage.Size();\n+    orphanage.LimitOrphans(prev_count - 1, det_rand);\n+    BOOST_CHECK(orphanage.Size() <= prev_count - 1);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 33,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "064af55a0aeb8da86386b19c97dc064807b1e862",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "This seems very cautious. The test first adds 150 txns, then another `DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS` (so there is a 1 to 1 relation between announcements and txns).\r\nIf all txns are distinct, this should be enough to assert that `Size()` should shrink by 150 compared to prev_count, not just 1.",
      "created_at": "2025-02-14T21:01:11Z",
      "updated_at": "2025-02-14T22:07:18Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956712751",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956712751"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 252,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956737572",
      "pull_request_review_id": 2618794047,
      "id": 1956737572,
      "node_id": "PRRC_kwDOABII5850oXIk",
      "diff_hunk": "@@ -375,6 +390,166 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": 120,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "793c80be58d0b5c2d14c9ba78353f3de188f46bc",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "the numbers don't add up for me: the tests creates 100 large orphans, sends 20, sends 1 small tx, then sends another 40 large orphans, and finally asserts that there are less than 101 entries in the orphanage. This would also be true without any eviction.",
      "created_at": "2025-02-14T21:26:59Z",
      "updated_at": "2025-02-14T22:07:18Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1956737572",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1956737572"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 467,
      "original_line": 467,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957128089",
      "pull_request_review_id": 2619421638,
      "id": 1957128089,
      "node_id": "PRRC_kwDOABII5850p2eZ",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] add per-peer iterator list and announcements accounting\"\r\n\r\nThe cost of this `std::distance` may be *O(num_orphans_per_peer)*, and the `peer : it->second.announcers` loop around can run up to *O(num_announcers_per_tx)*. However, since the sum of all `orphan_list` lengths is equal to the total number of announcements, the overall cost of `EraseTx` is bounded by *O(total_announcements)*. In both `MaybeExpireOrphan` and `EraseForBlock`, the function `EraseTx` may be invoked once per orphan, so I think this may actually mean *O(total_orphans * total_announcements)*, which may be millions, which could mean a concerning amount of time. Something similar may apply to the call in `MaybeTrimOrphans`, but it's a bit more complicated to analyse. Does that sound right?\r\n\r\nOne possibility to reduce this may be to batch the removals. Replace `EraseTx` with a function that takes a `set` of wtxids to remove, and just loops over all peers' `orphan_list`s once, removing anything that's in the set. That would reduce the cost to just *O(total_announcements)*. However, it would mean *always* iterating over all announcements whenever an orphan is erased.\r\n\r\nAlternatively, the `iter_list`s could be replaced with sets for faster removal, but that would increase the cost of random evictions in it from *O(1)* to *O(n)*. That might not actually be an improvement for `MaybeTrimOrphans`.\r\n\r\nI think the proper solution is replacing the data structures that together encode the announcement sets (`announcers`, `m_iter_list`, and optionally also `m_work_set`) with a single global boost::multiindex, with hashed by-wtxid index, and a ranked by-(peer,wtxid) index (which allows for fast random access).\r\n\r\n",
      "created_at": "2025-02-15T14:32:17Z",
      "updated_at": "2025-02-15T15:01:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957128089",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957128089"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957132917",
      "pull_request_review_id": 2619427042,
      "id": 1957132917,
      "node_id": "PRRC_kwDOABII5850p3p1",
      "diff_hunk": "@@ -0,0 +1,137 @@\n+// Copyright (c) 2011-2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <bench/bench.h>\n+#include <consensus/amount.h>\n+#include <net.h>\n+#include <primitives/transaction.h>\n+#include <pubkey.h>\n+#include <script/sign.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <util/check.h>\n+\n+#include <cstdint>\n+#include <memory>\n+\n+// Creates a transaction spending outpoints (or 1 randomly generated input if none are given), with num_outputs outputs.\n+static CTransactionRef MakeTransactionSpending(const std::vector<COutPoint>& outpoints, unsigned int num_outputs, FastRandomContext& det_rand)\n+{\n+    CMutableTransaction tx;\n+\n+    // Build vin\n+    // If no outpoints are given, create a random one.\n+    if (outpoints.empty()) {\n+        tx.vin.emplace_back(Txid::FromUint256(det_rand.rand256()), 0);\n+    } else {\n+        for (const auto& outpoint : outpoints) {\n+            tx.vin.emplace_back(outpoint);\n+        }\n+    }\n+    // Ensure txid != wtxid\n+    assert(tx.vin.size() > 0);\n+    tx.vin[0].scriptWitness.stack.push_back({1});\n+\n+    // Build vout\n+    assert(num_outputs > 0);\n+    tx.vout.resize(num_outputs);\n+    for (unsigned int o = 0; o < num_outputs; ++o) {\n+        tx.vout[o].nValue = det_rand.randrange(100) * CENT;\n+        tx.vout[o].scriptPubKey = CScript() << CScriptNum(det_rand.randrange(o + 100)) << OP_EQUAL;\n+    }\n+    return MakeTransactionRef(tx);\n+}\n+\n+static void OrphanageEvictionMany(benchmark::Bench& bench)\n+{\n+    NodeId NUM_PEERS{125};\n+    unsigned int NUM_TRANSACTIONS(DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / NUM_PEERS);",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 49,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3ce9ef7dd3c231976454e8c836640507bdb7e111",
      "in_reply_to_id": 1949655371,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "are you sure it's being sent via every peer for this benchmark? Looks like there's no overlap?",
      "created_at": "2025-02-15T15:02:22Z",
      "updated_at": "2025-02-15T15:02:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957132917",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957132917"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 103,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957150217",
      "pull_request_review_id": 2619452709,
      "id": 1957150217,
      "node_id": "PRRC_kwDOABII5850p74J",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": 1957128089,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added a few more benchmarks to get an idea of what it could look like with current PR: https://github.com/instagibbs/bitcoin/commit/ba2e3e339cafdf1b38742b2c288a18dd32c63db3\r\n\r\n```\r\n|               ns/op |                op/s |    err% |     total | benchmark\r\n|--------------------:|--------------------:|--------:|----------:|:----------\r\n|        7,012,786.00 |              142.60 |    0.9% |      0.08 | `OrphanageEvictionBlockManyPeers`\r\n|       27,505,341.00 |               36.36 |    0.8% |      0.30 | `OrphanageEvictionBlockOnePeer`\r\n|       12,507,729.00 |               79.95 |    0.6% |      0.14 | `OrphanageEvictionManyWithManyPeers`\r\n|       26,721,356.00 |               37.42 |    0.4% |      0.29 | `OrphanageEvictionManyWithOnePeer`\r\n|        7,262,273.00 |              137.70 |    3.3% |      0.08 | `OrphanageEvictionPeerMany`\r\n|       22,306,678.00 |               44.83 |    0.7% |      0.25 | `OrphanageEvictionPeerOne`\r\n\r\n```\r\nAdded EraseForBlock, EraseForPeer(in a loop), and parameterized number of peers. Looks like the `std::distance` work is causing most of the time since things are slower with a single peer?\r\n",
      "created_at": "2025-02-15T16:21:16Z",
      "updated_at": "2025-02-15T16:21:16Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957150217",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957150217"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957152330",
      "pull_request_review_id": 2619456799,
      "id": 1957152330,
      "node_id": "PRRC_kwDOABII5850p8ZK",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": 1957128089,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "@instagibbs I believe the worst case when max_orphans == max_announcements is to have exactly one peer, and then erasing the transactions in reverse order they appear in _m_list_iters.\n\nThat would cost n^2/2 steps in std::distance.\n\nWhen max_announcements is larger than max_orphans, the worst case is having max_announcements / max_orphans peers, and every transaction be announced by all, I think.",
      "created_at": "2025-02-15T16:35:09Z",
      "updated_at": "2025-02-15T16:35:10Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957152330",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957152330"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957154102",
      "pull_request_review_id": 2619458833,
      "id": 1957154102,
      "node_id": "PRRC_kwDOABII5850p802",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": 1957128089,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "> I believe the worst case when max_orphans == max_announcements is to have exactly one peer, and then erasing the transactions in reverse order they appear in _m_list_iters.\r\n\r\nI swapped the order of the block txns to force it to walk the whole list for the single peer, it's about 10% slower",
      "created_at": "2025-02-15T16:44:53Z",
      "updated_at": "2025-02-15T16:44:53Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957154102",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957154102"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957169813",
      "pull_request_review_id": 2619474645,
      "id": 1957169813,
      "node_id": "PRRC_kwDOABII5850qAqV",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": 1957128089,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Another solution maybe: replace `set<NodeId> announcers` in `OrphanTxBase` with a `std::map<NodeId, size_t> announcers`, where the value is the orphan's position in the `PeerOrphanInfo::m_iter_list`. Previously, we had a `list_pos`that tracked the orphan's location in `m_orphan_list`. That removes the need to do `std::distance`.\r\n\r\nOn the whole though, I agree a multiindex is probably the most natural data structure for orphanage.",
      "created_at": "2025-02-15T18:22:57Z",
      "updated_at": "2025-02-15T18:22:57Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957169813",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957169813"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957171207",
      "pull_request_review_id": 2619475938,
      "id": 1957171207,
      "node_id": "PRRC_kwDOABII5850qBAH",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": 1957128089,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "@glozow That works, I believe.",
      "created_at": "2025-02-15T18:32:39Z",
      "updated_at": "2025-02-15T18:32:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957171207",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957171207"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957232376",
      "pull_request_review_id": 2619531521,
      "id": 1957232376,
      "node_id": "PRRC_kwDOABII5850qP74",
      "diff_hunk": "@@ -592,47 +611,6 @@ def test_orphan_txid_inv(self):\n         assert_equal(node.getmempoolentry(tx_child[\"txid\"])[\"wtxid\"], tx_child[\"wtxid\"])\n         self.wait_until(lambda: len(node.getorphantxs()) == 0)\n \n-    @cleanup\n-    def test_max_orphan_amount(self):\n-        self.log.info(\"Check that we never exceed our storage limits for orphans\")\n-\n-        node = self.nodes[0]\n-        self.generate(self.wallet, 1)\n-        peer_1 = node.add_p2p_connection(P2PInterface())\n-\n-        self.log.info(\"Check that orphanage is empty on start of test\")\n-        assert len(node.getorphantxs()) == 0\n-\n-        self.log.info(\"Filling up orphanage with \" + str(DEFAULT_MAX_ORPHAN_TRANSACTIONS) + \"(DEFAULT_MAX_ORPHAN_TRANSACTIONS) orphans\")\n-        orphans = []\n-        parent_orphans = []\n-        for _ in range(DEFAULT_MAX_ORPHAN_TRANSACTIONS):\n-            tx_parent_1 = self.wallet.create_self_transfer()\n-            tx_child_1 = self.wallet.create_self_transfer(utxo_to_spend=tx_parent_1[\"new_utxo\"])\n-            parent_orphans.append(tx_parent_1[\"tx\"])\n-            orphans.append(tx_child_1[\"tx\"])\n-            peer_1.send_message(msg_tx(tx_child_1[\"tx\"]))\n-\n-        peer_1.sync_with_ping()\n-        orphanage = node.getorphantxs()\n-        self.wait_until(lambda: len(node.getorphantxs()) == DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-\n-        for orphan in orphans:\n-            assert tx_in_orphanage(node, orphan)\n-\n-        self.log.info(\"Check that we do not add more than the max orphan amount\")\n-        tx_parent_1 = self.wallet.create_self_transfer()\n-        tx_child_1 = self.wallet.create_self_transfer(utxo_to_spend=tx_parent_1[\"new_utxo\"])\n-        peer_1.send_and_ping(msg_tx(tx_child_1[\"tx\"]))\n-        parent_orphans.append(tx_parent_1[\"tx\"])\n-        orphanage = node.getorphantxs()\n-        assert_equal(len(orphanage), DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-\n-        self.log.info(\"Clearing the orphanage\")\n-        for index, parent_orphan in enumerate(parent_orphans):\n-            peer_1.send_and_ping(msg_tx(parent_orphan))\n-        self.wait_until(lambda: len(node.getorphantxs()) == 0)",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": null,
      "original_position": 118,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "212e1ea50cc229483cbdde04ed2b22b9e7e5dfc6",
      "in_reply_to_id": null,
      "user": {
        "login": "kevkevinpal",
        "id": 15950706,
        "node_id": "MDQ6VXNlcjE1OTUwNzA2",
        "avatar_url": "https://avatars.githubusercontent.com/u/15950706?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/kevkevinpal",
        "html_url": "https://github.com/kevkevinpal",
        "followers_url": "https://api.github.com/users/kevkevinpal/followers",
        "following_url": "https://api.github.com/users/kevkevinpal/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/kevkevinpal/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/kevkevinpal/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/kevkevinpal/subscriptions",
        "organizations_url": "https://api.github.com/users/kevkevinpal/orgs",
        "repos_url": "https://api.github.com/users/kevkevinpal/repos",
        "events_url": "https://api.github.com/users/kevkevinpal/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/kevkevinpal/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "instead of removing this test we can keep it if we restart the node with the previous max orphan amount\r\n\r\n```\r\nself.restart_node(0, extra_args=[\"-maxorphantx=\" + str(DEFAULT_MAX_ORPHAN_TRANSACTIONS)])\r\n```\r\n\r\nand we can probably move `DEFAULT_MAX_ORPHAN_TRANSACTIONS` into this `test_max_orphan_amount` and rename it to `max_orphan_amount` since this isnt the default max orphan amount anymore.\r\n\r\nIf we still don't want this test we can remove `DEFAULT_MAX_ORPHAN_TRANSACTIONS` since it is only used in this test",
      "created_at": "2025-02-16T03:25:07Z",
      "updated_at": "2025-02-16T03:25:07Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1957232376",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1957232376"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": 595,
      "start_side": "LEFT",
      "line": null,
      "original_line": 635,
      "side": "LEFT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959814286",
      "pull_request_review_id": 2623681622,
      "id": 1959814286,
      "node_id": "PRRC_kwDOABII58500GSO",
      "diff_hunk": "@@ -36,8 +36,12 @@ bool TxOrphanage::AddTx(const CTransactionRef& tx, NodeId peer)\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME}, m_orphan_list.size()});\n+    auto& orphan_list = m_peer_orphanage_info.try_emplace(peer).first->second.m_iter_list;\n+    std::map<NodeId, size_t> announcer_list_pos{{peer, orphan_list.size()}};\n+    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, announcer_list_pos, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME}, m_orphan_list.size()});",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 7,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] add per-peer iterator list and announcements accounting\"\r\n\r\nUse `tx, std::move(announcer_list_pos), ...` to avoid an allocation.",
      "created_at": "2025-02-18T14:04:26Z",
      "updated_at": "2025-02-18T15:24:21Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1959814286",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959814286"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 41,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959842788",
      "pull_request_review_id": 2623681622,
      "id": 1959842788,
      "node_id": "PRRC_kwDOABII58500NPk",
      "diff_hunk": "@@ -138,11 +149,29 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions announced by this peer. */\n+        std::vector<OrphanMap::iterator> m_iter_list;\n+\n+        /** Remove the element at list_pos in m_iter_list in O(1) time by swapping the last element\n+         * with the one at list_pos and popping the back if there are multiple elements. Returns the\n+         * swapped element, if applicable, so that the caller can update its list_pos.",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] add per-peer iterator list and announcements accounting\"\r\n\r\nWould it be possible to do the `list_pos` updating here without needing to return an iteration to push that responsibility to the caller? It would mean `RemoveIterAt` would need to know what peer it's operating in, so that means it's perhaps more appropriate to have it as ` TxOrphanage` member function rather than a `PeerOrphanInfo` member function.",
      "created_at": "2025-02-18T14:18:59Z",
      "updated_at": "2025-02-18T15:24:21Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1959842788",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959842788"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 158,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959859482",
      "pull_request_review_id": 2623681622,
      "id": 1959859482,
      "node_id": "PRRC_kwDOABII58500RUa",
      "diff_hunk": "@@ -104,6 +111,7 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n         m_orphan_list[old_pos] = it_last;\n         it_last->second.list_pos = old_pos;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] add per-peer iterator list and announcements accounting\"\r\n\r\nI think this line, and the 7 lines before it, can be replaced with `RemoveIterAt(it->second.list_pos)`, especially if it can be changed to do the `list_pos` updating internally?\r\n\r\nNot very important as the code disappears in the next commit, but would make it more obviously correct.",
      "created_at": "2025-02-18T14:26:48Z",
      "updated_at": "2025-02-18T15:24:21Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1959859482",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959859482"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 112,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959969112",
      "pull_request_review_id": 2623681622,
      "id": 1959969112,
      "node_id": "PRRC_kwDOABII58500sFY",
      "diff_hunk": "@@ -97,4 +97,105 @@ static void OrphanageEraseForBlockSinglePeer(benchmark::Bench& bench)\n     });\n }\n \n+static void OrphanageEvictionManyPeers(benchmark::Bench& bench)",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 4,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "2bffbd5c9d7459a2184a1a8a75cc1018f8094e80",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[bench] TxOrphanage::LimitOrphans\"\r\n\r\nWould it make sense to introduce this benchmark earlier (and the other ones below), so we can see what effect the previous commit has on it?",
      "created_at": "2025-02-18T15:21:32Z",
      "updated_at": "2025-02-18T15:24:21Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1959969112",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1959969112"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 102,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960532733",
      "pull_request_review_id": 2624937463,
      "id": 1960532733,
      "node_id": "PRRC_kwDOABII585021r9",
      "diff_hunk": "@@ -592,47 +611,6 @@ def test_orphan_txid_inv(self):\n         assert_equal(node.getmempoolentry(tx_child[\"txid\"])[\"wtxid\"], tx_child[\"wtxid\"])\n         self.wait_until(lambda: len(node.getorphantxs()) == 0)\n \n-    @cleanup\n-    def test_max_orphan_amount(self):\n-        self.log.info(\"Check that we never exceed our storage limits for orphans\")\n-\n-        node = self.nodes[0]\n-        self.generate(self.wallet, 1)\n-        peer_1 = node.add_p2p_connection(P2PInterface())\n-\n-        self.log.info(\"Check that orphanage is empty on start of test\")\n-        assert len(node.getorphantxs()) == 0\n-\n-        self.log.info(\"Filling up orphanage with \" + str(DEFAULT_MAX_ORPHAN_TRANSACTIONS) + \"(DEFAULT_MAX_ORPHAN_TRANSACTIONS) orphans\")\n-        orphans = []\n-        parent_orphans = []\n-        for _ in range(DEFAULT_MAX_ORPHAN_TRANSACTIONS):\n-            tx_parent_1 = self.wallet.create_self_transfer()\n-            tx_child_1 = self.wallet.create_self_transfer(utxo_to_spend=tx_parent_1[\"new_utxo\"])\n-            parent_orphans.append(tx_parent_1[\"tx\"])\n-            orphans.append(tx_child_1[\"tx\"])\n-            peer_1.send_message(msg_tx(tx_child_1[\"tx\"]))\n-\n-        peer_1.sync_with_ping()\n-        orphanage = node.getorphantxs()\n-        self.wait_until(lambda: len(node.getorphantxs()) == DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-\n-        for orphan in orphans:\n-            assert tx_in_orphanage(node, orphan)\n-\n-        self.log.info(\"Check that we do not add more than the max orphan amount\")\n-        tx_parent_1 = self.wallet.create_self_transfer()\n-        tx_child_1 = self.wallet.create_self_transfer(utxo_to_spend=tx_parent_1[\"new_utxo\"])\n-        peer_1.send_and_ping(msg_tx(tx_child_1[\"tx\"]))\n-        parent_orphans.append(tx_parent_1[\"tx\"])\n-        orphanage = node.getorphantxs()\n-        assert_equal(len(orphanage), DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-\n-        self.log.info(\"Clearing the orphanage\")\n-        for index, parent_orphan in enumerate(parent_orphans):\n-            peer_1.send_and_ping(msg_tx(parent_orphan))\n-        self.wait_until(lambda: len(node.getorphantxs()) == 0)",
      "path": "test/functional/p2p_orphan_handling.py",
      "position": null,
      "original_position": 118,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "212e1ea50cc229483cbdde04ed2b22b9e7e5dfc6",
      "in_reply_to_id": 1957232376,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "thanks, removed `DEFAULT_MAX_ORPHAN_TRANSACTIONS`",
      "created_at": "2025-02-18T20:15:36Z",
      "updated_at": "2025-02-18T20:15:36Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960532733",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960532733"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": 595,
      "start_side": "LEFT",
      "line": null,
      "original_line": 635,
      "side": "LEFT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960532993",
      "pull_request_review_id": 2624937845,
      "id": 1960532993,
      "node_id": "PRRC_kwDOABII585021wB",
      "diff_hunk": "@@ -375,6 +390,166 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": 120,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "793c80be58d0b5c2d14c9ba78353f3de188f46bc",
      "in_reply_to_id": 1956737572,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "thanks, fixed",
      "created_at": "2025-02-18T20:15:47Z",
      "updated_at": "2025-02-18T20:15:48Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960532993",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960532993"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 467,
      "original_line": 467,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960533250",
      "pull_request_review_id": 2624938263,
      "id": 1960533250,
      "node_id": "PRRC_kwDOABII5850210C",
      "diff_hunk": "@@ -220,6 +220,44 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n     BOOST_CHECK_EQUAL(orphanage.CountOrphans(), 0);\n }\n \n+BOOST_AUTO_TEST_CASE(eviction)\n+{\n+    FastRandomContext det_rand{true};\n+    TxOrphanage orphanage;\n+\n+    // Send 10 orphans from 15 other peers\n+    NodeId dos_peer{15};\n+    std::vector<int64_t> peer_usages;\n+    peer_usages.reserve(dos_peer + 1);\n+    for (NodeId peer{0}; peer < dos_peer; ++peer) {\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+            orphanage.AddTx(ptx, peer);\n+        }\n+        peer_usages.emplace_back(orphanage.UsageByPeer(peer));\n+    }\n+\n+    // Send max orphans from 1 peer\n+    for (unsigned int i{0}; i < DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS; ++i) {\n+        auto ptx = MakeTransactionSpending(/*outpoints=*/{}, det_rand);\n+        orphanage.AddTx(ptx, dos_peer);\n+    }\n+    peer_usages.emplace_back(orphanage.UsageByPeer(dos_peer));\n+\n+    // Force an eviction. Note that no limiting has happened yet at this point (we haven't called\n+    // LimitOrphans yet) so it may be oversize and LimitOrphans may evict more than 1 transaction.\n+    // All evictions will be from the dos_peer's transactions.\n+    const auto prev_count = orphanage.Size();\n+    orphanage.LimitOrphans(prev_count - 1, det_rand);\n+    BOOST_CHECK(orphanage.Size() <= prev_count - 1);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 33,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "064af55a0aeb8da86386b19c97dc064807b1e862",
      "in_reply_to_id": 1956712751,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "changed to be asserting exact counts ðŸ‘ ",
      "created_at": "2025-02-18T20:16:01Z",
      "updated_at": "2025-02-18T20:16:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960533250",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960533250"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 252,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960567794",
      "pull_request_review_id": 2624993182,
      "id": 1960567794,
      "node_id": "PRRC_kwDOABII58502-Py",
      "diff_hunk": "@@ -104,6 +111,7 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n         m_orphan_list[old_pos] = it_last;\n         it_last->second.list_pos = old_pos;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": 1959859482,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Maybe I'm misunderstanding, but I don't think we can use `RemoveIterAt` (which is for updating the peer list) for this (which is the global `TxOrphanage::m_orphan_list`)?",
      "created_at": "2025-02-18T20:45:45Z",
      "updated_at": "2025-02-18T20:45:45Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960567794",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960567794"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 112,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960570915",
      "pull_request_review_id": 2624998284,
      "id": 1960570915,
      "node_id": "PRRC_kwDOABII58502_Aj",
      "diff_hunk": "@@ -104,6 +111,7 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n         m_orphan_list[old_pos] = it_last;\n         it_last->second.list_pos = old_pos;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": 1959859482,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Oh of course; it just looked very similar.",
      "created_at": "2025-02-18T20:48:37Z",
      "updated_at": "2025-02-18T20:48:37Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960570915",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960570915"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 112,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960581755",
      "pull_request_review_id": 2625015977,
      "id": 1960581755,
      "node_id": "PRRC_kwDOABII58503Bp7",
      "diff_hunk": "@@ -36,8 +36,12 @@ bool TxOrphanage::AddTx(const CTransactionRef& tx, NodeId peer)\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME}, m_orphan_list.size()});\n+    auto& orphan_list = m_peer_orphanage_info.try_emplace(peer).first->second.m_iter_list;\n+    std::map<NodeId, size_t> announcer_list_pos{{peer, orphan_list.size()}};\n+    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, announcer_list_pos, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME}, m_orphan_list.size()});",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 7,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": 1959814286,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "thanks, done",
      "created_at": "2025-02-18T20:58:01Z",
      "updated_at": "2025-02-18T20:58:01Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960581755",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960581755"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 41,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960582140",
      "pull_request_review_id": 2625016585,
      "id": 1960582140,
      "node_id": "PRRC_kwDOABII58503Bv8",
      "diff_hunk": "@@ -138,11 +149,29 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions announced by this peer. */\n+        std::vector<OrphanMap::iterator> m_iter_list;\n+\n+        /** Remove the element at list_pos in m_iter_list in O(1) time by swapping the last element\n+         * with the one at list_pos and popping the back if there are multiple elements. Returns the\n+         * swapped element, if applicable, so that the caller can update its list_pos.",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "19c77223cd2d8dc720072d8430082e8e6cae2793",
      "in_reply_to_id": 1959842788,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "good point, I've made it a `TxOrphanage` method now",
      "created_at": "2025-02-18T20:58:18Z",
      "updated_at": "2025-02-18T20:58:18Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960582140",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960582140"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 158,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960582312",
      "pull_request_review_id": 2625016865,
      "id": 1960582312,
      "node_id": "PRRC_kwDOABII58503Byo",
      "diff_hunk": "@@ -97,4 +97,105 @@ static void OrphanageEraseForBlockSinglePeer(benchmark::Bench& bench)\n     });\n }\n \n+static void OrphanageEvictionManyPeers(benchmark::Bench& bench)",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 4,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "2bffbd5c9d7459a2184a1a8a75cc1018f8094e80",
      "in_reply_to_id": 1959969112,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "yes, moved it up",
      "created_at": "2025-02-18T20:58:27Z",
      "updated_at": "2025-02-18T20:58:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960582312",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960582312"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 102,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960668271",
      "pull_request_review_id": 2625167907,
      "id": 1960668271,
      "node_id": "PRRC_kwDOABII58503Wxv",
      "diff_hunk": "@@ -87,11 +90,21 @@ int TxOrphanage::EraseTx(const Wtxid& wtxid)\n     const auto tx_size{it->second.GetUsage()};\n     m_total_orphan_usage -= tx_size;\n     m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n+    // Decrement each announcer's m_total_usage and remove orphan from all m_iter_list.\n     for (const auto& peer : it->second.announcers) {\n         auto peer_it = m_peer_orphanage_info.find(peer);\n         if (Assume(peer_it != m_peer_orphanage_info.end())) {\n             peer_it->second.m_total_usage -= tx_size;\n+\n+            auto& orphan_list = peer_it->second.m_iter_list;\n+            size_t old_pos = std::distance(orphan_list.begin(), std::find(orphan_list.begin(), orphan_list.end(), it));",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 29,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "944f61e6d55c91aed0dd4585374c1fbeec018028",
      "in_reply_to_id": 1957128089,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "> replace set<NodeId> announcers in OrphanTxBase with a std::map<NodeId, size_t> announcers, where the value is the orphan's position in the PeerOrphanInfo::m_iter_list\r\n\r\nWent ahead with this solution.",
      "created_at": "2025-02-18T22:15:37Z",
      "updated_at": "2025-02-18T22:15:37Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960668271",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960668271"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 100,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960805496",
      "pull_request_review_id": 2625405683,
      "id": 1960805496,
      "node_id": "PRRC_kwDOABII585034R4",
      "diff_hunk": "@@ -0,0 +1,100 @@\n+// Copyright (c) 2011-2022 The Bitcoin Core developers",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 1,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "032b6237532fac9685d4ac89922b1eac815687e6",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[bench] TxOrphanage::EraseForBlock\"\r\n\r\nBetter not to have years listed than outdated/wrong ones.",
      "created_at": "2025-02-19T01:12:03Z",
      "updated_at": "2025-02-19T04:27:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960805496",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960805496"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 1,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960809301",
      "pull_request_review_id": 2625405683,
      "id": 1960809301,
      "node_id": "PRRC_kwDOABII585035NV",
      "diff_hunk": "@@ -168,6 +180,10 @@ class TxOrphanage {\n \n     /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n+\n+    /** Remove the element at list_pos in m_iter_list in O(1) time by swapping the last element",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 56,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "56f05a73d88320af45ad2eeb64eb89f159c203cc",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[txorphanage] add per-peer iterator list and announcements accounting\"\r\n\r\nNit: I may have instigated this, but given the `m_peer_orphanage_info.find(peer)` call, it's *O(log n)* really (in the number of peers, not *O(1)*). ",
      "created_at": "2025-02-19T01:18:01Z",
      "updated_at": "2025-02-19T04:27:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960809301",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960809301"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 184,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960932480",
      "pull_request_review_id": 2625405683,
      "id": 1960932480,
      "node_id": "PRRC_kwDOABII58504XSA",
      "diff_hunk": "@@ -138,10 +165,28 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions in vector for quick random eviction */\n+        std::vector<OrphanMap::iterator> m_iter_list;\n+\n+        /** There are 2 DoS scores:\n+         * - CPU score (ratio of num announcements / max allowed announcements)\n+         * - Memory score (ratio of total usage / max allowed usage).\n+         *\n+         * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+         * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+         * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+         * be selected for trimming sooner. If the orphanage NeedsTrim(), it must be that at least\n+         * one peer has a DoS score > 1. */\n+        FeeFrac GetDoSScore(unsigned int peer_max_ann, unsigned int peer_max_mem) {\n+            FeeFrac cpu_score(m_iter_list.size(), peer_max_ann);\n+            FeeFrac mem_score(m_total_usage, peer_max_mem);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n     };\n     std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 93,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949554535,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Regarding https://github.com/bitcoin/bitcoin/pull/31829/commits/2771b69e461230feb7761b0afff41b44bd3ba34f#r1949554535\r\n\r\nWith `GetGlobalMaxUsage()` computing memory limits on-the-fly, is this comment still relevant?",
      "created_at": "2025-02-19T04:26:30Z",
      "updated_at": "2025-02-19T04:27:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1960932480",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1960932480"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 196,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1961743938",
      "pull_request_review_id": 2626915481,
      "id": 1961743938,
      "node_id": "PRRC_kwDOABII58507dZC",
      "diff_hunk": "@@ -375,6 +390,160 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 20]))]\n+        return tx\n+\n+    def create_small_orphan(self):\n+        \"\"\"Create small orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 5)]\n+        tx.vout = [CTxOut(100, CScript([OP_RETURN, b'a' * 3]))]\n+        return tx\n+\n+    @cleanup\n+    def test_orphanage_dos_large(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers use lots of orphanage space\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+        peer_doser = node.add_p2p_connection(P2PInterface())\n+\n+        self.log.info(\"Create very large orphans to be sent by DoSy peers (may take a while)\")\n+        large_orphans = [self.create_large_orphan() for _ in range(100)]\n+        # Check to make sure these are orphans, within max standard size (to be accepted into the orphanage)\n+        for large_orphan in large_orphans:\n+            assert_greater_than_or_equal(100000, large_orphan.get_vsize())\n+            assert_greater_than(MAX_STANDARD_TX_WEIGHT, large_orphan.get_weight())\n+            assert_greater_than_or_equal(3 * large_orphan.get_vsize(), 2 * 100000)\n+            testres = node.testmempoolaccept([large_orphan.serialize().hex()])\n+            assert not testres[0][\"allowed\"]\n+            assert_equal(testres[0][\"reject-reason\"], \"missing-inputs\")\n+\n+        num_individual_dosers = 20\n+        self.log.info(f\"Connect {num_individual_dosers} peers and send a very large orphan from each one\")\n+        # This test assumes that unrequested transactions are processed (skipping inv and\n+        # getdata steps because they require going through request delays)\n+        # Connect 20 peers and have each of them send a large orphan.\n+        for large_orphan in large_orphans[:num_individual_dosers]:\n+            peer_doser_individual = node.add_p2p_connection(P2PInterface())\n+            peer_doser_individual.send_and_ping(msg_tx(large_orphan))\n+            node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+            peer_doser_individual.wait_for_getdata([large_orphan.vin[0].prevout.hash])\n+\n+        # Make sure that these transactions are going through the orphan handling codepaths.\n+        # Subsequent rounds will not wait for getdata because the time mocking will cause the\n+        # normal package request to time out.\n+        self.wait_until(lambda: len(node.getorphantxs()) == num_individual_dosers)\n+\n+        self.log.info(\"Send an orphan from a non-DoSy peer. Its orphan should not be evicted.\")\n+        low_fee_parent = self.create_tx_below_mempoolminfee(self.wallet)\n+        high_fee_child = self.wallet.create_self_transfer(\n+            utxo_to_spend=low_fee_parent[\"new_utxo\"],\n+            fee_rate=20*FEERATE_1SAT_VB,\n+            target_vsize=100000\n+        )\n+\n+        # Announce\n+        orphan_wtxid = high_fee_child[\"wtxid\"]\n+        orphan_tx = high_fee_child[\"tx\"]\n+        orphan_inv = CInv(t=MSG_WTX, h=int(orphan_wtxid, 16))\n+\n+        # Wait for getdata\n+        peer_normal.send_and_ping(msg_inv([orphan_inv]))\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY)\n+        peer_normal.wait_for_getdata([int(orphan_wtxid, 16)])\n+        peer_normal.send_and_ping(msg_tx(orphan_tx))\n+\n+        # Wait for parent request\n+        parent_txid_int = int(low_fee_parent[\"txid\"], 16)\n+        node.bumpmocktime(NONPREF_PEER_TX_DELAY + TXID_RELAY_DELAY)\n+        peer_normal.wait_for_getdata([parent_txid_int])\n+\n+        self.log.info(\"Send another round of very large orphans from a DoSy peer\")\n+        for large_orphan in large_orphans[60:]:\n+            peer_doser.send_and_ping(msg_tx(large_orphan))\n+\n+        # Something was evicted; the orphanage does not contain all large orphans + the 1p1c child\n+        self.wait_until(lambda: len(node.getorphantxs()) < len(large_orphans) + 1)\n+\n+        self.log.info(\"Provide the orphan's parent. This 1p1c package should be successfully accepted.\")\n+        peer_normal.send_and_ping(msg_tx(low_fee_parent[\"tx\"]))\n+        assert_equal(node.getmempoolentry(orphan_tx.rehash())[\"ancestorcount\"], 2)\n+\n+    @cleanup\n+    def test_orphanage_dos_many(self):\n+        self.log.info(\"Test that the node can still resolve orphans when peers are sending tons of orphans\")\n+        node = self.nodes[0]\n+        node.setmocktime(int(time.time()))\n+\n+        peer_normal = node.add_p2p_connection(P2PInterface())\n+\n+        batch_size = 100\n+        num_peers = 10\n+        # Each of the num_peers peers creates a distinct set of orphans\n+        many_orphans = [self.create_small_orphan() for _ in range(batch_size * num_peers)]\n+\n+        self.log.info(f\"Send sets of {batch_size} orphans from {num_peers} DoSy peers (may take a while)\")\n+        for peernum in range(num_peers):\n+            peer_doser_batch = node.add_p2p_connection(P2PInterface())\n+            for tx in many_orphans[batch_size*peernum : batch_size*(peernum+1)]:\n+                # Don't sync with ping or wait for responses, because it dramatically increases the\n+                # runtime of this test.\n+                peer_doser_batch.send_message(msg_tx(tx))\n+\n+        # Something was evicted\n+        self.wait_until(lambda: len(node.getorphantxs()) < batch_size * num_peers)",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 158,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "acbe37029ecea8518ecbf1f7a4846584b42ccaea",
      "in_reply_to_id": 1952818760,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "fwiw, here's what I landed on for `test_orphanage_dos_many`:\r\n(1) send 51 of the same orphan from 60 peers (51 orphans, 3060 announcements). `sync_with_ping` and wait until at least one of the orphans is in orphanage\r\n(2) send the 1p1c, which is a small orphan (not 100kvb because prior to increasing `-maxorphantxs`, this peer's memory DoS score could be higher than the other peers' CPU DoS scores and get the tx evicted. Better to compare apples to apples).\r\n(3) send 51 unique orphans from 40 peers (2040 orphans, 2040 announcements). `sync_with_ping` and wait until we have at least 1 of the orphans from each peer.\r\nThis gives us 2091 orphans, 5100 announcements total from the DoSy peers, plus 1 normal from the 1p1c.\r\n\r\nBefore we increase `-maxorphantxs`, there are evictions during (3).\r\nAfter we increase `-maxorphantxs`, there are evictions in (1) and (3). The reason I'm doing the shared orphans first is so that we get to maximum announcements more quickly, and we can expect evictions during both rounds.",
      "created_at": "2025-02-19T14:05:15Z",
      "updated_at": "2025-02-19T14:06:42Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1961743938",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1961743938"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 506,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1963963925",
      "pull_request_review_id": 2630521880,
      "id": 1963963925,
      "node_id": "PRRC_kwDOABII5851D7YV",
      "diff_hunk": "@@ -138,10 +165,28 @@ class TxOrphanage {\n          * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n          * remains in the orphanage, this number will be decremented. */\n         int64_t m_total_usage{0};\n+\n+        /** Orphan transactions in vector for quick random eviction */\n+        std::vector<OrphanMap::iterator> m_iter_list;\n+\n+        /** There are 2 DoS scores:\n+         * - CPU score (ratio of num announcements / max allowed announcements)\n+         * - Memory score (ratio of total usage / max allowed usage).\n+         *\n+         * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+         * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+         * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+         * be selected for trimming sooner. If the orphanage NeedsTrim(), it must be that at least\n+         * one peer has a DoS score > 1. */\n+        FeeFrac GetDoSScore(unsigned int peer_max_ann, unsigned int peer_max_mem) {\n+            FeeFrac cpu_score(m_iter_list.size(), peer_max_ann);\n+            FeeFrac mem_score(m_total_usage, peer_max_mem);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n     };\n     std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 93,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949554535,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I guess my worry is that we would somehow add a regression that results in the peer set growing indefinitely in the orphanage, which would grow memory usage substantially. Here's some suggested coverage which would hopefully uncover such an issue (unless the caller plum forgets to `EraseForPeer`):\r\n\r\n```\r\ndiff --git a/src/test/fuzz/txorphan.cpp b/src/test/fuzz/txorphan.cpp\r\nindex 9133323449..df0a02d75d 100644\r\n--- a/src/test/fuzz/txorphan.cpp\r\n+++ b/src/test/fuzz/txorphan.cpp\r\n@@ -45,10 +45,15 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\r\n         outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\r\n     }\r\n \r\n     CTransactionRef ptx_potential_parent = nullptr;\r\n \r\n+    // Peers which have offered orphans (via tx or announcement) and have not subsequently\r\n+    // \"disconnected\" aka called EraseForPeer\r\n+    std::set<NodeId> connected_peers;\r\n+\r\n+\r\n     LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * DEFAULT_MAX_ORPHAN_TRANSACTIONS)\r\n     {\r\n         // construct transaction\r\n         const CTransactionRef tx = [&] {\r\n             CMutableTransaction tx_mut;\r\n@@ -121,14 +126,16 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\r\n \r\n                         if (add_tx) {\r\n                             Assert(orphanage.UsageByPeer(peer_id) == tx_weight + total_peer_bytes_start);\r\n                             Assert(orphanage.TotalOrphanUsage() == tx_weight + total_bytes_start);\r\n                             Assert(tx_weight <= MAX_STANDARD_TX_WEIGHT);\r\n+                            connected_peers.insert(peer_id);\r\n                         } else {\r\n                             // Peer may have been added as an announcer.\r\n                             if (orphanage.UsageByPeer(peer_id) == tx_weight + total_peer_bytes_start) {\r\n                                 Assert(orphanage.HaveTxFromPeer(wtxid, peer_id));\r\n+                                connected_peers.insert(peer_id);\r\n                             } else {\r\n                                 // Otherwise, there must not be any change to the peer byte count.\r\n                                 Assert(orphanage.UsageByPeer(peer_id) == total_peer_bytes_start);\r\n                             }\r\n \r\n@@ -158,10 +165,11 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\r\n                         // Total bytes should not have changed. If peer was added as announcer, byte\r\n                         // accounting must have been updated.\r\n                         Assert(orphanage.TotalOrphanUsage() == total_bytes_start);\r\n                         if (added_announcer) {\r\n                             Assert(orphanage.UsageByPeer(peer_id) == tx_weight + total_peer_bytes_start);\r\n+                            connected_peers.insert(peer_id);\r\n                         } else {\r\n                             Assert(orphanage.UsageByPeer(peer_id) == total_peer_bytes_start);\r\n                         }\r\n                     }\r\n                 },\r\n@@ -190,10 +198,11 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\r\n                         Assert(!have_tx && !have_tx_and_peer && !orphanage.EraseTx(wtxid));\r\n                     }\r\n                 },\r\n                 [&] {\r\n                     orphanage.EraseForPeer(peer_id);\r\n+                    connected_peers.erase(peer_id); // \"DisconnectPeer\"\r\n                     Assert(!orphanage.HaveTxFromPeer(tx->GetWitnessHash(), peer_id));\r\n                     Assert(orphanage.UsageByPeer(peer_id) == 0);\r\n                 },\r\n                 [&] {\r\n                     // test mocktime and expiry\r\n@@ -212,7 +221,8 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\r\n \r\n         const bool have_tx{orphanage.HaveTx(tx->GetWitnessHash())};\r\n         const bool get_tx_nonnull{orphanage.GetTx(tx->GetWitnessHash()) != nullptr};\r\n         Assert(have_tx == get_tx_nonnull);\r\n     }\r\n-    orphanage.SanityCheck();\r\n+\r\n+    orphanage.SanityCheck(connected_peers.size());\r\n }\r\ndiff --git a/src/txorphanage.cpp b/src/txorphanage.cpp\r\nindex 40a2503af5..c6c156409d 100644\r\n--- a/src/txorphanage.cpp\r\n+++ b/src/txorphanage.cpp\r\n@@ -402,11 +402,11 @@ std::vector<TxOrphanage::OrphanTxBase> TxOrphanage::GetOrphanTransactions() cons\r\n         ret.push_back({o.second.tx, o.second.announcers, o.second.nTimeExpire});\r\n     }\r\n     return ret;\r\n }\r\n \r\n-void TxOrphanage::SanityCheck() const\r\n+void TxOrphanage::SanityCheck(int expected_num_peers) const\r\n {\r\n     // Check that cached m_total_announcements is correct. First count when iterating through m_orphans (counting number\r\n     // of announcers each), then count when iterating through peers (counting number of orphans per peer).\r\n     unsigned int counted_total_announcements{0};\r\n     // Check that m_total_orphan_usage is correct\r\n@@ -461,10 +461,16 @@ void TxOrphanage::SanityCheck() const\r\n                 return orphan_it->second.tx->GetWitnessHash() == wtxid;\r\n             }) != info.m_iter_list.end());\r\n         }\r\n     }\r\n \r\n+    // We should not be offering more global memory for orphanage than expected\r\n+    if (expected_num_peers != -1) {\r\n+        Assert((size_t) expected_num_peers == m_peer_orphanage_info.size());\r\n+        Assert(GetGlobalMaxUsage() == std::max<int64_t>(expected_num_peers * GetPerPeerMaxUsage(), 1));\r\n+    }\r\n+\r\n     Assert(wtxids_in_peer_map.size() == m_orphans.size());\r\n     Assert(counted_total_announcements == 0);\r\n }\r\n \r\n bool TxOrphanage::NeedsTrim(unsigned int max_orphans) const\r\ndiff --git a/src/txorphanage.h b/src/txorphanage.h\r\nindex a5a6a94bec..562e9a3321 100644\r\n--- a/src/txorphanage.h\r\n+++ b/src/txorphanage.h\r\n@@ -140,11 +140,11 @@ public:\r\n         return peer_it == m_peer_orphanage_info.end() ? 0 : peer_it->second.m_iter_list.size();\r\n     }\r\n \r\n     /** Check consistency between PeerOrphanInfo and m_orphans. Recalculate counters and ensure they\r\n      * match what is cached. */\r\n-    void SanityCheck() const;\r\n+    void SanityCheck(int expected_num_peers = -1) const;\r\n \r\n protected:\r\n     struct OrphanTx : public OrphanTxBase {\r\n     };\r\n ```",
      "created_at": "2025-02-20T16:40:35Z",
      "updated_at": "2025-02-20T16:41:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1963963925",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1963963925"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 196,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1963975702",
      "pull_request_review_id": 2630538241,
      "id": 1963975702,
      "node_id": "PRRC_kwDOABII5851D-QW",
      "diff_hunk": "@@ -0,0 +1,137 @@\n+// Copyright (c) 2011-2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <bench/bench.h>\n+#include <consensus/amount.h>\n+#include <net.h>\n+#include <primitives/transaction.h>\n+#include <pubkey.h>\n+#include <script/sign.h>\n+#include <test/util/setup_common.h>\n+#include <txorphanage.h>\n+#include <util/check.h>\n+\n+#include <cstdint>\n+#include <memory>\n+\n+// Creates a transaction spending outpoints (or 1 randomly generated input if none are given), with num_outputs outputs.\n+static CTransactionRef MakeTransactionSpending(const std::vector<COutPoint>& outpoints, unsigned int num_outputs, FastRandomContext& det_rand)\n+{\n+    CMutableTransaction tx;\n+\n+    // Build vin\n+    // If no outpoints are given, create a random one.\n+    if (outpoints.empty()) {\n+        tx.vin.emplace_back(Txid::FromUint256(det_rand.rand256()), 0);\n+    } else {\n+        for (const auto& outpoint : outpoints) {\n+            tx.vin.emplace_back(outpoint);\n+        }\n+    }\n+    // Ensure txid != wtxid\n+    assert(tx.vin.size() > 0);\n+    tx.vin[0].scriptWitness.stack.push_back({1});\n+\n+    // Build vout\n+    assert(num_outputs > 0);\n+    tx.vout.resize(num_outputs);\n+    for (unsigned int o = 0; o < num_outputs; ++o) {\n+        tx.vout[o].nValue = det_rand.randrange(100) * CENT;\n+        tx.vout[o].scriptPubKey = CScript() << CScriptNum(det_rand.randrange(o + 100)) << OP_EQUAL;\n+    }\n+    return MakeTransactionRef(tx);\n+}\n+\n+static void OrphanageEvictionMany(benchmark::Bench& bench)\n+{\n+    NodeId NUM_PEERS{125};\n+    unsigned int NUM_TRANSACTIONS(DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / NUM_PEERS);",
      "path": "src/bench/txorphanage.cpp",
      "position": null,
      "original_position": 49,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3ce9ef7dd3c231976454e8c836640507bdb7e111",
      "in_reply_to_id": 1949655371,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "You are right. That explains why it doesn't get slower haha",
      "created_at": "2025-02-20T16:44:11Z",
      "updated_at": "2025-02-20T16:44:11Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1963975702",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1963975702"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 103,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964166748",
      "pull_request_review_id": 2630852607,
      "id": 1964166748,
      "node_id": "PRRC_kwDOABII5851Es5c",
      "diff_hunk": "@@ -332,16 +333,19 @@ void TxOrphanage::EraseForBlock(const CBlock& block)\n             if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n             for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n                 const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+                wtxids_to_erase.insert(orphanTx.GetWitnessHash());\n+                // Stop to avoid doing too much work. If there are more orphans to erase, rely on\n+                // expiration and evictions to clean up everything eventually.\n+                if (wtxids_to_erase.size() >= 100) break;",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 25,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "021fc20f9cbac4803c4e91269811904fb0384e4c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "seems like we're leaving only one of 3 loops? is this intended?",
      "created_at": "2025-02-20T18:47:32Z",
      "updated_at": "2025-02-20T22:48:56Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1964166748",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964166748"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 339,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964220595",
      "pull_request_review_id": 2630943858,
      "id": 1964220595,
      "node_id": "PRRC_kwDOABII5851E6Cz",
      "diff_hunk": "@@ -188,13 +175,65 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim(max_orphans)) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+\n+    // Sort peers that have the highest ratio of DoSiness first\n+    auto compare_peer = [this](PeerMap::iterator left, PeerMap::iterator right) {\n+        const auto max_ann{GetPerPeerMaxAnnouncements()};\n+        const auto max_mem{GetPerPeerMaxUsage()};\n+        return left->second.GetDoSScore(max_ann, max_mem) < right->second.GetDoSScore(max_ann, max_mem);\n+    };\n+\n+    std::make_heap(peer_it_heap.begin(), peer_it_heap.end(), compare_peer);\n+\n     unsigned int nEvicted = 0;\n-    while (m_orphans.size() > max_orphans)\n+\n+    // Since each iteration should remove 1 announcement, this loop runs at most m_total_announcements times.\n+    // Note that we don't necessarily delete an orphan on each iteration. We might only be deleting\n+    // a peer from its announcers list.\n+    while (NeedsTrim(max_orphans))\n     {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+        if (!Assume(!peer_it_heap.empty())) break;\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used\n+        // over the respective allowances. This metric causes us to naturally select peers who have\n+        // exceeded their limits (i.e. a DoS score > 1) before peers who haven't. However, no matter\n+        // what, we evict from the DoSiest peers first. We may choose the same peer as the last\n+        // iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since\n+        // announcements is always lower, this means that a peer with only high CPU DoS score will\n+        // be targeted before a peer with only high memory DoS score, even if they have the same\n+        // ratios.\n+        std::pop_heap(peer_it_heap.begin(), peer_it_heap.end(), compare_peer);\n+        auto it_worst_peer = peer_it_heap.back();\n+        peer_it_heap.pop_back();\n+\n+        // Evict a random orphan from this peer.",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 82,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "\"Remove a random announcement from this peer.\" seems better because we only sometimes evict an orphan.",
      "created_at": "2025-02-20T19:31:02Z",
      "updated_at": "2025-02-20T21:27:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1964220595",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964220595"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 215,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964227057",
      "pull_request_review_id": 2630943858,
      "id": 1964227057,
      "node_id": "PRRC_kwDOABII5851E7nx",
      "diff_hunk": "@@ -188,13 +175,65 @@ unsigned int TxOrphanage::MaybeExpireOrphans()\n \n unsigned int TxOrphanage::MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng)\n {\n+    // Exit early to avoid building the heap unnecessarily\n+    if (!NeedsTrim(max_orphans)) return 0;\n+\n+    std::vector<PeerMap::iterator> peer_it_heap;\n+    peer_it_heap.reserve(m_peer_orphanage_info.size());\n+    for (auto it = m_peer_orphanage_info.begin(); it != m_peer_orphanage_info.end(); ++it) peer_it_heap.push_back(it);\n+\n+    // Sort peers that have the highest ratio of DoSiness first\n+    auto compare_peer = [this](PeerMap::iterator left, PeerMap::iterator right) {\n+        const auto max_ann{GetPerPeerMaxAnnouncements()};\n+        const auto max_mem{GetPerPeerMaxUsage()};\n+        return left->second.GetDoSScore(max_ann, max_mem) < right->second.GetDoSScore(max_ann, max_mem);\n+    };\n+\n+    std::make_heap(peer_it_heap.begin(), peer_it_heap.end(), compare_peer);\n+\n     unsigned int nEvicted = 0;\n-    while (m_orphans.size() > max_orphans)\n+\n+    // Since each iteration should remove 1 announcement, this loop runs at most m_total_announcements times.\n+    // Note that we don't necessarily delete an orphan on each iteration. We might only be deleting\n+    // a peer from its announcers list.\n+    while (NeedsTrim(max_orphans))\n     {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+        if (!Assume(!peer_it_heap.empty())) break;\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used\n+        // over the respective allowances. This metric causes us to naturally select peers who have\n+        // exceeded their limits (i.e. a DoS score > 1) before peers who haven't. However, no matter\n+        // what, we evict from the DoSiest peers first. We may choose the same peer as the last\n+        // iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since\n+        // announcements is always lower, this means that a peer with only high CPU DoS score will\n+        // be targeted before a peer with only high memory DoS score, even if they have the same\n+        // ratios.\n+        std::pop_heap(peer_it_heap.begin(), peer_it_heap.end(), compare_peer);\n+        auto it_worst_peer = peer_it_heap.back();\n+        peer_it_heap.pop_back();\n+\n+        // Evict a random orphan from this peer.\n+        size_t randompos = rng.randrange(it_worst_peer->second.m_iter_list.size());\n+        auto it_to_evict = it_worst_peer->second.m_iter_list.at(randompos);\n+\n+        // Only erase this peer as an announcer, unless it is the only announcer. Otherwise peers",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 86,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "This is a bit ambiguous, I first read it as \"don't erase the peer as an announcer if it was the only one\", but what is meant is \"erase the peer as an announcer, also remove the orphan if the peer was the only announcer\", so maybe reword it.",
      "created_at": "2025-02-20T19:35:40Z",
      "updated_at": "2025-02-20T21:27:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1964227057",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964227057"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 219,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964238336",
      "pull_request_review_id": 2630943858,
      "id": 1964238336,
      "node_id": "PRRC_kwDOABII5851E-YA",
      "diff_hunk": "@@ -168,22 +209,51 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n \n     /** Remove the element at list_pos in m_iter_list in O(1) time by swapping the last element\n      * with the one at list_pos and popping the back if there are multiple elements. */\n     void RemoveIterAt(NodeId peer, size_t list_pos);\n+\n+    int64_t GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    int64_t GetGlobalMaxUsage() const {\n+        return std::max<int64_t>(int64_t(m_peer_orphanage_info.size()) * m_reserved_weight_per_peer, 1);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 129,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "If I understand it correctly, the current logic is that we assign additional weight for all peers that have an entry in `m_peer_orphanage_info`, which means we don't assign weight for peers not participating in tx relay or that do but never sent us an orphan before. But once they sent us an orphan, that weight will stay reserved until they disconnect (and can be used by other peers too), even if they never send us another orphan.\r\n\r\nThis seems like a middle-ground between assigning each peer a fixed `DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER` share which may not be exceeded, and assigning a pool `DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER` for each peer (whether that peer sent us an orphan before or not) - was that the purpose of choosing to do it this way? ",
      "created_at": "2025-02-20T19:45:24Z",
      "updated_at": "2025-02-20T21:27:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1964238336",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964238336"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 243,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964296427",
      "pull_request_review_id": 2630943858,
      "id": 1964296427,
      "node_id": "PRRC_kwDOABII5851FMjr",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 35,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": null,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "One possibility is that an attacker who wants to spam us with orphans can do so via other peers, without  providing the orphans themselves:\r\n\r\n1.) Attacker A inv's a parent P to victim V but doesn't answer `GETDATA` (2 minutes timeout)\r\n2.) Within these 2 minutes, A sends P and multiple non-conflicting children C to the rest of the network - these are accepted/relayed by all other peers, so will eventually be announced to V by all of its legitimate peers.\r\n3.) All of V's legitimate peers will announce P and C, V will only request C (because P is in flight) and saves them as orphans / adds all of its peers as announcers.\r\n4.) V's orphanage reaches its limits. With 125 peers, you'd need ~25 children to reach the max announcement limit of 3000, so you might need to split the children over multiple parents because of the mempool descendant limit. \r\n5.) V will start evicting announcements randomly from peers, so it may also evict legitimate unrelated orphans.\r\n\r\nUnlike with the status quo where attackers can just spam us with orphans for free, this is not free (P and C need to be valid transactions with a sufficient fee to be relayed), but I couldn't think of any countermeasure, so maybe it kind of sets a theoretical limit on how certain we can be that legitimate orphans are resolved?\r\n",
      "created_at": "2025-02-20T20:30:37Z",
      "updated_at": "2025-02-20T21:27:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1964296427",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964296427"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 42,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964465497",
      "pull_request_review_id": 2630852607,
      "id": 1964465497,
      "node_id": "PRRC_kwDOABII5851F11Z",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 35,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": 1964296427,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "IIUC this is basically a way of slowing down the parent resolution of a target package by 2 minutes, thereby increasing the window of possible random eviction when under real cpfp traffic.\r\n\r\nWithout this delay we can still have natural overflow if there are too many (or too large) real packages in flight, the time window here just gets a lot longer\r\n\r\nUnfortunately we have no way of peers to communicate which orphans they claim are higher paying (to preferentially evict those last f.e.). Then at least orphan package makers could try to outbid the queue. Maybe something to think about with a future sender-initiated protocol?\r\n\r\nBeing more aggressive about timing out inbound peers(and or txid-relay) when they aren't responding to `getdata`s could also be on the table, at the cost of bandwidth in the average case over a slow link.\r\n\r\nre:(2) you could also just imagine the scenario where the attacker simply relies on natural cpfp traffic and may just get lucky that it gets evicted in the two minutes. Costs the attacker nothing in this case though chances of failure are likely way higher?",
      "created_at": "2025-02-20T22:48:17Z",
      "updated_at": "2025-02-20T22:50:22Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1964465497",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1964465497"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 42,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1965867683",
      "pull_request_review_id": 2633684707,
      "id": 1965867683,
      "node_id": "PRRC_kwDOABII5851LMKj",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 35,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": 1964296427,
      "user": {
        "login": "mzumsande",
        "id": 48763452,
        "node_id": "MDQ6VXNlcjQ4NzYzNDUy",
        "avatar_url": "https://avatars.githubusercontent.com/u/48763452?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mzumsande",
        "html_url": "https://github.com/mzumsande",
        "followers_url": "https://api.github.com/users/mzumsande/followers",
        "following_url": "https://api.github.com/users/mzumsande/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/mzumsande/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/mzumsande/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/mzumsande/subscriptions",
        "organizations_url": "https://api.github.com/users/mzumsande/orgs",
        "repos_url": "https://api.github.com/users/mzumsande/repos",
        "events_url": "https://api.github.com/users/mzumsande/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/mzumsande/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "> IIUC this is basically a way of slowing down the parent resolution of a target package by 2 minutes, thereby increasing the window of possible random eviction when under real cpfp traffic.\r\n\r\nNot sure if I understood that right, but I think that would be a different kind of attack where the attacker  knows the target packet. What I meant was that that the attacker crafts spam transactions (P/C) that the rest of the network relays, but that end up only in the victim's orphanage, resulting in eviction of random other orphans (about which the attacker doesn't need to know any specifics) - similar to how an attacker could today just spam orphans to trigger random eviction on master, but no longer for free.",
      "created_at": "2025-02-21T16:49:02Z",
      "updated_at": "2025-02-21T16:49:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1965867683",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1965867683"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 42,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1968322091",
      "pull_request_review_id": 2638283819,
      "id": 1968322091,
      "node_id": "PRRC_kwDOABII5851UjYr",
      "diff_hunk": "@@ -168,22 +209,51 @@ class TxOrphanage {\n      *  to remove orphan transactions from the m_orphans */\n     std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n-\n     /** Timestamp for the next scheduled sweep of expired orphans */\n     NodeSeconds m_next_sweep{0s};\n \n     /** If ORPHAN_TX_EXPIRE_INTERVAL has elapsed since the last sweep, expire orphans older than\n      * ORPHAN_TX_EXPIRE_TIME. Called within LimitOrphans. */\n     unsigned int MaybeExpireOrphans();\n \n-    /** If there are more than max_orphans total orphans, evict randomly until that is no longer the case. */\n+    /** If any of the following conditions are met, trim orphans until none are true:\n+     * 1. The global memory usage exceeds the maximum allowed.\n+     * 2. The global number of announcements exceeds the maximum allowed.\n+     * 3. The total number of orphans exceeds max_orphans.\n+     *\n+     * The trimming process sorts peers by their DoS score, only removing announcements /  orphans\n+     * of the peer with the worst DoS score. We use a heap to sort the peers, pop the worst one off,\n+     * and then re-add it if the peer still has transactions. The loop can run a maximum of\n+     * m_max_global_announcements times before there cannot be any more transactions to evict.\n+     * Bounds: O(p) to build the heap, O(n log(p)) for subsequent heap operations.\n+     *   p = number of peers\n+     *   n = number of announcements\n+     * */\n     unsigned int MaybeTrimOrphans(unsigned int max_orphans, FastRandomContext& rng);\n \n     /** Remove the element at list_pos in m_iter_list in O(1) time by swapping the last element\n      * with the one at list_pos and popping the back if there are multiple elements. */\n     void RemoveIterAt(NodeId peer, size_t list_pos);\n+\n+    int64_t GetPerPeerMaxUsage() const {\n+        return m_reserved_weight_per_peer;\n+    }\n+\n+    int64_t GetGlobalMaxUsage() const {\n+        return std::max<int64_t>(int64_t(m_peer_orphanage_info.size()) * m_reserved_weight_per_peer, 1);",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 129,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": 1964238336,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "> If I understand it correctly, ...\r\n\r\nCorrect ðŸ‘ the general idea is to put a hard cap on the memory usage per peer. However, if a peer is using a lot more than the others simply because it is very useful, we don't penalize them until we run out of space.\r\n\r\nWe could do a `RegisterPeer` type of thing when the peer first connects, but I don't see any particular reason to do that extra step right now. Perhaps we can add this in the future, if we want to give peers a different reservation depending on the type of connection. This has a nice side effect where we don't reserve any space for useless spy peers, and save a bit of extra work for short-lived connections or ones where no transactions are relayed, though I wouldn't say this is a motivation.",
      "created_at": "2025-02-24T19:45:40Z",
      "updated_at": "2025-02-24T19:45:41Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1968322091",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1968322091"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 243,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1968340075",
      "pull_request_review_id": 2638312992,
      "id": 1968340075,
      "node_id": "PRRC_kwDOABII5851Unxr",
      "diff_hunk": "@@ -27,7 +34,26 @@ static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    /** The usage (weight) reserved for each peer, representing the amount of memory we are willing\n+     * to allocate for orphanage space. Note that this number is a reservation, not a limit: peers\n+     * are allowed to exceed this reservation until the global limit is reached, and peers are\n+     * effectively guaranteed this amount of space. Reservation is per-peer, so the global upper\n+     * bound on memory usage scales up with more peers. */\n+    unsigned int m_reserved_weight_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 35,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "6cbe944539d421893f007ab27e7e00c2de503d62",
      "in_reply_to_id": 1964296427,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "My general impression is that, since these \"spam\" orphans are real, fee-paying transactions that end up in mempool, they are equally useful / equally deserve the space. I do think this represents a bound on how much total orphan volume we can handle, but I can't really see why the victim node should evict these orphans over the others, just because they only originate from 1 peer.\r\n\r\n> Unfortunately we have no way of peers to communicate which orphans they claim are higher paying (to preferentially evict those last f.e.). Then at least orphan package makers could try to outbid the queue. Maybe something to think about with a future sender-initiated protocol?\r\n\r\nEven if we had a way to communicate this information, I don't think it could be trusted. I think the only real solution to this is a sender-initiated protocol. I have half a mind to go ahead and propose a quick-and-dirty sender-initiated protocol for 1p1cs right now, but maybe that's too short term thinking.",
      "created_at": "2025-02-24T20:00:33Z",
      "updated_at": "2025-02-24T20:00:34Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r1968340075",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/1968340075"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 42,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2109790109",
      "pull_request_review_id": 2871976352,
      "id": 2109790109,
      "node_id": "PRRC_kwDOABII5859wNed",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 221,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "extra fn doesn't seem worth it\r\n```\r\ndiff --git a/src/node/txorphanage_impl.h b/src/node/txorphanage_impl.h\r\nindex 89974ec506..b6137845b4 100644\r\n--- a/src/node/txorphanage_impl.h\r\n+++ b/src/node/txorphanage_impl.h\r\n@@ -205,11 +205,11 @@ class TxOrphanageImpl\r\n     }\r\n \r\n-    /** Return number of announcements with the same wtxid as it. */\r\n-    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\r\n+    /** Return number of announcements with this wtxid. */\r\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\r\n     {\r\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\r\n         if (it == m_orphans.end()) return 0;\r\n \r\n         unsigned int count{0};\r\n-        const auto& wtxid{it->m_tx->GetWitnessHash()};\r\n         while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\r\n             ++count;\r\n@@ -218,12 +218,4 @@ class TxOrphanageImpl\r\n         return count;\r\n     }\r\n-\r\n-    /** Return number of announcements with this wtxid. */\r\n-    unsigned int CountWtxid(const Wtxid& wtxid) const\r\n-    {\r\n-        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\r\n-        if (it == m_orphans.end()) return 0;\r\n-        return CountSameWtxid(it);\r\n-    }\r\n public:\r\n     TxOrphanageImpl() = default;\r\n```",
      "created_at": "2025-05-27T17:36:29Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2109790109",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2109790109"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 221,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2109879316",
      "pull_request_review_id": 2871976352,
      "id": 2109879316,
      "node_id": "PRRC_kwDOABII5859wjQU",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;\n+\n+        const auto original_unique_txns{CountUniqueOrphans()};\n+\n+        // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+        // does not change unless a peer is removed.\n+        const auto max_ann{MaxPeerAnnouncements()};\n+        const auto max_mem{ReservedPeerUsage()};\n+\n+        // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+        // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+        std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+        heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+        for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+        }\n+        auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+        std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+        unsigned int num_erased{0};\n+        // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+        do {\n+            Assume(!heap_peer_dos.empty());\n+            // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+            // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+            // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+            // haven't. We may choose the same peer as the last iteration of this loop.\n+            // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+            // always lower, this means that a peer with only high number of announcements will be targeted before a\n+            // peer using a lot of memory, even if they have the same ratios.\n+            std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+            const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+            heap_peer_dos.pop_back();\n+\n+            // If needs trim, then at least one peer has a DoS score higher than 1.\n+            Assume(dos_score.fee > dos_score.size);\n+\n+            // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 629,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "455b4b817884f860cd4467f0a9be4a459e89891c\r\n\r\nTake or leave suggestion to reduce churn in the heap, did no benchmarking but may reduce work for most DoSy peers.\r\n```\r\ndiff --git a/src/node/txorphanage_impl.h b/src/node/txorphanage_impl.h\r\nindex 89974ec506..6fe7422054 100644\r\n--- a/src/node/txorphanage_impl.h\r\n+++ b/src/node/txorphanage_impl.h\r\n@@ -623,20 +623,27 @@ public:\r\n             heap_peer_dos.pop_back();\r\n \r\n+            auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\r\n+\r\n             // If needs trim, then at least one peer has a DoS score higher than 1.\r\n             Assume(dos_score.fee > dos_score.size);\r\n \r\n-            // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\r\n-            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\r\n-            Assume(it_ann->m_announcer == worst_peer);\r\n-            Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/CountWtxid(it_ann->m_tx->GetWitnessHash()) == 1);\r\n-            num_erased += 1;\r\n-\r\n-            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\r\n-            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\r\n-            // its orphans. Calculate the DoS score anew. This peer might still be the DoSiest one.\r\n-            auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\r\n-            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\r\n-                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\r\n-                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\r\n+            if (it_worst_peer != m_peer_orphanage_info.end()) {\r\n+                // Avoid churn by re-entering only when worst peer's score is no longer worst\r\n+                // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\r\n+                auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\r\n+                const auto& next_dos_score = heap_peer_dos.empty() ? FeeFrac{0, 1} : heap_peer_dos.front().second;\r\n+                while (NeedsTrim() && it_worst_peer->second.GetDosScore(max_ann, max_mem) > next_dos_score) {\r\n+                    Assume(it_ann->m_announcer == worst_peer);\r\n+                    Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/CountWtxid(it_ann->m_tx->GetWitnessHash()) == 1);\r\n+                    num_erased += 1;\r\n+                    it_ann++; // advance to next announcement from this peer in case loop continues\r\n+                }\r\n+                // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\r\n+                // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\r\n+                // its orphans. Calculate the DoS score anew. This peer might still be the DoSiest one.\r\n+                if (it_worst_peer->second.m_count_announcements > 0) {\r\n+                    heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\r\n+                    std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\r\n+                }\r\n             }\r\n         } while (!heap_peer_dos.empty() && NeedsTrim());\r\n```",
      "created_at": "2025-05-27T18:26:56Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2109879316",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2109879316"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 616,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112159931",
      "pull_request_review_id": 2871976352,
      "id": 2112159931,
      "node_id": "PRRC_kwDOABII58595QC7",
      "diff_hunk": "@@ -327,10 +327,10 @@ void TxOrphanage::SanityCheck() const\n     // Check that cached m_total_announcements is correct\n     unsigned int counted_total_announcements{0};\n     // Check that m_total_orphan_usage is correct\n-    unsigned int counted_total_usage{0};\n+    int64_t counted_total_usage{0};",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "aed51fe7d5cbcc43eba2be3cd5af666fe1d95dd7",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "aed51fe7d5cbcc43eba2be3cd5af666fe1d95dd7\r\n\r\ngive motivation in commit message for the change?",
      "created_at": "2025-05-28T15:11:48Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112159931",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112159931"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 330,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112167760",
      "pull_request_review_id": 2871976352,
      "id": 2112167760,
      "node_id": "PRRC_kwDOABII58595R9Q",
      "diff_hunk": "@@ -37,7 +37,7 @@ bool TxOrphanage::AddTx(const CTransactionRef& tx, NodeId peer)\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME}, m_orphan_list.size()});\n+    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "737c5127df841e9c8037b1885284f80b0aba17dd",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "737c5127df841e9c8037b1885284f80b0aba17dd\r\n\r\nmight be good to note in commit message the getorphantxs is experimental, so breaking is considered ok",
      "created_at": "2025-05-28T15:15:29Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112167760",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112167760"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 40,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112259957",
      "pull_request_review_id": 2871976352,
      "id": 2112259957,
      "node_id": "PRRC_kwDOABII58595od1",
      "diff_hunk": "@@ -305,9 +304,9 @@ FUZZ_TARGET(txdownloadman_impl, .init = initialize)\n     // Initialize a TxDownloadManagerImpl\n     bilingual_str error;\n     CTxMemPool pool{MemPoolOptionsForTest(g_setup->m_node), error};\n-    const auto max_orphan_count = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(0, 300);\n+    const auto max_orphan_count = node::DEFAULT_MAX_ORPHAN_TRANSACTIONS;",
      "path": "src/test/fuzz/txdownloadman.cpp",
      "position": null,
      "original_position": 16,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f2dcdbf700b3b20a315f5a6eec57c7463955fe43",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "f2dcdbf700b3b20a315f5a6eec57c7463955fe43\r\n\r\nif this goes away later anyways, ignore, but `CheckInvariants` could just directly use `node::DEFAULT_MAX_ORPHAN_TRANSACTIONS`",
      "created_at": "2025-05-28T16:02:05Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112259957",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112259957"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 307,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112547493",
      "pull_request_review_id": 2871976352,
      "id": 2112547493,
      "node_id": "PRRC_kwDOABII58596uql",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 77,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "455b4b817884f860cd4467f0a9be4a459e89891c\r\n\r\nnit: unsure if \"uses\" section adds a lot to clarity vs reading the code",
      "created_at": "2025-05-28T18:51:37Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112547493",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112547493"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 77,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112572392",
      "pull_request_review_id": 2871976352,
      "id": 2112572392,
      "node_id": "PRRC_kwDOABII585960vo",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 88,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "not sure what result_type is doing here or in ByPeerViewExtractor",
      "created_at": "2025-05-28T19:08:11Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112572392",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112572392"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 70,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112585455",
      "pull_request_review_id": 2871976352,
      "id": 2112585455,
      "node_id": "PRRC_kwDOABII5859637v",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 169,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "PeerMap is unused circa 455b4b817884f860cd4467f0a9be4a459e89891c",
      "created_at": "2025-05-28T19:16:56Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112585455",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112585455"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 169,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112592805",
      "pull_request_review_id": 2876188083,
      "id": 2112592805,
      "node_id": "PRRC_kwDOABII585965ul",
      "diff_hunk": "@@ -126,13 +123,15 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n         tx.vout[0].nValue = i*CENT;\n         tx.vout[0].scriptPubKey = GetScriptForDestination(PKHash(key.GetPubKey()));\n \n-        orphanage.AddTx(MakeTransactionRef(tx), i);\n+        auto ptx = MakeTransactionRef(tx);\n+        orphanage.AddTx(ptx, i);\n+        orphans_added.emplace_back(ptx);\n     }\n \n     // ... and 50 that depend on other orphans:\n     for (int i = 0; i < 50; i++)\n     {\n-        CTransactionRef txPrev = orphanage.RandomOrphan();\n+        CTransactionRef txPrev = Random(orphans_added, m_rng);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 56,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "b5fe4383ada8a16076a9665e9ee9557d93fd659f",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[prep/test] modify test to not access TxOrphanage internals\"\r\n\r\nIt seems all invocations of `Random()` assume that the returned value won't be `nullptr` anyway, so I think they can just be replaced with:\r\n\r\n```c++\r\nCTransactionRef txPrev = orphans_added[m_rng.randrange(orphans_added.size())];\r\n```\r\n",
      "created_at": "2025-05-28T19:21:36Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112592805",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112592805"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 134,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112597837",
      "pull_request_review_id": 2871976352,
      "id": 2112597837,
      "node_id": "PRRC_kwDOABII5859669N",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 132,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nit: s/PeerInfo/PeerDoSInfo/",
      "created_at": "2025-05-28T19:24:08Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112597837",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112597837"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 132,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112606438",
      "pull_request_review_id": 2871976352,
      "id": 2112606438,
      "node_id": "PRRC_kwDOABII585969Dm",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 162,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "probably should assert the denominators are not 0, otherwise FeeFrac comparison becomes nonsensical ",
      "created_at": "2025-05-28T19:27:56Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112606438",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112606438"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 142,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112621971",
      "pull_request_review_id": 2871976352,
      "id": 2112621971,
      "node_id": "PRRC_kwDOABII58597A2T",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 244,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```Suggestion\r\n    /** Number of stored orphans from this peer */\r\n```\r\n",
      "created_at": "2025-05-28T19:39:17Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112621971",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112621971"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 244,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112644130",
      "pull_request_review_id": 2871976352,
      "id": 2112644130,
      "node_id": "PRRC_kwDOABII58597GQi",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 350,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "could use `it->m_announcer == peer` since you already did the lookup",
      "created_at": "2025-05-28T19:54:45Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112644130",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112644130"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 350,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112646478",
      "pull_request_review_id": 2871976352,
      "id": 2112646478,
      "node_id": "PRRC_kwDOABII58597G1O",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 361,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```Suggestion\r\n        const auto& txid = ptx->GetHash();\r\n```",
      "created_at": "2025-05-28T19:56:26Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112646478",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112646478"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 361,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112708800",
      "pull_request_review_id": 2871976352,
      "id": 2112708800,
      "node_id": "PRRC_kwDOABII58597WDA",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 395,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "455b4b817884f860cd4467f0a9be4a459e89891c\r\n\r\nLittle confused how this logic is necessary. The `while` loop will exit as soon as `it` is incremented to `index_by_peer.end()` or `it->m_announcer != peer`. What am I missing?\r\n\r\nSame with `EraseAll`",
      "created_at": "2025-05-28T20:36:51Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112708800",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112708800"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 395,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112720613",
      "pull_request_review_id": 2871976352,
      "id": 2112720613,
      "node_id": "PRRC_kwDOABII58597Y7l",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 411,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "455b4b817884f860cd4467f0a9be4a459e89891c\r\n\r\ndifference with EraseTx is pretty subtle, and only `EraseTx` appears to be used externally. Make this private or just subsume into `EraseTx`?",
      "created_at": "2025-05-28T20:45:02Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112720613",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112720613"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 411,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112726648",
      "pull_request_review_id": 2876188083,
      "id": 2112726648,
      "node_id": "PRRC_kwDOABII58597aZ4",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 21,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nMany of the includes here seem unused:\r\n\r\n```diff\r\n--- a/src/node/txorphanage_impl.h\r\n+++ b/src/node/txorphanage_impl.h\r\n@@ -5,33 +5,20 @@\r\n #ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\r\n #define BITCOIN_NODE_TXORPHANAGE_IMPL_H\r\n \r\n-#include <coins.h>\r\n-#include <consensus/amount.h>\r\n-#include <indirectmap.h>\r\n #include <logging.h>\r\n-#include <net.h>\r\n #include <policy/policy.h>\r\n #include <primitives/transaction.h>\r\n-#include <sync.h>\r\n-#include <util/epochguard.h>\r\n #include <util/hasher.h>\r\n #include <util/result.h>\r\n #include <util/feefrac.h>\r\n \r\n-#include <boost/multi_index/hashed_index.hpp>\r\n-#include <boost/multi_index/identity.hpp>\r\n #include <boost/multi_index/indexed_by.hpp>\r\n #include <boost/multi_index/ordered_index.hpp>\r\n-#include <boost/multi_index/sequenced_index.hpp>\r\n #include <boost/multi_index/tag.hpp>\r\n #include <boost/multi_index_container.hpp>\r\n \r\n-#include <atomic>\r\n #include <map>\r\n-#include <optional>\r\n #include <set>\r\n-#include <string>\r\n-#include <string_view>\r\n #include <utility>\r\n #include <vector>\r\n```",
      "created_at": "2025-05-28T20:49:16Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112726648",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112726648"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 21,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112727149",
      "pull_request_review_id": 2871976352,
      "id": 2112727149,
      "node_id": "PRRC_kwDOABII58597aht",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 454,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "just noting this is going to get oldest-reconsidered-by-peer first\r\n\r\nsounds logical",
      "created_at": "2025-05-28T20:49:35Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112727149",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112727149"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 454,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112731246",
      "pull_request_review_id": 2876188083,
      "id": 2112731246,
      "node_id": "PRRC_kwDOABII58597bhu",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nWould it be possible to use `std::map<COutPoint, std::set<Iter>>` here as type? That would be faster (avoiding a lookup to resolve `Wtxid` -> `Iter`) and use less memory. `boost::multi_index` iterator objects are stable (remain valid as long as the object they point to exists), unlike `std::unordered_map`.",
      "created_at": "2025-05-28T20:52:35Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112731246",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112731246"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 108,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112731966",
      "pull_request_review_id": 2871976352,
      "id": 2112731966,
      "node_id": "PRRC_kwDOABII58597bs-",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 480,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "455b4b817884f860cd4467f0a9be4a459e89891c\r\n\r\ndoesn't the inserter above do this",
      "created_at": "2025-05-28T20:53:08Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112731966",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112731966"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 480,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112736485",
      "pull_request_review_id": 2871976352,
      "id": 2112736485,
      "node_id": "PRRC_kwDOABII58597czl",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 495,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```Suggestion\r\n        Assume(wtxids_to_erase.size() == num_erased);\r\n        return wtxids_to_erase.size();\r\n```",
      "created_at": "2025-05-28T20:56:24Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112736485",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112736485"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 483,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112744241",
      "pull_request_review_id": 2876188083,
      "id": 2112744241,
      "node_id": "PRRC_kwDOABII58597esx",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 184,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\n`Assume(peer_it != m_peer_orphanage_info.end());` ?",
      "created_at": "2025-05-28T21:00:08Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112744241",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112744241"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 163,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112750662",
      "pull_request_review_id": 2876188083,
      "id": 2112750662,
      "node_id": "PRRC_kwDOABII58597gRG",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 207,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nThis has an unstated assumption that `it` is the iterator the first entry in the `ByWtxid` index for a given wtxid.\r\n\r\nGiven that there is only one call site (`CountWtxid` below), maybe it is better to inline this function there?",
      "created_at": "2025-05-28T21:04:05Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112750662",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112750662"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 207,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112753138",
      "pull_request_review_id": 2871976352,
      "id": 2112753138,
      "node_id": "PRRC_kwDOABII58597g3y",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 550,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "probably too cautious already but\r\n```Suggestion\r\n                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\r\n```",
      "created_at": "2025-05-28T21:06:10Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112753138",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112753138"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 550,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112767194",
      "pull_request_review_id": 2876188083,
      "id": 2112767194,
      "node_id": "PRRC_kwDOABII58597kTa",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 235,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nNit: grammar parse error.",
      "created_at": "2025-05-28T21:14:21Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112767194",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112767194"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 235,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112768226",
      "pull_request_review_id": 2871976352,
      "id": 2112768226,
      "node_id": "PRRC_kwDOABII58597kji",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 591,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```Suggestion\r\n        if (!NeedsTrim()) return;\r\n```",
      "created_at": "2025-05-28T21:14:55Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112768226",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112768226"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 591,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112772043",
      "pull_request_review_id": 2876188083,
      "id": 2112772043,
      "node_id": "PRRC_kwDOABII58597lfL",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 259,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nNit: ` ` after `int64_t`.",
      "created_at": "2025-05-28T21:17:20Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112772043",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112772043"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 259,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112773426",
      "pull_request_review_id": 2876188083,
      "id": 2112773426,
      "node_id": "PRRC_kwDOABII58597l0y",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 268,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nNit: maybe `auto& peer_info = reconstructed_peer_info[it->m_announcer];` ?",
      "created_at": "2025-05-28T21:18:27Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112773426",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112773426"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 268,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112777005",
      "pull_request_review_id": 2876188083,
      "id": 2112777005,
      "node_id": "PRRC_kwDOABII58597mst",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 44,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nStyle: `MIN_PEER`? It wasn't immediately clear when reading the code that this referred to a constant.",
      "created_at": "2025-05-28T21:21:06Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112777005",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112777005"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 44,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112783352",
      "pull_request_review_id": 2876188083,
      "id": 2112783352,
      "node_id": "PRRC_kwDOABII58597oP4",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 300,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nThis could be avoided by checking the `ret.first` result of `auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);` below. The `ByWtxid` index is unique, so emplacement will fail if the same the wtxid/peer combination already exist, I think.",
      "created_at": "2025-05-28T21:26:25Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112783352",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112783352"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 300,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112785010",
      "pull_request_review_id": 2876188083,
      "id": 2112785010,
      "node_id": "PRRC_kwDOABII58597opy",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 350,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nThis can be avoided by checking `ret.first` from the `auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);` call below, because the `ByWtxid` index will fail if the same announcement already exists.",
      "created_at": "2025-05-28T21:27:50Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112785010",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112785010"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 350,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112789455",
      "pull_request_review_id": 2876188083,
      "id": 2112789455,
      "node_id": "PRRC_kwDOABII58597pvP",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 454,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"feature: Add TxOrphanageImpl\"\r\n\r\nMaybe note that if a tx is returned, it is also marked as non-reconsiderable.",
      "created_at": "2025-05-28T21:31:28Z",
      "updated_at": "2025-05-28T21:31:59Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112789455",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112789455"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 454,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112799295",
      "pull_request_review_id": 2871976352,
      "id": 2112799295,
      "node_id": "PRRC_kwDOABII58597sI_",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;\n+\n+        const auto original_unique_txns{CountUniqueOrphans()};\n+\n+        // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+        // does not change unless a peer is removed.\n+        const auto max_ann{MaxPeerAnnouncements()};\n+        const auto max_mem{ReservedPeerUsage()};\n+\n+        // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+        // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+        std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+        heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+        for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+        }\n+        auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+        std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+        unsigned int num_erased{0};\n+        // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+        do {\n+            Assume(!heap_peer_dos.empty());\n+            // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+            // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+            // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+            // haven't. We may choose the same peer as the last iteration of this loop.\n+            // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+            // always lower, this means that a peer with only high number of announcements will be targeted before a\n+            // peer using a lot of memory, even if they have the same ratios.\n+            std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+            const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+            heap_peer_dos.pop_back();\n+\n+            // If needs trim, then at least one peer has a DoS score higher than 1.\n+            Assume(dos_score.fee > dos_score.size);\n+\n+            // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            Assume(it_ann->m_announcer == worst_peer);\n+            Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/CountWtxid(it_ann->m_tx->GetWitnessHash()) == 1);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 631,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "If you had `MaxGlobalAnnouncements` peers all announcing the same tx, it would end up being `n^2 * logn` work with `CountWtxid` calls?",
      "created_at": "2025-05-28T21:39:37Z",
      "updated_at": "2025-05-28T21:45:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2112799295",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2112799295"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 631,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114070740",
      "pull_request_review_id": 2878472725,
      "id": 2114070740,
      "node_id": "PRRC_kwDOABII585-AijU",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 45,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\n```Suggestion\r\n        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE);\r\n```",
      "created_at": "2025-05-29T14:15:24Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114070740",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114070740"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 126,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114080543",
      "pull_request_review_id": 2878472725,
      "id": 2114080543,
      "node_id": "PRRC_kwDOABII585-Ak8f",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 62,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\ncould run these checks just before additions to assert no-op",
      "created_at": "2025-05-29T14:20:39Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114080543",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114080543"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 143,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114084722",
      "pull_request_review_id": 2878472725,
      "id": 2114084722,
      "node_id": "PRRC_kwDOABII585-Al9y",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 101,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nmight as well use and assert return of `CheckNumEvictions`",
      "created_at": "2025-05-29T14:22:53Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114084722",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114084722"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 182,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114084831",
      "pull_request_review_id": 2878472725,
      "id": 2114084831,
      "node_id": "PRRC_kwDOABII585-Al_f",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 109,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nmight as well use and assert return of `CheckNumEvictions`",
      "created_at": "2025-05-29T14:22:56Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114084831",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114084831"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 190,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114084933",
      "pull_request_review_id": 2878472725,
      "id": 2114084933,
      "node_id": "PRRC_kwDOABII585-AmBF",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 122,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nmight as well use and assert return of `CheckNumEvictions`",
      "created_at": "2025-05-29T14:23:00Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114084933",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114084933"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 203,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114085090",
      "pull_request_review_id": 2878472725,
      "id": 2114085090,
      "node_id": "PRRC_kwDOABII585-AmDi",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 133,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nmight as well use and assert return of `CheckNumEvictions`",
      "created_at": "2025-05-29T14:23:05Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114085090",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114085090"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 214,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114089251",
      "pull_request_review_id": 2878472725,
      "id": 2114089251,
      "node_id": "PRRC_kwDOABII585-AnEj",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 145,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nnit: s/peer0/dos_peer/",
      "created_at": "2025-05-29T14:25:19Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114089251",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114089251"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 226,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114091408",
      "pull_request_review_id": 2878472725,
      "id": 2114091408,
      "node_id": "PRRC_kwDOABII585-AnmQ",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        node::TxOrphanageImpl orphanage(max_announcements, USAGE_TXNS_CREATED * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage.AddTx(TXNS.at(i), peer0);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 159,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n```Suggestion\r\n        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);\r\n        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer2), 0);\r\n```",
      "created_at": "2025-05-29T14:26:32Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114091408",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114091408"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 240,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114103109",
      "pull_request_review_id": 2878472725,
      "id": 2114103109,
      "node_id": "PRRC_kwDOABII585-AqdF",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        node::TxOrphanageImpl orphanage(max_announcements, USAGE_TXNS_CREATED * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage.AddTx(TXNS.at(i), peer0);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);\n+\n+        // Add 10 unique transactions from peer1.\n+        // LimitOrphans should evict from peer0, because that's the one exceeding announcement limits.\n+        unsigned int num_from_peer1 = 10;\n+        for (unsigned int i{0}; i < num_from_peer1; ++i) {\n+            orphanage.AddTx(TXNS.at(max_announcements + i), peer1);\n+            // The announcement limit per peer has halved, but LimitOrphans does not evict beyond what is necessary to\n+            // bring the total announcements within its global limit.\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+            BOOST_CHECK(orphanage.AnnouncementsFromPeer(peer0) > orphanage.MaxPeerAnnouncements());\n+\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), i + 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+        // Add 10 transactions that are duplicates of the ones sent by peer0. We need to add 10 because the first 10\n+        // were just evicted in the previous block additions.\n+        for (unsigned int i{num_from_peer1}; i < num_from_peer1 + 10; ++i) {\n+            // Tx has already been sent by peer0\n+            BOOST_CHECK(orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            orphanage.AddTx(TXNS.at(i), peer2);\n+\n+            // Announcement limit is by entry, not by unique orphans\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+\n+            // peer0 is still the only one getting evicted\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), num_from_peer1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer2), i + 1 - num_from_peer1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            BOOST_CHECK(orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+\n+        // With 6 peers, each can add 10, and still only peer0's orphans are evicted.\n+        const unsigned int max_per_peer{max_announcements / 6};\n+        for (NodeId peer{3}; peer < 6; ++peer) {\n+            for (unsigned int i{0}; i < max_per_peer; ++i) {\n+                orphanage.AddTx(TXNS.at(peer * max_per_peer + i), peer);\n+                BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+            }\n+        }\n+        for (NodeId peer{0}; peer < 6; ++peer) {\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer), max_per_peer);\n+        }\n+    }\n+\n+    // Limits change as more peers are added.\n+    {\n+        node::TxOrphanageImpl orphanage;\n+        // These stay the same regardless of number of peers\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+\n+        // These change with number of peers\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 1\n+        orphanage.AddTx(TXNS.at(0), 0);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 2\n+        orphanage.AddTx(TXNS.at(1), 1);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 2);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 2);\n+\n+        // Number of peers = 3\n+        orphanage.AddTx(TXNS.at(2), 2);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 3);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 3);\n+\n+        // Number of peers didn't change.",
      "path": "src/test/orphanage_tests.cpp",
      "position": 319,
      "original_position": 242,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\n`EraseForPeer` and `EraseTx` coverage here would be good. IIUC max memory goes up IFF a peer has a live orphan announcement?",
      "created_at": "2025-05-29T14:32:45Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114103109",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114103109"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 345,
      "original_line": 345,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114104811",
      "pull_request_review_id": 2878472725,
      "id": 2114104811,
      "node_id": "PRRC_kwDOABII585-Aq3r",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 12,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nSingle scenario that boots out 2+ txns with a single `CheckNumEvictions` seems apt",
      "created_at": "2025-05-29T14:33:41Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114104811",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114104811"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 93,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114106683",
      "pull_request_review_id": 2878472725,
      "id": 2114106683,
      "node_id": "PRRC_kwDOABII585-ArU7",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        node::TxOrphanageImpl orphanage(max_announcements, USAGE_TXNS_CREATED * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage.AddTx(TXNS.at(i), peer0);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);\n+\n+        // Add 10 unique transactions from peer1.\n+        // LimitOrphans should evict from peer0, because that's the one exceeding announcement limits.\n+        unsigned int num_from_peer1 = 10;\n+        for (unsigned int i{0}; i < num_from_peer1; ++i) {\n+            orphanage.AddTx(TXNS.at(max_announcements + i), peer1);\n+            // The announcement limit per peer has halved, but LimitOrphans does not evict beyond what is necessary to\n+            // bring the total announcements within its global limit.\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+            BOOST_CHECK(orphanage.AnnouncementsFromPeer(peer0) > orphanage.MaxPeerAnnouncements());\n+\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), i + 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+        // Add 10 transactions that are duplicates of the ones sent by peer0. We need to add 10 because the first 10\n+        // were just evicted in the previous block additions.\n+        for (unsigned int i{num_from_peer1}; i < num_from_peer1 + 10; ++i) {\n+            // Tx has already been sent by peer0\n+            BOOST_CHECK(orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            orphanage.AddTx(TXNS.at(i), peer2);\n+\n+            // Announcement limit is by entry, not by unique orphans\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+\n+            // peer0 is still the only one getting evicted\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), num_from_peer1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer2), i + 1 - num_from_peer1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            BOOST_CHECK(orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+\n+        // With 6 peers, each can add 10, and still only peer0's orphans are evicted.",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 197,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a\r\n\r\nWould like test coverage for an \"alternation\" to deleting another peer's announcement to demonstrate heap behavior. IIUC this test is only doing peer0",
      "created_at": "2025-05-29T14:34:43Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114106683",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114106683"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 278,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114112352",
      "pull_request_review_id": 2878472725,
      "id": 2114112352,
      "node_id": "PRRC_kwDOABII585-Astg",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 23,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a\r\n\r\n```Suggestion\r\n    // who will never exceed their reserved weight or announcement\r\n```",
      "created_at": "2025-05-29T14:37:52Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114112352",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114112352"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 248,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114119359",
      "pull_request_review_id": 2878472725,
      "id": 2114119359,
      "node_id": "PRRC_kwDOABII585-Aua_",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    node::TxOrphanageImpl orphanage{global_announcement_limit, per_peer_weight_reservation};\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 100000);\n+                if (payload_size) {",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 292,
      "original_position": 68,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a\r\n\r\nthis conditional is always taken",
      "created_at": "2025-05-29T14:41:31Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114119359",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114119359"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 296,
      "original_line": 296,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114123598",
      "pull_request_review_id": 2878472725,
      "id": 2114123598,
      "node_id": "PRRC_kwDOABII585-AvdO",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    node::TxOrphanageImpl orphanage{global_announcement_limit, per_peer_weight_reservation};\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 269,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```Suggestion\r\n\r\n    // This set of wtxids are honest peer's live announcements that must be protected\r\n```",
      "created_at": "2025-05-29T14:43:50Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114123598",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114123598"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 273,
      "original_line": 273,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114137366",
      "pull_request_review_id": 2878472725,
      "id": 2114137366,
      "node_id": "PRRC_kwDOABII585-Ay0W",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    node::TxOrphanageImpl orphanage{global_announcement_limit, per_peer_weight_reservation};\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 100000);\n+                if (payload_size) {\n+                    tx_mut.vout.emplace_back(0, CScript() << OP_RETURN << std::vector<unsigned char>(payload_size));\n+                } else {\n+                    tx_mut.vout.emplace_back(0, CScript{});\n+                }\n+            }\n+            auto new_tx = MakeTransactionRef(tx_mut);\n+            // add newly constructed outpoints to the coin pool\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                outpoints.emplace_back(new_tx->GetHash(), i);\n+            }\n+            return new_tx;\n+        }();\n+\n+        const auto wtxid{tx->GetWitnessHash()};\n+\n+        // orphanage functions\n+        LIMITED_WHILE(fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+        {\n+            NodeId peer_id = fuzzed_data_provider.ConsumeIntegralInRange<NodeId>(0, NUM_PEERS - 1);\n+            const auto tx_weight{GetTransactionWeight(*tx)};\n+\n+            // This protected peer will never send orphans that would\n+            // exceed their own personal allotment, so is never evicted.\n+            const bool peer_is_protected{peer_id == honest_peerid};\n+\n+            CallOneOf(\n+                fuzzed_data_provider,\n+                [&] { // AddTx\n+                    bool have_tx_and_peer = orphanage.HaveTxFromPeer(wtxid, peer_id);\n+                    if (peer_is_protected && !have_tx_and_peer &&\n+                        (orphanage.UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                        orphanage.AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                        // We never want our protected peer oversized or over-announced\n+                    } else {\n+                        orphanage.AddTx(tx, peer_id);\n+                        if (peer_is_protected && orphanage.HaveTxFromPeer(wtxid, peer_id)) {\n+                            protected_wtxids.insert(wtxid);\n+                        }\n+                    }\n+                },\n+                [&] { // AddAnnouncer\n+                    bool have_tx_and_peer = orphanage.HaveTxFromPeer(tx->GetWitnessHash(), peer_id);\n+                    // AddAnnouncer should return false if tx doesn't exist or we already HaveTxFromPeer.\n+                    {\n+                        if (peer_is_protected && !have_tx_and_peer &&\n+                            (orphanage.UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                            orphanage.AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                            // We never want our protected peer oversized\n+                        } else {\n+                            orphanage.AddAnnouncer(tx->GetWitnessHash(), peer_id);\n+                            if (peer_is_protected && orphanage.HaveTxFromPeer(wtxid, peer_id)) {\n+                                protected_wtxids.insert(wtxid);\n+                            }\n+                        }\n+                    }\n+                },\n+                [&] { // EraseTx\n+                    if (protected_wtxids.count(tx->GetWitnessHash())) {\n+                        protected_wtxids.erase(wtxid);\n+                    }\n+                    orphanage.EraseTx(wtxid);\n+                },\n+                [&] { // EraseForPeer\n+                    if (peer_id != honest_peerid) {\n+                        orphanage.EraseForPeer(peer_id);\n+                    }\n+                },\n+                [&] { // LimitOrphans\n+                    // Assert that protected peer is never affected by LimitOrphans.\n+                    const auto protected_bytes{orphanage.UsageFromPeer(honest_peerid)};\n+                    const auto protected_txns{orphanage.AnnouncementsFromPeer(honest_peerid)};\n+\n+                    orphanage.LimitOrphans();\n+\n+                    Assert(orphanage.CountAnnouncements() <= global_announcement_limit);\n+                    Assert(orphanage.TotalOrphanUsage() <= per_peer_weight_reservation * NUM_PEERS);\n+\n+                    // This should never differ before and after since we aren't allowing\n+                    // expiries and we've never exceeded the per-peer reservations.",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 147,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a\r\n\r\nexpiries aren't at thing anymore",
      "created_at": "2025-05-29T14:51:14Z",
      "updated_at": "2025-05-29T15:09:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114137366",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114137366"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 372,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114242408",
      "pull_request_review_id": 2878764858,
      "id": 2114242408,
      "node_id": "PRRC_kwDOABII585-BMdo",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 512,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "what if the peer sent us the first non-reconsidered orphan? would that not be considered below due to sequence number being 0?",
      "created_at": "2025-05-29T15:46:52Z",
      "updated_at": "2025-05-29T15:46:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2114242408",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2114242408"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 500,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2119024575",
      "pull_request_review_id": 2885479578,
      "id": 2119024575,
      "node_id": "PRRC_kwDOABII585-Tb-_",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;\n+\n+        const auto original_unique_txns{CountUniqueOrphans()};\n+\n+        // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+        // does not change unless a peer is removed.\n+        const auto max_ann{MaxPeerAnnouncements()};\n+        const auto max_mem{ReservedPeerUsage()};\n+\n+        // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+        // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+        std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+        heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+        for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+        }\n+        auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+        std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+        unsigned int num_erased{0};\n+        // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+        do {\n+            Assume(!heap_peer_dos.empty());\n+            // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+            // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+            // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+            // haven't. We may choose the same peer as the last iteration of this loop.\n+            // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+            // always lower, this means that a peer with only high number of announcements will be targeted before a\n+            // peer using a lot of memory, even if they have the same ratios.\n+            std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+            const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+            heap_peer_dos.pop_back();\n+\n+            // If needs trim, then at least one peer has a DoS score higher than 1.\n+            Assume(dos_score.fee > dos_score.size);\n+\n+            // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            Assume(it_ann->m_announcer == worst_peer);\n+            Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/CountWtxid(it_ann->m_tx->GetWitnessHash()) == 1);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 631,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112799295,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Oof yes! Should be replaced with an \"IsUnique\" type of thing.",
      "created_at": "2025-06-01T11:03:14Z",
      "updated_at": "2025-06-01T11:03:14Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2119024575",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2119024575"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 631,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2120989801",
      "pull_request_review_id": 2888158073,
      "id": 2120989801,
      "node_id": "PRRC_kwDOABII585-a7xp",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 88,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112572392,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "It's a part of what boost multiindex requires for its \"key extractor\" concept: https://www.boost.org/doc/libs/1_88_0/libs/multi_index/doc/reference/key_extraction.html",
      "created_at": "2025-06-02T12:24:36Z",
      "updated_at": "2025-06-02T13:49:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2120989801",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2120989801"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 70,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2120994262",
      "pull_request_review_id": 2888158073,
      "id": 2120994262,
      "node_id": "PRRC_kwDOABII585-a83W",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 454,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112727149,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Yes, seemed like the most fair way to do it.",
      "created_at": "2025-06-02T12:26:41Z",
      "updated_at": "2025-06-02T13:49:52Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2120994262",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2120994262"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 454,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121238950",
      "pull_request_review_id": 2888547849,
      "id": 2121238950,
      "node_id": "PRRC_kwDOABII585-b4mm",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 21,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112726648,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Fixed",
      "created_at": "2025-06-02T13:58:15Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121238950",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121238950"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 21,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121239249",
      "pull_request_review_id": 2888547849,
      "id": 2121239249,
      "node_id": "PRRC_kwDOABII585-b4rR",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 44,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112777005,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "makes sense, done",
      "created_at": "2025-06-02T13:58:25Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121239249",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121239249"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 44,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121240683",
      "pull_request_review_id": 2888547849,
      "id": 2121240683,
      "node_id": "PRRC_kwDOABII585-b5Br",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 77,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112547493,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "removed",
      "created_at": "2025-06-02T13:59:01Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121240683",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121240683"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 77,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121334653",
      "pull_request_review_id": 2888547849,
      "id": 2121334653,
      "node_id": "PRRC_kwDOABII585-cP99",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 132,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112597837,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T14:30:48Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121334653",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121334653"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 132,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121336441",
      "pull_request_review_id": 2888547849,
      "id": 2121336441,
      "node_id": "PRRC_kwDOABII585-cQZ5",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 162,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112606438,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T14:31:41Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121336441",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121336441"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 142,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121336985",
      "pull_request_review_id": 2888547849,
      "id": 2121336985,
      "node_id": "PRRC_kwDOABII585-cQiZ",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 169,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112585455,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "removed",
      "created_at": "2025-06-02T14:31:56Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121336985",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121336985"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 169,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121343331",
      "pull_request_review_id": 2888547849,
      "id": 2121343331,
      "node_id": "PRRC_kwDOABII585-cSFj",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 184,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112744241,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T14:34:00Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121343331",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121343331"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 163,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121347331",
      "pull_request_review_id": 2888547849,
      "id": 2121347331,
      "node_id": "PRRC_kwDOABII585-cTED",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 207,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112750662,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T14:35:15Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121347331",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121347331"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 207,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121349624",
      "pull_request_review_id": 2888547849,
      "id": 2121349624,
      "node_id": "PRRC_kwDOABII585-cTn4",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 221,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2109790109,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "have consolidated the two",
      "created_at": "2025-06-02T14:36:03Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121349624",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121349624"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 221,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121352694",
      "pull_request_review_id": 2888547849,
      "id": 2121352694,
      "node_id": "PRRC_kwDOABII585-cUX2",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 235,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112767194,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "fixed",
      "created_at": "2025-06-02T14:37:08Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121352694",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121352694"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 235,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121353880",
      "pull_request_review_id": 2888547849,
      "id": 2121353880,
      "node_id": "PRRC_kwDOABII585-cUqY",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 244,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112621971,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T14:37:34Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121353880",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121353880"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 244,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121354909",
      "pull_request_review_id": 2888547849,
      "id": 2121354909,
      "node_id": "PRRC_kwDOABII585-cU6d",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 259,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112772043,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "removed",
      "created_at": "2025-06-02T14:37:53Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121354909",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121354909"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 259,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121371142",
      "pull_request_review_id": 2888547849,
      "id": 2121371142,
      "node_id": "PRRC_kwDOABII585-cY4G",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 268,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112773426,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T14:42:44Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121371142",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121371142"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 268,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121372039",
      "pull_request_review_id": 2888547849,
      "id": 2121372039,
      "node_id": "PRRC_kwDOABII585-cZGH",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 300,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112783352,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "looks correct, done",
      "created_at": "2025-06-02T14:43:04Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121372039",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121372039"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 300,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121375257",
      "pull_request_review_id": 2888547849,
      "id": 2121375257,
      "node_id": "PRRC_kwDOABII585-cZ4Z",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 350,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112785010,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "yes, done",
      "created_at": "2025-06-02T14:44:01Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121375257",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121375257"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 350,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121375791",
      "pull_request_review_id": 2888547849,
      "id": 2121375791,
      "node_id": "PRRC_kwDOABII585-caAv",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 350,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112644130,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "removed",
      "created_at": "2025-06-02T14:44:08Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121375791",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121375791"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 350,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121377830",
      "pull_request_review_id": 2888547849,
      "id": 2121377830,
      "node_id": "PRRC_kwDOABII585-cagm",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 361,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112646478,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T14:44:46Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121377830",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121377830"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 361,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121381847",
      "pull_request_review_id": 2888547849,
      "id": 2121381847,
      "node_id": "PRRC_kwDOABII585-cbfX",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 395,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112708800,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "right, removed",
      "created_at": "2025-06-02T14:45:57Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121381847",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121381847"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 395,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121382356",
      "pull_request_review_id": 2888547849,
      "id": 2121382356,
      "node_id": "PRRC_kwDOABII585-cbnU",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 411,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112720613,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "made private",
      "created_at": "2025-06-02T14:46:09Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121382356",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121382356"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 411,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121383901",
      "pull_request_review_id": 2888547849,
      "id": 2121383901,
      "node_id": "PRRC_kwDOABII585-cb_d",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 454,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112789455,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added in the documentation",
      "created_at": "2025-06-02T14:46:45Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121383901",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121383901"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 454,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121385848",
      "pull_request_review_id": 2888547849,
      "id": 2121385848,
      "node_id": "PRRC_kwDOABII585-ccd4",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 480,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112731966,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "ha yes, removed the duplicate",
      "created_at": "2025-06-02T14:47:28Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121385848",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121385848"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 480,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121390872",
      "pull_request_review_id": 2888547849,
      "id": 2121390872,
      "node_id": "PRRC_kwDOABII585-cdsY",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 495,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112736485,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T14:49:15Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121390872",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121390872"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 483,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121444691",
      "pull_request_review_id": 2888547849,
      "id": 2121444691,
      "node_id": "PRRC_kwDOABII585-cq1T",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 512,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2114242408,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "That element would be equal to `it_lower`. I guess the concern is if we skip that element in the `while (rit != rit_end)` loop? `rit_end` is one past the last element. Here's a diagram from cpp reference:\r\nhttps://saco-evaluator.org.za/docs/cppreference/en/cpp/iterator/rbegin.html",
      "created_at": "2025-06-02T15:05:52Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121444691",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121444691"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 500,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121445876",
      "pull_request_review_id": 2888547849,
      "id": 2121445876,
      "node_id": "PRRC_kwDOABII585-crH0",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 550,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112753138,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:06:15Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121445876",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121445876"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 550,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121447098",
      "pull_request_review_id": 2888547849,
      "id": 2121447098,
      "node_id": "PRRC_kwDOABII585-cra6",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 591,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112768226,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:06:38Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121447098",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121447098"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 591,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121473032",
      "pull_request_review_id": 2888547849,
      "id": 2121473032,
      "node_id": "PRRC_kwDOABII585-cxwI",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;\n+\n+        const auto original_unique_txns{CountUniqueOrphans()};\n+\n+        // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+        // does not change unless a peer is removed.\n+        const auto max_ann{MaxPeerAnnouncements()};\n+        const auto max_mem{ReservedPeerUsage()};\n+\n+        // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+        // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+        std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+        heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+        for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+        }\n+        auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+        std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+        unsigned int num_erased{0};\n+        // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+        do {\n+            Assume(!heap_peer_dos.empty());\n+            // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+            // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+            // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+            // haven't. We may choose the same peer as the last iteration of this loop.\n+            // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+            // always lower, this means that a peer with only high number of announcements will be targeted before a\n+            // peer using a lot of memory, even if they have the same ratios.\n+            std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+            const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+            heap_peer_dos.pop_back();\n+\n+            // If needs trim, then at least one peer has a DoS score higher than 1.\n+            Assume(dos_score.fee > dos_score.size);\n+\n+            // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            Assume(it_ann->m_announcer == worst_peer);\n+            Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/CountWtxid(it_ann->m_tx->GetWitnessHash()) == 1);",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 631,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2112799295,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added an `IsUnique` to avoid this",
      "created_at": "2025-06-02T15:15:51Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121473032",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121473032"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 631,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121527261",
      "pull_request_review_id": 2888547849,
      "id": 2121527261,
      "node_id": "PRRC_kwDOABII585-c-_d",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 23,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": 2114112352,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:36:21Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121527261",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121527261"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 248,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121528207",
      "pull_request_review_id": 2888547849,
      "id": 2121528207,
      "node_id": "PRRC_kwDOABII585-c_OP",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    node::TxOrphanageImpl orphanage{global_announcement_limit, per_peer_weight_reservation};\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 269,
      "original_position": 46,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": 2114123598,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T15:36:51Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121528207",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121528207"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 273,
      "original_line": 273,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121529225",
      "pull_request_review_id": 2888547849,
      "id": 2121529225,
      "node_id": "PRRC_kwDOABII585-c_eJ",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    node::TxOrphanageImpl orphanage{global_announcement_limit, per_peer_weight_reservation};\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 100000);\n+                if (payload_size) {",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 292,
      "original_position": 68,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": 2114119359,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "changed",
      "created_at": "2025-06-02T15:37:21Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121529225",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121529225"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 296,
      "original_line": 296,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121532938",
      "pull_request_review_id": 2888547849,
      "id": 2121532938,
      "node_id": "PRRC_kwDOABII585-dAYK",
      "diff_hunk": "@@ -233,3 +234,153 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage.SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // Peer that must have orphans protected from eviction\n+    NodeId honest_peerid{0};\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight of announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 125);\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    node::TxOrphanageImpl orphanage{global_announcement_limit, per_peer_weight_reservation};\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, 100000);\n+                if (payload_size) {\n+                    tx_mut.vout.emplace_back(0, CScript() << OP_RETURN << std::vector<unsigned char>(payload_size));\n+                } else {\n+                    tx_mut.vout.emplace_back(0, CScript{});\n+                }\n+            }\n+            auto new_tx = MakeTransactionRef(tx_mut);\n+            // add newly constructed outpoints to the coin pool\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                outpoints.emplace_back(new_tx->GetHash(), i);\n+            }\n+            return new_tx;\n+        }();\n+\n+        const auto wtxid{tx->GetWitnessHash()};\n+\n+        // orphanage functions\n+        LIMITED_WHILE(fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+        {\n+            NodeId peer_id = fuzzed_data_provider.ConsumeIntegralInRange<NodeId>(0, NUM_PEERS - 1);\n+            const auto tx_weight{GetTransactionWeight(*tx)};\n+\n+            // This protected peer will never send orphans that would\n+            // exceed their own personal allotment, so is never evicted.\n+            const bool peer_is_protected{peer_id == honest_peerid};\n+\n+            CallOneOf(\n+                fuzzed_data_provider,\n+                [&] { // AddTx\n+                    bool have_tx_and_peer = orphanage.HaveTxFromPeer(wtxid, peer_id);\n+                    if (peer_is_protected && !have_tx_and_peer &&\n+                        (orphanage.UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                        orphanage.AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                        // We never want our protected peer oversized or over-announced\n+                    } else {\n+                        orphanage.AddTx(tx, peer_id);\n+                        if (peer_is_protected && orphanage.HaveTxFromPeer(wtxid, peer_id)) {\n+                            protected_wtxids.insert(wtxid);\n+                        }\n+                    }\n+                },\n+                [&] { // AddAnnouncer\n+                    bool have_tx_and_peer = orphanage.HaveTxFromPeer(tx->GetWitnessHash(), peer_id);\n+                    // AddAnnouncer should return false if tx doesn't exist or we already HaveTxFromPeer.\n+                    {\n+                        if (peer_is_protected && !have_tx_and_peer &&\n+                            (orphanage.UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                            orphanage.AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                            // We never want our protected peer oversized\n+                        } else {\n+                            orphanage.AddAnnouncer(tx->GetWitnessHash(), peer_id);\n+                            if (peer_is_protected && orphanage.HaveTxFromPeer(wtxid, peer_id)) {\n+                                protected_wtxids.insert(wtxid);\n+                            }\n+                        }\n+                    }\n+                },\n+                [&] { // EraseTx\n+                    if (protected_wtxids.count(tx->GetWitnessHash())) {\n+                        protected_wtxids.erase(wtxid);\n+                    }\n+                    orphanage.EraseTx(wtxid);\n+                },\n+                [&] { // EraseForPeer\n+                    if (peer_id != honest_peerid) {\n+                        orphanage.EraseForPeer(peer_id);\n+                    }\n+                },\n+                [&] { // LimitOrphans\n+                    // Assert that protected peer is never affected by LimitOrphans.\n+                    const auto protected_bytes{orphanage.UsageFromPeer(honest_peerid)};\n+                    const auto protected_txns{orphanage.AnnouncementsFromPeer(honest_peerid)};\n+\n+                    orphanage.LimitOrphans();\n+\n+                    Assert(orphanage.CountAnnouncements() <= global_announcement_limit);\n+                    Assert(orphanage.TotalOrphanUsage() <= per_peer_weight_reservation * NUM_PEERS);\n+\n+                    // This should never differ before and after since we aren't allowing\n+                    // expiries and we've never exceeded the per-peer reservations.",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 147,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f6c4f1ed3e353d6bf1f4372adb63b1906d18890a",
      "in_reply_to_id": 2114137366,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "that's what I meant to say, but yeah probably not helpful to mention",
      "created_at": "2025-06-02T15:38:26Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121532938",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121532938"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 372,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121538459",
      "pull_request_review_id": 2888547849,
      "id": 2121538459,
      "node_id": "PRRC_kwDOABII585-dBub",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 45,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114070740,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:39:59Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121538459",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121538459"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 126,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121541835",
      "pull_request_review_id": 2888547849,
      "id": 2121541835,
      "node_id": "PRRC_kwDOABII585-dCjL",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 101,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114084722,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:41:33Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121541835",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121541835"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 182,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121542553",
      "pull_request_review_id": 2888547849,
      "id": 2121542553,
      "node_id": "PRRC_kwDOABII585-dCuZ",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 109,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114084831,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:41:43Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121542553",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121542553"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 190,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121547903",
      "pull_request_review_id": 2888547849,
      "id": 2121547903,
      "node_id": "PRRC_kwDOABII585-dEB_",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 122,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114084933,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:43:20Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121547903",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121547903"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 203,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121548405",
      "pull_request_review_id": 2888547849,
      "id": 2121548405,
      "node_id": "PRRC_kwDOABII585-dEJ1",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 133,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114085090,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T15:43:30Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121548405",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121548405"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 214,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121621381",
      "pull_request_review_id": 2888547849,
      "id": 2121621381,
      "node_id": "PRRC_kwDOABII585-dV-F",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 145,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114089251,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done, `peer_dosy`",
      "created_at": "2025-06-02T16:18:52Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121621381",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121621381"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 226,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121622494",
      "pull_request_review_id": 2888547849,
      "id": 2121622494,
      "node_id": "PRRC_kwDOABII585-dWPe",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        node::TxOrphanageImpl orphanage(max_announcements, USAGE_TXNS_CREATED * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage.AddTx(TXNS.at(i), peer0);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 159,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114091408,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T16:19:12Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121622494",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121622494"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 240,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121642443",
      "pull_request_review_id": 2888547849,
      "id": 2121642443,
      "node_id": "PRRC_kwDOABII585-dbHL",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        node::TxOrphanageImpl orphanage(max_announcements, USAGE_TXNS_CREATED * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage.AddTx(TXNS.at(i), peer0);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);\n+\n+        // Add 10 unique transactions from peer1.\n+        // LimitOrphans should evict from peer0, because that's the one exceeding announcement limits.\n+        unsigned int num_from_peer1 = 10;\n+        for (unsigned int i{0}; i < num_from_peer1; ++i) {\n+            orphanage.AddTx(TXNS.at(max_announcements + i), peer1);\n+            // The announcement limit per peer has halved, but LimitOrphans does not evict beyond what is necessary to\n+            // bring the total announcements within its global limit.\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+            BOOST_CHECK(orphanage.AnnouncementsFromPeer(peer0) > orphanage.MaxPeerAnnouncements());\n+\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), i + 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+        // Add 10 transactions that are duplicates of the ones sent by peer0. We need to add 10 because the first 10\n+        // were just evicted in the previous block additions.\n+        for (unsigned int i{num_from_peer1}; i < num_from_peer1 + 10; ++i) {\n+            // Tx has already been sent by peer0\n+            BOOST_CHECK(orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            orphanage.AddTx(TXNS.at(i), peer2);\n+\n+            // Announcement limit is by entry, not by unique orphans\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+\n+            // peer0 is still the only one getting evicted\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), num_from_peer1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer2), i + 1 - num_from_peer1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            BOOST_CHECK(orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+\n+        // With 6 peers, each can add 10, and still only peer0's orphans are evicted.\n+        const unsigned int max_per_peer{max_announcements / 6};\n+        for (NodeId peer{3}; peer < 6; ++peer) {\n+            for (unsigned int i{0}; i < max_per_peer; ++i) {\n+                orphanage.AddTx(TXNS.at(peer * max_per_peer + i), peer);\n+                BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+            }\n+        }\n+        for (NodeId peer{0}; peer < 6; ++peer) {\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer), max_per_peer);\n+        }\n+    }\n+\n+    // Limits change as more peers are added.\n+    {\n+        node::TxOrphanageImpl orphanage;\n+        // These stay the same regardless of number of peers\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+\n+        // These change with number of peers\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 1\n+        orphanage.AddTx(TXNS.at(0), 0);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 2\n+        orphanage.AddTx(TXNS.at(1), 1);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 2);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 2);\n+\n+        // Number of peers = 3\n+        orphanage.AddTx(TXNS.at(2), 2);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage.ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage.MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 3);\n+        BOOST_CHECK_EQUAL(orphanage.MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 3);\n+\n+        // Number of peers didn't change.",
      "path": "src/test/orphanage_tests.cpp",
      "position": 319,
      "original_position": 242,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114103109,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T16:27:43Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121642443",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121642443"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 345,
      "original_line": 345,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121650357",
      "pull_request_review_id": 2888547849,
      "id": 2121650357,
      "node_id": "PRRC_kwDOABII585-ddC1",
      "diff_hunk": "@@ -126,13 +123,15 @@ BOOST_AUTO_TEST_CASE(DoS_mapOrphans)\n         tx.vout[0].nValue = i*CENT;\n         tx.vout[0].scriptPubKey = GetScriptForDestination(PKHash(key.GetPubKey()));\n \n-        orphanage.AddTx(MakeTransactionRef(tx), i);\n+        auto ptx = MakeTransactionRef(tx);\n+        orphanage.AddTx(ptx, i);\n+        orphans_added.emplace_back(ptx);\n     }\n \n     // ... and 50 that depend on other orphans:\n     for (int i = 0; i < 50; i++)\n     {\n-        CTransactionRef txPrev = orphanage.RandomOrphan();\n+        CTransactionRef txPrev = Random(orphans_added, m_rng);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 56,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "b5fe4383ada8a16076a9665e9ee9557d93fd659f",
      "in_reply_to_id": 2112592805,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-02T16:31:31Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121650357",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121650357"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 134,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121656293",
      "pull_request_review_id": 2888547849,
      "id": 2121656293,
      "node_id": "PRRC_kwDOABII585-defl",
      "diff_hunk": "@@ -327,10 +327,10 @@ void TxOrphanage::SanityCheck() const\n     // Check that cached m_total_announcements is correct\n     unsigned int counted_total_announcements{0};\n     // Check that m_total_orphan_usage is correct\n-    unsigned int counted_total_usage{0};\n+    int64_t counted_total_usage{0};",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "aed51fe7d5cbcc43eba2be3cd5af666fe1d95dd7",
      "in_reply_to_id": 2112159931,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T16:34:38Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121656293",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121656293"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 330,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121656398",
      "pull_request_review_id": 2888547849,
      "id": 2121656398,
      "node_id": "PRRC_kwDOABII585-dehO",
      "diff_hunk": "@@ -37,7 +37,7 @@ bool TxOrphanage::AddTx(const CTransactionRef& tx, NodeId peer)\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME}, m_orphan_list.size()});\n+    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "737c5127df841e9c8037b1885284f80b0aba17dd",
      "in_reply_to_id": 2112167760,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-02T16:34:41Z",
      "updated_at": "2025-06-02T16:36:09Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121656398",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121656398"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 40,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121695775",
      "pull_request_review_id": 2889242365,
      "id": 2121695775,
      "node_id": "PRRC_kwDOABII585-doIf",
      "diff_hunk": "@@ -30,7 +28,11 @@ static const uint32_t DEFAULT_MAX_ORPHAN_TRANSACTIONS{100};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    const std::unique_ptr<TxOrphanageImpl> m_impl;",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 17,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3da112f33b11dffbfcc6cf1b01783501f5790a16",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "What do you think about using the \"exposed `std::unique_ptr<>`\" pattern (don't know if it has a name) as opposed to full-blown pimpl?\r\n\r\nSo like `TxGraph` / `TxGraphImpl`, I'm suggesting there would be 2 files (no `_impl.h`), with a `TxOrphanage` abstract class with virtual member functions, and an implementation defined only inside the `.cpp` file, and a factory function `std::unique_ptr<TxOrphanage> MakeTxOrphanage()` or so that returns a newly-constructed `TxOrphanageImpl`. It avoids the boilerplate of `TxOrphanage` functions that forward to the impl code, and the need for a `_impl.h` file. A downside is that it's (probably negligibly) slower to dispatch (because virtual functions), and an inability to test the implementation beyond what the public interface offers, but I don't think that's happening here anyway?\r\n\r\n",
      "created_at": "2025-06-02T16:53:05Z",
      "updated_at": "2025-06-02T17:06:30Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2121695775",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2121695775"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 31,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124443576",
      "pull_request_review_id": 2893371305,
      "id": 2124443576,
      "node_id": "PRRC_kwDOABII585-oG-4",
      "diff_hunk": "@@ -30,7 +28,11 @@ static const uint32_t DEFAULT_MAX_ORPHAN_TRANSACTIONS{100};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    const std::unique_ptr<TxOrphanageImpl> m_impl;",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 17,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3da112f33b11dffbfcc6cf1b01783501f5790a16",
      "in_reply_to_id": 2121695775,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Sure, yes. I'll add a commit to the beginning to refactor to this structure + change all clients to do `MakeTxOrphanage`, and then swap out the `Impl`s basically.",
      "created_at": "2025-06-03T17:02:23Z",
      "updated_at": "2025-06-03T17:02:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2124443576",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124443576"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 31,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124891663",
      "pull_request_review_id": 2894063829,
      "id": 2124891663,
      "node_id": "PRRC_kwDOABII585-p0YP",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 12,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114104811,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added a test that has 10 evictions in 1 go",
      "created_at": "2025-06-03T20:43:26Z",
      "updated_at": "2025-06-03T20:54:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2124891663",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124891663"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 93,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124892503",
      "pull_request_review_id": 2894063829,
      "id": 2124892503,
      "node_id": "PRRC_kwDOABII585-p0lX",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 62,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114080543,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-03T20:43:53Z",
      "updated_at": "2025-06-03T20:54:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2124892503",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124892503"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 143,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124894458",
      "pull_request_review_id": 2894063829,
      "id": 2124894458,
      "node_id": "PRRC_kwDOABII585-p1D6",
      "diff_hunk": "@@ -305,9 +304,9 @@ FUZZ_TARGET(txdownloadman_impl, .init = initialize)\n     // Initialize a TxDownloadManagerImpl\n     bilingual_str error;\n     CTxMemPool pool{MemPoolOptionsForTest(g_setup->m_node), error};\n-    const auto max_orphan_count = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(0, 300);\n+    const auto max_orphan_count = node::DEFAULT_MAX_ORPHAN_TRANSACTIONS;",
      "path": "src/test/fuzz/txdownloadman.cpp",
      "position": null,
      "original_position": 16,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "f2dcdbf700b3b20a315f5a6eec57c7463955fe43",
      "in_reply_to_id": 2112259957,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "ignoring because the constant gets deleted",
      "created_at": "2025-06-03T20:45:06Z",
      "updated_at": "2025-06-03T20:54:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2124894458",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124894458"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 307,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124907696",
      "pull_request_review_id": 2894063829,
      "id": 2124907696,
      "node_id": "PRRC_kwDOABII585-p4Sw",
      "diff_hunk": "@@ -30,7 +28,11 @@ static const uint32_t DEFAULT_MAX_ORPHAN_TRANSACTIONS{100};\n  * Not thread-safe. Requires external synchronization.\n  */\n class TxOrphanage {\n+    const std::unique_ptr<TxOrphanageImpl> m_impl;",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 17,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3da112f33b11dffbfcc6cf1b01783501f5790a16",
      "in_reply_to_id": 2121695775,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Restructured this way, with the help of ðŸª„ âœ¨AI âœ¨ ",
      "created_at": "2025-06-03T20:53:41Z",
      "updated_at": "2025-06-03T20:54:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2124907696",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2124907696"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 31,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2127121713",
      "pull_request_review_id": 2897586136,
      "id": 2127121713,
      "node_id": "PRRC_kwDOABII585-yU0x",
      "diff_hunk": "@@ -111,7 +137,6 @@ class TxOrphanage {\n \n protected:\n     struct OrphanTx : public OrphanTxBase {",
      "path": "src/txorphanage.h",
      "position": null,
      "original_position": 56,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ef2f44e653a4877d4e65fbd5a51ec83ceb96d212",
      "in_reply_to_id": 1949519057,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "this is gone now",
      "created_at": "2025-06-04T17:42:25Z",
      "updated_at": "2025-06-04T17:42:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2127121713",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2127121713"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 148,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129019547",
      "pull_request_review_id": 2900619885,
      "id": 2129019547,
      "node_id": "PRRC_kwDOABII585-5kKb",
      "diff_hunk": "@@ -228,3 +228,154 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 233,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3322f9301e2ccb54678d32257fcedcd710aebe65",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Had a thought: this harness could be relaxed to where the fuzzer input selects the protected peers, which could be any subset of all the peers. This would allow coverage of a scenario where no peers exceed reservation limits, and possibly stronger assertions in that case.",
      "created_at": "2025-06-05T14:37:04Z",
      "updated_at": "2025-06-05T14:37:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2129019547",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129019547"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 237,
      "original_line": 237,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129634568",
      "pull_request_review_id": 2901493170,
      "id": 2129634568,
      "node_id": "PRRC_kwDOABII585-76UI",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112731246,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I went pretty far into implementing this, but realized there is a downside to this approach - the set stores entries for each announcement instead of each unique orphan. It requires us to update this map each time a new announcement is added/removed instead of just for unique ones. Perhaps worth keeping as `Wtxid` - what do you think?",
      "created_at": "2025-06-05T18:01:49Z",
      "updated_at": "2025-06-05T18:01:49Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2129634568",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129634568"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 108,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129683785",
      "pull_request_review_id": 2901548354,
      "id": 2129683785,
      "node_id": "PRRC_kwDOABII585-8GVJ",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112731246,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ah, I see. So you could have an $\\mathcal{O(n)}$ blowup factor with $n$ the number of peers that have announced that Wtxid? If so, that doesn't sound like a worthwhile tradeoff.\r\n",
      "created_at": "2025-06-05T18:14:05Z",
      "updated_at": "2025-06-05T18:14:05Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2129683785",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129683785"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 108,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129925291",
      "pull_request_review_id": 2901823872,
      "id": 2129925291,
      "node_id": "PRRC_kwDOABII585-9BSr",
      "diff_hunk": "@@ -89,6 +90,244 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanageImpl& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        node::TxOrphanageImpl orphanage_low_ann(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        node::TxOrphanageImpl orphanage_low_mem(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE + 1);\n+\n+        // Add the first transaction\n+        orphanage_low_ann.AddTx(TXNS.at(0), peer);\n+        orphanage_low_mem.AddTx(TXNS.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann.CountAnnouncements() > orphanage_low_ann.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann.TotalOrphanUsage() <= orphanage_low_ann.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann.NeedsTrim());\n+\n+        orphanage_low_mem.AddTx(TXNS.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem.CountAnnouncements() <= orphanage_low_mem.MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem.TotalOrphanUsage() > orphanage_low_mem.MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem.NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem.HaveTx(TXNS.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem.HaveTx(TXNS.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        node::TxOrphanageImpl orphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage.AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage.AddTx(children.at(1), peer);\n+        orphanage.AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage.AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage.HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage.AddTx(children.at(3), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage.AddTx(children.at(4), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage.AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage.AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage.AddTx(children.at(5), peer);\n+        orphanage.AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(3));\n+        orphanage.AddTx(children.at(6), peer);\n+        orphanage.LimitOrphans();\n+        BOOST_CHECK(!orphanage.HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage.HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage.GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer0{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        node::TxOrphanageImpl orphanage(max_announcements, USAGE_TXNS_CREATED * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage.AddTx(TXNS.at(i), peer0);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), 0);\n+\n+        // Add 10 unique transactions from peer1.\n+        // LimitOrphans should evict from peer0, because that's the one exceeding announcement limits.\n+        unsigned int num_from_peer1 = 10;\n+        for (unsigned int i{0}; i < num_from_peer1; ++i) {\n+            orphanage.AddTx(TXNS.at(max_announcements + i), peer1);\n+            // The announcement limit per peer has halved, but LimitOrphans does not evict beyond what is necessary to\n+            // bring the total announcements within its global limit.\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+            BOOST_CHECK(orphanage.AnnouncementsFromPeer(peer0) > orphanage.MaxPeerAnnouncements());\n+\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), i + 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+        // Add 10 transactions that are duplicates of the ones sent by peer0. We need to add 10 because the first 10\n+        // were just evicted in the previous block additions.\n+        for (unsigned int i{num_from_peer1}; i < num_from_peer1 + 10; ++i) {\n+            // Tx has already been sent by peer0\n+            BOOST_CHECK(orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            orphanage.AddTx(TXNS.at(i), peer2);\n+\n+            // Announcement limit is by entry, not by unique orphans\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(orphanage), 1);\n+\n+            // peer0 is still the only one getting evicted\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer0), max_announcements - i - 1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer1), num_from_peer1);\n+            BOOST_CHECK_EQUAL(orphanage.AnnouncementsFromPeer(peer2), i + 1 - num_from_peer1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer0 is the one that was evicted.\n+            BOOST_CHECK(!orphanage.HaveTxFromPeer(TXNS.at(i)->GetWitnessHash(), peer0));\n+            BOOST_CHECK(orphanage.HaveTx(TXNS.at(i)->GetWitnessHash()));\n+        }\n+\n+        // With 6 peers, each can add 10, and still only peer0's orphans are evicted.",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 197,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c9a34d4cdb5f5eca385304dc5c836960fad2a74a",
      "in_reply_to_id": 2114106683,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Added a test that has interleaved worst peers in a LimitOrphans call",
      "created_at": "2025-06-05T19:11:12Z",
      "updated_at": "2025-06-05T19:11:12Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2129925291",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129925291"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 278,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129927509",
      "pull_request_review_id": 2901826932,
      "id": 2129927509,
      "node_id": "PRRC_kwDOABII585-9B1V",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+        if (it_upper != index_by_peer.begin()) {\n+            auto rit = std::make_reverse_iterator(it_upper);\n+            auto rit_end = std::make_reverse_iterator(it_lower);\n+            while (rit != rit_end) {\n+                if (rit->m_announcer != peer) continue;\n+                // Check if this tx spends from parent.\n+                for (const auto& input : rit->m_tx->vin) {\n+                    if (input.prevout.hash == parent_txid) {\n+                        children_found.emplace_back(rit->m_tx);\n+                        break;\n+                    }\n+                }\n+                ++rit;\n+            }\n+\n+        }\n+        return children_found;\n+    }\n+\n+    void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+        for (unsigned int i = 0; i < tx.vout.size(); i++) {\n+            const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n+            if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n+                for (const auto& wtxid : it_by_prev->second) {\n+                    // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+                    if (!Assume(it != index_by_wtxid.end())) continue;\n+\n+                    // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n+                    // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n+                    // from processing the orphan by disconnecting.\n+                    const auto num_announcers{CountWtxid(wtxid)};\n+                    if (!Assume(num_announcers > 0)) continue;\n+                    std::advance(it, rng.randrange(num_announcers));\n+                    if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) continue;\n+\n+                    // Mark this orphan as ready to be reconsidered.\n+                    auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                    m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n+                    LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n+                             it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n+                }\n+            }\n+        }\n+    }\n+\n+    /** Constant, decided on initialization. */\n+    unsigned int MaxGlobalAnnouncements() const { return m_max_global_announcements; }\n+    /** Constant, decided on initialization. */\n+    unsigned int ReservedPeerUsage() const { return m_reserved_usage_per_peer; }\n+    /** Dynamic based on number of peers. Each peer has an equal amount, but the global maximum number of announcements\n+     * stays constant. The number of peers times MaxPeerAnnouncements() (rounded) adds up to MaxGlobalAnnouncements().\n+     * As long as every peer's m_count_announcements / MaxPeerAnnouncements() < 1, MaxGlobalAnnouncements() is not\n+     * exceeded. */\n+    unsigned int MaxPeerAnnouncements() const { return m_max_global_announcements / std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+    /** Dynamic based on number of peers. More peers means more allowed memory usage. The number of peers times\n+     * ReservedPeerUsage() adds up to MaxGlobalUsage(). As long as every peer's m_total_usage / ReservedPeerUsage() < 1,\n+     * MaxGlobalUsage() is not exceeded. */\n+    unsigned int MaxGlobalUsage() const { return m_reserved_usage_per_peer * std::max<unsigned int>(m_peer_orphanage_info.size(), 1); }\n+\n+    /** Returns whether global announcement or usage limits have been exceeded. */\n+    bool NeedsTrim() const\n+    {\n+        return m_orphans.size() > MaxGlobalAnnouncements() || m_unique_orphan_bytes > MaxGlobalUsage();\n+    }\n+\n+    /** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+     * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+     * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+     * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+     * are peers spamming the orphanage.\n+     */\n+    void LimitOrphans()\n+    {\n+        if (m_orphans.empty() || !NeedsTrim()) return;\n+\n+        const auto original_unique_txns{CountUniqueOrphans()};\n+\n+        // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+        // does not change unless a peer is removed.\n+        const auto max_ann{MaxPeerAnnouncements()};\n+        const auto max_mem{ReservedPeerUsage()};\n+\n+        // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+        // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+        std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+        heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+        for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+        }\n+        auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+        std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+        unsigned int num_erased{0};\n+        // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+        do {\n+            Assume(!heap_peer_dos.empty());\n+            // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+            // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+            // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+            // haven't. We may choose the same peer as the last iteration of this loop.\n+            // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+            // always lower, this means that a peer with only high number of announcements will be targeted before a\n+            // peer using a lot of memory, even if they have the same ratios.\n+            std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+            const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+            heap_peer_dos.pop_back();\n+\n+            // If needs trim, then at least one peer has a DoS score higher than 1.\n+            Assume(dos_score.fee > dos_score.size);\n+\n+            // Evict the oldest announcement from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 629,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2109879316,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Implemented the general idea, i.e. keep trimming until this peer wouldn't be the next thing we pop from the heap. There was some iterator invalidation going on here",
      "created_at": "2025-06-05T19:11:42Z",
      "updated_at": "2025-06-05T19:11:42Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2129927509",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129927509"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 616,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129928431",
      "pull_request_review_id": 2901827992,
      "id": 2129928431,
      "node_id": "PRRC_kwDOABII585-9CDv",
      "diff_hunk": "@@ -228,3 +228,154 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 233,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3322f9301e2ccb54678d32257fcedcd710aebe65",
      "in_reply_to_id": 2129019547,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Good idea, done",
      "created_at": "2025-06-05T19:11:55Z",
      "updated_at": "2025-06-05T19:11:55Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2129928431",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2129928431"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 237,
      "original_line": 237,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132631041",
      "pull_request_review_id": 2905651896,
      "id": 2132631041,
      "node_id": "PRRC_kwDOABII585_HV4B",
      "diff_hunk": "@@ -8,68 +8,159 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>",
      "path": "src/node/txorphanage.cpp",
      "position": 14,
      "original_position": 7,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nNitty McNitface: commit title undersells it a bit. Maybe \"Overhaul TxOrphanage with smarter limits\" or so?",
      "created_at": "2025-06-06T18:00:34Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132631041",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132631041"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 14,
      "original_line": 14,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132633811",
      "pull_request_review_id": 2905651896,
      "id": 2132633811,
      "node_id": "PRRC_kwDOABII585_HWjT",
      "diff_hunk": "@@ -8,68 +8,159 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n \n class TxOrphanageImpl final : public TxOrphanage {\n private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 127,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nI see in other places `int64_t` is used for expressing usage (like `PeerDosInfo::m_total_usage`). Maybe better to pick one type for all places that involve usage? Or even introduce some type aliases for things like announcementcounts/txcounts/memusages, as that may improve readability too.",
      "created_at": "2025-06-06T18:02:46Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132633811",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132633811"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 94,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132644726",
      "pull_request_review_id": 2905651896,
      "id": 2132644726,
      "node_id": "PRRC_kwDOABII585_HZN2",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 216,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nNit: this function documentation may be more appropriate near its declaration inline in `TxOrphanageImpl`, rather than here with its implementation.\r\n\r\n(and elsewhere below)",
      "created_at": "2025-06-06T18:11:02Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132644726",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132644726"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 184,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132873114",
      "pull_request_review_id": 2905651896,
      "id": 2132873114,
      "node_id": "PRRC_kwDOABII585_IQ-a",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();",
      "path": "src/node/txorphanage.cpp",
      "position": 196,
      "original_position": 241,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nNit: if `cleanup_outpoints_map` also controls whether `m_unique_orphans` and `m_unique_orphan_bytes` gets updated, maybe it's better to call it \"was_last_for_wtxid\" or so?\r\n\r\nAlternative, it seems possible to just drop the argument, and have this function call `IsUnique` directly. That would remove the responsibility from the caller. The only caller that doesn't already do this is `EraseTx`, but even there it's correct I think, and only negligibly slower?",
      "created_at": "2025-06-06T20:30:25Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132873114",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132873114"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 196,
      "original_line": 196,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132879588",
      "pull_request_review_id": 2905651896,
      "id": 2132879588,
      "node_id": "PRRC_kwDOABII585_ISjk",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 524,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nI think `IsUnique(it)` would work here too, and be more efficient? Or move into `Erase`, see comment there.",
      "created_at": "2025-06-06T20:36:47Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132879588",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132879588"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 393,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132880562",
      "pull_request_review_id": 2905651896,
      "id": 2132880562,
      "node_id": "PRRC_kwDOABII585_ISyy",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 609,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\n`IsUnique(it_ann)` here too? (or move it inside `Erase`, see comment there).",
      "created_at": "2025-06-06T20:37:51Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132880562",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132880562"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 463,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132887033",
      "pull_request_review_id": 2905651896,
      "id": 2132887033,
      "node_id": "PRRC_kwDOABII585_IUX5",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 669,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nCalling `lower_bound` to initialize `it`, and then calling `CountWtxid(wtxid)` which will do the same seems superfluous.\r\n\r\nHow about:\r\n```c++\r\nauto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\r\nauto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\r\nconst auto num_announcers{std::distance(it, it_end)};\r\nif (num_announcers == 0) continue;\r\nstd::advance(it, rng.randrange(num_announcers));\r\n```\r\n\r\nThis would perhaps even allow you to get rid of `CountWtxid`, as all remaining calls are in `Assume(CountWtxid(wtxid) > 1);`.",
      "created_at": "2025-06-06T20:44:13Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132887033",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132887033"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 499,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132893009",
      "pull_request_review_id": 2905651896,
      "id": 2132893009,
      "node_id": "PRRC_kwDOABII585_IV1R",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 730,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nNit: `static constexpr auto mark_reconsider_modifier = ...`",
      "created_at": "2025-06-06T20:49:50Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132893009",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132893009"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 541,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132893986",
      "pull_request_review_id": 2905651896,
      "id": 2132893986,
      "node_id": "PRRC_kwDOABII585_IWEi",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 675,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nNit: `static constexpr auto mark_reconsidered_modifier = ...`",
      "created_at": "2025-06-06T20:50:47Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132893986",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132893986"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 505,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132899931",
      "pull_request_review_id": 2905651896,
      "id": 2132899931,
      "node_id": "PRRC_kwDOABII585_IXhb",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nThis loop could also be written as:\r\n\r\n```c++\r\nauto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\r\nauto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\r\nunsigned int num_erased{0};\r\nwhile (it != it_end) {\r\n    Erase<ByWtxid>(it++, num_erased == 0);\r\n    ++num_erased;\r\n}\r\n```\r\n\r\n(also applies to `EraseForPeer`)\r\n\r\n    ",
      "created_at": "2025-06-06T20:56:55Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132899931",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132899931"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132904878",
      "pull_request_review_id": 2905651896,
      "id": 2132904878,
      "node_id": "PRRC_kwDOABII585_IYuu",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 491,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nIf the `if (it == index_by_wtxid.end()) return 0;` above is kept, then I think this is equivalent to `return 1;`.\r\n\r\n",
      "created_at": "2025-06-06T21:01:45Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132904878",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132904878"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 379,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132905059",
      "pull_request_review_id": 2905651896,
      "id": 2132905059,
      "node_id": "PRRC_kwDOABII585_IYxj",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 478,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nIf the `if (it == index_by_wtxid.end()) return 0;` above is kept, then I think this condition is always true.\r\n\r\n",
      "created_at": "2025-06-06T21:01:53Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132905059",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132905059"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132907103",
      "pull_request_review_id": 2905651896,
      "id": 2132907103,
      "node_id": "PRRC_kwDOABII585_IZRf",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 427,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nThis function only ever returns 0 or 1. Maybe make its return type `bool`?",
      "created_at": "2025-06-06T21:04:17Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132907103",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132907103"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 353,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132910529",
      "pull_request_review_id": 2905651896,
      "id": 2132910529,
      "node_id": "PRRC_kwDOABII585_IaHB",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 574,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nNit: `static constexpr auto compare_score =`\r\n\r\nAlso, the arguments should probably be `auto&`, though the copy will probably be optimized away anyway.",
      "created_at": "2025-06-06T21:08:14Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132910529",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132910529"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 428,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132911909",
      "pull_request_review_id": 2905651896,
      "id": 2132911909,
      "node_id": "PRRC_kwDOABII585_Iacl",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 598,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nIs it possible that this condition is not true?",
      "created_at": "2025-06-06T21:09:48Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132911909",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132911909"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 452,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132916963",
      "pull_request_review_id": 2905651896,
      "id": 2132916963,
      "node_id": "PRRC_kwDOABII585_Ibrj",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 614,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] improve TxOrphanage DoS limits\"\r\n\r\nI don't think this search is necessary, because no more announcements from the same peer left can be determined by looking if `it_ann` is `end()` or refers to another peer now.\r\n\r\n(Feel free to disregard, if you think the current code is sufficiently cleaner; I don't think the performance difference matters)",
      "created_at": "2025-06-06T21:14:40Z",
      "updated_at": "2025-06-06T21:16:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2132916963",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2132916963"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 468,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2135952193",
      "pull_request_review_id": 2910455209,
      "id": 2135952193,
      "node_id": "PRRC_kwDOABII585_UAtB",
      "diff_hunk": "@@ -8,68 +8,159 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>",
      "path": "src/node/txorphanage.cpp",
      "position": 14,
      "original_position": 7,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132631041,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Done",
      "created_at": "2025-06-09T15:33:31Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2135952193",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2135952193"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 14,
      "original_line": 14,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136241875",
      "pull_request_review_id": 2910934699,
      "id": 2136241875,
      "node_id": "PRRC_kwDOABII585_VHbT",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerInfo {\n+        int64_t m_total_usage{0};\n+        unsigned int m_count_announcements{0};\n+        bool operator==(const PeerInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(unsigned int max_peer_count, int64_t max_peer_bytes) const\n+        {\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerInfo> m_peer_orphanage_info;\n+    using PeerMap = decltype(m_peer_orphanage_info);\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n+    {\n+        // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+        // This means peers that are not storing any orphans do not have an entry in\n+        // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+        // ensures disconnected peers are not tracked forever.\n+        auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+        if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+        if (cleanup_outpoints_map) {\n+            m_unique_orphans -= 1;\n+            m_unique_orphan_bytes -= it->GetUsage();\n+\n+            // Remove references in m_outpoint_to_orphan_it\n+            const auto& wtxid{it->m_tx->GetWitnessHash()};\n+            for (const auto& input : it->m_tx->vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    it_prev->second.erase(wtxid);\n+                    // Clean up keys if they point to an empty set.\n+                    if (it_prev->second.empty()) {\n+                        m_outpoint_to_orphan_it.erase(it_prev);\n+                    }\n+                }\n+            }\n+        }\n+        m_orphans.get<Tag>().erase(it);\n+    }\n+\n+    /** Return number of announcements with the same wtxid as it. */\n+    unsigned int CountSameWtxid(Iter<ByWtxid> it) const\n+    {\n+        if (it == m_orphans.end()) return 0;\n+\n+        unsigned int count{0};\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            ++count;\n+            ++it;\n+        }\n+        return count;\n+    }\n+\n+    /** Return number of announcements with this wtxid. */\n+    unsigned int CountWtxid(const Wtxid& wtxid) const\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == m_orphans.end()) return 0;\n+        return CountSameWtxid(it);\n+    }\n+public:\n+    TxOrphanageImpl() = default;\n+    TxOrphanageImpl(unsigned int max_global_ann, int64_t reserved_peer_usage) :\n+        m_max_global_announcements{max_global_ann},\n+        m_reserved_usage_per_peer{reserved_peer_usage}\n+    {}\n+\n+    /** Number of announcements ones for the same wtxid are not de-duplicated. */\n+    unsigned int CountAnnouncements() const { return m_orphans.size(); }\n+\n+    /** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+    int64_t TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+    /** Number of unique orphans */\n+    unsigned int CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+    /** Number of orphans from this peer */\n+    unsigned int AnnouncementsFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+    }\n+\n+    /** Total usage of orphans from this peer */\n+    int64_t UsageFromPeer(NodeId peer) const {\n+        auto it = m_peer_orphanage_info.find(peer);\n+        return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+    }\n+\n+    void SanityCheck() const\n+    {\n+        std::unordered_map<NodeId, PeerInfo> reconstructed_peer_info;\n+        std::map<Wtxid, int64_t > unique_wtxids_to_usage;\n+        std::set<COutPoint> all_outpoints;\n+\n+        for (auto it = m_orphans.begin(); it != m_orphans.end(); ++it) {\n+            for (const auto& input : it->m_tx->vin) {\n+                all_outpoints.insert(input.prevout);\n+            }\n+            unique_wtxids_to_usage.emplace(it->m_tx->GetWitnessHash(), it->GetUsage());\n+\n+            auto& peer_info = reconstructed_peer_info.try_emplace(it->m_announcer).first->second;\n+            peer_info.m_total_usage += it->GetUsage();\n+            peer_info.m_count_announcements += 1;\n+        }\n+\n+        // Recalculated per-peer stats are identical to m_peer_orphanage_info\n+        assert(reconstructed_peer_info == m_peer_orphanage_info);\n+\n+        // All outpoints exist in m_outpoint_to_orphan_it, all keys in m_outpoint_to_orphan_it correspond to some\n+        // orphan, and all wtxids referenced in m_outpoint_to_orphan_it are also in m_orphans.\n+        assert(all_outpoints.size() == m_outpoint_to_orphan_it.size());\n+        for (const auto& [outpoint, wtxid_set] : m_outpoint_to_orphan_it) {\n+            assert(all_outpoints.contains(outpoint));\n+            for (const auto& wtxid : wtxid_set) {\n+                assert(unique_wtxids_to_usage.contains(wtxid));\n+            }\n+        }\n+\n+        // Cached m_unique_orphans value is correct.\n+        assert(m_orphans.size() >= m_unique_orphans);\n+        assert(unique_wtxids_to_usage.size() == m_unique_orphans);\n+\n+        const auto calculated_dedup_usage = std::accumulate(unique_wtxids_to_usage.begin(), unique_wtxids_to_usage.end(),\n+            int64_t{0}, [](int64_t sum, const auto pair) { return sum + pair.second; });\n+        assert(calculated_dedup_usage == m_unique_orphan_bytes);\n+    }\n+\n+    bool AddTx(const CTransactionRef& tx, NodeId peer)\n+    {\n+        const auto& wtxid{tx->GetWitnessHash()};\n+        const auto& txid{tx->GetHash()};\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+        int64_t sz = GetTransactionWeight(*tx);\n+        if (sz > MAX_STANDARD_TX_WEIGHT) {\n+            LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+            return false;\n+        }\n+\n+        // We will return false if the tx already exists under a different peer.\n+        const bool brand_new{!HaveTx(wtxid)};\n+\n+        auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        // Add links in m_outpoint_to_orphan_it\n+        if (brand_new) {\n+            for (const auto& input : tx->vin) {\n+                auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+                wtxids_for_prevout.emplace(wtxid);\n+            }\n+\n+            m_unique_orphans += 1;\n+            m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+            LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                     txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+            Assume(CountWtxid(wtxid) == 1);\n+        } else {\n+            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                     peer, txid.ToString(), wtxid.ToString());\n+            Assume(CountWtxid(wtxid) > 1);\n+        }\n+        return brand_new;\n+    }\n+\n+    bool AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+\n+        // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+        // have the tx data.\n+        if (it == m_orphans.end()) return false;\n+        if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+        // Quit if we already have this announcement (same wtxid and peer).\n+        if (HaveTxFromPeer(wtxid, peer)) return false;\n+\n+        // Add another announcement, copying one that exists\n+        const auto& ptx = it->m_tx;\n+        auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+        if (!Assume(ret.second)) return false;\n+\n+        ++m_current_sequence;\n+        auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+        peer_info.Add(*ret.first);\n+\n+        const auto& txid = ret.first->m_tx->GetHash();\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                 peer, txid.ToString(), wtxid.ToString());\n+\n+        Assume(CountWtxid(wtxid) > 1);\n+        return true;\n+    }\n+\n+    CTransactionRef GetTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+        return nullptr;\n+    }\n+\n+    bool HaveTx(const Wtxid& wtxid) const\n+    {\n+        auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, min_peer});\n+        return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n+    }\n+\n+    bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n+    {\n+        return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n+    }\n+\n+    /** Erase all entries by this peer. */\n+    void EraseForPeer(NodeId peer)\n+    {\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+        unsigned int num_erased{0};\n+        while (it != index_by_peer.end() && it->m_announcer == peer) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_peer.end() || std::next(it)->m_announcer != peer};\n+            auto it_next = last_item ? index_by_peer.end() : std::next(it);\n+\n+            // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+            Erase<ByPeer>(it, /*cleanup_outpoints_map=*/CountWtxid(it->m_tx->GetWitnessHash()) == 1);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+        Assume(!m_peer_orphanage_info.contains(peer));\n+\n+        if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of announcements erased. */\n+    unsigned int EraseAll(const Wtxid& wtxid)\n+    {\n+        auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+        auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, min_peer});\n+        if (it == index_by_wtxid.end()) return 0;\n+\n+        unsigned int num_erased{0};\n+        const auto& txid = it->m_tx->GetHash();\n+        while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+            // Decide what will happen next before the iter is invalidated.\n+            const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+            auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+            // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+            Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+            // Advance pointer\n+            it = it_next;\n+            num_erased += 1;\n+        }\n+\n+        if (num_erased > 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n+        }\n+\n+        return num_erased;\n+    }\n+\n+    /** Erase all entries with this wtxid. Return the number of unique orphans by wtxid erased. */\n+    unsigned int EraseTx(const Wtxid& wtxid)\n+    {\n+        const unsigned int num_announcements_erased{EraseAll(wtxid)};\n+        return std::min<unsigned int>(1, num_announcements_erased);\n+    }\n+\n+    /** Return whether there is a tx that can be reconsidered. */\n+    bool HaveTxToReconsider(NodeId peer) const\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n+    }\n+\n+    /** If there is a tx that can be reconsidered, return it. Otherwise, return a nullptr. */\n+    CTransactionRef GetTxToReconsider(NodeId peer)\n+    {\n+        auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+        if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+            // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+            // reconsidered again until there is a new reason to do so.\n+            auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+            m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+            return it->m_tx;\n+        }\n+        return nullptr;\n+    }\n+\n+    unsigned int EraseForBlock(const CBlock& block)\n+    {\n+        std::set<Wtxid> wtxids_to_erase;\n+        for (const CTransactionRef& ptx : block.vtx) {\n+            const CTransaction& block_tx = *ptx;\n+\n+            // Which orphan pool entries must we evict?\n+            for (const auto& input : block_tx.vin) {\n+                auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+                if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                    // Copy all wtxids to wtxids_to_erase.\n+                    std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n+                    for (const auto& wtxid : it_prev->second) {\n+                        wtxids_to_erase.insert(wtxid);\n+                    }\n+                }\n+            }\n+        }\n+\n+        unsigned int num_erased{0};\n+        for (const auto& wtxid : wtxids_to_erase) {\n+            num_erased += EraseTx(wtxid);\n+        }\n+\n+        if (num_erased != 0) {\n+            LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+        }\n+        return wtxids_to_erase.size();\n+    }\n+\n+\n+    /** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+     * recent to least recent. */\n+    std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n+    {\n+        std::vector<CTransactionRef> children_found;\n+        const auto& parent_txid{parent->GetHash()};\n+\n+        // Iterate through all orphans from this peer, in reverse order, so that more recent\n+        // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+        // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+        // not bias how we process other peer's orphans.\n+        auto& index_by_peer = m_orphans.get<ByPeer>();\n+        auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+        auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 512,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "455b4b817884f860cd4467f0a9be4a459e89891c",
      "in_reply_to_id": 2114242408,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "ah yep, you can mark as resolved",
      "created_at": "2025-06-09T18:25:40Z",
      "updated_at": "2025-06-09T18:25:41Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136241875",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136241875"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 500,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136244685",
      "pull_request_review_id": 2910938872,
      "id": 2136244685,
      "node_id": "PRRC_kwDOABII585_VIHN",
      "diff_hunk": "@@ -327,10 +327,10 @@ void TxOrphanage::SanityCheck() const\n     // Check that cached m_total_announcements is correct\n     unsigned int counted_total_announcements{0};\n     // Check that m_total_orphan_usage is correct\n-    unsigned int counted_total_usage{0};\n+    int64_t counted_total_usage{0};",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "aed51fe7d5cbcc43eba2be3cd5af666fe1d95dd7",
      "in_reply_to_id": 2112159931,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "do we care about signed-ness?",
      "created_at": "2025-06-09T18:27:35Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136244685",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136244685"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 330,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136251223",
      "pull_request_review_id": 2910938872,
      "id": 2136251223,
      "node_id": "PRRC_kwDOABII585_VJtX",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+        m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+        return it->m_tx;\n     }\n     return nullptr;\n }\n \n+/** Return whether there is a tx that can be reconsidered. */\n bool TxOrphanageImpl::HaveTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return false;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    return !work_set.empty();\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n }\n-\n void TxOrphanageImpl::EraseForBlock(const CBlock& block)\n {\n-    std::vector<Wtxid> vOrphanErase;\n-\n+    std::set<Wtxid> wtxids_to_erase;\n     for (const CTransactionRef& ptx : block.vtx) {\n-        const CTransaction& tx = *ptx;\n+        const CTransaction& block_tx = *ptx;\n \n         // Which orphan pool entries must we evict?\n-        for (const auto& txin : tx.vin) {\n-            auto itByPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-            if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n-            for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n-                const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+        for (const auto& input : block_tx.vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                // Copy all wtxids to wtxids_to_erase.\n+                std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n             }\n         }\n     }\n \n-    // Erase orphan transactions included or precluded by this block\n-    if (vOrphanErase.size()) {\n-        int nErased = 0;\n-        for (const auto& orphanHash : vOrphanErase) {\n-            nErased += EraseTx(orphanHash);\n-        }\n-        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", nErased);\n+    unsigned int num_erased{0};\n+    for (const auto& wtxid : wtxids_to_erase) {\n+        num_erased += EraseTx(wtxid);\n     }\n+\n+    if (num_erased != 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+    }\n+    Assume(wtxids_to_erase.size() == num_erased);\n }\n \n-std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const\n+/** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+ * recent to least recent. */\n+std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n {\n-    // First construct a vector of iterators to ensure we do not return duplicates of the same tx\n-    // and so we can sort by nTimeExpire.\n-    std::vector<OrphanMap::iterator> iters;\n-\n-    // For each output, get all entries spending this prevout, filtering for ones from the specified peer.\n-    for (unsigned int i = 0; i < parent->vout.size(); i++) {\n-        const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(parent->GetHash(), i));\n-        if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                if (elem->second.announcers.contains(nodeid)) {\n-                    iters.emplace_back(elem);\n+    std::vector<CTransactionRef> children_found;\n+    const auto& parent_txid{parent->GetHash()};\n+\n+    // Iterate through all orphans from this peer, in reverse order, so that more recent\n+    // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+    // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+    // not bias how we process other peer's orphans.\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+    auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+    if (it_upper != index_by_peer.begin()) {\n+        auto rit = std::make_reverse_iterator(it_upper);\n+        auto rit_end = std::make_reverse_iterator(it_lower);\n+        while (rit != rit_end) {\n+            if (rit->m_announcer != peer) continue;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 823,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "498f1c019197a8e4105490cdc4a0605594ca97d5\r\n\r\nif this line is hit, the `rit` iterator is never incremented; infinite loop?\r\n\r\nalternative formulation to consider for the entire conditional starting at https://github.com/bitcoin/bitcoin/pull/31829/commits/498f1c019197a8e4105490cdc4a0605594ca97d5#diff-e6100361fa0e9e25478f808ca084e5f681d4dddbbee7b3bea0f9d5bcd29db3aaR596\r\n```\r\nfor (auto rit = std::make_reverse_iterator(it_upper);\r\n         rit != std::make_reverse_iterator(it_lower); ++rit)\r\n{\r\n    if (rit->m_announcer != peer) continue;\r\n    for (const auto& input : rit->m_tx->vin) {\r\n        if (input.prevout.hash == parent_txid) {\r\n            children_found.emplace_back(rit->m_tx);\r\n            break;\r\n        }\r\n    }\r\n}\r\n```",
      "created_at": "2025-06-09T18:32:20Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136251223",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136251223"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 556,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136395364",
      "pull_request_review_id": 2910455209,
      "id": 2136395364,
      "node_id": "PRRC_kwDOABII585_Vs5k",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 478,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132905059,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I added a check that the wtxid matches, and removed this extra stuff",
      "created_at": "2025-06-09T19:53:50Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136395364",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136395364"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136415815",
      "pull_request_review_id": 2910455209,
      "id": 2136415815,
      "node_id": "PRRC_kwDOABII585_Vx5H",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 427,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132907103,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-09T20:05:33Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136415815",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136415815"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 353,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136417290",
      "pull_request_review_id": 2910455209,
      "id": 2136417290,
      "node_id": "PRRC_kwDOABII585_VyQK",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 491,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132904878,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "`num_erased` has the number of announcements so it can be greater than 1. However, since I've changed this to return a bool, I just made this `return true`.",
      "created_at": "2025-06-09T20:06:42Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136417290",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136417290"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 379,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136421097",
      "pull_request_review_id": 2910455209,
      "id": 2136421097,
      "node_id": "PRRC_kwDOABII585_VzLp",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 574,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132910529,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nice, done",
      "created_at": "2025-06-09T20:08:25Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136421097",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136421097"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 428,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136423210",
      "pull_request_review_id": 2910455209,
      "id": 2136423210,
      "node_id": "PRRC_kwDOABII585_Vzsq",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 598,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132911909,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I don't think so, removed the condition",
      "created_at": "2025-06-09T20:09:06Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136423210",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136423210"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 452,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136455433",
      "pull_request_review_id": 2910455209,
      "id": 2136455433,
      "node_id": "PRRC_kwDOABII585_V7kJ",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 614,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132916963,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Seems slightly simpler as is so leaving",
      "created_at": "2025-06-09T20:29:42Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136455433",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136455433"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 468,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136462525",
      "pull_request_review_id": 2910455209,
      "id": 2136462525,
      "node_id": "PRRC_kwDOABII585_V9S9",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 669,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132887033,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Nice, done",
      "created_at": "2025-06-09T20:34:25Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136462525",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136462525"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 499,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136463200",
      "pull_request_review_id": 2910455209,
      "id": 2136463200,
      "node_id": "PRRC_kwDOABII585_V9dg",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 675,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132893986,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Done",
      "created_at": "2025-06-09T20:34:45Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136463200",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136463200"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 505,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136463914",
      "pull_request_review_id": 2910455209,
      "id": 2136463914,
      "node_id": "PRRC_kwDOABII585_V9oq",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 730,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132893009,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Done",
      "created_at": "2025-06-09T20:35:03Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136463914",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136463914"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 541,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136484132",
      "pull_request_review_id": 2910455209,
      "id": 2136484132,
      "node_id": "PRRC_kwDOABII585_WCkk",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 216,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132644726,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Moved",
      "created_at": "2025-06-09T20:45:51Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136484132",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136484132"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 184,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136530972",
      "pull_request_review_id": 2910455209,
      "id": 2136530972,
      "node_id": "PRRC_kwDOABII585_WOAc",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();",
      "path": "src/node/txorphanage.cpp",
      "position": 196,
      "original_position": 241,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132873114,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Renamed to `unique`. I consolidated `IsUnique` to only have the `wtxid` variant, and it's now only used by the erasure functions that aren't holding `ByWtxid` iterators.",
      "created_at": "2025-06-09T21:21:13Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136530972",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136530972"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 196,
      "original_line": 196,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136531813",
      "pull_request_review_id": 2910455209,
      "id": 2136531813,
      "node_id": "PRRC_kwDOABII585_WONl",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132899931,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Changed this one, but wasn't sure if there is a max Wtxid I can use for `EraseForPeer`?",
      "created_at": "2025-06-09T21:21:56Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136531813",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136531813"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136535101",
      "pull_request_review_id": 2910455209,
      "id": 2136535101,
      "node_id": "PRRC_kwDOABII585_WPA9",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 524,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132879588,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "`it` is a `ByPeer` iterator, so its neighbors won't tell us much information about how many announcers of the tx there are. `Erase` would also need to see that this is the case and make a separate query by wtxid to check uniqueness... seems a bit cleaner as is?",
      "created_at": "2025-06-09T21:24:45Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136535101",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136535101"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 393,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136535935",
      "pull_request_review_id": 2910455209,
      "id": 2136535935,
      "node_id": "PRRC_kwDOABII585_WPN_",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 609,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132880562,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Also a `ByPeer` iterator (see other comment)",
      "created_at": "2025-06-09T21:25:25Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136535935",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136535935"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 463,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136540717",
      "pull_request_review_id": 2910455209,
      "id": 2136540717,
      "node_id": "PRRC_kwDOABII585_WQYt",
      "diff_hunk": "@@ -8,68 +8,159 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n \n class TxOrphanageImpl final : public TxOrphanage {\n private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 127,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132633811,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Nice yes, made `Usage = int64_t` and `Count = unsigned int`",
      "created_at": "2025-06-09T21:29:49Z",
      "updated_at": "2025-06-09T22:27:58Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2136540717",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2136540717"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 94,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137865722",
      "pull_request_review_id": 2913515215,
      "id": 2137865722,
      "node_id": "PRRC_kwDOABII585_bT36",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 524,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132879588,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Here is what I had in mind, making `IsUnique` work by ByWtxid iterator only, and making `Erase` figure out uniqueness of the passed argument by itself: https://github.com/sipa/bitcoin/commits/pr31829\r\n\r\nFeel free to use/squash in any part of it.",
      "created_at": "2025-06-10T13:10:06Z",
      "updated_at": "2025-06-10T13:22:20Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2137865722",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137865722"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 393,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137884115",
      "pull_request_review_id": 2913547103,
      "id": 2137884115,
      "node_id": "PRRC_kwDOABII585_bYXT",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132899931,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ah, you'd need the `ffff...ffff` Wtxid for that, but I think you can avoid it by incrementing the peer instead:\r\n\r\n```c++\r\nauto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\r\nauto it_end = index_by_peer.lower_bound(ByPeerView{peer + 1, false, 0});\r\n```",
      "created_at": "2025-06-10T13:17:29Z",
      "updated_at": "2025-06-10T13:17:29Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2137884115",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137884115"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137937680",
      "pull_request_review_id": 2913637907,
      "id": 2137937680,
      "node_id": "PRRC_kwDOABII585_blcQ",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132899931,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Yeah, it didn't work for me yesterday for some reason. Taking another look.",
      "created_at": "2025-06-10T13:40:26Z",
      "updated_at": "2025-06-10T13:40:27Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2137937680",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137937680"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137941928",
      "pull_request_review_id": 2910938872,
      "id": 2137941928,
      "node_id": "PRRC_kwDOABII585_bmeo",
      "diff_hunk": "@@ -327,10 +327,10 @@ void TxOrphanage::SanityCheck() const\n     // Check that cached m_total_announcements is correct\n     unsigned int counted_total_announcements{0};\n     // Check that m_total_orphan_usage is correct\n-    unsigned int counted_total_usage{0};\n+    int64_t counted_total_usage{0};",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "22d6cdd4f9dd6e03ad88946c130dad98fc45d7ad",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "22d6cdd4f9dd6e03ad88946c130dad98fc45d7ad\r\n\r\nwhy signed int?",
      "created_at": "2025-06-10T13:42:10Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2137941928",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137941928"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 330,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137961509",
      "pull_request_review_id": 2910938872,
      "id": 2137961509,
      "node_id": "PRRC_kwDOABII585_brQl",
      "diff_hunk": "@@ -207,29 +206,25 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n                         auto& tx_to_remove = PickValue(fuzzed_data_provider, tx_history);\n                         block.vtx.push_back(tx_to_remove);\n                     }\n-                    orphanage.EraseForBlock(block);\n+                    orphanage->EraseForBlock(block);\n                     for (const auto& tx_removed : block.vtx) {\n-                        Assert(!orphanage.HaveTx(tx_removed->GetWitnessHash()));\n-                        Assert(!orphanage.HaveTxFromPeer(tx_removed->GetWitnessHash(), peer_id));\n+                        Assert(!orphanage->HaveTx(tx_removed->GetWitnessHash()));\n+                        Assert(!orphanage->HaveTxFromPeer(tx_removed->GetWitnessHash(), peer_id));\n                     }\n                 },\n                 [&] {\n                     // test mocktime and expiry\n                     SetMockTime(ConsumeTime(fuzzed_data_provider));\n-                    orphanage.LimitOrphans(orphanage_rng);\n-                    Assert(orphanage.Size() <= node::DEFAULT_MAX_ORPHAN_TRANSACTIONS);\n+                    orphanage->LimitOrphans(orphanage_rng);\n+                    Assert(orphanage->Size() <= node::DEFAULT_MAX_ORPHAN_TRANSACTIONS);\n                 });\n-\n         }\n \n-        // Set tx as potential parent to be used for future GetChildren() calls.\n-        if (!ptx_potential_parent || fuzzed_data_provider.ConsumeBool()) {\n-            ptx_potential_parent = tx;\n-        }\n+        ptx_potential_parent = tx;",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 193,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "9afbf15b99508982b1a73bc416246ffbbce22d89",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "9afbf15b99508982b1a73bc416246ffbbce22d89\r\n\r\nwas this logic change necessary for this commit?",
      "created_at": "2025-06-10T13:49:39Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2137961509",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2137961509"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 223,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138025794",
      "pull_request_review_id": 2913790240,
      "id": 2138025794,
      "node_id": "PRRC_kwDOABII585_b69C",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 15,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] overhaul TxOrphanage with smarter limits\"\r\n\r\nSince these types are used in the return types of (the implementation of) `TxOrphanage` interface functions, maybe they belong in `TxOrphanage` directly, so that e.g. both `TxOrphanage::UsageFromPeer` and `TxOrphanageImpl::UsageFromPeer` can use `Usage` as return type?",
      "created_at": "2025-06-10T14:14:13Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138025794",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138025794"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 22,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138044941",
      "pull_request_review_id": 2910938872,
      "id": 2138044941,
      "node_id": "PRRC_kwDOABII585_b_oN",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 61,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "a703a3086a6a3a6250fb97e799712443eaedf5d0\r\n\r\nI think you can `const` all fields except `m_reconsider`?",
      "created_at": "2025-06-10T14:22:52Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138044941",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138044941"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 36,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138070999",
      "pull_request_review_id": 2913790240,
      "id": 2138070999,
      "node_id": "PRRC_kwDOABII585_cF_X",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 545,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] overhaul TxOrphanage with smarter limits\"\r\n\r\nI'm confused by this comment. Neither `MaxPeerAnnouncements()` or `ReservedPeerUsage()` are affected by the size of `m_peer_orphanage_info`, so even if that map's size were to change (which can happen in this function...), nothing would change? In fact, they're both just returning `const` class member variables.",
      "created_at": "2025-06-10T14:34:37Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138070999",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138070999"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138082482",
      "pull_request_review_id": 2910938872,
      "id": 2138082482,
      "node_id": "PRRC_kwDOABII585_cIyy",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const Count m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const Usage m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    Count m_unique_orphans{0};\n \n-    /** Timestamp for the next scheduled sweep of expired orphans */\n-    NodeSeconds m_next_sweep{0s};\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    Usage m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerDoSInfo {\n+        Usage m_total_usage{0};\n+        Count m_count_announcements{0};\n+        bool operator==(const PeerDoSInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(Count max_peer_count, Usage max_peer_bytes) const\n+        {\n+            assert(max_peer_count > 0);\n+            assert(max_peer_bytes > 0);\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerDoSInfo> m_peer_orphanage_info;\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If unique is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool unique);\n+\n+    /** Check if there is exactly one transaction with this wtxid.",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 186,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "a703a3086a6a3a6250fb97e799712443eaedf5d0\r\n\r\nexactly one *announcement* for this wtxid I presume",
      "created_at": "2025-06-10T14:40:03Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138082482",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138082482"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 150,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138105074",
      "pull_request_review_id": 2913790240,
      "id": 2138105074,
      "node_id": "PRRC_kwDOABII585_cOTy",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 583,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] overhaul TxOrphanage with smarter limits\"\r\n\r\nNit: maybe point out that it isn't strictly necessary to use 1 as a lower limit, because when the last peer goes below ratio 1, necessarily `NeedsTrim()` will be false, and we'd stop anyway. But it's more convenient to have some fallback number to use anyway.",
      "created_at": "2025-06-10T14:48:33Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138105074",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138105074"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 412,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138115140",
      "pull_request_review_id": 2910938872,
      "id": 2138115140,
      "node_id": "PRRC_kwDOABII585_cQxE",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const Count m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const Usage m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    Count m_unique_orphans{0};\n \n-    /** Timestamp for the next scheduled sweep of expired orphans */\n-    NodeSeconds m_next_sweep{0s};\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    Usage m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerDoSInfo {\n+        Usage m_total_usage{0};\n+        Count m_count_announcements{0};\n+        bool operator==(const PeerDoSInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(Count max_peer_count, Usage max_peer_bytes) const\n+        {\n+            assert(max_peer_count > 0);\n+            assert(max_peer_bytes > 0);\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 174,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "a703a3086a6a3a6250fb97e799712443eaedf5d0\r\n\r\nand helps determine the total memory limits based on number of entries",
      "created_at": "2025-06-10T14:51:17Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138115140",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138115140"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 138,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138131119",
      "pull_request_review_id": 2913790240,
      "id": 2138131119,
      "node_id": "PRRC_kwDOABII585_cUqv",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 555,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] overhaul TxOrphanage with smarter limits\"\r\n\r\nNit: this could skip inserting any peer with DoS score < 1? In the typical (?) case where there are just a few spammy peers, this avoids an $\\mathcal{O}(\\log n)$ factor in cost per announcement removal in heap maintenance.",
      "created_at": "2025-06-10T14:57:33Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138131119",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138131119"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 385,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138149816",
      "pull_request_review_id": 2913790240,
      "id": 2138149816,
      "node_id": "PRRC_kwDOABII585_cZO4",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            // Decide what will happen next before the iter is invalidated.\n+            auto it_next = std::next(it_ann);\n+\n+            Erase<ByPeer>(it_ann, /*unique=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+            num_erased += 1;\n+            it_ann = it_next;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+        }\n+        // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+        // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+        // its orphans.\n+        if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+            heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+            std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        }\n+    } while (!heap_peer_dos.empty() && NeedsTrim());",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 608,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] overhaul TxOrphanage with smarter limits\"\r\n\r\nNit: the `!heap_peer_dos.empty()` is redundant I think, because that would imply there are no peers left (or no peers with score >= 1 left, if above suggestion is followed), so `NeedsTrim()` is definitely false.\r\n\r\nThis could arguably also be moved above the `if (it_worst_peer != ...)` check:\r\n\r\n```c++\r\n            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\r\n        }\r\n        if (!NeedsTrim()) break;\r\n        // ...\r\n        if (it_worst_peer != m_peer_orphanage_info.end() && ...\r\n        ...\r\n        }\r\n    } while(true);\r\n```",
      "created_at": "2025-06-10T15:04:24Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138149816",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138149816"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 433,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138186805",
      "pull_request_review_id": 2914060549,
      "id": 2138186805,
      "node_id": "PRRC_kwDOABII585_ciQ1",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132899931,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ok I must have been tripping yesterday... changed",
      "created_at": "2025-06-10T15:19:32Z",
      "updated_at": "2025-06-10T15:19:33Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138186805",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138186805"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138187785",
      "pull_request_review_id": 2914061884,
      "id": 2138187785,
      "node_id": "PRRC_kwDOABII585_cigJ",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 524,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132879588,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Thanks! Squashed this in with a couple small edits",
      "created_at": "2025-06-10T15:19:49Z",
      "updated_at": "2025-06-10T15:20:02Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138187785",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138187785"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 393,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138376457",
      "pull_request_review_id": 2913790240,
      "id": 2138376457,
      "node_id": "PRRC_kwDOABII585_dQkJ",
      "diff_hunk": "@@ -83,373 +176,491 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n-    }\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n-    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    auto it_next = std::next(it);\n+    if (it_next != index.end() && it_next->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+\n+    auto it_prev = std::prev(it);\n+    if (it != index.begin() && it_prev->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n     return true;\n }\n \n-bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n }\n \n-bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n         }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n     }\n+    return brand_new;\n+}\n+\n+bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n+}\n+\n+bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n+{\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n+\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n+\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end()) return;\n+\n+    auto it_end = index_by_peer.lower_bound(ByPeerView{peer + 1, false, 0});\n+    unsigned int num_ann{0};\n+    while (it != it_end && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+        }\n+        // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+        // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+        // its orphans.\n+        if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+            heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+            std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        }\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+                const auto num_announcers{std::distance(it, it_end)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+        m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+        return it->m_tx;\n     }\n     return nullptr;\n }\n \n+/** Return whether there is a tx that can be reconsidered. */\n bool TxOrphanageImpl::HaveTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return false;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    return !work_set.empty();\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n }\n-\n void TxOrphanageImpl::EraseForBlock(const CBlock& block)\n {\n-    std::vector<Wtxid> vOrphanErase;\n-\n+    std::set<Wtxid> wtxids_to_erase;\n     for (const CTransactionRef& ptx : block.vtx) {\n-        const CTransaction& tx = *ptx;\n+        const CTransaction& block_tx = *ptx;\n \n         // Which orphan pool entries must we evict?\n-        for (const auto& txin : tx.vin) {\n-            auto itByPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-            if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n-            for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n-                const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+        for (const auto& input : block_tx.vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                // Copy all wtxids to wtxids_to_erase.\n+                std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n             }\n         }\n     }\n \n-    // Erase orphan transactions included or precluded by this block\n-    if (vOrphanErase.size()) {\n-        int nErased = 0;\n-        for (const auto& orphanHash : vOrphanErase) {\n-            nErased += EraseTx(orphanHash);\n-        }\n-        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", nErased);\n+    unsigned int num_erased{0};\n+    for (const auto& wtxid : wtxids_to_erase) {\n+        num_erased += EraseTx(wtxid);\n+    }\n+\n+    if (num_erased != 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n     }\n+    Assume(wtxids_to_erase.size() == num_erased);\n }\n \n-std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const\n+/** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+ * recent to least recent. */\n+std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n {\n-    // First construct a vector of iterators to ensure we do not return duplicates of the same tx\n-    // and so we can sort by nTimeExpire.\n-    std::vector<OrphanMap::iterator> iters;\n-\n-    // For each output, get all entries spending this prevout, filtering for ones from the specified peer.\n-    for (unsigned int i = 0; i < parent->vout.size(); i++) {\n-        const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(parent->GetHash(), i));\n-        if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                if (elem->second.announcers.contains(nodeid)) {\n-                    iters.emplace_back(elem);\n+    std::vector<CTransactionRef> children_found;\n+    const auto& parent_txid{parent->GetHash()};\n+\n+    // Iterate through all orphans from this peer, in reverse order, so that more recent\n+    // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+    // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+    // not bias how we process other peer's orphans.\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+    auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+    if (it_upper != index_by_peer.begin()) {\n+        auto rit = std::make_reverse_iterator(it_upper);\n+        auto rit_end = std::make_reverse_iterator(it_lower);\n+        while (rit != rit_end) {\n+            if (rit->m_announcer != peer) continue;\n+            // Check if this tx spends from parent.\n+            for (const auto& input : rit->m_tx->vin) {\n+                if (input.prevout.hash == parent_txid) {\n+                    children_found.emplace_back(rit->m_tx);\n+                    break;\n                 }\n             }\n+            ++rit;\n         }\n     }\n-\n-    // Sort by address so that duplicates can be deleted. At the same time, sort so that more recent\n-    // orphans (which expire later) come first.  Break ties based on address, as nTimeExpire is\n-    // quantified in seconds and it is possible for orphans to have the same expiry.\n-    std::sort(iters.begin(), iters.end(), [](const auto& lhs, const auto& rhs) {\n-        if (lhs->second.nTimeExpire == rhs->second.nTimeExpire) {\n-            return &(*lhs) < &(*rhs);\n-        } else {\n-            return lhs->second.nTimeExpire > rhs->second.nTimeExpire;\n-        }\n-    });\n-    // Erase duplicates\n-    iters.erase(std::unique(iters.begin(), iters.end()), iters.end());\n-\n-    // Convert to a vector of CTransactionRef\n-    std::vector<CTransactionRef> children_found;\n-    children_found.reserve(iters.size());\n-    for (const auto& child_iter : iters) {\n-        children_found.emplace_back(child_iter->second.tx);\n-    }\n     return children_found;\n }\n \n std::vector<TxOrphanage::OrphanTxBase> TxOrphanageImpl::GetOrphanTransactions() const\n {\n-    std::vector<OrphanTxBase> ret;\n-    ret.reserve(m_orphans.size());\n-    for (auto const& o : m_orphans) {\n-        ret.push_back({o.second.tx, o.second.announcers});\n+    std::vector<TxOrphanage::OrphanTxBase> result;\n+    result.reserve(m_unique_orphans);\n+\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+    auto it = index_by_wtxid.begin();\n+    std::set<NodeId> this_orphan_announcers;\n+    while (it != index_by_wtxid.end()) {\n+        this_orphan_announcers.insert(it->m_announcer);\n+        // If this is the last entry, or the next entry has a different wtxid, build a OrphanTxBase.\n+        if (std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash()) {\n+            result.emplace_back(TxOrphanage::OrphanTxBase{it->m_tx, this_orphan_announcers});",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 838,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd9be630e01140d911441866811eff6a9ed04bbd",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[p2p] overhaul TxOrphanage with smarter limits\"\r\n\r\nUse `std::move(this_orphan_announcers)` to avoid a copy of the set.\r\n\r\nAlso nit: invoking the `OrphanTxBase` constructor negates the advantage of using `emplace_back` (which can construct it in place, but instead it's being constructed by the caller, and then copied in place):\r\n\r\n```c++\r\n    result.emplace_back(it->m_tx, std::move(this_orphan_announcers));\r\n```\r\n\r\n(to be clear, this doesn't matter for performance or anything at all here, but it seems silly to actively bypass in-place construction where it's easier to not do that)",
      "created_at": "2025-06-10T16:57:55Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138376457",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138376457"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 582,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138395335",
      "pull_request_review_id": 2913790240,
      "id": 2138395335,
      "node_id": "PRRC_kwDOABII585_dVLH",
      "diff_hunk": "@@ -72,6 +72,344 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 18,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "1c37a4e27a0496064e17fdad51f1a68ea2846b91",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[unit test] basic TxOrphanageImpl eviction and protection\"\r\n\r\nStyle nit: not a constant, shouldn't be ALLCAPS.",
      "created_at": "2025-06-10T17:10:22Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138395335",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138395335"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 98,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138395712",
      "pull_request_review_id": 2913790240,
      "id": 2138395712,
      "node_id": "PRRC_kwDOABII585_dVRA",
      "diff_hunk": "@@ -72,6 +72,344 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 21,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "1c37a4e27a0496064e17fdad51f1a68ea2846b91",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[unit test] basic TxOrphanageImpl eviction and protection\"\r\n\r\nStyle nit: not a constant, shouldn't be ALLCAPS.\r\n",
      "created_at": "2025-06-10T17:10:36Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138395712",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138395712"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 101,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138396884",
      "pull_request_review_id": 2913790240,
      "id": 2138396884,
      "node_id": "PRRC_kwDOABII585_dVjU",
      "diff_hunk": "@@ -72,6 +72,344 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 31,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "1c37a4e27a0496064e17fdad51f1a68ea2846b91",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "\r\n\r\nIn commit \"[unit test] basic TxOrphanageImpl eviction and protection\"\r\n\r\nStyle nit: not a (compile-time) constant, shouldn't be ALLCAPS.\r\n",
      "created_at": "2025-06-10T17:11:25Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138396884",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138396884"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 111,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138477486",
      "pull_request_review_id": 2913790240,
      "id": 2138477486,
      "node_id": "PRRC_kwDOABII585_dpOu",
      "diff_hunk": "@@ -72,6 +72,15 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+static bool ExactEqualTxns(const std::vector<CTransactionRef>& expected, const std::vector<CTransactionRef>& vec_txns)",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 4,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "62b7e67862847eed46967690622fe9699a4e13b8",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[unit test] strengthen GetChildrenFromSamePeer tests: results are in\"\r\n\r\nIsn't this just `expected == vec_txns` ?",
      "created_at": "2025-06-10T17:53:00Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138477486",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138477486"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 75,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138478924",
      "pull_request_review_id": 2913790240,
      "id": 2138478924,
      "node_id": "PRRC_kwDOABII585_dplM",
      "diff_hunk": "@@ -600,7 +617,7 @@ BOOST_AUTO_TEST_CASE(get_children)\n         BOOST_CHECK(orphanage->GetChildrenFromSamePeer(child_p1n0_p2n0, node2).empty());\n     }\n \n-    // Orphans provided by node1 and node2\n+",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 57,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "62b7e67862847eed46967690622fe9699a4e13b8",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[unit test] strengthen GetChildrenFromSamePeer tests: results are in\"\r\n\r\nComment accidentally removed? If not, unnecessary double newline?",
      "created_at": "2025-06-10T17:53:44Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138478924",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138478924"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 620,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138482911",
      "pull_request_review_id": 2913790240,
      "id": 2138482911,
      "node_id": "PRRC_kwDOABII585_dqjf",
      "diff_hunk": "@@ -228,3 +229,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 23,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd940478bb479490f081ce52c16f5419f5d84d99",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[fuzz] txorphanage_impl protection harness\"\r\n\r\nStyle nit: not a compile-time constant, shouldn't be ALLCAPS.",
      "created_at": "2025-06-10T17:55:35Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138482911",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138482911"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 243,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138513329",
      "pull_request_review_id": 2913790240,
      "id": 2138513329,
      "node_id": "PRRC_kwDOABII585_dx-x",
      "diff_hunk": "@@ -228,3 +229,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);\n+    // Generate a vector of bools for whether each peer is protected from eviction\n+    std::bitset<MAX_PEERS> protected_peers;\n+    for (unsigned int i = 0; i < NUM_PEERS; i++) {\n+        protected_peers.set(i, fuzzed_data_provider.ConsumeBool());\n+    }\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    auto orphanage = node::MakeTxOrphanage(global_announcement_limit, per_peer_weight_reservation);\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    // These are honest peer's live announcements. We expect them to be protected from eviction.\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 53,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd940478bb479490f081ce52c16f5419f5d84d99",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[fuzz] txorphanage_impl protection harness\"\r\n\r\nAny reason why such a high number (200000) is desirable? It would be extremely slow, and normal fuzz infrastructure won't even try it, as it limits seeds to 4096 bytes, and each iteration of this loop consumes at least 11 bytes if I counted correctly, so you can't even get above 400.\r\n\r\n",
      "created_at": "2025-06-10T18:13:20Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138513329",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138513329"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 273,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138525330",
      "pull_request_review_id": 2913790240,
      "id": 2138525330,
      "node_id": "PRRC_kwDOABII585_d06S",
      "diff_hunk": "@@ -228,3 +229,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);\n+    // Generate a vector of bools for whether each peer is protected from eviction\n+    std::bitset<MAX_PEERS> protected_peers;\n+    for (unsigned int i = 0; i < NUM_PEERS; i++) {\n+        protected_peers.set(i, fuzzed_data_provider.ConsumeBool());\n+    }\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    auto orphanage = node::MakeTxOrphanage(global_announcement_limit, per_peer_weight_reservation);\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    // These are honest peer's live announcements. We expect them to be protected from eviction.\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(0, 100000);\n+                if (payload_size) {\n+                    tx_mut.vout.emplace_back(0, CScript() << OP_RETURN << std::vector<unsigned char>(payload_size));\n+                } else {\n+                    tx_mut.vout.emplace_back(0, CScript{});\n+                }\n+            }\n+            auto new_tx = MakeTransactionRef(tx_mut);\n+            // add newly constructed outpoints to the coin pool\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                outpoints.emplace_back(new_tx->GetHash(), i);\n+            }\n+            return new_tx;\n+        }();\n+\n+        const auto wtxid{tx->GetWitnessHash()};\n+\n+        // orphanage functions\n+        LIMITED_WHILE(fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 89,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd940478bb479490f081ce52c16f5419f5d84d99",
      "in_reply_to_id": null,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "In commit \"[fuzz] txorphanage_impl protection harness\"\r\n\r\nI would use `LIMITED_WHILE(provider.remaining_bytes(), 10 * global_announcement_limit) {` here to avoiding consuming an extra byte per iteration (and also, why stop when you have more bytes left that could be used to tell you things to try)?",
      "created_at": "2025-06-10T18:20:09Z",
      "updated_at": "2025-06-10T18:22:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138525330",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138525330"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 309,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138534365",
      "pull_request_review_id": 2910938872,
      "id": 2138534365,
      "node_id": "PRRC_kwDOABII585_d3Hd",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();",
      "path": "src/node/txorphanage.cpp",
      "position": 196,
      "original_position": 241,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132873114,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "good change was about to suggest it. Could store `wtxid` and use it twice rather than project and grabbing it again later?",
      "created_at": "2025-06-10T18:25:56Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138534365",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138534365"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 196,
      "original_line": 196,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138563428",
      "pull_request_review_id": 2910938872,
      "id": 2138563428,
      "node_id": "PRRC_kwDOABII585_d-Nk",
      "diff_hunk": "@@ -8,68 +8,161 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 115,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "nit(?): is it more of an AnnouncementMap?\r\n\r\n",
      "created_at": "2025-06-10T18:45:01Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138563428",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138563428"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 83,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138569907",
      "pull_request_review_id": 2910938872,
      "id": 2138569907,
      "node_id": "PRRC_kwDOABII585_d_yz",
      "diff_hunk": "@@ -8,68 +8,161 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const Count m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const Usage m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    Count m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    Usage m_unique_orphan_bytes{0};",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 127,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c21466b83d725ab38e8b2b6c5b3e01815b300745\r\n\r\nit's not actually bytes; we we want to just refer to Usage() directly here",
      "created_at": "2025-06-10T18:49:27Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138569907",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138569907"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 95,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138571084",
      "pull_request_review_id": 2914729252,
      "id": 2138571084,
      "node_id": "PRRC_kwDOABII585_eAFM",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 545,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138070999,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "`MaxPeerAnnouncements()` is affected by the number of peers, since it's the global limit / num peers.\r\n\r\nHowever, I just realized this comment is also wrong because `m_peer_orphanage_info` size *can* change during the call. I think it's only possible when the per-peer reservation is below 400k, so we allow adding a tx, but immediately remove it because the peer is using \"too much\" space. Weird, but possible.",
      "created_at": "2025-06-10T18:49:54Z",
      "updated_at": "2025-06-10T18:49:54Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138571084",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138571084"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138586549",
      "pull_request_review_id": 2910938872,
      "id": 2138586549,
      "node_id": "PRRC_kwDOABII585_eD21",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 383,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "\"copying one that exists\" I assume means grabbing the CTransactionRef?",
      "created_at": "2025-06-10T18:59:49Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138586549",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138586549"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 307,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138596553",
      "pull_request_review_id": 2910938872,
      "id": 2138596553,
      "node_id": "PRRC_kwDOABII585_eGTJ",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);",
      "path": "src/node/txorphanage.cpp",
      "position": 334,
      "original_position": 442,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```Suggestion\r\n        Assume(it->m_tx.GetWitnessHash() == wtxid);\r\n        Erase<ByWtxid>(it++);\r\n```",
      "created_at": "2025-06-10T19:06:25Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138596553",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138596553"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 334,
      "original_line": 334,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138604490",
      "pull_request_review_id": 2910938872,
      "id": 2138604490,
      "node_id": "PRRC_kwDOABII585_eIPK",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 545,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138070999,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "It used to be correct back when as soon as a peer ever registered an orphan, the max would increase and it would be decreased on disconnect of peer. \r\n\r\nNow limits will dynamically shrink as peers are \"completely\" evicted.\r\n\r\nIt also means the heap is being \"invalidated\" as peers are completely evicted, if these limits are recalculated.",
      "created_at": "2025-06-10T19:11:30Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138604490",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138604490"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138610576",
      "pull_request_review_id": 2914792560,
      "id": 2138610576,
      "node_id": "PRRC_kwDOABII585_eJuQ",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 545,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138070999,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Oh, duh, it's the per-peer announcement reservation, not the global announcement limit. :man_facepalming:.\r\n\r\nBut I don't think it matters really that this is a constant. We'd be ok with using `global_announcement_limit / total_peers` as per-peer reservation, but we are - as a resource optimization on top - using `global_announcement_limit / peers_with_at_least_one_orphan` instead. Not updating the constant here when the last orphan of a peer disappears means using something in between temporarily. No big deal.\r\n\r\n",
      "created_at": "2025-06-10T19:15:50Z",
      "updated_at": "2025-06-10T19:15:50Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138610576",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138610576"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138610629",
      "pull_request_review_id": 2910938872,
      "id": 2138610629,
      "node_id": "PRRC_kwDOABII585_eJvF",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n+\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n+\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end()) return;\n+\n+    auto it_end = index_by_peer.lower_bound(ByPeerView{peer + 1, false, 0});\n+    unsigned int num_ann{0};\n+    while (it != it_end && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;",
      "path": "src/node/txorphanage.cpp",
      "position": 424,
      "original_position": 586,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "c21466b83d725ab38e8b2b6c5b3e01815b300745\r\n\r\nthis `dos_threshold` check does tie-breaker on \"size\", and probably should be `<=`? Not sure the former fact matters but bringing it up.",
      "created_at": "2025-06-10T19:15:52Z",
      "updated_at": "2025-06-10T19:44:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2138610629",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2138610629"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 424,
      "original_line": 424,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143568910",
      "pull_request_review_id": 2922512698,
      "id": 2143568910,
      "node_id": "PRRC_kwDOABII585_xEQO",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 15,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138025794,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Right, done",
      "created_at": "2025-06-12T20:05:01Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143568910",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143568910"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 22,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143568995",
      "pull_request_review_id": 2922512698,
      "id": 2143568995,
      "node_id": "PRRC_kwDOABII585_xERj",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 61,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138044941,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-12T20:05:05Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143568995",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143568995"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 36,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569132",
      "pull_request_review_id": 2922512698,
      "id": 2143569132,
      "node_id": "PRRC_kwDOABII585_xETs",
      "diff_hunk": "@@ -8,68 +8,161 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 115,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": 2138563428,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "renamed",
      "created_at": "2025-06-12T20:05:12Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143569132",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569132"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 83,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569324",
      "pull_request_review_id": 2922512698,
      "id": 2143569324,
      "node_id": "PRRC_kwDOABII585_xEWs",
      "diff_hunk": "@@ -8,68 +8,161 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const Count m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const Usage m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    Count m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    Usage m_unique_orphan_bytes{0};",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 127,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": 2138569907,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "reworded this comment to point to GetUsage",
      "created_at": "2025-06-12T20:05:20Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143569324",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569324"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 95,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569474",
      "pull_request_review_id": 2922512698,
      "id": 2143569474,
      "node_id": "PRRC_kwDOABII585_xEZC",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const Count m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const Usage m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    Count m_unique_orphans{0};\n \n-    /** Timestamp for the next scheduled sweep of expired orphans */\n-    NodeSeconds m_next_sweep{0s};\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    Usage m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerDoSInfo {\n+        Usage m_total_usage{0};\n+        Count m_count_announcements{0};\n+        bool operator==(const PeerDoSInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(Count max_peer_count, Usage max_peer_bytes) const\n+        {\n+            assert(max_peer_count > 0);\n+            assert(max_peer_bytes > 0);\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 174,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138115140,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "reworded",
      "created_at": "2025-06-12T20:05:28Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143569474",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569474"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 138,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569583",
      "pull_request_review_id": 2922512698,
      "id": 2143569583,
      "node_id": "PRRC_kwDOABII585_xEav",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 383,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": 2138586549,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "reworded",
      "created_at": "2025-06-12T20:05:35Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143569583",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569583"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 307,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569647",
      "pull_request_review_id": 2922512698,
      "id": 2143569647,
      "node_id": "PRRC_kwDOABII585_xEbv",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);",
      "path": "src/node/txorphanage.cpp",
      "position": 334,
      "original_position": 442,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": 2138596553,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-12T20:05:40Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143569647",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569647"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 334,
      "original_line": 334,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569919",
      "pull_request_review_id": 2922512698,
      "id": 2143569919,
      "node_id": "PRRC_kwDOABII585_xEf_",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 545,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138070999,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I don't think we ever did peer \"registration,\" we just briefly considered it and then left it for when/if we make outbound limits different from inbound limits?\r\n\r\nI reworded the comments in this function and kept the constants",
      "created_at": "2025-06-12T20:05:55Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143569919",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143569919"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 375,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143571427",
      "pull_request_review_id": 2922512698,
      "id": 2143571427,
      "node_id": "PRRC_kwDOABII585_xE3j",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 555,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138131119,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ah yeah! done.",
      "created_at": "2025-06-12T20:07:20Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143571427",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143571427"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 385,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143571635",
      "pull_request_review_id": 2922512698,
      "id": 2143571635,
      "node_id": "PRRC_kwDOABII585_xE6z",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 583,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138105074,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added a sentence to this comment",
      "created_at": "2025-06-12T20:07:30Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143571635",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143571635"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 412,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143572510",
      "pull_request_review_id": 2922512698,
      "id": 2143572510,
      "node_id": "PRRC_kwDOABII585_xFIe",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n+\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n+\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end()) return;\n+\n+    auto it_end = index_by_peer.lower_bound(ByPeerView{peer + 1, false, 0});\n+    unsigned int num_ann{0};\n+    while (it != it_end && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;",
      "path": "src/node/txorphanage.cpp",
      "position": 424,
      "original_position": 586,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": 2138610629,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Hm, I think we want this peer to become at least the second-DoSiest, right? So it should be `< dos_threshold`?",
      "created_at": "2025-06-12T20:08:18Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143572510",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143572510"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 424,
      "original_line": 424,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143572771",
      "pull_request_review_id": 2922512698,
      "id": 2143572771,
      "node_id": "PRRC_kwDOABII585_xFMj",
      "diff_hunk": "@@ -83,373 +183,492 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool unique)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (unique) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(wtxid));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(wtxid));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it++, /*unique=*/num_ann == 0);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*unique=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            // Decide what will happen next before the iter is invalidated.\n+            auto it_next = std::next(it_ann);\n+\n+            Erase<ByPeer>(it_ann, /*unique=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+            num_erased += 1;\n+            it_ann = it_next;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+        }\n+        // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+        // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+        // its orphans.\n+        if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+            heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+            std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        }\n+    } while (!heap_peer_dos.empty() && NeedsTrim());",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 608,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138149816,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "done",
      "created_at": "2025-06-12T20:08:32Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143572771",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143572771"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 433,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143573712",
      "pull_request_review_id": 2922512698,
      "id": 2143573712,
      "node_id": "PRRC_kwDOABII585_xFbQ",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        // Decide what will happen next before the iter is invalidated.\n+        const bool last_item{std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != wtxid};\n+        auto it_next = last_item ? index_by_wtxid.end() : std::next(it);\n+\n+        // Delete item. We only need to clean up m_outpoint_to_orphan_it the first time.\n+        Erase<ByWtxid>(it, /*cleanup_outpoints_map=*/num_erased == 0);\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    if (num_erased > 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_erased);\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n-    return 1;\n+\n+    return std::min<unsigned int>(1, num_erased);\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    unsigned int num_erased{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Decide what will happen next before the iter is invalidated.\n+        auto it_next = std::next(it);\n+\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it, /*cleanup_outpoints_map=*/IsUnique(it->m_tx->GetWitnessHash()));\n+\n+        // Advance pointer\n+        it = it_next;\n+        num_erased += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_erased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_erased, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n+    }\n+    auto compare_score = [](auto left, auto right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+        if (it_worst_peer != m_peer_orphanage_info.end()) {\n+            // Keep trimming until this peer is no longer the DoSiest one or has a score within 1.\n+            const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+            // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+            auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+            while (NeedsTrim()) {\n+                if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+                // Decide what will happen next before the iter is invalidated.\n+                auto it_next = std::next(it_ann);\n+\n+                Erase<ByPeer>(it_ann, /*cleanup_outpoints_map=*/IsUnique(it_ann->m_tx->GetWitnessHash()));\n+                num_erased += 1;\n+                it_ann = it_next;\n+\n+                // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+                it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+                if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+            }\n+            // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+            // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+            // its orphans.\n+            if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+                heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+                std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n             }\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n-    }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                const auto num_announcers{CountWtxid(wtxid)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+        m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+        return it->m_tx;\n     }\n     return nullptr;\n }\n \n+/** Return whether there is a tx that can be reconsidered. */\n bool TxOrphanageImpl::HaveTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return false;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    return !work_set.empty();\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n }\n-\n void TxOrphanageImpl::EraseForBlock(const CBlock& block)\n {\n-    std::vector<Wtxid> vOrphanErase;\n-\n+    std::set<Wtxid> wtxids_to_erase;\n     for (const CTransactionRef& ptx : block.vtx) {\n-        const CTransaction& tx = *ptx;\n+        const CTransaction& block_tx = *ptx;\n \n         // Which orphan pool entries must we evict?\n-        for (const auto& txin : tx.vin) {\n-            auto itByPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-            if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n-            for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n-                const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+        for (const auto& input : block_tx.vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                // Copy all wtxids to wtxids_to_erase.\n+                std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n             }\n         }\n     }\n \n-    // Erase orphan transactions included or precluded by this block\n-    if (vOrphanErase.size()) {\n-        int nErased = 0;\n-        for (const auto& orphanHash : vOrphanErase) {\n-            nErased += EraseTx(orphanHash);\n-        }\n-        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", nErased);\n+    unsigned int num_erased{0};\n+    for (const auto& wtxid : wtxids_to_erase) {\n+        num_erased += EraseTx(wtxid);\n     }\n+\n+    if (num_erased != 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n+    }\n+    Assume(wtxids_to_erase.size() == num_erased);\n }\n \n-std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const\n+/** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+ * recent to least recent. */\n+std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n {\n-    // First construct a vector of iterators to ensure we do not return duplicates of the same tx\n-    // and so we can sort by nTimeExpire.\n-    std::vector<OrphanMap::iterator> iters;\n-\n-    // For each output, get all entries spending this prevout, filtering for ones from the specified peer.\n-    for (unsigned int i = 0; i < parent->vout.size(); i++) {\n-        const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(parent->GetHash(), i));\n-        if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                if (elem->second.announcers.contains(nodeid)) {\n-                    iters.emplace_back(elem);\n+    std::vector<CTransactionRef> children_found;\n+    const auto& parent_txid{parent->GetHash()};\n+\n+    // Iterate through all orphans from this peer, in reverse order, so that more recent\n+    // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+    // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+    // not bias how we process other peer's orphans.\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+    auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+    if (it_upper != index_by_peer.begin()) {\n+        auto rit = std::make_reverse_iterator(it_upper);\n+        auto rit_end = std::make_reverse_iterator(it_lower);\n+        while (rit != rit_end) {\n+            if (rit->m_announcer != peer) continue;",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 823,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2136251223,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Yeah good point, and the fact that it never infinite loops is a sign this is never true. I took the `for` loop changes and made it `Assume(==peer)`.",
      "created_at": "2025-06-12T20:09:25Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143573712",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143573712"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 556,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143573925",
      "pull_request_review_id": 2922512698,
      "id": 2143573925,
      "node_id": "PRRC_kwDOABII585_xFel",
      "diff_hunk": "@@ -83,373 +176,491 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n-    }\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n-    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    auto it_next = std::next(it);\n+    if (it_next != index.end() && it_next->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+\n+    auto it_prev = std::prev(it);\n+    if (it != index.begin() && it_prev->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n     return true;\n }\n \n-bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n }\n \n-bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n         }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n     }\n+    return brand_new;\n+}\n+\n+bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n+}\n+\n+bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n+{\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n+\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n+\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end()) return;\n+\n+    auto it_end = index_by_peer.lower_bound(ByPeerView{peer + 1, false, 0});\n+    unsigned int num_ann{0};\n+    while (it != it_end && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+        }\n+        // Unless this peer is empty (which should never happen as long as per-peer reserved usage is at least as\n+        // large as the maximum allowed orphan size), put it back in the heap so we continue to consider evicting\n+        // its orphans.\n+        if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+            heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+            std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        }\n+    } while (!heap_peer_dos.empty() && NeedsTrim());\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+                const auto num_announcers{std::distance(it, it_end)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+        m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+        return it->m_tx;\n     }\n     return nullptr;\n }\n \n+/** Return whether there is a tx that can be reconsidered. */\n bool TxOrphanageImpl::HaveTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return false;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    return !work_set.empty();\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n }\n-\n void TxOrphanageImpl::EraseForBlock(const CBlock& block)\n {\n-    std::vector<Wtxid> vOrphanErase;\n-\n+    std::set<Wtxid> wtxids_to_erase;\n     for (const CTransactionRef& ptx : block.vtx) {\n-        const CTransaction& tx = *ptx;\n+        const CTransaction& block_tx = *ptx;\n \n         // Which orphan pool entries must we evict?\n-        for (const auto& txin : tx.vin) {\n-            auto itByPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-            if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n-            for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n-                const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+        for (const auto& input : block_tx.vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                // Copy all wtxids to wtxids_to_erase.\n+                std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n             }\n         }\n     }\n \n-    // Erase orphan transactions included or precluded by this block\n-    if (vOrphanErase.size()) {\n-        int nErased = 0;\n-        for (const auto& orphanHash : vOrphanErase) {\n-            nErased += EraseTx(orphanHash);\n-        }\n-        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", nErased);\n+    unsigned int num_erased{0};\n+    for (const auto& wtxid : wtxids_to_erase) {\n+        num_erased += EraseTx(wtxid);\n+    }\n+\n+    if (num_erased != 0) {\n+        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", num_erased);\n     }\n+    Assume(wtxids_to_erase.size() == num_erased);\n }\n \n-std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const\n+/** Get all children that spend from this tx and were received from nodeid. Sorted from most\n+ * recent to least recent. */\n+std::vector<CTransactionRef> TxOrphanageImpl::GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId peer) const\n {\n-    // First construct a vector of iterators to ensure we do not return duplicates of the same tx\n-    // and so we can sort by nTimeExpire.\n-    std::vector<OrphanMap::iterator> iters;\n-\n-    // For each output, get all entries spending this prevout, filtering for ones from the specified peer.\n-    for (unsigned int i = 0; i < parent->vout.size(); i++) {\n-        const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(parent->GetHash(), i));\n-        if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                if (elem->second.announcers.contains(nodeid)) {\n-                    iters.emplace_back(elem);\n+    std::vector<CTransactionRef> children_found;\n+    const auto& parent_txid{parent->GetHash()};\n+\n+    // Iterate through all orphans from this peer, in reverse order, so that more recent\n+    // transactions are added first. Doing so helps avoid work when one of the orphans replaced\n+    // an earlier one. Since we require the NodeId to match, one peer's announcement order does\n+    // not bias how we process other peer's orphans.\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it_upper = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<uint64_t>::max()});\n+    auto it_lower = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+\n+    if (it_upper != index_by_peer.begin()) {\n+        auto rit = std::make_reverse_iterator(it_upper);\n+        auto rit_end = std::make_reverse_iterator(it_lower);\n+        while (rit != rit_end) {\n+            if (rit->m_announcer != peer) continue;\n+            // Check if this tx spends from parent.\n+            for (const auto& input : rit->m_tx->vin) {\n+                if (input.prevout.hash == parent_txid) {\n+                    children_found.emplace_back(rit->m_tx);\n+                    break;\n                 }\n             }\n+            ++rit;\n         }\n     }\n-\n-    // Sort by address so that duplicates can be deleted. At the same time, sort so that more recent\n-    // orphans (which expire later) come first.  Break ties based on address, as nTimeExpire is\n-    // quantified in seconds and it is possible for orphans to have the same expiry.\n-    std::sort(iters.begin(), iters.end(), [](const auto& lhs, const auto& rhs) {\n-        if (lhs->second.nTimeExpire == rhs->second.nTimeExpire) {\n-            return &(*lhs) < &(*rhs);\n-        } else {\n-            return lhs->second.nTimeExpire > rhs->second.nTimeExpire;\n-        }\n-    });\n-    // Erase duplicates\n-    iters.erase(std::unique(iters.begin(), iters.end()), iters.end());\n-\n-    // Convert to a vector of CTransactionRef\n-    std::vector<CTransactionRef> children_found;\n-    children_found.reserve(iters.size());\n-    for (const auto& child_iter : iters) {\n-        children_found.emplace_back(child_iter->second.tx);\n-    }\n     return children_found;\n }\n \n std::vector<TxOrphanage::OrphanTxBase> TxOrphanageImpl::GetOrphanTransactions() const\n {\n-    std::vector<OrphanTxBase> ret;\n-    ret.reserve(m_orphans.size());\n-    for (auto const& o : m_orphans) {\n-        ret.push_back({o.second.tx, o.second.announcers});\n+    std::vector<TxOrphanage::OrphanTxBase> result;\n+    result.reserve(m_unique_orphans);\n+\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+    auto it = index_by_wtxid.begin();\n+    std::set<NodeId> this_orphan_announcers;\n+    while (it != index_by_wtxid.end()) {\n+        this_orphan_announcers.insert(it->m_announcer);\n+        // If this is the last entry, or the next entry has a different wtxid, build a OrphanTxBase.\n+        if (std::next(it) == index_by_wtxid.end() || std::next(it)->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash()) {\n+            result.emplace_back(TxOrphanage::OrphanTxBase{it->m_tx, this_orphan_announcers});",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 838,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd9be630e01140d911441866811eff6a9ed04bbd",
      "in_reply_to_id": 2138376457,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "taken",
      "created_at": "2025-06-12T20:09:36Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143573925",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143573925"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 582,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143574557",
      "pull_request_review_id": 2922512698,
      "id": 2143574557,
      "node_id": "PRRC_kwDOABII585_xFod",
      "diff_hunk": "@@ -72,6 +72,15 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+static bool ExactEqualTxns(const std::vector<CTransactionRef>& expected, const std::vector<CTransactionRef>& vec_txns)",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 4,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "62b7e67862847eed46967690622fe9699a4e13b8",
      "in_reply_to_id": 2138477486,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "yes, fixed",
      "created_at": "2025-06-12T20:10:08Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143574557",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143574557"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 75,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143574922",
      "pull_request_review_id": 2922512698,
      "id": 2143574922,
      "node_id": "PRRC_kwDOABII585_xFuK",
      "diff_hunk": "@@ -72,6 +72,344 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 18,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "1c37a4e27a0496064e17fdad51f1a68ea2846b91",
      "in_reply_to_id": 2138395335,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "renamed, now lowercase",
      "created_at": "2025-06-12T20:10:27Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143574922",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143574922"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 98,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143576536",
      "pull_request_review_id": 2922512698,
      "id": 2143576536,
      "node_id": "PRRC_kwDOABII585_xGHY",
      "diff_hunk": "@@ -72,6 +72,344 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 21,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "1c37a4e27a0496064e17fdad51f1a68ea2846b91",
      "in_reply_to_id": 2138395712,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "I turned it into a (magic) constant, I had it as a variable earlier just in case the implementation was going to change",
      "created_at": "2025-06-12T20:11:16Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143576536",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143576536"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 101,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143577082",
      "pull_request_review_id": 2922512698,
      "id": 2143577082,
      "node_id": "PRRC_kwDOABII585_xGP6",
      "diff_hunk": "@@ -72,6 +72,344 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use\n+    unsigned int NUM_TXNS_CREATED = 100;\n+    std::vector<CTransactionRef> TXNS;\n+    TXNS.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    int64_t TX_SIZE{0};\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        TXNS.emplace_back(ptx);\n+        if (TX_SIZE) {\n+            BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+        } else {\n+            TX_SIZE = GetTransactionWeight(*ptx);\n+        }\n+    }\n+    int64_t USAGE_TXNS_CREATED = NUM_TXNS_CREATED * TX_SIZE;",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 31,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "1c37a4e27a0496064e17fdad51f1a68ea2846b91",
      "in_reply_to_id": 2138396884,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "made it a compile-time constant",
      "created_at": "2025-06-12T20:11:27Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143577082",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143577082"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 111,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143577855",
      "pull_request_review_id": 2922512698,
      "id": 2143577855,
      "node_id": "PRRC_kwDOABII585_xGb_",
      "diff_hunk": "@@ -600,7 +617,7 @@ BOOST_AUTO_TEST_CASE(get_children)\n         BOOST_CHECK(orphanage->GetChildrenFromSamePeer(child_p1n0_p2n0, node2).empty());\n     }\n \n-    // Orphans provided by node1 and node2\n+",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 57,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "62b7e67862847eed46967690622fe9699a4e13b8",
      "in_reply_to_id": 2138478924,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "restored",
      "created_at": "2025-06-12T20:11:44Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143577855",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143577855"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 620,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143580800",
      "pull_request_review_id": 2922512698,
      "id": 2143580800,
      "node_id": "PRRC_kwDOABII585_xHKA",
      "diff_hunk": "@@ -207,29 +206,25 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n                         auto& tx_to_remove = PickValue(fuzzed_data_provider, tx_history);\n                         block.vtx.push_back(tx_to_remove);\n                     }\n-                    orphanage.EraseForBlock(block);\n+                    orphanage->EraseForBlock(block);\n                     for (const auto& tx_removed : block.vtx) {\n-                        Assert(!orphanage.HaveTx(tx_removed->GetWitnessHash()));\n-                        Assert(!orphanage.HaveTxFromPeer(tx_removed->GetWitnessHash(), peer_id));\n+                        Assert(!orphanage->HaveTx(tx_removed->GetWitnessHash()));\n+                        Assert(!orphanage->HaveTxFromPeer(tx_removed->GetWitnessHash(), peer_id));\n                     }\n                 },\n                 [&] {\n                     // test mocktime and expiry\n                     SetMockTime(ConsumeTime(fuzzed_data_provider));\n-                    orphanage.LimitOrphans(orphanage_rng);\n-                    Assert(orphanage.Size() <= node::DEFAULT_MAX_ORPHAN_TRANSACTIONS);\n+                    orphanage->LimitOrphans(orphanage_rng);\n+                    Assert(orphanage->Size() <= node::DEFAULT_MAX_ORPHAN_TRANSACTIONS);\n                 });\n-\n         }\n \n-        // Set tx as potential parent to be used for future GetChildren() calls.\n-        if (!ptx_potential_parent || fuzzed_data_provider.ConsumeBool()) {\n-            ptx_potential_parent = tx;\n-        }\n+        ptx_potential_parent = tx;",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 193,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "9afbf15b99508982b1a73bc416246ffbbce22d89",
      "in_reply_to_id": 2137961509,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "restored",
      "created_at": "2025-06-12T20:13:20Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143580800",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143580800"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 223,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143580972",
      "pull_request_review_id": 2922512698,
      "id": 2143580972,
      "node_id": "PRRC_kwDOABII585_xHMs",
      "diff_hunk": "@@ -228,3 +229,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 23,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd940478bb479490f081ce52c16f5419f5d84d99",
      "in_reply_to_id": 2138482911,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "lowercased",
      "created_at": "2025-06-12T20:13:28Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143580972",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143580972"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 243,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143581447",
      "pull_request_review_id": 2922512698,
      "id": 2143581447,
      "node_id": "PRRC_kwDOABII585_xHUH",
      "diff_hunk": "@@ -228,3 +229,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);\n+    // Generate a vector of bools for whether each peer is protected from eviction\n+    std::bitset<MAX_PEERS> protected_peers;\n+    for (unsigned int i = 0; i < NUM_PEERS; i++) {\n+        protected_peers.set(i, fuzzed_data_provider.ConsumeBool());\n+    }\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    auto orphanage = node::MakeTxOrphanage(global_announcement_limit, per_peer_weight_reservation);\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    // These are honest peer's live announcements. We expect them to be protected from eviction.\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(0, 100000);\n+                if (payload_size) {\n+                    tx_mut.vout.emplace_back(0, CScript() << OP_RETURN << std::vector<unsigned char>(payload_size));\n+                } else {\n+                    tx_mut.vout.emplace_back(0, CScript{});\n+                }\n+            }\n+            auto new_tx = MakeTransactionRef(tx_mut);\n+            // add newly constructed outpoints to the coin pool\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                outpoints.emplace_back(new_tx->GetHash(), i);\n+            }\n+            return new_tx;\n+        }();\n+\n+        const auto wtxid{tx->GetWitnessHash()};\n+\n+        // orphanage functions\n+        LIMITED_WHILE(fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 89,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd940478bb479490f081ce52c16f5419f5d84d99",
      "in_reply_to_id": 2138525330,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "taken",
      "created_at": "2025-06-12T20:13:54Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143581447",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143581447"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 309,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143583754",
      "pull_request_review_id": 2922512698,
      "id": 2143583754,
      "node_id": "PRRC_kwDOABII585_xH4K",
      "diff_hunk": "@@ -327,10 +327,10 @@ void TxOrphanage::SanityCheck() const\n     // Check that cached m_total_announcements is correct\n     unsigned int counted_total_announcements{0};\n     // Check that m_total_orphan_usage is correct\n-    unsigned int counted_total_usage{0};\n+    int64_t counted_total_usage{0};",
      "path": "src/txorphanage.cpp",
      "position": null,
      "original_position": 5,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "22d6cdd4f9dd6e03ad88946c130dad98fc45d7ad",
      "in_reply_to_id": 2137941928,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "we're doing some arithmetic :shrug:",
      "created_at": "2025-06-12T20:15:45Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143583754",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143583754"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 330,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143584002",
      "pull_request_review_id": 2922512698,
      "id": 2143584002,
      "node_id": "PRRC_kwDOABII585_xH8C",
      "diff_hunk": "@@ -228,3 +229,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have NUM_PEERS, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int NUM_PEERS = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);\n+    // Generate a vector of bools for whether each peer is protected from eviction\n+    std::bitset<MAX_PEERS> protected_peers;\n+    for (unsigned int i = 0; i < NUM_PEERS; i++) {\n+        protected_peers.set(i, fuzzed_data_provider.ConsumeBool());\n+    }\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(NUM_PEERS, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    auto orphanage = node::MakeTxOrphanage(global_announcement_limit, per_peer_weight_reservation);\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / NUM_PEERS;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(200'000);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    // These are honest peer's live announcements. We expect them to be protected from eviction.\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 200'000 && fuzzed_data_provider.ConsumeBool(), 10 * global_announcement_limit)",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": null,
      "original_position": 53,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "bd940478bb479490f081ce52c16f5419f5d84d99",
      "in_reply_to_id": 2138513329,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "No reason, changing to 400",
      "created_at": "2025-06-12T20:15:57Z",
      "updated_at": "2025-06-12T22:11:19Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2143584002",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2143584002"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 273,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2145171356",
      "pull_request_review_id": 2924953005,
      "id": 2145171356,
      "node_id": "PRRC_kwDOABII585_3Lec",
      "diff_hunk": "@@ -0,0 +1,672 @@\n+// Copyright (c) The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+#define BITCOIN_NODE_TXORPHANAGE_IMPL_H\n+\n+#include <coins.h>\n+#include <consensus/amount.h>\n+#include <indirectmap.h>\n+#include <logging.h>\n+#include <net.h>\n+#include <policy/policy.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/epochguard.h>\n+#include <util/hasher.h>\n+#include <util/result.h>\n+#include <util/feefrac.h>\n+\n+#include <boost/multi_index/hashed_index.hpp>\n+#include <boost/multi_index/identity.hpp>\n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/sequenced_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n+#include <atomic>\n+#include <map>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <string_view>\n+#include <utility>\n+#include <vector>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId min_peer{std::numeric_limits<NodeId>::min()};\n+\n+class TxOrphanageImpl\n+{\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n+\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n+\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        int64_t GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n+\n+    // Index by wtxid, then peer. Uses:\n+    // - Get a tx or query its existence, by wtxid.\n+    // - Erase all entries corresponding to an orphan by wtxid.\n+    // - Add a new announcer for a transaction, if we only know the wtxid and an entry already exists.\n+    // - AddChildrenToWorkSet: mark an orphan as reconsiderable when its parent is accepted\n+    // - GetOrphanTransactions: return the list of all unique transactions in orphanage.\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n+    {\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n+        }\n+    };\n+\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency. Uses:\n+    // - Erase all announcements from a peer when it disconnects.\n+    // - Look up whether a peer has orphans to reconsider or return the oldest reconsiderable orphan.\n+    // - Get the children of a transaction provided by a given peer.\n+    // - Evict an orphan from a peer whose DoS score is high.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const unsigned int m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const int64_t m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n+\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    unsigned int m_unique_orphans{0};\n+\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    unsigned int m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;",
      "path": "src/node/txorphanage_impl.h",
      "position": null,
      "original_position": 130,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "ea3a65e698f519afee23484ce1b399e9a4c62529",
      "in_reply_to_id": 2112731246,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Yep, tradeoff = either touch this `set` for every announcement added/removed, or do the extra lookup by `Wtxid`.",
      "created_at": "2025-06-13T14:02:10Z",
      "updated_at": "2025-06-13T14:02:11Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2145171356",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2145171356"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 108,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2146129331",
      "pull_request_review_id": 2926488501,
      "id": 2146129331,
      "node_id": "PRRC_kwDOABII585_61Wz",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132899931,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Aha fuzz crash reminded me what the problem was for `EraseForPeer`: if peer = `MAX_PEER` and there are only announcements from that peer, then `MAX_PEER + 1` wraps around, `it` and `it_end` both point to the first entry from that peer, and we don't end up erasing anything. Not really an issue in practice, but I reverted back to `while (it != index_by_peer.end() && it->m_announcer == peer)`.",
      "created_at": "2025-06-13T21:35:23Z",
      "updated_at": "2025-06-13T21:35:23Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2146129331",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2146129331"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2146134856",
      "pull_request_review_id": 2926499275,
      "id": 2146134856,
      "node_id": "PRRC_kwDOABII585_62tI",
      "diff_hunk": "@@ -8,68 +8,168 @@\n #include <logging.h>\n #include <policy/policy.h>\n #include <primitives/transaction.h>\n+#include <util/feefrac.h>\n #include <util/time.h>\n \n+#include <boost/multi_index/indexed_by.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+#include <boost/multi_index/tag.hpp>\n+#include <boost/multi_index_container.hpp>\n+\n #include <cassert>\n \n namespace node {\n+using Usage = int64_t;\n+using Count = unsigned int;\n \n class TxOrphanageImpl final : public TxOrphanage {\n-private:\n-    struct OrphanTx : public OrphanTxBase {\n-        NodeSeconds nTimeExpire;\n-        size_t list_pos;\n-    };\n+    // Type alias for sequence numbers\n+    using SequenceNumber = uint64_t;\n \n-    /** Total usage (weight) of all entries in m_orphans. */\n-    int64_t m_total_orphan_usage{0};\n-\n-    /** Total number of <peer, tx> pairs. Can be larger than m_orphans.size() because multiple peers\n-     * may have announced the same orphan. */\n-    unsigned int m_total_announcements{0};\n-\n-    /** Map from wtxid to orphan transaction record. Limited by\n-     *  DEFAULT_MAX_ORPHAN_TRANSACTIONS */\n-    std::map<Wtxid, OrphanTx> m_orphans;\n-\n-    struct PeerOrphanInfo {\n-        /** List of transactions that should be reconsidered: added to in AddChildrenToWorkSet,\n-         * removed from one-by-one with each call to GetTxToReconsider. The wtxids may refer to\n-         * transactions that are no longer present in orphanage; these are lazily removed in\n-         * GetTxToReconsider. */\n-        std::set<Wtxid> m_work_set;\n-\n-        /** Total weight of orphans for which this peer is an announcer.\n-         * If orphans are provided by different peers, its weight will be accounted for in each\n-         * PeerOrphanInfo, so the total of all peers' m_total_usage may be larger than\n-         * m_total_orphan_size. If a peer is removed as an announcer, even if the orphan still\n-         * remains in the orphanage, this number will be decremented. */\n-        int64_t m_total_usage{0};\n-    };\n-    std::map<NodeId, PeerOrphanInfo> m_peer_orphanage_info;\n+    /** Global sequence number, increment each time an announcement is added. */\n+    SequenceNumber m_current_sequence{0};\n \n-    using OrphanMap = decltype(m_orphans);\n+    /** One orphan announcement. Each announcement (i.e. combination of wtxid, nodeid) is unique. There may be multiple\n+     * announcements for the same tx, and multiple transactions with the same txid but different wtxid are possible. */\n+    struct Announcement\n+    {\n+        CTransactionRef m_tx;\n+        /** Which peer announced this tx */\n+        NodeId m_announcer;\n+        /** What order this transaction entered the orphanage. */\n+        SequenceNumber m_entry_sequence;\n+        /** Whether this tx should be reconsidered. Always starts out false. A peer's workset is the collection of all\n+         * announcements with m_reconsider=true. */\n+        bool m_reconsider{false};\n+\n+        Announcement(const CTransactionRef& tx, NodeId peer, SequenceNumber seq) :\n+            m_tx{tx}, m_announcer{peer}, m_entry_sequence{seq}\n+        { }\n+\n+        /** Get the weight of the transaction, our approximation for \"memory usage\". */\n+        Usage GetUsage()  const {\n+            return GetTransactionWeight(*m_tx);\n+        }\n+    };\n \n-    struct IteratorComparator\n+    // Index by wtxid, then peer\n+    struct ByWtxid {};\n+    using ByWtxidView = std::tuple<Wtxid, NodeId>;\n+    struct WtxidExtractor\n     {\n-        template<typename I>\n-        bool operator()(const I& a, const I& b) const\n+        using result_type = ByWtxidView;\n+        result_type operator()(const Announcement& ann) const\n         {\n-            return a->first < b->first;\n+            return ByWtxidView{ann.m_tx->GetWitnessHash(), ann.m_announcer};\n         }\n     };\n \n-    /** Index from the parents' COutPoint into the m_orphans. Used\n-     *  to remove orphan transactions from the m_orphans */\n-    std::map<COutPoint, std::set<OrphanMap::iterator, IteratorComparator>> m_outpoint_to_orphan_it;\n+    // Sort by peer, then by whether it is ready to reconsider, then by recency.\n+    struct ByPeer {};\n+    using ByPeerView = std::tuple<NodeId, bool, SequenceNumber>;\n+    struct ByPeerViewExtractor {\n+        using result_type = ByPeerView;\n+        result_type operator()(const Announcement& ann) const\n+        {\n+            return ByPeerView{ann.m_announcer, ann.m_reconsider, ann.m_entry_sequence};\n+        }\n+    };\n+\n+    struct OrphanIndices final : boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByWtxid>, WtxidExtractor>,\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>\n+    >{};\n+\n+    using OrphanMap = boost::multi_index::multi_index_container<Announcement, OrphanIndices>;\n+    template<typename Tag>\n+    using Iter = typename OrphanMap::index<Tag>::type::iterator;\n+    OrphanMap m_orphans;\n+\n+    const Count m_max_global_announcements{DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS};\n+    const Usage m_reserved_usage_per_peer{DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER};\n \n-    /** Orphan transactions in vector for quick random eviction */\n-    std::vector<OrphanMap::iterator> m_orphan_list;\n+    /** Number of unique orphans by wtxid. Less than or equal to the number of entries in m_orphans. */\n+    Count m_unique_orphans{0};\n \n-    /** Timestamp for the next scheduled sweep of expired orphans */\n-    NodeSeconds m_next_sweep{0s};\n+    /** Total bytes used by orphans, deduplicated by wtxid. */\n+    Usage m_unique_orphan_bytes{0};\n+\n+    /** Index from the parents' outputs to wtxids that exist in m_orphans. Used to find children of\n+     * a transaction that can be reconsidered and to remove entries that conflict with a block.*/\n+    std::map<COutPoint, std::set<Wtxid>> m_outpoint_to_orphan_it;\n+\n+    struct PeerDoSInfo {\n+        Usage m_total_usage{0};\n+        Count m_count_announcements{0};\n+        bool operator==(const PeerDoSInfo& other) const\n+        {\n+            return m_total_usage == other.m_total_usage &&\n+                   m_count_announcements == other.m_count_announcements;\n+        }\n+        void Add(const Announcement& ann)\n+        {\n+            m_total_usage += ann.GetUsage();\n+            m_count_announcements += 1;\n+        }\n+        bool Subtract(const Announcement& ann)\n+        {\n+            m_total_usage -= ann.GetUsage();\n+            m_count_announcements -= 1;\n+            return m_count_announcements == 0;\n+        }\n+        /** There are 2 DoS scores:\n+        * - CPU score (ratio of num announcements / max allowed announcements)\n+        * - Memory score (ratio of total usage / max allowed usage).\n+        *\n+        * If the peer is using more than the allowed for either resource, its DoS score is > 1.\n+        * A peer having a DoS score > 1 does not necessarily mean that something is wrong, since we\n+        * do not trim unless the orphanage exceeds global limits, but it means that this peer will\n+        * be selected for trimming sooner. If the global announcement or global memory usage\n+        * limits are exceeded, it must be that there is a peer whose DoS score > 1. */\n+        FeeFrac GetDosScore(Count max_peer_count, Usage max_peer_bytes) const\n+        {\n+            assert(max_peer_count > 0);\n+            assert(max_peer_bytes > 0);\n+            const FeeFrac cpu_score(m_count_announcements, max_peer_count);\n+            const FeeFrac mem_score(m_total_usage, max_peer_bytes);\n+            return std::max<FeeFrac>(cpu_score, mem_score);\n+        }\n+    };\n+    /** Store per-peer statistics. Used to determine each peer's DoS score. */\n+    std::unordered_map<NodeId, PeerDoSInfo> m_peer_orphanage_info;\n+\n+    /** Erase from m_orphans and update m_peer_orphanage_info.\n+     * If unique is true, removes this wtxid from the sets corresponding to each\n+     * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+     * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+     * growing. Set it to false when other announcements for the same tx exist.\n+     */\n+    template<typename Tag>\n+    void Erase(Iter<Tag> it, bool unique);\n+\n+    /** Check if there is exactly one transaction with this wtxid.",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 186,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a703a3086a6a3a6250fb97e799712443eaedf5d0",
      "in_reply_to_id": 2138082482,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "edited",
      "created_at": "2025-06-13T21:38:48Z",
      "updated_at": "2025-06-13T21:38:49Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2146134856",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2146134856"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 150,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2146136878",
      "pull_request_review_id": 2926503204,
      "id": 2146136878,
      "node_id": "PRRC_kwDOABII585_63Mu",
      "diff_hunk": "@@ -83,373 +174,530 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n+    int64_t TotalOrphanUsage() const override;\n     int64_t UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+/** Erase from m_orphans and update m_peer_orphanage_info.\n+ * If cleanup_outpoints_map is true, removes this wtxid from the sets corresponding to each\n+ * outpoint in m_outpoint_to_orphan_it. The caller must remember to set this to true when all\n+ * announcements for a transaction are erased, otherwise m_outpoint_to_orphan_it will keep\n+ * growing. Set it to false when other announcements for the same tx exist.\n+ */\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it, bool cleanup_outpoints_map)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (cleanup_outpoints_map) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n-        return false;\n+/** Check if this iterator points to a unique transaction by wtxid, assuming it is the first item with this wtxid.\n+ * Returns true if there are no more items with this wtxid after it.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    if (it == m_orphans.end()) return false;\n+    auto next = std::next(it);\n+    return (next == m_orphans.end() || next->m_tx->GetWitnessHash() != it->m_tx->GetWitnessHash());\n+}\n+\n+/** Check if there is exactly one transaction with this wtxid.\n+ * Returns true if there is exactly one transaction with this wtxid.\n+ * Returns false if there are zero or multiple transactions with this wtxid. */\n+bool TxOrphanageImpl::IsUnique(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+    return IsUnique(it);\n+}\n+\n+/** Return number of announcements with this wtxid. */\n+unsigned int TxOrphanageImpl::CountWtxid(const Wtxid& wtxid) const\n+{\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == m_orphans.end()) return 0;\n+\n+    unsigned int count{0};\n+    while (it != m_orphans.end() && it->m_tx->GetWitnessHash() == wtxid) {\n+        ++count;\n+        ++it;\n     }\n+    return count;\n+}\n+\n+int64_t TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+unsigned int TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+int64_t TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+unsigned int TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n+/** Number of orphans stored from this peer. */\n+unsigned int TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+int64_t TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    int64_t sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n+        return false;\n     }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(wtxid));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(CountWtxid(wtxid) > 1);\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(CountWtxid(wtxid) > 1);\n+    return true;\n }\n \n int TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return 0;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end()) return 0;\n+\n+    unsigned int num_erased{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != index_by_wtxid.end() && it->m_tx->GetWitnessHash() == wtxid) {",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 457,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "498f1c019197a8e4105490cdc4a0605594ca97d5",
      "in_reply_to_id": 2132899931,
      "user": {
        "login": "sipa",
        "id": 548488,
        "node_id": "MDQ6VXNlcjU0ODQ4OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/sipa",
        "html_url": "https://github.com/sipa",
        "followers_url": "https://api.github.com/users/sipa/followers",
        "following_url": "https://api.github.com/users/sipa/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/sipa/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/sipa/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
        "organizations_url": "https://api.github.com/users/sipa/orgs",
        "repos_url": "https://api.github.com/users/sipa/repos",
        "events_url": "https://api.github.com/users/sipa/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/sipa/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ha, ok.\r\n\r\nFWIW (but no need to change), you don't need a MAX_WTXID, because `ByPeerView` doesn't contain a wtxid:\r\n\r\n```c++\r\nauto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\r\nauto it_end = index_by_peer.upper_bound(ByPeerView{peer, true, std::numeric_limits<SequenceNumber>::max()});\r\n```\r\n\r\n",
      "created_at": "2025-06-13T21:39:41Z",
      "updated_at": "2025-06-13T21:39:42Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2146136878",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2146136878"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2154797287",
      "pull_request_review_id": 2939536398,
      "id": 2154797287,
      "node_id": "PRRC_kwDOABII586Ab5jn",
      "diff_hunk": "@@ -72,6 +72,11 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+static bool ExactEqualTxns(const std::vector<CTransactionRef>& expected, const std::vector<CTransactionRef>& vec_txns)",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 4,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "e83f2b0b00e3e78f28a8ea76bb1001a4cde0fe9d",
      "in_reply_to_id": null,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "this function is now completely superfluous? ",
      "created_at": "2025-06-18T14:42:13Z",
      "updated_at": "2025-06-18T15:23:37Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2154797287",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2154797287"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 75,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2154901919",
      "pull_request_review_id": 2939536398,
      "id": 2154901919,
      "node_id": "PRRC_kwDOABII586AcTGf",
      "diff_hunk": "@@ -83,373 +176,486 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    Usage TotalOrphanUsage() const override;\n+    Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying one that exists\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n-    }\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n+\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n+\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end()) return;\n+\n+    auto it_end = index_by_peer.lower_bound(ByPeerView{peer + 1, false, 0});\n+    unsigned int num_ann{0};\n+    while (it != it_end && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n-        }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // These numbers cannot change within a single call to LimitOrphans because the size of m_peer_orphanage_info\n+    // does not change unless a peer is removed.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This loop runs a maximum number of MaxGlobalAnnouncements() iterations.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // Find the peer with the highest DoS score, which is a fraction of {usage, announcements} used over the\n+        // respective allowances. This metric causes us to naturally select peers who have exceeded their limits\n+        // (i.e. a DoS score > 1) before peers who haven't, and the loop should halt before we ever select peers who\n+        // haven't. We may choose the same peer as the last iteration of this loop.\n+        // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator is\n+        // always lower, this means that a peer with only high number of announcements will be targeted before a\n+        // peer using a lot of memory, even if they have the same ratios.\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // Trim until this peer is no longer the DoSiest one or has a score within 1.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+\n+        // Evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;",
      "path": "src/node/txorphanage.cpp",
      "position": 424,
      "original_position": 586,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "c21466b83d725ab38e8b2b6c5b3e01815b300745",
      "in_reply_to_id": 2138610629,
      "user": {
        "login": "instagibbs",
        "id": 5767891,
        "node_id": "MDQ6VXNlcjU3Njc4OTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5767891?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/instagibbs",
        "html_url": "https://github.com/instagibbs",
        "followers_url": "https://api.github.com/users/instagibbs/followers",
        "following_url": "https://api.github.com/users/instagibbs/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/instagibbs/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/instagibbs/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/instagibbs/subscriptions",
        "organizations_url": "https://api.github.com/users/instagibbs/orgs",
        "repos_url": "https://api.github.com/users/instagibbs/repos",
        "events_url": "https://api.github.com/users/instagibbs/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/instagibbs/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Ok I'm confusing myself here, the denominator (\"size\") is constant for the entire evaluation of `LimitOrphans`, so tie-breaking is not going to happen. This behavior is fine.",
      "created_at": "2025-06-18T15:22:54Z",
      "updated_at": "2025-06-18T15:23:37Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2154901919",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2154901919"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 424,
      "original_line": 424,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2155976703",
      "pull_request_review_id": 2941377198,
      "id": 2155976703,
      "node_id": "PRRC_kwDOABII586AgZf_",
      "diff_hunk": "@@ -571,22 +576,30 @@ BOOST_AUTO_TEST_CASE(get_children)\n     // Spends the same outpoint as previous tx. Should still be returned; don't assume outpoints are unique.\n     auto child_p1n0_p2n0 = MakeTransactionSpending({{parent1->GetHash(), 0}, {parent2->GetHash(), 0}}, det_rand);\n \n+    const NodeId node0{0};\n     const NodeId node1{1};\n     const NodeId node2{2};\n+    const NodeId node3{3};\n \n     // All orphans provided by node1\n     {\n-        std::unique_ptr<node::TxOrphanage> orphanage{node::MakeTxOrphanage()};\n+        auto orphanage{node::MakeTxOrphanage()};\n         BOOST_CHECK(orphanage->AddTx(child_p1n0, node1));\n         BOOST_CHECK(orphanage->AddTx(child_p2n1, node1));\n         BOOST_CHECK(orphanage->AddTx(child_p1n0_p1n1, node1));\n         BOOST_CHECK(orphanage->AddTx(child_p1n0_p2n0, node1));\n \n-        std::set<CTransactionRef> expected_parent1_children{child_p1n0, child_p1n0_p2n0, child_p1n0_p1n1};\n-        std::set<CTransactionRef> expected_parent2_children{child_p2n1, child_p1n0_p2n0};\n+        BOOST_CHECK(!orphanage->AddTx(child_p1n0_p1n1, node0));\n+        BOOST_CHECK(!orphanage->AddTx(child_p2n1, node0));\n+        BOOST_CHECK(!orphanage->AddTx(child_p1n0, node3));",
      "path": "src/test/orphanage_tests.cpp",
      "position": 575,
      "original_position": 34,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "e83f2b0b00e3e78f28a8ea76bb1001a4cde0fe9d",
      "in_reply_to_id": null,
      "user": {
        "login": "monlovesmango",
        "id": 96307647,
        "node_id": "U_kgDOBb2Jvw",
        "avatar_url": "https://avatars.githubusercontent.com/u/96307647?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/monlovesmango",
        "html_url": "https://github.com/monlovesmango",
        "followers_url": "https://api.github.com/users/monlovesmango/followers",
        "following_url": "https://api.github.com/users/monlovesmango/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/monlovesmango/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/monlovesmango/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/monlovesmango/subscriptions",
        "organizations_url": "https://api.github.com/users/monlovesmango/orgs",
        "repos_url": "https://api.github.com/users/monlovesmango/repos",
        "events_url": "https://api.github.com/users/monlovesmango/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/monlovesmango/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```suggestion\r\n        BOOST_CHECK(!orphanage->AddTx(child_p1n0_p2n0, node3));\r\n```\r\nI think this is probably what was intended? Otherwise it is a duplicate line.",
      "created_at": "2025-06-19T03:08:27Z",
      "updated_at": "2025-06-19T04:37:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2155976703",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2155976703"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 582,
      "original_line": 582,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2156002563",
      "pull_request_review_id": 2941377198,
      "id": 2156002563,
      "node_id": "PRRC_kwDOABII586Agf0D",
      "diff_hunk": "@@ -233,3 +234,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have num_peers, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int num_peers = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);\n+    // Generate a vector of bools for whether each peer is protected from eviction\n+    std::bitset<MAX_PEERS> protected_peers;\n+    for (unsigned int i = 0; i < num_peers; i++) {\n+        protected_peers.set(i, fuzzed_data_provider.ConsumeBool());\n+    }\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(num_peers, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    auto orphanage = node::MakeTxOrphanage(global_announcement_limit, per_peer_weight_reservation);\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / num_peers;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(400);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    // These are honest peer's live announcements. We expect them to be protected from eviction.\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 400 && fuzzed_data_provider.ConsumeBool(), 1000)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(0, 100000);\n+                if (payload_size) {\n+                    tx_mut.vout.emplace_back(0, CScript() << OP_RETURN << std::vector<unsigned char>(payload_size));\n+                } else {\n+                    tx_mut.vout.emplace_back(0, CScript{});\n+                }\n+            }\n+            auto new_tx = MakeTransactionRef(tx_mut);\n+            // add newly constructed outpoints to the coin pool\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                outpoints.emplace_back(new_tx->GetHash(), i);\n+            }\n+            return new_tx;\n+        }();\n+\n+        const auto wtxid{tx->GetWitnessHash()};\n+\n+        // orphanage functions\n+        LIMITED_WHILE(fuzzed_data_provider.remaining_bytes(), 10 * global_announcement_limit)\n+        {\n+            NodeId peer_id = fuzzed_data_provider.ConsumeIntegralInRange<NodeId>(0, num_peers - 1);\n+            const auto tx_weight{GetTransactionWeight(*tx)};\n+\n+            // This protected peer will never send orphans that would\n+            // exceed their own personal allotment, so is never evicted.\n+            const bool peer_is_protected{protected_peers[peer_id]};\n+\n+            CallOneOf(\n+                fuzzed_data_provider,\n+                [&] { // AddTx\n+                    bool have_tx_and_peer = orphanage->HaveTxFromPeer(wtxid, peer_id);\n+                    if (peer_is_protected && !have_tx_and_peer &&\n+                        (orphanage->UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                        orphanage->AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                        // We never want our protected peer oversized or over-announced\n+                    } else {\n+                        orphanage->AddTx(tx, peer_id);\n+                        if (peer_is_protected && orphanage->HaveTxFromPeer(wtxid, peer_id)) {\n+                            protected_wtxids.insert(wtxid);\n+                        }\n+                    }\n+                },\n+                [&] { // AddAnnouncer\n+                    bool have_tx_and_peer = orphanage->HaveTxFromPeer(tx->GetWitnessHash(), peer_id);\n+                    // AddAnnouncer should return false if tx doesn't exist or we already HaveTxFromPeer.\n+                    {\n+                        if (peer_is_protected && !have_tx_and_peer &&\n+                            (orphanage->UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                            orphanage->AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                            // We never want our protected peer oversized\n+                        } else {\n+                            orphanage->AddAnnouncer(tx->GetWitnessHash(), peer_id);\n+                            if (peer_is_protected && orphanage->HaveTxFromPeer(wtxid, peer_id)) {\n+                                protected_wtxids.insert(wtxid);\n+                            }\n+                        }\n+                    }\n+                },\n+                [&] { // EraseTx\n+                    if (protected_wtxids.count(tx->GetWitnessHash())) {\n+                        protected_wtxids.erase(wtxid);\n+                    }\n+                    orphanage->EraseTx(wtxid);\n+                    Assert(!orphanage->HaveTx(wtxid));\n+                },\n+                [&] { // EraseForPeer\n+                    if (!protected_peers[peer_id]) {\n+                        orphanage->EraseForPeer(peer_id);",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 358,
      "original_position": 138,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "101c3f9299d776037c9c6a8d1326a9d1310b8911",
      "in_reply_to_id": null,
      "user": {
        "login": "monlovesmango",
        "id": 96307647,
        "node_id": "U_kgDOBb2Jvw",
        "avatar_url": "https://avatars.githubusercontent.com/u/96307647?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/monlovesmango",
        "html_url": "https://github.com/monlovesmango",
        "followers_url": "https://api.github.com/users/monlovesmango/followers",
        "following_url": "https://api.github.com/users/monlovesmango/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/monlovesmango/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/monlovesmango/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/monlovesmango/subscriptions",
        "organizations_url": "https://api.github.com/users/monlovesmango/orgs",
        "repos_url": "https://api.github.com/users/monlovesmango/repos",
        "events_url": "https://api.github.com/users/monlovesmango/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/monlovesmango/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Perhaps assert that `orphanage->AnnouncementsFromPeer(peer_id)` and `orphanage->UsageFromPeer(peer_id)` are both 0 here?",
      "created_at": "2025-06-19T03:24:28Z",
      "updated_at": "2025-06-19T04:37:26Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2156002563",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2156002563"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 362,
      "original_line": 362,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157096794",
      "pull_request_review_id": 2943147997,
      "id": 2157096794,
      "node_id": "PRRC_kwDOABII586Akq9a",
      "diff_hunk": "@@ -0,0 +1,154 @@\n+// Copyright (c) 2021-2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_H\n+#define BITCOIN_NODE_TXORPHANAGE_H\n+\n+#include <consensus/validation.h>\n+#include <net.h>\n+#include <primitives/block.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/time.h>\n+\n+#include <map>\n+#include <set>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId MIN_PEER{std::numeric_limits<NodeId>::min()};\n+/** Maximum NodeId for upper_bound lookups. */\n+static constexpr NodeId MAX_PEER{std::numeric_limits<NodeId>::max()};\n+\n+/** A class to track orphan transactions (failed on TX_MISSING_INPUTS)\n+ * Since we cannot distinguish orphans from bad transactions with non-existent inputs, we heavily limit the amount of\n+ * announcements (unique (NodeId, tx) pairs). We also try to prevent adversaries churning this data structure: when\n+ * global limits are reached, we continuously evict the oldest announcement (sorting non-reconsiderable orphans before\n+ * reconsiderable ones) from the most resource-intensive peer until we are back within limits.\n+ * - Peers can exceed their individual limits (e.g. because they are very useful transaction relay peers) as long as the\n+ *   global limits are not exceeded.\n+ * - As long as the orphan has 1 announcer, it remains in the orphanage.\n+ * - No peer can trigger the eviction of another peer's orphans.\n+ * - Peers' orphans are effectively protected from eviction as long as they don't exceed their limits.\n+ * Not thread-safe. Requires external synchronization.\n+ */\n+class TxOrphanage {\n+public:\n+    using Usage = int64_t;\n+    using Count = unsigned int;\n+\n+    /** Allows providing orphan information externally */\n+    struct OrphanTxBase {\n+        CTransactionRef tx;\n+        /** Peers added with AddTx or AddAnnouncer. */\n+        std::set<NodeId> announcers;\n+\n+        // Constructor with moved announcers\n+        OrphanTxBase(CTransactionRef tx, std::set<NodeId>&& announcers) :\n+            tx(std::move(tx)),\n+            announcers(std::move(announcers))\n+        {}\n+    };\n+\n+    virtual ~TxOrphanage() = default;\n+\n+    /** Add a new orphan transaction */\n+    virtual bool AddTx(const CTransactionRef& tx, NodeId peer) = 0;\n+\n+    /** Add an additional announcer to an orphan if it exists. Otherwise, do nothing. */\n+    virtual bool AddAnnouncer(const Wtxid& wtxid, NodeId peer) = 0;\n+\n+    /** Get a transaction by its witness txid */\n+    virtual CTransactionRef GetTx(const Wtxid& wtxid) const = 0;\n+\n+    /** Check if we already have an orphan transaction (by wtxid only) */\n+    virtual bool HaveTx(const Wtxid& wtxid) const = 0;\n+\n+    /** Check if a {tx, peer} exists in the orphanage.*/\n+    virtual bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const = 0;\n+\n+    /** Extract a transaction from a peer's work set, and flip it back to non-reconsiderable.\n+     *  Returns nullptr if there are no transactions to work on.\n+     *  Otherwise returns the transaction reference, and removes\n+     *  it from the work set.\n+     */\n+    virtual CTransactionRef GetTxToReconsider(NodeId peer) = 0;\n+\n+    /** Erase an orphan by wtxid, including all announcements if there are multiple.\n+     * Returns true if an orphan was erased, false if no tx with this wtxid exists. */\n+    virtual bool EraseTx(const Wtxid& wtxid) = 0;\n+\n+    /** Maybe erase all orphans announced by a peer (eg, after that peer disconnects). If an orphan\n+     * has been announced by another peer, don't erase, just remove this peer from the list of announcers. */\n+    virtual void EraseForPeer(NodeId peer) = 0;\n+\n+    /** Erase all orphans included in or invalidated by a new block */\n+    virtual void EraseForBlock(const CBlock& block) = 0;\n+\n+    /** Limit the orphanage to DEFAULT_MAX_ORPHAN_TRANSACTIONS. */",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 93,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "in_reply_to_id": null,
      "user": {
        "login": "jsarenik",
        "id": 244565,
        "node_id": "MDQ6VXNlcjI0NDU2NQ==",
        "avatar_url": "https://avatars.githubusercontent.com/u/244565?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jsarenik",
        "html_url": "https://github.com/jsarenik",
        "followers_url": "https://api.github.com/users/jsarenik/followers",
        "following_url": "https://api.github.com/users/jsarenik/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/jsarenik/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/jsarenik/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/jsarenik/subscriptions",
        "organizations_url": "https://api.github.com/users/jsarenik/orgs",
        "repos_url": "https://api.github.com/users/jsarenik/repos",
        "events_url": "https://api.github.com/users/jsarenik/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/jsarenik/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "This comment refers to `DEFAULT_MAX_ORPHAN_TRANSACTIONS` which is not used anymore in the rest of the code (all lines that contain this string are being removed, except this one which is being added)",
      "created_at": "2025-06-19T13:58:24Z",
      "updated_at": "2025-06-19T14:01:53Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2157096794",
      "author_association": "NONE",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157096794"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 93,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157759381",
      "pull_request_review_id": 2944177234,
      "id": 2157759381,
      "node_id": "PRRC_kwDOABII586AnMuV",
      "diff_hunk": "@@ -374,6 +389,174 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 51,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "in_reply_to_id": null,
      "user": {
        "login": "theStack",
        "id": 91535,
        "node_id": "MDQ6VXNlcjkxNTM1",
        "avatar_url": "https://avatars.githubusercontent.com/u/91535?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theStack",
        "html_url": "https://github.com/theStack",
        "followers_url": "https://api.github.com/users/theStack/followers",
        "following_url": "https://api.github.com/users/theStack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theStack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theStack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theStack/subscriptions",
        "organizations_url": "https://api.github.com/users/theStack/orgs",
        "repos_url": "https://api.github.com/users/theStack/repos",
        "events_url": "https://api.github.com/users/theStack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theStack/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "in commit d4b787b25f07b212bedb26433e64378673a27f6a:\r\n```suggestion\r\n        tx.wit.vtxinwit[0].scriptWitness.stack = [b'X' * 390000]\r\n```\r\nfor a significant orphan-tx creation speed-up (~30s vs ~30ms on my machine for the `large_orphans` list creation at the call-site)\r\n\r\ncould also move the orphan creation helpers to `mempool_util.py`, since the large one is defined in `p2p_orphan_handling.py` as well",
      "created_at": "2025-06-19T23:11:09Z",
      "updated_at": "2025-06-19T23:44:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2157759381",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157759381"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 398,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157767954",
      "pull_request_review_id": 2944177234,
      "id": 2157767954,
      "node_id": "PRRC_kwDOABII586AnO0S",
      "diff_hunk": "@@ -72,6 +72,341 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use. They must all be the same size.\n+    static constexpr unsigned int NUM_TXNS_CREATED = 100;\n+    static constexpr int64_t TX_SIZE{469};\n+    static constexpr int64_t TOTAL_SIZE = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    std::vector<CTransactionRef> txns;\n+    txns.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        txns.emplace_back(ptx);\n+        BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+    }\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        auto orphanage_low_ann = node::MakeTxOrphanage(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        auto orphanage_low_mem = node::MakeTxOrphanage(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE);\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_mem), 0);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_ann), 0);\n+\n+        // Add the first transaction\n+        orphanage_low_ann->AddTx(txns.at(0), peer);\n+        orphanage_low_mem->AddTx(txns.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann->AddTx(txns.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann->CountAnnouncements() > orphanage_low_ann->MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann->TotalOrphanUsage() <= orphanage_low_ann->MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann->NeedsTrim());\n+\n+        orphanage_low_mem->AddTx(txns.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem->CountAnnouncements() <= orphanage_low_mem->MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem->TotalOrphanUsage() > orphanage_low_mem->MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem->NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann->HaveTx(txns.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem->HaveTx(txns.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann->HaveTx(txns.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem->HaveTx(txns.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        auto orphanage = node::MakeTxOrphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage->AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage->AddTx(children.at(1), peer);\n+        orphanage->AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage->AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage->HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage->AddTx(children.at(3), peer);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(orphanage->HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage->AddTx(children.at(4), peer);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(orphanage->HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage->AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage->AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage->AddTx(children.at(5), peer);\n+        orphanage->AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage->GetTxToReconsider(peer), children.at(3));\n+        orphanage->AddTx(children.at(6), peer);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage->GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage->GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer_dosy{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        auto orphanage = node::MakeTxOrphanage(max_announcements, TOTAL_SIZE * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage->AddTx(txns.at(i), peer_dosy);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer_dosy), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1), 0);\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer2), 0);\n+\n+        // Add 10 unique transactions from peer1.\n+        // LimitOrphans should evict from peer_dosy, because that's the one exceeding announcement limits.\n+        unsigned int num_from_peer1 = 10;\n+        for (unsigned int i{0}; i < num_from_peer1; ++i) {\n+            orphanage->AddTx(txns.at(max_announcements + i), peer1);\n+            // The announcement limit per peer has halved, but LimitOrphans does not evict beyond what is necessary to\n+            // bring the total announcements within its global limit.\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+            BOOST_CHECK(orphanage->AnnouncementsFromPeer(peer_dosy) > orphanage->MaxPeerAnnouncements());\n+\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1), i + 1);\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer_dosy), max_announcements - i - 1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer_dosy is the one that was evicted.\n+            BOOST_CHECK(!orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+        // Add 10 transactions that are duplicates of the ones sent by peer_dosy. We need to add 10 because the first 10\n+        // were just evicted in the previous block additions.\n+        for (unsigned int i{num_from_peer1}; i < num_from_peer1 + 10; ++i) {\n+            // Tx has already been sent by peer_dosy\n+            BOOST_CHECK(orphanage->HaveTxFromPeer(txns.at(i)->GetWitnessHash(), peer_dosy));\n+            orphanage->AddTx(txns.at(i), peer2);\n+\n+            // Announcement limit is by entry, not by unique orphans\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+\n+            // peer_dosy is still the only one getting evicted\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer_dosy), max_announcements - i - 1);\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1), num_from_peer1);\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer2), i + 1 - num_from_peer1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer_dosy is the one that was evicted.\n+            BOOST_CHECK(!orphanage->HaveTxFromPeer(txns.at(i)->GetWitnessHash(), peer_dosy));\n+            BOOST_CHECK(orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+\n+        // With 6 peers, each can add 10, and still only peer_dosy's orphans are evicted.\n+        const unsigned int max_per_peer{max_announcements / 6};\n+        for (NodeId peer{3}; peer < 6; ++peer) {\n+            for (unsigned int i{0}; i < max_per_peer; ++i) {\n+                orphanage->AddTx(txns.at(peer * max_per_peer + i), peer);\n+                BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+            }\n+        }\n+        for (NodeId peer{0}; peer < 6; ++peer) {\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer), max_per_peer);\n+        }\n+    }\n+\n+    // One LimitOrphans call can evict announcements from multiple peers.\n+    {\n+        // Two peers, both of which send too many announcements.\n+        NodeId peer1_dosy{1};\n+        NodeId peer2_dosy{2};\n+        NodeId peer3_quiet{3};\n+        NodeId peer4_quiet{4};\n+\n+        auto orphanage = node::MakeTxOrphanage(/*max_global_ann=*/12, /*reserved_peer_usage=*/TX_SIZE * 100);\n+\n+        // peer3_quiet adds 1 announcement\n+        orphanage->AddTx(txns.at(20), peer3_quiet);\n+\n+        // Add 10 announcements from each peer. Normally, LimitOrphans would be\n+        // called after each AddTx, but we want to do eviction in one batch.\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            orphanage->AddTx(txns.at(2 * i), peer1_dosy);\n+            orphanage->AddTx(txns.at(2 * i + 1), peer2_dosy);\n+        }\n+\n+        // peer4_quiet adds 1 announcement\n+        orphanage->AddTx(txns.at(21), peer4_quiet);\n+\n+        BOOST_CHECK_EQUAL(orphanage->CountAnnouncements(), 22);\n+\n+        // LimitOrphans should evict from both peers equally, and not touch peer3_quiet or peer4_quiet.\n+        // The title of DoSiest peer alternates between peer1_dosy and peer2_dosy in the loop.\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 10);\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1_dosy), orphanage->AnnouncementsFromPeer(peer2_dosy));\n+\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            BOOST_CHECK(!orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+        for (unsigned int i{10}; i < 22; ++i) {\n+            BOOST_CHECK(orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+    }\n+\n+    // Limits change as more peers are added.\n+    {\n+        auto orphanage{node::MakeTxOrphanage()};\n+        // These stay the same regardless of number of peers\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+\n+        // These change with number of peers\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 1\n+        orphanage->AddTx(txns.at(0), 0);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 2\n+        orphanage->AddTx(txns.at(1), 1);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 2);\n+\n+        // Number of peers = 3\n+        orphanage->AddTx(txns.at(2), 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 3);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 3);\n+\n+        // Number of peers didn't change.\n+        orphanage->AddTx(txns.at(3), 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 3);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 3);\n+\n+        // Once a peer has no orphans, it is not considered in the limits.\n+        // Number of peers = 2\n+        orphanage->EraseForPeer(2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 2);\n+\n+        // Number of peers = 1\n+        orphanage->EraseTx(txns.at(0)->GetWitnessHash());\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+    }\n+\n+    // Test eviction of multiple transactions at a time\n+    {\n+        // Create a large transaction that is 10 times larger than the normal size transaction.\n+        CMutableTransaction tx_large;\n+        tx_large.vin.resize(10);\n+        tx_large.vout.resize(2);\n+        for (int i = 0; i < 10; i++) {\n+            tx_large.vin[i].prevout.n = i;\n+            tx_large.vin[i].prevout.hash = Txid::FromUint256(m_rng.rand256());\n+        }\n+        const auto size_diff = 10 * TX_SIZE - GetTransactionWeight(*MakeTransactionRef(tx_large));\n+        // Pad the last transaction until it is roughly 10 times larger than the normal size transaction.\n+        tx_large.vout.back().scriptPubKey = CScript() << OP_RETURN << std::vector<unsigned char>(size_diff / WITNESS_SCALE_FACTOR);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 309,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3e2985630cea8d59a6045e8a3451753130b18cab",
      "in_reply_to_id": null,
      "user": {
        "login": "theStack",
        "id": 91535,
        "node_id": "MDQ6VXNlcjkxNTM1",
        "avatar_url": "https://avatars.githubusercontent.com/u/91535?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theStack",
        "html_url": "https://github.com/theStack",
        "followers_url": "https://api.github.com/users/theStack/followers",
        "following_url": "https://api.github.com/users/theStack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theStack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theStack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theStack/subscriptions",
        "organizations_url": "https://api.github.com/users/theStack/orgs",
        "repos_url": "https://api.github.com/users/theStack/repos",
        "events_url": "https://api.github.com/users/theStack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theStack/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "in 3e2985630cea8d59a6045e8a3451753130b18cab: could use the `BulkTransaction` helper here\r\n```suggestion\r\n        tx_large.vin.resize(1);\r\n        BulkTransaction(tx_large, 10 * TX_SIZE);\r\n```",
      "created_at": "2025-06-19T23:15:37Z",
      "updated_at": "2025-06-19T23:44:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2157767954",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157767954"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": 372,
      "start_side": "RIGHT",
      "line": null,
      "original_line": 380,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157778964",
      "pull_request_review_id": 2944177234,
      "id": 2157778964,
      "node_id": "PRRC_kwDOABII586AnRgU",
      "diff_hunk": "@@ -83,373 +174,487 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    TxOrphanage::Usage TotalOrphanUsage() const override;\n+    TxOrphanage::Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+TxOrphanage::Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+TxOrphanage::Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+TxOrphanage::Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+TxOrphanage::Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+TxOrphanage::Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+TxOrphanage::Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    TxOrphanage::Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying the CTransactionRef from one that already exists.\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Assume(it->m_tx->GetWitnessHash() == wtxid);\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end() || it->m_announcer != peer) return;\n+\n+    unsigned int num_ann{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // Even though it's possible for MaxPeerAnnouncements to increase within this call to LimitOrphans\n+    // (e.g. if a peer's orphans are removed entirely, changing the number of peers), use consistent limits throughout.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        // Performance optimization: only consider peers with a DoS score >= 1.\n+        if (entry.GetDosScore(max_ann, max_mem) >= FeeFrac{1, 1}) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This outer loop finds the peer with the highest DoS score, which is a fraction of {usage, announcements} used\n+    // over the respective allowances. We continue until the orphanage is within global limits. That means some peers\n+    // might still have a DoS score > 1 at the end.\n+    // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator (number of\n+    // announcements) is always lower, this means that a peer with only high number of announcements will be targeted\n+    // before a peer using a lot of memory, even if they have the same ratios.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // This inner loop trims until this peer is no longer the DoSiest one or has a score within 1. The score 1 is\n+        // just a conservative fallback: once the last peer goes below ratio 1, NeedsTrim() will return false anyway.\n+        // We evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        // The number of inner loop iterations is bounded by the total number of announcements.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+        }\n+\n+        if (!NeedsTrim()) break;\n+\n+        // Unless this peer is empty, put it back in the heap so we continue to consider evicting its orphans.\n+        // We may select this peer for evictions again if there are multiple DoSy peers.\n+        if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+            heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+            std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        }\n+    } while (true);\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+                const auto num_announcers{std::distance(it, it_end)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+        m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+        return it->m_tx;\n     }\n     return nullptr;\n }\n \n+/** Return whether there is a tx that can be reconsidered. */\n bool TxOrphanageImpl::HaveTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return false;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    return !work_set.empty();\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n }\n-\n void TxOrphanageImpl::EraseForBlock(const CBlock& block)\n {\n-    std::vector<Wtxid> vOrphanErase;\n-\n+    std::set<Wtxid> wtxids_to_erase;\n     for (const CTransactionRef& ptx : block.vtx) {\n-        const CTransaction& tx = *ptx;\n+        const CTransaction& block_tx = *ptx;\n \n         // Which orphan pool entries must we evict?\n-        for (const auto& txin : tx.vin) {\n-            auto itByPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-            if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n-            for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n-                const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+        for (const auto& input : block_tx.vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                // Copy all wtxids to wtxids_to_erase.\n+                std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n             }\n         }\n     }\n \n-    // Erase orphan transactions included or precluded by this block\n-    if (vOrphanErase.size()) {\n-        int nErased = 0;\n-        for (const auto& orphanHash : vOrphanErase) {\n-            nErased += EraseTx(orphanHash);\n-        }\n-        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", nErased);\n+    unsigned int num_erased{0};\n+    for (const auto& wtxid : wtxids_to_erase) {\n+        num_erased += EraseTx(wtxid);",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 745,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a1bdebf370bf2fc43c0204ca2d6291e73fc7f91f",
      "in_reply_to_id": null,
      "user": {
        "login": "theStack",
        "id": 91535,
        "node_id": "MDQ6VXNlcjkxNTM1",
        "avatar_url": "https://avatars.githubusercontent.com/u/91535?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theStack",
        "html_url": "https://github.com/theStack",
        "followers_url": "https://api.github.com/users/theStack/followers",
        "following_url": "https://api.github.com/users/theStack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theStack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theStack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theStack/subscriptions",
        "organizations_url": "https://api.github.com/users/theStack/orgs",
        "repos_url": "https://api.github.com/users/theStack/repos",
        "events_url": "https://api.github.com/users/theStack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theStack/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "in a1bdebf370bf2fc43c0204ca2d6291e73fc7f91f: nit: since the previous commit 42e59cd5a4a119ba15991178f0438b4a7ffb5bab, this is now an implicit bool-to-int-cast\r\n```suggestion\r\n        num_erased += EraseTx(wtxid) ? 1 : 0;\r\n```\r\n(not sure how much we care about those, I guess there are countless other similar instances in the codebase; might be interesting to try https://clang.llvm.org/extra/clang-tidy/checks/readability/implicit-bool-conversion.html one day)",
      "created_at": "2025-06-19T23:31:00Z",
      "updated_at": "2025-06-19T23:44:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2157778964",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157778964"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 531,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157779831",
      "pull_request_review_id": 2944177234,
      "id": 2157779831,
      "node_id": "PRRC_kwDOABII586AnRt3",
      "diff_hunk": "@@ -16,31 +16,45 @@\n #include <set>\n \n namespace node {\n-/** Expiration time for orphan transactions */\n-static constexpr auto ORPHAN_TX_EXPIRE_TIME{20min};\n-/** Minimum time between orphan transactions expire time checks */\n-static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId MIN_PEER{std::numeric_limits<NodeId>::min()};\n+/** Maximum NodeId for upper_bound lookups. */\n+static constexpr NodeId MAX_PEER{std::numeric_limits<NodeId>::max()};\n /** Default maximum number of orphan transactions kept in memory */\n static const uint32_t DEFAULT_MAX_ORPHAN_TRANSACTIONS{100};\n \n /** A class to track orphan transactions (failed on TX_MISSING_INPUTS)\n- * Since we cannot distinguish orphans from bad transactions with\n- * non-existent inputs, we heavily limit the number of orphans\n- * we keep and the duration we keep them for.\n+ * Since we cannot distinguish orphans from bad transactions with non-existent inputs, we heavily limit the amount of\n+ * announcements (unique (NodeId, tx) pairs). We also try to prevent adversaries churning this data structure: when",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 24,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a1bdebf370bf2fc43c0204ca2d6291e73fc7f91f",
      "in_reply_to_id": null,
      "user": {
        "login": "theStack",
        "id": 91535,
        "node_id": "MDQ6VXNlcjkxNTM1",
        "avatar_url": "https://avatars.githubusercontent.com/u/91535?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/theStack",
        "html_url": "https://github.com/theStack",
        "followers_url": "https://api.github.com/users/theStack/followers",
        "following_url": "https://api.github.com/users/theStack/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/theStack/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/theStack/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/theStack/subscriptions",
        "organizations_url": "https://api.github.com/users/theStack/orgs",
        "repos_url": "https://api.github.com/users/theStack/repos",
        "events_url": "https://api.github.com/users/theStack/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/theStack/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "```suggestion\r\n * announcements (unique (NodeId, wtxid) pairs). We also try to prevent adversaries churning this data structure: when\r\n```",
      "created_at": "2025-06-19T23:31:46Z",
      "updated_at": "2025-06-19T23:44:39Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2157779831",
      "author_association": "CONTRIBUTOR",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2157779831"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 32,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162321964",
      "pull_request_review_id": 2951201583,
      "id": 2162321964,
      "node_id": "PRRC_kwDOABII586A4mos",
      "diff_hunk": "@@ -72,6 +72,11 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+static bool ExactEqualTxns(const std::vector<CTransactionRef>& expected, const std::vector<CTransactionRef>& vec_txns)",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 4,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "e83f2b0b00e3e78f28a8ea76bb1001a4cde0fe9d",
      "in_reply_to_id": 2154797287,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Replaced it with `==`s",
      "created_at": "2025-06-23T18:45:12Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162321964",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162321964"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 75,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162323981",
      "pull_request_review_id": 2951201583,
      "id": 2162323981,
      "node_id": "PRRC_kwDOABII586A4nIN",
      "diff_hunk": "@@ -72,6 +72,341 @@ static bool EqualTxns(const std::set<CTransactionRef>& set_txns, const std::vect\n     return true;\n }\n \n+unsigned int CheckNumEvictions(node::TxOrphanage& orphanage)\n+{\n+    const auto original_total_count{orphanage.CountAnnouncements()};\n+    orphanage.LimitOrphans();\n+    assert(!orphanage.NeedsTrim());\n+    return original_total_count - orphanage.CountAnnouncements();\n+}\n+\n+BOOST_AUTO_TEST_CASE(peer_dos_limits)\n+{\n+    FastRandomContext det_rand{true};\n+\n+    // Construct transactions to use. They must all be the same size.\n+    static constexpr unsigned int NUM_TXNS_CREATED = 100;\n+    static constexpr int64_t TX_SIZE{469};\n+    static constexpr int64_t TOTAL_SIZE = NUM_TXNS_CREATED * TX_SIZE;\n+\n+    std::vector<CTransactionRef> txns;\n+    txns.reserve(NUM_TXNS_CREATED);\n+    // All transactions are the same size.\n+    for (unsigned int i{0}; i < NUM_TXNS_CREATED; ++i) {\n+        auto ptx = MakeTransactionSpending({}, det_rand);\n+        txns.emplace_back(ptx);\n+        BOOST_CHECK_EQUAL(TX_SIZE, GetTransactionWeight(*ptx));\n+    }\n+\n+    // Single peer: eviction is triggered if either limit is hit\n+    {\n+        // Test announcement limits\n+        NodeId peer{8};\n+        auto orphanage_low_ann = node::MakeTxOrphanage(/*max_global_ann=*/1, /*reserved_peer_usage=*/TX_SIZE * 10);\n+        auto orphanage_low_mem = node::MakeTxOrphanage(/*max_global_ann=*/10, /*reserved_peer_usage=*/TX_SIZE);\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_mem), 0);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_ann), 0);\n+\n+        // Add the first transaction\n+        orphanage_low_ann->AddTx(txns.at(0), peer);\n+        orphanage_low_mem->AddTx(txns.at(0), peer);\n+\n+        // Add more. One of the limits is exceeded, so LimitOrphans evicts 1.\n+        orphanage_low_ann->AddTx(txns.at(1), peer);\n+        BOOST_CHECK(orphanage_low_ann->CountAnnouncements() > orphanage_low_ann->MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_ann->TotalOrphanUsage() <= orphanage_low_ann->MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_ann->NeedsTrim());\n+\n+        orphanage_low_mem->AddTx(txns.at(1), peer);\n+        BOOST_CHECK(orphanage_low_mem->CountAnnouncements() <= orphanage_low_mem->MaxGlobalAnnouncements());\n+        BOOST_CHECK(orphanage_low_mem->TotalOrphanUsage() > orphanage_low_mem->MaxGlobalUsage());\n+        BOOST_CHECK(orphanage_low_mem->NeedsTrim());\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_mem), 1);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage_low_ann), 1);\n+\n+        // The older transaction is evicted.\n+        BOOST_CHECK(!orphanage_low_ann->HaveTx(txns.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage_low_mem->HaveTx(txns.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_ann->HaveTx(txns.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage_low_mem->HaveTx(txns.at(1)->GetWitnessHash()));\n+    }\n+\n+    // Single peer: eviction order is FIFO on non-reconsiderable, then reconsiderable orphans.\n+    {\n+        // Construct parent + child pairs\n+        std::vector<CTransactionRef> parents;\n+        std::vector<CTransactionRef> children;\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            CTransactionRef parent = MakeTransactionSpending({}, det_rand);\n+            CTransactionRef child = MakeTransactionSpending({{parent->GetHash(), 0}}, det_rand);\n+            parents.emplace_back(parent);\n+            children.emplace_back(child);\n+        }\n+\n+        // Test announcement limits\n+        NodeId peer{9};\n+        auto orphanage = node::MakeTxOrphanage(/*max_global_ann=*/3, /*reserved_peer_usage=*/TX_SIZE * 10);\n+\n+        // First add a tx which will be made reconsiderable.\n+        orphanage->AddTx(children.at(0), peer);\n+\n+        // Then add 2 more orphans... not oversize yet.\n+        orphanage->AddTx(children.at(1), peer);\n+        orphanage->AddTx(children.at(2), peer);\n+\n+        // Make child0 ready to reconsider\n+        orphanage->AddChildrenToWorkSet(*parents.at(0), det_rand);\n+        BOOST_CHECK(orphanage->HaveTxToReconsider(peer));\n+\n+        // Add 1 more orphan, causing the orphanage to be oversize. child1 is evicted.\n+        orphanage->AddTx(children.at(3), peer);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(orphanage->HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(1)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+\n+        // Add 1 more... child2 is evicted.\n+        orphanage->AddTx(children.at(4), peer);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(orphanage->HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(2)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(4)->GetWitnessHash()));\n+\n+        // Eviction order is FIFO within the orphans that are ready to be reconsidered.\n+        orphanage->AddChildrenToWorkSet(*parents.at(4), det_rand);\n+        orphanage->AddChildrenToWorkSet(*parents.at(3), det_rand);\n+\n+        orphanage->AddTx(children.at(5), peer);\n+        orphanage->AddChildrenToWorkSet(*parents.at(5), det_rand);\n+\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(0)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(5)->GetWitnessHash()));\n+\n+        // The first transaction returned from GetTxToReconsider is the older one, not the one that was marked for\n+        // reconsideration earlier.\n+        // Transactions are marked non-reconsiderable again when returned through GetTxToReconsider\n+        BOOST_CHECK_EQUAL(orphanage->GetTxToReconsider(peer), children.at(3));\n+        orphanage->AddTx(children.at(6), peer);\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+        BOOST_CHECK(!orphanage->HaveTx(children.at(3)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(4)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(5)->GetWitnessHash()));\n+        BOOST_CHECK(orphanage->HaveTx(children.at(6)->GetWitnessHash()));\n+\n+        BOOST_CHECK_EQUAL(orphanage->GetTxToReconsider(peer), children.at(4));\n+        BOOST_CHECK_EQUAL(orphanage->GetTxToReconsider(peer), children.at(5));\n+    }\n+\n+    // Multiple peers: when limit is exceeded, we choose the DoSiest peer and evict their oldest transaction.\n+    {\n+        NodeId peer_dosy{0};\n+        NodeId peer1{1};\n+        NodeId peer2{2};\n+\n+        unsigned int max_announcements = 60;\n+        // Set a high per-peer reservation so announcement limit is always hit first.\n+        auto orphanage = node::MakeTxOrphanage(max_announcements, TOTAL_SIZE * 10);\n+\n+        // No evictions happen before the global limit is reached.\n+        for (unsigned int i{0}; i < max_announcements; ++i) {\n+            orphanage->AddTx(txns.at(i), peer_dosy);\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 0);\n+        }\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer_dosy), max_announcements);\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1), 0);\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer2), 0);\n+\n+        // Add 10 unique transactions from peer1.\n+        // LimitOrphans should evict from peer_dosy, because that's the one exceeding announcement limits.\n+        unsigned int num_from_peer1 = 10;\n+        for (unsigned int i{0}; i < num_from_peer1; ++i) {\n+            orphanage->AddTx(txns.at(max_announcements + i), peer1);\n+            // The announcement limit per peer has halved, but LimitOrphans does not evict beyond what is necessary to\n+            // bring the total announcements within its global limit.\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+            BOOST_CHECK(orphanage->AnnouncementsFromPeer(peer_dosy) > orphanage->MaxPeerAnnouncements());\n+\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1), i + 1);\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer_dosy), max_announcements - i - 1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer_dosy is the one that was evicted.\n+            BOOST_CHECK(!orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+        // Add 10 transactions that are duplicates of the ones sent by peer_dosy. We need to add 10 because the first 10\n+        // were just evicted in the previous block additions.\n+        for (unsigned int i{num_from_peer1}; i < num_from_peer1 + 10; ++i) {\n+            // Tx has already been sent by peer_dosy\n+            BOOST_CHECK(orphanage->HaveTxFromPeer(txns.at(i)->GetWitnessHash(), peer_dosy));\n+            orphanage->AddTx(txns.at(i), peer2);\n+\n+            // Announcement limit is by entry, not by unique orphans\n+            BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+\n+            // peer_dosy is still the only one getting evicted\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer_dosy), max_announcements - i - 1);\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1), num_from_peer1);\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer2), i + 1 - num_from_peer1);\n+\n+            // Evictions are FIFO within a peer, so the ith transaction sent by peer_dosy is the one that was evicted.\n+            BOOST_CHECK(!orphanage->HaveTxFromPeer(txns.at(i)->GetWitnessHash(), peer_dosy));\n+            BOOST_CHECK(orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+\n+        // With 6 peers, each can add 10, and still only peer_dosy's orphans are evicted.\n+        const unsigned int max_per_peer{max_announcements / 6};\n+        for (NodeId peer{3}; peer < 6; ++peer) {\n+            for (unsigned int i{0}; i < max_per_peer; ++i) {\n+                orphanage->AddTx(txns.at(peer * max_per_peer + i), peer);\n+                BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 1);\n+            }\n+        }\n+        for (NodeId peer{0}; peer < 6; ++peer) {\n+            BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer), max_per_peer);\n+        }\n+    }\n+\n+    // One LimitOrphans call can evict announcements from multiple peers.\n+    {\n+        // Two peers, both of which send too many announcements.\n+        NodeId peer1_dosy{1};\n+        NodeId peer2_dosy{2};\n+        NodeId peer3_quiet{3};\n+        NodeId peer4_quiet{4};\n+\n+        auto orphanage = node::MakeTxOrphanage(/*max_global_ann=*/12, /*reserved_peer_usage=*/TX_SIZE * 100);\n+\n+        // peer3_quiet adds 1 announcement\n+        orphanage->AddTx(txns.at(20), peer3_quiet);\n+\n+        // Add 10 announcements from each peer. Normally, LimitOrphans would be\n+        // called after each AddTx, but we want to do eviction in one batch.\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            orphanage->AddTx(txns.at(2 * i), peer1_dosy);\n+            orphanage->AddTx(txns.at(2 * i + 1), peer2_dosy);\n+        }\n+\n+        // peer4_quiet adds 1 announcement\n+        orphanage->AddTx(txns.at(21), peer4_quiet);\n+\n+        BOOST_CHECK_EQUAL(orphanage->CountAnnouncements(), 22);\n+\n+        // LimitOrphans should evict from both peers equally, and not touch peer3_quiet or peer4_quiet.\n+        // The title of DoSiest peer alternates between peer1_dosy and peer2_dosy in the loop.\n+        BOOST_CHECK_EQUAL(CheckNumEvictions(*orphanage), 10);\n+        BOOST_CHECK_EQUAL(orphanage->AnnouncementsFromPeer(peer1_dosy), orphanage->AnnouncementsFromPeer(peer2_dosy));\n+\n+        for (unsigned int i{0}; i < 10; ++i) {\n+            BOOST_CHECK(!orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+        for (unsigned int i{10}; i < 22; ++i) {\n+            BOOST_CHECK(orphanage->HaveTx(txns.at(i)->GetWitnessHash()));\n+        }\n+    }\n+\n+    // Limits change as more peers are added.\n+    {\n+        auto orphanage{node::MakeTxOrphanage()};\n+        // These stay the same regardless of number of peers\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+\n+        // These change with number of peers\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 1\n+        orphanage->AddTx(txns.at(0), 0);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+\n+        // Number of peers = 2\n+        orphanage->AddTx(txns.at(1), 1);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 2);\n+\n+        // Number of peers = 3\n+        orphanage->AddTx(txns.at(2), 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 3);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 3);\n+\n+        // Number of peers didn't change.\n+        orphanage->AddTx(txns.at(3), 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 3);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 3);\n+\n+        // Once a peer has no orphans, it is not considered in the limits.\n+        // Number of peers = 2\n+        orphanage->EraseForPeer(2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER * 2);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS / 2);\n+\n+        // Number of peers = 1\n+        orphanage->EraseTx(txns.at(0)->GetWitnessHash());\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+        BOOST_CHECK_EQUAL(orphanage->ReservedPeerUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxGlobalUsage(), node::DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER);\n+        BOOST_CHECK_EQUAL(orphanage->MaxPeerAnnouncements(), node::DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS);\n+    }\n+\n+    // Test eviction of multiple transactions at a time\n+    {\n+        // Create a large transaction that is 10 times larger than the normal size transaction.\n+        CMutableTransaction tx_large;\n+        tx_large.vin.resize(10);\n+        tx_large.vout.resize(2);\n+        for (int i = 0; i < 10; i++) {\n+            tx_large.vin[i].prevout.n = i;\n+            tx_large.vin[i].prevout.hash = Txid::FromUint256(m_rng.rand256());\n+        }\n+        const auto size_diff = 10 * TX_SIZE - GetTransactionWeight(*MakeTransactionRef(tx_large));\n+        // Pad the last transaction until it is roughly 10 times larger than the normal size transaction.\n+        tx_large.vout.back().scriptPubKey = CScript() << OP_RETURN << std::vector<unsigned char>(size_diff / WITNESS_SCALE_FACTOR);",
      "path": "src/test/orphanage_tests.cpp",
      "position": null,
      "original_position": 309,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "3e2985630cea8d59a6045e8a3451753130b18cab",
      "in_reply_to_id": 2157767954,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Nice! Used this instead",
      "created_at": "2025-06-23T18:46:35Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162323981",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162323981"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": 372,
      "start_side": "RIGHT",
      "line": null,
      "original_line": 380,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162324172",
      "pull_request_review_id": 2951201583,
      "id": 2162324172,
      "node_id": "PRRC_kwDOABII586A4nLM",
      "diff_hunk": "@@ -571,22 +576,30 @@ BOOST_AUTO_TEST_CASE(get_children)\n     // Spends the same outpoint as previous tx. Should still be returned; don't assume outpoints are unique.\n     auto child_p1n0_p2n0 = MakeTransactionSpending({{parent1->GetHash(), 0}, {parent2->GetHash(), 0}}, det_rand);\n \n+    const NodeId node0{0};\n     const NodeId node1{1};\n     const NodeId node2{2};\n+    const NodeId node3{3};\n \n     // All orphans provided by node1\n     {\n-        std::unique_ptr<node::TxOrphanage> orphanage{node::MakeTxOrphanage()};\n+        auto orphanage{node::MakeTxOrphanage()};\n         BOOST_CHECK(orphanage->AddTx(child_p1n0, node1));\n         BOOST_CHECK(orphanage->AddTx(child_p2n1, node1));\n         BOOST_CHECK(orphanage->AddTx(child_p1n0_p1n1, node1));\n         BOOST_CHECK(orphanage->AddTx(child_p1n0_p2n0, node1));\n \n-        std::set<CTransactionRef> expected_parent1_children{child_p1n0, child_p1n0_p2n0, child_p1n0_p1n1};\n-        std::set<CTransactionRef> expected_parent2_children{child_p2n1, child_p1n0_p2n0};\n+        BOOST_CHECK(!orphanage->AddTx(child_p1n0_p1n1, node0));\n+        BOOST_CHECK(!orphanage->AddTx(child_p2n1, node0));\n+        BOOST_CHECK(!orphanage->AddTx(child_p1n0, node3));",
      "path": "src/test/orphanage_tests.cpp",
      "position": 575,
      "original_position": 34,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "e83f2b0b00e3e78f28a8ea76bb1001a4cde0fe9d",
      "in_reply_to_id": 2155976703,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "removed",
      "created_at": "2025-06-23T18:46:42Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162324172",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162324172"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 582,
      "original_line": 582,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162324644",
      "pull_request_review_id": 2951201583,
      "id": 2162324644,
      "node_id": "PRRC_kwDOABII586A4nSk",
      "diff_hunk": "@@ -374,6 +389,174 @@ def test_other_parent_in_mempool(self):\n         result_missing_parent = node.submitpackage(package_hex_missing_parent)\n         assert_equal(result_missing_parent[\"package_msg\"], \"package-not-child-with-unconfirmed-parents\")\n \n+    def create_large_orphan(self):\n+        \"\"\"Create huge orphan transaction\"\"\"\n+        tx = CTransaction()\n+        # Nonexistent UTXO\n+        tx.vin = [CTxIn(COutPoint(random.randrange(1 << 256), random.randrange(1, 100)))]\n+        tx.wit.vtxinwit = [CTxInWitness()]\n+        tx.wit.vtxinwit[0].scriptWitness.stack = [CScript([OP_NOP] * 390000)]",
      "path": "test/functional/p2p_opportunistic_1p1c.py",
      "position": null,
      "original_position": 51,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "in_reply_to_id": 2157759381,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "Nice, took suggestion and moved the helper into mempool_util",
      "created_at": "2025-06-23T18:47:02Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162324644",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162324644"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 398,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162325631",
      "pull_request_review_id": 2951201583,
      "id": 2162325631,
      "node_id": "PRRC_kwDOABII586A4nh_",
      "diff_hunk": "@@ -83,373 +174,487 @@ class TxOrphanageImpl final : public TxOrphanage {\n     void AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng) override;\n     bool HaveTxToReconsider(NodeId peer) override;\n     std::vector<CTransactionRef> GetChildrenFromSamePeer(const CTransactionRef& parent, NodeId nodeid) const override;\n-    size_t Size() const override { return m_orphans.size(); }\n+    size_t Size() const override { return m_unique_orphans; }\n     std::vector<OrphanTxBase> GetOrphanTransactions() const override;\n-    int64_t TotalOrphanUsage() const override { return m_total_orphan_usage; }\n-    int64_t UsageByPeer(NodeId peer) const override;\n+    TxOrphanage::Usage TotalOrphanUsage() const override;\n+    TxOrphanage::Usage UsageByPeer(NodeId peer) const override;\n     void SanityCheck() const override;\n };\n \n-bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+template<typename Tag>\n+void TxOrphanageImpl::Erase(Iter<Tag> it)\n {\n-    const Txid& hash = tx->GetHash();\n-    const Wtxid& wtxid = tx->GetWitnessHash();\n-    if (auto it{m_orphans.find(wtxid)}; it != m_orphans.end()) {\n-        AddAnnouncer(wtxid, peer);\n-        // No new orphan entry was created. An announcer may have been added.\n-        return false;\n+    // Update m_peer_orphanage_info and clean up entries if they point to an empty struct.\n+    // This means peers that are not storing any orphans do not have an entry in\n+    // m_peer_orphanage_info (they can be added back later if they announce another orphan) and\n+    // ensures disconnected peers are not tracked forever.\n+    auto peer_it = m_peer_orphanage_info.find(it->m_announcer);\n+    Assume(peer_it != m_peer_orphanage_info.end());\n+    if (peer_it->second.Subtract(*it)) m_peer_orphanage_info.erase(peer_it);\n+\n+    if (IsUnique(m_orphans.project<ByWtxid>(it))) {\n+        m_unique_orphans -= 1;\n+        m_unique_orphan_bytes -= it->GetUsage();\n+\n+        // Remove references in m_outpoint_to_orphan_it\n+        const auto& wtxid{it->m_tx->GetWitnessHash()};\n+        for (const auto& input : it->m_tx->vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                it_prev->second.erase(wtxid);\n+                // Clean up keys if they point to an empty set.\n+                if (it_prev->second.empty()) {\n+                    m_outpoint_to_orphan_it.erase(it_prev);\n+                }\n+            }\n+        }\n     }\n+    m_orphans.get<Tag>().erase(it);\n+}\n \n-    // Ignore big transactions, to avoid a\n-    // send-big-orphans memory exhaustion attack. If a peer has a legitimate\n-    // large transaction with a missing parent then we assume\n-    // it will rebroadcast it later, after the parent transaction(s)\n-    // have been mined or received.\n-    // 100 orphans, each of which is at most 100,000 bytes big is\n-    // at most 10 megabytes of orphans and somewhat more byprev index (in the worst case):\n-    unsigned int sz = GetTransactionWeight(*tx);\n-    if (sz > MAX_STANDARD_TX_WEIGHT)\n-    {\n-        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, hash.ToString(), wtxid.ToString());\n+bool TxOrphanageImpl::IsUnique(Iter<ByWtxid> it) const\n+{\n+    // Iterators ByWtxid are sorted by wtxid, so check if neighboring elements have the same wtxid.\n+    auto& index = m_orphans.get<ByWtxid>();\n+    if (it == index.end()) return false;\n+    if (std::next(it) != index.end() && std::next(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    if (it != index.begin() && std::prev(it)->m_tx->GetWitnessHash() == it->m_tx->GetWitnessHash()) return false;\n+    return true;\n+}\n+\n+TxOrphanage::Usage TxOrphanageImpl::UsageByPeer(NodeId peer) const\n+{\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+/** Number of announcements. Ones for the same wtxid are not de-duplicated, use CountUniqueOrphans() instead. */\n+TxOrphanage::Count TxOrphanageImpl::CountAnnouncements() const { return m_orphans.size(); }\n+\n+/** Total number of bytes used by orphans, de-duplicated by wtxid. */\n+TxOrphanage::Usage TxOrphanageImpl::TotalOrphanUsage() const { return m_unique_orphan_bytes; }\n+\n+/** Number of unique orphans. */\n+TxOrphanage::Count TxOrphanageImpl::CountUniqueOrphans() const { return m_unique_orphans; }\n+\n+/** Number of orphans stored from this peer. */\n+TxOrphanage::Count TxOrphanageImpl::AnnouncementsFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_count_announcements;\n+}\n+\n+/** Total usage of orphans from this peer */\n+TxOrphanage::Usage TxOrphanageImpl::UsageFromPeer(NodeId peer) const {\n+    auto it = m_peer_orphanage_info.find(peer);\n+    return it == m_peer_orphanage_info.end() ? 0 : it->second.m_total_usage;\n+}\n+\n+bool TxOrphanageImpl::AddTx(const CTransactionRef& tx, NodeId peer)\n+{\n+    const auto& wtxid{tx->GetWitnessHash()};\n+    const auto& txid{tx->GetHash()};\n+\n+    // Ignore transactions above max standard size to avoid a send-big-orphans memory exhaustion attack.\n+    TxOrphanage::Usage sz = GetTransactionWeight(*tx);\n+    if (sz > MAX_STANDARD_TX_WEIGHT) {\n+        LogDebug(BCLog::TXPACKAGES, \"ignoring large orphan tx (size: %u, txid: %s, wtxid: %s)\\n\", sz, txid.ToString(), wtxid.ToString());\n         return false;\n     }\n \n-    auto ret = m_orphans.emplace(wtxid, OrphanTx{{tx, {peer}}, Now<NodeSeconds>() + ORPHAN_TX_EXPIRE_TIME, m_orphan_list.size()});\n-    assert(ret.second);\n-    m_orphan_list.push_back(ret.first);\n-    for (const CTxIn& txin : tx->vin) {\n-        m_outpoint_to_orphan_it[txin.prevout].insert(ret.first);\n-    }\n-    m_total_orphan_usage += sz;\n-    m_total_announcements += 1;\n+    // We will return false if the tx already exists under a different peer.\n+    const bool brand_new{!HaveTx(wtxid)};\n+\n+    auto ret = m_orphans.get<ByWtxid>().emplace(tx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n     auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-    peer_info.m_total_usage += sz;\n+    peer_info.Add(*ret.first);\n \n-    LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\", hash.ToString(), wtxid.ToString(), sz,\n-             m_orphans.size(), m_outpoint_to_orphan_it.size());\n-    return true;\n+    // Add links in m_outpoint_to_orphan_it\n+    if (brand_new) {\n+        for (const auto& input : tx->vin) {\n+            auto& wtxids_for_prevout = m_outpoint_to_orphan_it.try_emplace(input.prevout).first->second;\n+            wtxids_for_prevout.emplace(wtxid);\n+        }\n+\n+        m_unique_orphans += 1;\n+        m_unique_orphan_bytes += ret.first->GetUsage();\n+\n+        LogDebug(BCLog::TXPACKAGES, \"stored orphan tx %s (wtxid=%s), weight: %u (mapsz %u outsz %u)\\n\",\n+                    txid.ToString(), wtxid.ToString(), sz, m_orphans.size(), m_outpoint_to_orphan_it.size());\n+        Assume(IsUnique(ret.first));\n+    } else {\n+        LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                    peer, txid.ToString(), wtxid.ToString());\n+        Assume(!IsUnique(ret.first));\n+    }\n+    return brand_new;\n }\n \n bool TxOrphanageImpl::AddAnnouncer(const Wtxid& wtxid, NodeId peer)\n {\n-    const auto it = m_orphans.find(wtxid);\n-    if (it != m_orphans.end()) {\n-        Assume(!it->second.announcers.empty());\n-        const auto ret = it->second.announcers.insert(peer);\n-        if (ret.second) {\n-            auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n-            peer_info.m_total_usage += it->second.GetUsage();\n-            m_total_announcements += 1;\n-            LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s\\n\", peer, wtxid.ToString());\n-            return true;\n-        }\n-    }\n-    return false;\n+    auto it = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+\n+    // Do nothing if this transaction isn't already present. We can't create an entry if we don't\n+    // have the tx data.\n+    if (it == m_orphans.end()) return false;\n+    if (it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    // Add another announcement, copying the CTransactionRef from one that already exists.\n+    const auto& ptx = it->m_tx;\n+    auto ret = m_orphans.get<ByWtxid>().emplace(ptx, peer, m_current_sequence);\n+    // If the announcement (same wtxid, same peer) already exists, emplacement fails. Return false.\n+    if (!ret.second) return false;\n+\n+    ++m_current_sequence;\n+    auto& peer_info = m_peer_orphanage_info.try_emplace(peer).first->second;\n+    peer_info.Add(*ret.first);\n+\n+    const auto& txid = ptx->GetHash();\n+    LogDebug(BCLog::TXPACKAGES, \"added peer=%d as announcer of orphan tx %s (wtxid=%s)\\n\",\n+                peer, txid.ToString(), wtxid.ToString());\n+\n+    Assume(!IsUnique(ret.first));\n+    return true;\n }\n \n bool TxOrphanageImpl::EraseTx(const Wtxid& wtxid)\n {\n-    std::map<Wtxid, OrphanTx>::iterator it = m_orphans.find(wtxid);\n-    if (it == m_orphans.end())\n-        return false;\n-    for (const CTxIn& txin : it->second.tx->vin)\n-    {\n-        auto itPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-        if (itPrev == m_outpoint_to_orphan_it.end())\n-            continue;\n-        itPrev->second.erase(it);\n-        if (itPrev->second.empty())\n-            m_outpoint_to_orphan_it.erase(itPrev);\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n+\n+    auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it == index_by_wtxid.end() || it->m_tx->GetWitnessHash() != wtxid) return false;\n+\n+    auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+    unsigned int num_ann{0};\n+    const auto& txid = it->m_tx->GetHash();\n+    while (it != it_end) {\n+        Assume(it->m_tx->GetWitnessHash() == wtxid);\n+        Erase<ByWtxid>(it++);\n+        num_ann += 1;\n     }\n \n-    const auto tx_size{it->second.GetUsage()};\n-    m_total_orphan_usage -= tx_size;\n-    m_total_announcements -= it->second.announcers.size();\n-    // Decrement each announcer's m_total_usage\n-    for (const auto& peer : it->second.announcers) {\n-        auto peer_it = m_peer_orphanage_info.find(peer);\n-        if (Assume(peer_it != m_peer_orphanage_info.end())) {\n-            peer_it->second.m_total_usage -= tx_size;\n-        }\n-    }\n+    LogDebug(BCLog::TXPACKAGES, \"removed orphan tx %s (wtxid=%s) (%u announcements)\\n\", txid.ToString(), wtxid.ToString(), num_ann);\n \n-    size_t old_pos = it->second.list_pos;\n-    assert(m_orphan_list[old_pos] == it);\n-    if (old_pos + 1 != m_orphan_list.size()) {\n-        // Unless we're deleting the last entry in m_orphan_list, move the last\n-        // entry to the position we're deleting.\n-        auto it_last = m_orphan_list.back();\n-        m_orphan_list[old_pos] = it_last;\n-        it_last->second.list_pos = old_pos;\n-    }\n-    const auto& txid = it->second.tx->GetHash();\n-    // Time spent in orphanage = difference between current and entry time.\n-    // Entry time is equal to ORPHAN_TX_EXPIRE_TIME earlier than entry's expiry.\n-    LogDebug(BCLog::TXPACKAGES, \"   removed orphan tx %s (wtxid=%s) after %ds\\n\", txid.ToString(), wtxid.ToString(),\n-             Ticks<std::chrono::seconds>(NodeClock::now() + ORPHAN_TX_EXPIRE_TIME - it->second.nTimeExpire));\n-    m_orphan_list.pop_back();\n-\n-    m_orphans.erase(it);\n     return true;\n }\n \n+/** Erase all entries by this peer. */\n void TxOrphanageImpl::EraseForPeer(NodeId peer)\n {\n-    // Zeroes out this peer's m_total_usage.\n-    m_peer_orphanage_info.erase(peer);\n-\n-    int nErased = 0;\n-    std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-    while (iter != m_orphans.end())\n-    {\n-        // increment to avoid iterator becoming invalid after erasure\n-        auto& [wtxid, orphan] = *iter++;\n-        auto orphan_it = orphan.announcers.find(peer);\n-        if (orphan_it != orphan.announcers.end()) {\n-            orphan.announcers.erase(peer);\n-            m_total_announcements -= 1;\n-\n-            // No remaining announcers: clean up entry\n-            if (orphan.announcers.empty()) {\n-                nErased += EraseTx(orphan.tx->GetWitnessHash());\n-            }\n-        }\n+    auto& index_by_peer = m_orphans.get<ByPeer>();\n+    auto it = index_by_peer.lower_bound(ByPeerView{peer, false, 0});\n+    if (it == index_by_peer.end() || it->m_announcer != peer) return;\n+\n+    unsigned int num_ann{0};\n+    while (it != index_by_peer.end() && it->m_announcer == peer) {\n+        // Delete item, cleaning up m_outpoint_to_orphan_it iff this entry is unique by wtxid.\n+        Erase<ByPeer>(it++);\n+        num_ann += 1;\n     }\n-    if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", nErased, peer);\n+    Assume(!m_peer_orphanage_info.contains(peer));\n+\n+    if (num_ann > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) from peer=%d\\n\", num_ann, peer);\n }\n \n+/** If the data structure needs trimming, evicts announcements by selecting the DoSiest peer and evicting its oldest\n+ * announcement (sorting non-reconsiderable orphans first, to give reconsiderable orphans a greater chance of being\n+ * processed). Does nothing if no global limits are exceeded.  This eviction strategy effectively \"reserves\" an\n+ * amount of announcements and space for each peer. The reserved amount is protected from eviction even if there\n+ * are peers spamming the orphanage.\n+ */\n void TxOrphanageImpl::LimitOrphans(FastRandomContext& rng)\n {\n-    unsigned int nEvicted = 0;\n-    auto nNow{Now<NodeSeconds>()};\n-    if (m_next_sweep <= nNow) {\n-        // Sweep out expired orphan pool entries:\n-        int nErased = 0;\n-        auto nMinExpTime{nNow + ORPHAN_TX_EXPIRE_TIME - ORPHAN_TX_EXPIRE_INTERVAL};\n-        std::map<Wtxid, OrphanTx>::iterator iter = m_orphans.begin();\n-        while (iter != m_orphans.end())\n-        {\n-            std::map<Wtxid, OrphanTx>::iterator maybeErase = iter++;\n-            if (maybeErase->second.nTimeExpire <= nNow) {\n-                nErased += EraseTx(maybeErase->first);\n-            } else {\n-                nMinExpTime = std::min(maybeErase->second.nTimeExpire, nMinExpTime);\n-            }\n+    if (!NeedsTrim()) return;\n+\n+    const auto original_unique_txns{CountUniqueOrphans()};\n+\n+    // Even though it's possible for MaxPeerAnnouncements to increase within this call to LimitOrphans\n+    // (e.g. if a peer's orphans are removed entirely, changing the number of peers), use consistent limits throughout.\n+    const auto max_ann{MaxPeerAnnouncements()};\n+    const auto max_mem{ReservedPeerUsage()};\n+\n+    // We have exceeded the global limit(s). Now, identify who is using too much and evict their orphans.\n+    // Create a heap of pairs (NodeId, DoS score), sorted by descending DoS score.\n+    std::vector<std::pair<NodeId, FeeFrac>> heap_peer_dos;\n+    heap_peer_dos.reserve(m_peer_orphanage_info.size());\n+    for (const auto& [nodeid, entry] : m_peer_orphanage_info) {\n+        // Performance optimization: only consider peers with a DoS score >= 1.\n+        if (entry.GetDosScore(max_ann, max_mem) >= FeeFrac{1, 1}) {\n+            heap_peer_dos.emplace_back(nodeid, entry.GetDosScore(max_ann, max_mem));\n         }\n-        // Sweep again 5 minutes after the next entry that expires in order to batch the linear scan.\n-        m_next_sweep = nMinExpTime + ORPHAN_TX_EXPIRE_INTERVAL;\n-        if (nErased > 0) LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan tx due to expiration\\n\", nErased);\n-    }\n-    while (m_orphans.size() > DEFAULT_MAX_ORPHAN_TRANSACTIONS)\n-    {\n-        // Evict a random orphan:\n-        size_t randompos = rng.randrange(m_orphan_list.size());\n-        EraseTx(m_orphan_list[randompos]->first);\n-        ++nEvicted;\n     }\n-    if (nEvicted > 0) LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx\\n\", nEvicted);\n+    static constexpr auto compare_score = [](const auto& left, const auto& right) { return left.second < right.second; };\n+    std::make_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+\n+    unsigned int num_erased{0};\n+    // This outer loop finds the peer with the highest DoS score, which is a fraction of {usage, announcements} used\n+    // over the respective allowances. We continue until the orphanage is within global limits. That means some peers\n+    // might still have a DoS score > 1 at the end.\n+    // Note: if ratios are the same, FeeFrac tiebreaks by denominator. In practice, since the CPU denominator (number of\n+    // announcements) is always lower, this means that a peer with only high number of announcements will be targeted\n+    // before a peer using a lot of memory, even if they have the same ratios.\n+    do {\n+        Assume(!heap_peer_dos.empty());\n+        // This is a max-heap, so the worst peer is at the front. pop_heap()\n+        // moves it to the back, and the next worst peer is moved to the front.\n+        std::pop_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        const auto [worst_peer, dos_score] = std::move(heap_peer_dos.back());\n+        heap_peer_dos.pop_back();\n+\n+        // If needs trim, then at least one peer has a DoS score higher than 1.\n+        Assume(dos_score.fee > dos_score.size);\n+\n+        auto it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+\n+        // This inner loop trims until this peer is no longer the DoSiest one or has a score within 1. The score 1 is\n+        // just a conservative fallback: once the last peer goes below ratio 1, NeedsTrim() will return false anyway.\n+        // We evict the oldest announcement(s) from this peer, sorting non-reconsiderable before reconsiderable.\n+        // The number of inner loop iterations is bounded by the total number of announcements.\n+        const auto& dos_threshold = heap_peer_dos.empty() ? FeeFrac{1, 1} : heap_peer_dos.front().second;\n+        auto it_ann = m_orphans.get<ByPeer>().lower_bound(ByPeerView{worst_peer, false, 0});\n+        while (NeedsTrim()) {\n+            if (!Assume(it_ann->m_announcer == worst_peer)) break;\n+            Erase<ByPeer>(it_ann++);\n+            num_erased += 1;\n+\n+            // If we erased the last orphan from this peer, it_worst_peer will be invalidated.\n+            it_worst_peer = m_peer_orphanage_info.find(worst_peer);\n+            if (it_worst_peer == m_peer_orphanage_info.end() || it_worst_peer->second.GetDosScore(max_ann, max_mem) < dos_threshold) break;\n+        }\n+\n+        if (!NeedsTrim()) break;\n+\n+        // Unless this peer is empty, put it back in the heap so we continue to consider evicting its orphans.\n+        // We may select this peer for evictions again if there are multiple DoSy peers.\n+        if (it_worst_peer != m_peer_orphanage_info.end() && it_worst_peer->second.m_count_announcements > 0) {\n+            heap_peer_dos.emplace_back(worst_peer, it_worst_peer->second.GetDosScore(max_ann, max_mem));\n+            std::push_heap(heap_peer_dos.begin(), heap_peer_dos.end(), compare_score);\n+        }\n+    } while (true);\n+\n+    const auto remaining_unique_orphans{CountUniqueOrphans()};\n+    LogDebug(BCLog::TXPACKAGES, \"orphanage overflow, removed %u tx (%u announcements)\\n\", original_unique_txns - remaining_unique_orphans, num_erased);\n }\n \n void TxOrphanageImpl::AddChildrenToWorkSet(const CTransaction& tx, FastRandomContext& rng)\n {\n+    auto& index_by_wtxid = m_orphans.get<ByWtxid>();\n     for (unsigned int i = 0; i < tx.vout.size(); i++) {\n         const auto it_by_prev = m_outpoint_to_orphan_it.find(COutPoint(tx.GetHash(), i));\n         if (it_by_prev != m_outpoint_to_orphan_it.end()) {\n-            for (const auto& elem : it_by_prev->second) {\n-                // Belt and suspenders, each orphan should always have at least 1 announcer.\n-                if (!Assume(!elem->second.announcers.empty())) continue;\n+            for (const auto& wtxid : it_by_prev->second) {\n+                // Belt and suspenders, each entry in m_outpoint_to_orphan_it should always have at least 1 announcement.\n+                auto it = index_by_wtxid.lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+                if (!Assume(it != index_by_wtxid.end())) continue;\n \n                 // Select a random peer to assign orphan processing, reducing wasted work if the orphan is still missing\n                 // inputs. However, we don't want to create an issue in which the assigned peer can purposefully stop us\n                 // from processing the orphan by disconnecting.\n-                auto announcer_iter = std::begin(elem->second.announcers);\n-                std::advance(announcer_iter, rng.randrange(elem->second.announcers.size()));\n-                auto announcer = *(announcer_iter);\n-\n-                // Get this source peer's work set, emplacing an empty set if it didn't exist\n-                // (note: if this peer wasn't still connected, we would have removed the orphan tx already)\n-                std::set<Wtxid>& orphan_work_set = m_peer_orphanage_info.try_emplace(announcer).first->second.m_work_set;\n-                // Add this tx to the work set\n-                orphan_work_set.insert(elem->first);\n+                auto it_end = index_by_wtxid.upper_bound(ByWtxidView{wtxid, MAX_PEER});\n+                const auto num_announcers{std::distance(it, it_end)};\n+                if (!Assume(num_announcers > 0)) continue;\n+                std::advance(it, rng.randrange(num_announcers));\n+\n+                if (!Assume(it->m_tx->GetWitnessHash() == wtxid)) break;\n+\n+                // Mark this orphan as ready to be reconsidered.\n+                static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = true; };\n+                m_orphans.get<ByWtxid>().modify(it, mark_reconsidered_modifier);\n+\n                 LogDebug(BCLog::TXPACKAGES, \"added %s (wtxid=%s) to peer %d workset\\n\",\n-                         tx.GetHash().ToString(), tx.GetWitnessHash().ToString(), announcer);\n+                            it->m_tx->GetHash().ToString(), it->m_tx->GetWitnessHash().ToString(), it->m_announcer);\n             }\n         }\n     }\n }\n \n bool TxOrphanageImpl::HaveTx(const Wtxid& wtxid) const\n {\n-    return m_orphans.count(wtxid);\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    return it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid;\n }\n \n CTransactionRef TxOrphanageImpl::GetTx(const Wtxid& wtxid) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return it != m_orphans.end() ? it->second.tx : nullptr;\n+    auto it_lower = m_orphans.get<ByWtxid>().lower_bound(ByWtxidView{wtxid, MIN_PEER});\n+    if (it_lower != m_orphans.end() && it_lower->m_tx->GetWitnessHash() == wtxid) return it_lower->m_tx;\n+    return nullptr;\n }\n \n-\n bool TxOrphanageImpl::HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const\n {\n-    auto it = m_orphans.find(wtxid);\n-    return (it != m_orphans.end() && it->second.announcers.contains(peer));\n+    return m_orphans.get<ByWtxid>().count(ByWtxidView{wtxid, peer}) > 0;\n }\n \n+/** If there is a tx that can be reconsidered, return it and set it back to\n+ * non-reconsiderable. Otherwise, return a nullptr. */\n CTransactionRef TxOrphanageImpl::GetTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return nullptr;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    while (!work_set.empty()) {\n-        Wtxid wtxid = *work_set.begin();\n-        work_set.erase(work_set.begin());\n-\n-        const auto orphan_it = m_orphans.find(wtxid);\n-        if (orphan_it != m_orphans.end()) {\n-            return orphan_it->second.tx;\n-        }\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    if (it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider) {\n+        // Flip m_reconsider. Even if this transaction stays in orphanage, it shouldn't be\n+        // reconsidered again until there is a new reason to do so.\n+        static constexpr auto mark_reconsidered_modifier = [](auto& ann) { ann.m_reconsider = false; };\n+        m_orphans.get<ByPeer>().modify(it, mark_reconsidered_modifier);\n+        return it->m_tx;\n     }\n     return nullptr;\n }\n \n+/** Return whether there is a tx that can be reconsidered. */\n bool TxOrphanageImpl::HaveTxToReconsider(NodeId peer)\n {\n-    auto peer_it = m_peer_orphanage_info.find(peer);\n-    if (peer_it == m_peer_orphanage_info.end()) return false;\n-\n-    auto& work_set = peer_it->second.m_work_set;\n-    return !work_set.empty();\n+    auto it = m_orphans.get<ByPeer>().lower_bound(ByPeerView{peer, true, 0});\n+    return it != m_orphans.get<ByPeer>().end() && it->m_announcer == peer && it->m_reconsider;\n }\n-\n void TxOrphanageImpl::EraseForBlock(const CBlock& block)\n {\n-    std::vector<Wtxid> vOrphanErase;\n-\n+    std::set<Wtxid> wtxids_to_erase;\n     for (const CTransactionRef& ptx : block.vtx) {\n-        const CTransaction& tx = *ptx;\n+        const CTransaction& block_tx = *ptx;\n \n         // Which orphan pool entries must we evict?\n-        for (const auto& txin : tx.vin) {\n-            auto itByPrev = m_outpoint_to_orphan_it.find(txin.prevout);\n-            if (itByPrev == m_outpoint_to_orphan_it.end()) continue;\n-            for (auto mi = itByPrev->second.begin(); mi != itByPrev->second.end(); ++mi) {\n-                const CTransaction& orphanTx = *(*mi)->second.tx;\n-                vOrphanErase.push_back(orphanTx.GetWitnessHash());\n+        for (const auto& input : block_tx.vin) {\n+            auto it_prev = m_outpoint_to_orphan_it.find(input.prevout);\n+            if (it_prev != m_outpoint_to_orphan_it.end()) {\n+                // Copy all wtxids to wtxids_to_erase.\n+                std::copy(it_prev->second.cbegin(), it_prev->second.cend(), std::inserter(wtxids_to_erase, wtxids_to_erase.end()));\n             }\n         }\n     }\n \n-    // Erase orphan transactions included or precluded by this block\n-    if (vOrphanErase.size()) {\n-        int nErased = 0;\n-        for (const auto& orphanHash : vOrphanErase) {\n-            nErased += EraseTx(orphanHash);\n-        }\n-        LogDebug(BCLog::TXPACKAGES, \"Erased %d orphan transaction(s) included or conflicted by block\\n\", nErased);\n+    unsigned int num_erased{0};\n+    for (const auto& wtxid : wtxids_to_erase) {\n+        num_erased += EraseTx(wtxid);",
      "path": "src/node/txorphanage.cpp",
      "position": null,
      "original_position": 745,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a1bdebf370bf2fc43c0204ca2d6291e73fc7f91f",
      "in_reply_to_id": 2157778964,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "taken",
      "created_at": "2025-06-23T18:47:31Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162325631",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162325631"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 531,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162325701",
      "pull_request_review_id": 2951201583,
      "id": 2162325701,
      "node_id": "PRRC_kwDOABII586A4njF",
      "diff_hunk": "@@ -16,31 +16,45 @@\n #include <set>\n \n namespace node {\n-/** Expiration time for orphan transactions */\n-static constexpr auto ORPHAN_TX_EXPIRE_TIME{20min};\n-/** Minimum time between orphan transactions expire time checks */\n-static constexpr auto ORPHAN_TX_EXPIRE_INTERVAL{5min};\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{100};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId MIN_PEER{std::numeric_limits<NodeId>::min()};\n+/** Maximum NodeId for upper_bound lookups. */\n+static constexpr NodeId MAX_PEER{std::numeric_limits<NodeId>::max()};\n /** Default maximum number of orphan transactions kept in memory */\n static const uint32_t DEFAULT_MAX_ORPHAN_TRANSACTIONS{100};\n \n /** A class to track orphan transactions (failed on TX_MISSING_INPUTS)\n- * Since we cannot distinguish orphans from bad transactions with\n- * non-existent inputs, we heavily limit the number of orphans\n- * we keep and the duration we keep them for.\n+ * Since we cannot distinguish orphans from bad transactions with non-existent inputs, we heavily limit the amount of\n+ * announcements (unique (NodeId, tx) pairs). We also try to prevent adversaries churning this data structure: when",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 24,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "a1bdebf370bf2fc43c0204ca2d6291e73fc7f91f",
      "in_reply_to_id": 2157779831,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "taken",
      "created_at": "2025-06-23T18:47:34Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162325701",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162325701"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 32,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162326378",
      "pull_request_review_id": 2951201583,
      "id": 2162326378,
      "node_id": "PRRC_kwDOABII586A4ntq",
      "diff_hunk": "@@ -0,0 +1,154 @@\n+// Copyright (c) 2021-2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_NODE_TXORPHANAGE_H\n+#define BITCOIN_NODE_TXORPHANAGE_H\n+\n+#include <consensus/validation.h>\n+#include <net.h>\n+#include <primitives/block.h>\n+#include <primitives/transaction.h>\n+#include <sync.h>\n+#include <util/time.h>\n+\n+#include <map>\n+#include <set>\n+\n+namespace node {\n+/** Default value for TxOrphanage::m_reserved_usage_per_peer. */\n+static constexpr int64_t DEFAULT_RESERVED_ORPHAN_WEIGHT_PER_PEER{404'000};\n+/** Default value for TxOrphanage::m_max_global_announcements. */\n+static constexpr unsigned int DEFAULT_MAX_ORPHAN_ANNOUNCEMENTS{3000};\n+/** Minimum NodeId for lower_bound lookups (in practice, NodeIds start at 0). */\n+static constexpr NodeId MIN_PEER{std::numeric_limits<NodeId>::min()};\n+/** Maximum NodeId for upper_bound lookups. */\n+static constexpr NodeId MAX_PEER{std::numeric_limits<NodeId>::max()};\n+\n+/** A class to track orphan transactions (failed on TX_MISSING_INPUTS)\n+ * Since we cannot distinguish orphans from bad transactions with non-existent inputs, we heavily limit the amount of\n+ * announcements (unique (NodeId, tx) pairs). We also try to prevent adversaries churning this data structure: when\n+ * global limits are reached, we continuously evict the oldest announcement (sorting non-reconsiderable orphans before\n+ * reconsiderable ones) from the most resource-intensive peer until we are back within limits.\n+ * - Peers can exceed their individual limits (e.g. because they are very useful transaction relay peers) as long as the\n+ *   global limits are not exceeded.\n+ * - As long as the orphan has 1 announcer, it remains in the orphanage.\n+ * - No peer can trigger the eviction of another peer's orphans.\n+ * - Peers' orphans are effectively protected from eviction as long as they don't exceed their limits.\n+ * Not thread-safe. Requires external synchronization.\n+ */\n+class TxOrphanage {\n+public:\n+    using Usage = int64_t;\n+    using Count = unsigned int;\n+\n+    /** Allows providing orphan information externally */\n+    struct OrphanTxBase {\n+        CTransactionRef tx;\n+        /** Peers added with AddTx or AddAnnouncer. */\n+        std::set<NodeId> announcers;\n+\n+        // Constructor with moved announcers\n+        OrphanTxBase(CTransactionRef tx, std::set<NodeId>&& announcers) :\n+            tx(std::move(tx)),\n+            announcers(std::move(announcers))\n+        {}\n+    };\n+\n+    virtual ~TxOrphanage() = default;\n+\n+    /** Add a new orphan transaction */\n+    virtual bool AddTx(const CTransactionRef& tx, NodeId peer) = 0;\n+\n+    /** Add an additional announcer to an orphan if it exists. Otherwise, do nothing. */\n+    virtual bool AddAnnouncer(const Wtxid& wtxid, NodeId peer) = 0;\n+\n+    /** Get a transaction by its witness txid */\n+    virtual CTransactionRef GetTx(const Wtxid& wtxid) const = 0;\n+\n+    /** Check if we already have an orphan transaction (by wtxid only) */\n+    virtual bool HaveTx(const Wtxid& wtxid) const = 0;\n+\n+    /** Check if a {tx, peer} exists in the orphanage.*/\n+    virtual bool HaveTxFromPeer(const Wtxid& wtxid, NodeId peer) const = 0;\n+\n+    /** Extract a transaction from a peer's work set, and flip it back to non-reconsiderable.\n+     *  Returns nullptr if there are no transactions to work on.\n+     *  Otherwise returns the transaction reference, and removes\n+     *  it from the work set.\n+     */\n+    virtual CTransactionRef GetTxToReconsider(NodeId peer) = 0;\n+\n+    /** Erase an orphan by wtxid, including all announcements if there are multiple.\n+     * Returns true if an orphan was erased, false if no tx with this wtxid exists. */\n+    virtual bool EraseTx(const Wtxid& wtxid) = 0;\n+\n+    /** Maybe erase all orphans announced by a peer (eg, after that peer disconnects). If an orphan\n+     * has been announced by another peer, don't erase, just remove this peer from the list of announcers. */\n+    virtual void EraseForPeer(NodeId peer) = 0;\n+\n+    /** Erase all orphans included in or invalidated by a new block */\n+    virtual void EraseForBlock(const CBlock& block) = 0;\n+\n+    /** Limit the orphanage to DEFAULT_MAX_ORPHAN_TRANSACTIONS. */",
      "path": "src/node/txorphanage.h",
      "position": null,
      "original_position": 93,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "d4b787b25f07b212bedb26433e64378673a27f6a",
      "in_reply_to_id": 2157096794,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "good catch, fixed the doc in the main commit",
      "created_at": "2025-06-23T18:48:02Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162326378",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162326378"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": null,
      "original_line": 93,
      "side": "RIGHT"
    },
    {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162326495",
      "pull_request_review_id": 2951201583,
      "id": 2162326495,
      "node_id": "PRRC_kwDOABII586A4nvf",
      "diff_hunk": "@@ -233,3 +234,168 @@ FUZZ_TARGET(txorphan, .init = initialize_orphanage)\n     }\n     orphanage->SanityCheck();\n }\n+\n+FUZZ_TARGET(txorphan_protected, .init = initialize_orphanage)\n+{\n+    FuzzedDataProvider fuzzed_data_provider(buffer.data(), buffer.size());\n+    FastRandomContext orphanage_rng{/*fDeterministic=*/true};\n+    SetMockTime(ConsumeTime(fuzzed_data_provider));\n+\n+    // We have num_peers, of which Peer==0 is the \"honest\" one\n+    // who will never exceed their reserved weight or announcement\n+    // count, and should therefore never be evicted.\n+    const unsigned int MAX_PEERS = 125;\n+    const unsigned int num_peers = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(1, MAX_PEERS);\n+    // Generate a vector of bools for whether each peer is protected from eviction\n+    std::bitset<MAX_PEERS> protected_peers;\n+    for (unsigned int i = 0; i < num_peers; i++) {\n+        protected_peers.set(i, fuzzed_data_provider.ConsumeBool());\n+    }\n+\n+    // Params for orphanage.\n+    const unsigned int global_announcement_limit = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(num_peers, 6'000);\n+    const int64_t per_peer_weight_reservation = fuzzed_data_provider.ConsumeIntegralInRange<int64_t>(1, 4'040'000);\n+    auto orphanage = node::MakeTxOrphanage(global_announcement_limit, per_peer_weight_reservation);\n+\n+    // The actual limit, MaxPeerAnnouncements(), may be higher, since TxOrphanage only counts peers\n+    // that have announced an orphan. The honest peer will not experience evictions if it never\n+    // exceeds this.\n+    const unsigned int honest_ann_limit = global_announcement_limit / num_peers;\n+    // Honest peer will not experience evictions if it never exceeds this.\n+    const int64_t honest_mem_limit = per_peer_weight_reservation;\n+\n+    std::vector<COutPoint> outpoints; // Duplicates are tolerated\n+    outpoints.reserve(400);\n+\n+    // initial outpoints used to construct transactions later\n+    for (uint8_t i = 0; i < 4; i++) {\n+        outpoints.emplace_back(Txid::FromUint256(uint256{i}), 0);\n+    }\n+\n+    // These are honest peer's live announcements. We expect them to be protected from eviction.\n+    std::set<Wtxid> protected_wtxids;\n+\n+    LIMITED_WHILE(outpoints.size() < 400 && fuzzed_data_provider.ConsumeBool(), 1000)\n+    {\n+        // construct transaction\n+        const CTransactionRef tx = [&] {\n+            CMutableTransaction tx_mut;\n+            const auto num_in = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, outpoints.size());\n+            const auto num_out = fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(1, 256);\n+            // pick outpoints from outpoints as input. We allow input duplicates on purpose, given we are not\n+            // running any transaction validation logic before adding transactions to the orphanage\n+            tx_mut.vin.reserve(num_in);\n+            for (uint32_t i = 0; i < num_in; i++) {\n+                auto& prevout = PickValue(fuzzed_data_provider, outpoints);\n+                // try making transactions unique by setting a random nSequence, but allow duplicate transactions if they happen\n+                tx_mut.vin.emplace_back(prevout, CScript{}, fuzzed_data_provider.ConsumeIntegralInRange<uint32_t>(0, CTxIn::SEQUENCE_FINAL));\n+            }\n+            // output amount or spendability will not affect txorphanage\n+            tx_mut.vout.reserve(num_out);\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                const auto payload_size = fuzzed_data_provider.ConsumeIntegralInRange<unsigned int>(0, 100000);\n+                if (payload_size) {\n+                    tx_mut.vout.emplace_back(0, CScript() << OP_RETURN << std::vector<unsigned char>(payload_size));\n+                } else {\n+                    tx_mut.vout.emplace_back(0, CScript{});\n+                }\n+            }\n+            auto new_tx = MakeTransactionRef(tx_mut);\n+            // add newly constructed outpoints to the coin pool\n+            for (uint32_t i = 0; i < num_out; i++) {\n+                outpoints.emplace_back(new_tx->GetHash(), i);\n+            }\n+            return new_tx;\n+        }();\n+\n+        const auto wtxid{tx->GetWitnessHash()};\n+\n+        // orphanage functions\n+        LIMITED_WHILE(fuzzed_data_provider.remaining_bytes(), 10 * global_announcement_limit)\n+        {\n+            NodeId peer_id = fuzzed_data_provider.ConsumeIntegralInRange<NodeId>(0, num_peers - 1);\n+            const auto tx_weight{GetTransactionWeight(*tx)};\n+\n+            // This protected peer will never send orphans that would\n+            // exceed their own personal allotment, so is never evicted.\n+            const bool peer_is_protected{protected_peers[peer_id]};\n+\n+            CallOneOf(\n+                fuzzed_data_provider,\n+                [&] { // AddTx\n+                    bool have_tx_and_peer = orphanage->HaveTxFromPeer(wtxid, peer_id);\n+                    if (peer_is_protected && !have_tx_and_peer &&\n+                        (orphanage->UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                        orphanage->AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                        // We never want our protected peer oversized or over-announced\n+                    } else {\n+                        orphanage->AddTx(tx, peer_id);\n+                        if (peer_is_protected && orphanage->HaveTxFromPeer(wtxid, peer_id)) {\n+                            protected_wtxids.insert(wtxid);\n+                        }\n+                    }\n+                },\n+                [&] { // AddAnnouncer\n+                    bool have_tx_and_peer = orphanage->HaveTxFromPeer(tx->GetWitnessHash(), peer_id);\n+                    // AddAnnouncer should return false if tx doesn't exist or we already HaveTxFromPeer.\n+                    {\n+                        if (peer_is_protected && !have_tx_and_peer &&\n+                            (orphanage->UsageFromPeer(peer_id) + tx_weight > honest_mem_limit ||\n+                            orphanage->AnnouncementsFromPeer(peer_id) + 1 > honest_ann_limit)) {\n+                            // We never want our protected peer oversized\n+                        } else {\n+                            orphanage->AddAnnouncer(tx->GetWitnessHash(), peer_id);\n+                            if (peer_is_protected && orphanage->HaveTxFromPeer(wtxid, peer_id)) {\n+                                protected_wtxids.insert(wtxid);\n+                            }\n+                        }\n+                    }\n+                },\n+                [&] { // EraseTx\n+                    if (protected_wtxids.count(tx->GetWitnessHash())) {\n+                        protected_wtxids.erase(wtxid);\n+                    }\n+                    orphanage->EraseTx(wtxid);\n+                    Assert(!orphanage->HaveTx(wtxid));\n+                },\n+                [&] { // EraseForPeer\n+                    if (!protected_peers[peer_id]) {\n+                        orphanage->EraseForPeer(peer_id);",
      "path": "src/test/fuzz/txorphan.cpp",
      "position": 358,
      "original_position": 138,
      "commit_id": "6093300bfcb9be7f76a662d1bb29dbeec60816a2",
      "original_commit_id": "101c3f9299d776037c9c6a8d1326a9d1310b8911",
      "in_reply_to_id": 2156002563,
      "user": {
        "login": "glozow",
        "id": 25183001,
        "node_id": "MDQ6VXNlcjI1MTgzMDAx",
        "avatar_url": "https://avatars.githubusercontent.com/u/25183001?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/glozow",
        "html_url": "https://github.com/glozow",
        "followers_url": "https://api.github.com/users/glozow/followers",
        "following_url": "https://api.github.com/users/glozow/following%7B/other_user%7D",
        "gists_url": "https://api.github.com/users/glozow/gists%7B/gist_id%7D",
        "starred_url": "https://api.github.com/users/glozow/starred%7B/owner%7D%7B/repo%7D",
        "subscriptions_url": "https://api.github.com/users/glozow/subscriptions",
        "organizations_url": "https://api.github.com/users/glozow/orgs",
        "repos_url": "https://api.github.com/users/glozow/repos",
        "events_url": "https://api.github.com/users/glozow/events%7B/privacy%7D",
        "received_events_url": "https://api.github.com/users/glozow/received_events",
        "type": "User",
        "site_admin": false,
        "patch_url": null
      },
      "body": "added",
      "created_at": "2025-06-23T18:48:07Z",
      "updated_at": "2025-06-23T20:07:06Z",
      "html_url": "https://github.com/bitcoin/bitcoin/pull/31829#discussion_r2162326495",
      "author_association": "MEMBER",
      "_links": {
        "self": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/2162326495"
        },
        "pull_request": {
          "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/31829"
        }
      },
      "start_line": null,
      "original_start_line": null,
      "start_side": null,
      "line": 362,
      "original_line": 362,
      "side": "RIGHT"
    }
  ]
}